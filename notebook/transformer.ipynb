{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d7f736-b9af-48e3-adb5-18ab3536abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmasked attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d29dfa4-a1e1-4dd2-b2c5-e3ed8653fbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3, 3])\n",
      "torch.Size([2, 4, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def self_attention(q, k, v):\n",
    "    # if 3 dim: b t d\n",
    "    #prod = Q.bmm(K.permute(0, 2, 1))\n",
    "    # or\n",
    "    # prod = torch.einsum(\"btd, bsd -> bts\", q, k)\n",
    "    # if 4 dim: b t h dh\n",
    "    # q = q.permute(0, 2, 1, 3)\n",
    "    prod = torch.einsum(\"bthd, bshd -> bhts\", q, k)\n",
    "    scaled_prod = prod/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "    softmaxed_prod = F.softmax(scaled_prod, dim=-1)\n",
    "    print(softmaxed_prod.shape)\n",
    "    # print(softmaxed_prod)\n",
    "    return softmaxed_prod @ v.permute(0, 2, 1, 3)\n",
    "\n",
    "\n",
    "x = torch.rand([2, 3, 4, 5])\n",
    "self_attention(x, x, x)\n",
    "self_attention(x, x, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae60133-3d0c-4ada-8789-51107800432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        assert d % h == 0\n",
    "        self.d = d\n",
    "        self.dh = d // h\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(self.d, self.d)\n",
    "        self.wk = nn.Linear(self.d, self.d)\n",
    "        self.wv = nn.Linear(self.d, self.d)\n",
    "        self.wo = nn.Linear(self.d, self.d)\n",
    " \n",
    "    def forward(self, q, k, v):\n",
    "        # b, t, d\n",
    "        b, t, d = q.size()\n",
    "        wq = self.wq(q)\n",
    "        wk = self.wk(k)\n",
    "        wv = self.wv(v)\n",
    "        wq = wq.view(b, t, self.h, self.dh)\n",
    "        wk = wk.view(b, t, self.h, self.dh)\n",
    "        wv = wv.view(b, t, self.h, self.dh)\n",
    "        # b, t, h, dh\n",
    "        # if changing from 4 dim -> 3 dim: b*h, t, dh\n",
    "        # wq = wq.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wk = wk.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wv = wv.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # another option 4 dim -> 3 dim\n",
    "        # wq = wq.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wk = wk.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wv = wv.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # changing the number of dims is not necessary as @ supports 4 dims\n",
    "        attn = self_attention(wq, wk, wv)\n",
    "        # b * h, t, dh\n",
    "        # attn = attn.view(b, self.h, t, self.dh).permute(0, 2, 1, 3).reshape(b, t, d)\n",
    "        attn = attn.view(b, self.h, t, self.dh).transpose(1, 2).contiguous().view(b, t, d)\n",
    "        wo = self.wo(attn)\n",
    "        return wo\n",
    "        # # 1 2 3 4\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # return F.relu(self.conv2(x))\n",
    "\n",
    "mhsa = MHSA()\n",
    "x = torch.rand(2, 3, 512)\n",
    "mhsa(x, x, x).shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abcca093-9e66-4b46-8ec3-aded63ece6f8",
   "metadata": {},
   "source": [
    "class PE1():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # -> d vector\n",
    "    def __call__(self, pos):\n",
    "        pow = torch.pow(10000, torch.arange(0, self.d) / self.d)\n",
    "        return torch.sin(torch.arange(0, self.d) / pow)\n",
    "\n",
    "print(PE1()(1).size()) # torch.Size([512])\n",
    "\n",
    "class PEScalar():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # 1 -> d vector\n",
    "    def __call__(self, pos):\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2)\n",
    "        # b = torch.arange(1, 12, 2)\n",
    "        # torch.stack((a, b), dim=1).view(-1)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1)\n",
    "\n",
    "print(PEScalar()(1).size()) # torch.Size([1, 512])\n",
    "\n",
    "class PEVector():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # 1 -> 1 d\n",
    "    # t 1 -> t d\n",
    "    def __call__(self, pos):\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2).view(-1, 2)\n",
    "        # b = torch.arange(1, 12, 2).view(-1, 2)\n",
    "        # torch.stack((a, b), dim=-1).view(-1, 4)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1, self.d)\n",
    "\n",
    "print(PEVector()(1).size()) # torch.Size([1, 512])\n",
    "print(PEVector()(torch.arange(3).view(-1, 1)).size()) # torch.Size([3, 512])\n",
    "\n",
    "class PE():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # b t 1 -> b t d\n",
    "    def __call__(self, pos):\n",
    "        b, t, _ = pos.size()\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2).view(-1, 2)\n",
    "        # b = torch.arange(1, 12, 2).view(-1, 2)\n",
    "        # torch.stack((a, b), dim=-1).view(-1, 4)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1, t, self.d)\n",
    "\n",
    "print(PE()(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])\n",
    "\n",
    "class PEAnotherImpl():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # b t 1 -> b t d\n",
    "    def __call__(self, pos):\n",
    "        b, t, _ = pos.size()\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        max_len = 1024\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        sin_p = torch.sin(position / pow_)\n",
    "        cos_p = torch.cos(position / pow_)\n",
    "        pe = torch.zeros(max_len, self.d)\n",
    "        pe[:, 0::2] = sin_p\n",
    "        pe[:, 1::2] = cos_p\n",
    "        return pe[:t, :].unsqueeze(0).repeat(b, 1, 1)\n",
    "\n",
    "print(PEAnotherImpl()(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])\n",
    "\n",
    "class PEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        pos = torch.arange(max_len).unsqueeze(1)\n",
    "        print(pos.size())\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        print(sin_p.size())\n",
    "        print(cos_p.size())\n",
    "        pe = torch.stack((sin_p, cos_p), dim=-1).view(-1, self.d) # downside sin, cos don't alternate\n",
    "        print(pe.size())\n",
    "        pe = pe.unsqueeze(0)\n",
    "        print(pe.size())\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.size: b, t, d\n",
    "        x = x + self.pe[:, : t, :]\n",
    "        return self.dropout(x)\n",
    "print(PEModule(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])\n",
    "\n",
    "class PositionalEncodingAnnotatedTransformerModule(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncodingAnnotatedTransformer, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        print(position.size())\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        print(div_term.size())\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        print(pe.size())\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.pe[:, : x.size(1)].size())\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "print(PositionalEncodingAnnotatedTransformerModule(512, 0.1)(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56a9e6b-8461-4417-ab07-e5fbd79c60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4413f3-ef3e-4d04-baad-f49354915c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PE(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        sin_p = torch.sin(position / pow_)\n",
    "        cos_p = torch.cos(position / pow_)\n",
    "        pe = torch.zeros(max_len, self.d, requires_grad=False) # Explicit, register buffer insures requires grad = False\n",
    "        pe[:, 0::2] = sin_p\n",
    "        pe[:, 1::2] = cos_p\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe) \n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.pe[:, : t, :]\n",
    "        return self.dropout(x)\n",
    "print(PE(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd49c59-e4b6-4b7d-9719-79079f2f40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PEEmbed(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.pe = nn.Embedding(max_len, d)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        pos = self.pe(torch.arange(t))\n",
    "        x = x + pos\n",
    "        return self.dropout(x)\n",
    "print(PEEmbed(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c5bf9-3800-4b22-b7d8-8886d4f15b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d626059-fd88-4a03-8b20-ffbf0115fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderLayerWithoutMask(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSA(d, h)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.attn_dropout(self.mhsa(x, x, x))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "encoder_layer = EncoderLayerWithoutMask()\n",
    "x = torch.rand(2, 3, 512)\n",
    "encoder_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851eff3d-4816-4410-9184-f30c157e4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class EncoderWithoutMask(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [EncoderLayerWithoutMask(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t = x.size()\n",
    "        x = self.embed(x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "encoder = EncoderWithoutMask()\n",
    "x = torch.randint(0, 2**13, (2, 3))\n",
    "encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddfbf32-dd33-4246-adad-0baa8b6ba5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With masks\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def self_attention_masked(q, k, v, mask=None):\n",
    "    # if 3 dim: b t d\n",
    "    #prod = Q.bmm(K.permute(0, 2, 1))\n",
    "    # or\n",
    "    # prod = torch.einsum(\"btd, bsd -> bts\", q, k)\n",
    "    # if 4 dim: b t h dh:\n",
    "    prod = torch.einsum(\"bthd, bshd -> bhts\", q, k)\n",
    "    scaled_prod = prod/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "    print(f\"scaled_prod.shape: \\n {scaled_prod.shape}\")\n",
    "    # mask should be in shape to be broadcastable to bhts and lead to masked keys only (last s dim)\n",
    "    if mask is not None:\n",
    "        scaled_prod = scaled_prod.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    print(f\"scaled_prod: \\n {scaled_prod}\")\n",
    "    softmaxed_prod = F.softmax(scaled_prod, dim=-1)\n",
    "    # print(softmaxed_prod.shape)\n",
    "    print(f\"softmaxed_prod: \\n {softmaxed_prod}\")\n",
    "    # swap h and t in v\n",
    "    return softmaxed_prod @ v.permute(0, 2, 1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eac5e23-ea43-4295-ba24-a7edbe1a1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d78a45-be0c-4d97-9020-4b83e8c499f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9857, 0.7291, 0.6403, 0.0374],\n",
      "          [0.7394, 0.3984, 0.7374, 0.5068]],\n",
      "\n",
      "         [[0.5068, 0.0564, 0.7493, 0.8834],\n",
      "          [0.8811, 0.7136, 0.0284, 0.0695]],\n",
      "\n",
      "         [[0.2602, 0.4339, 0.2987, 0.8893],\n",
      "          [0.4672, 0.3633, 0.7519, 0.5286]]],\n",
      "\n",
      "\n",
      "        [[[0.4021, 0.0263, 0.4238, 0.1005],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168]],\n",
      "\n",
      "         [[0.4193, 0.7159, 0.8073, 0.5569],\n",
      "          [0.3141, 0.4790, 0.3625, 0.9635]],\n",
      "\n",
      "         [[0.2780, 0.7656, 0.6667, 0.0436],\n",
      "          [0.2631, 0.8770, 0.0948, 0.5818]]]])\n",
      "mask: \n",
      " tensor([[1., 1., 0.],\n",
      "        [1., 0., 0.]])\n",
      "wrong mask: \n",
      " tensor([[[1., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0.]]])\n",
      "wrong mask broadcast: \n",
      " tensor([[[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.9573, 0.5267,   -inf],\n",
      "          [0.5267, 0.8009,   -inf],\n",
      "          [0.3987, 0.5829,   -inf]],\n",
      "\n",
      "         [[0.7530,   -inf,   -inf],\n",
      "          [0.4960,   -inf,   -inf],\n",
      "          [0.6563,   -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.1761, 0.2928,   -inf],\n",
      "          [0.2928, 0.8251,   -inf],\n",
      "          [0.2094, 0.6135,   -inf]],\n",
      "\n",
      "         [[0.4272,   -inf,   -inf],\n",
      "          [0.3417,   -inf,   -inf],\n",
      "          [0.4465,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6060, 0.3940, 0.0000],\n",
      "          [0.4319, 0.5681, 0.0000],\n",
      "          [0.4541, 0.5459, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4709, 0.5291, 0.0000],\n",
      "          [0.3700, 0.6300, 0.0000],\n",
      "          [0.4003, 0.5997, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "wrong a: \n",
      " tensor([[[[0.7970, 0.4641, 0.6832, 0.3707],\n",
      "          [0.7136, 0.3470, 0.7022, 0.5180],\n",
      "          [0.7243, 0.3619, 0.6998, 0.4992]],\n",
      "\n",
      "         [[0.7394, 0.3984, 0.7374, 0.5068],\n",
      "          [0.7394, 0.3984, 0.7374, 0.5068],\n",
      "          [0.7394, 0.3984, 0.7374, 0.5068]]],\n",
      "\n",
      "\n",
      "        [[[0.4112, 0.3912, 0.6267, 0.3420],\n",
      "          [0.4130, 0.4608, 0.6654, 0.3880],\n",
      "          [0.4124, 0.4398, 0.6538, 0.3742]],\n",
      "\n",
      "         [[0.1994, 0.8508, 0.2777, 0.1168],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168]]]])\n",
      "wrong a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n",
      "mask: \n",
      " tensor([[[[1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.]]]])\n",
      "mask broadcast: \n",
      " tensor([[[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.9573, 0.5267,   -inf],\n",
      "          [0.5267, 0.8009,   -inf],\n",
      "          [0.3987, 0.5829,   -inf]],\n",
      "\n",
      "         [[0.7530, 0.4960,   -inf],\n",
      "          [0.4960, 0.6457,   -inf],\n",
      "          [0.6563, 0.3645,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.1761,   -inf,   -inf],\n",
      "          [0.2928,   -inf,   -inf],\n",
      "          [0.2094,   -inf,   -inf]],\n",
      "\n",
      "         [[0.4272,   -inf,   -inf],\n",
      "          [0.3417,   -inf,   -inf],\n",
      "          [0.4465,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6060, 0.3940, 0.0000],\n",
      "          [0.4319, 0.5681, 0.0000],\n",
      "          [0.4541, 0.5459, 0.0000]],\n",
      "\n",
      "         [[0.5639, 0.4361, 0.0000],\n",
      "          [0.4627, 0.5373, 0.0000],\n",
      "          [0.5724, 0.4276, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "a: \n",
      " tensor([[[[0.7970, 0.4641, 0.6832, 0.3707],\n",
      "          [0.7136, 0.3470, 0.7022, 0.5180],\n",
      "          [0.7243, 0.3619, 0.6998, 0.4992]],\n",
      "\n",
      "         [[0.8012, 0.5359, 0.4282, 0.3161],\n",
      "          [0.8155, 0.5678, 0.3564, 0.2718],\n",
      "          [0.8000, 0.5332, 0.4343, 0.3198]]],\n",
      "\n",
      "\n",
      "        [[[0.4021, 0.0263, 0.4238, 0.1005],\n",
      "          [0.4021, 0.0263, 0.4238, 0.1005],\n",
      "          [0.4021, 0.0263, 0.4238, 0.1005]],\n",
      "\n",
      "         [[0.1994, 0.8508, 0.2777, 0.1168],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168]]]])\n",
      "a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# play with mask\n",
    "\n",
    "x = torch.rand([2, 3, 2, 4])\n",
    "print(x)\n",
    "# mask 2 batches 3 timeseries\n",
    "mask = torch.ones([2, 3])\n",
    "mask[0, 2] = 0\n",
    "mask[1, 2] = 0\n",
    "mask[1, 1] = 0\n",
    "print(f\"mask: \\n {mask}\")\n",
    "# add head dim to make mask broatcastable to q x k.T prod. mask shape 2, 1, 3\n",
    "mask = mask.unsqueeze(1)\n",
    "\n",
    "\n",
    "# mask = mask.permute(0, 2, 1)\n",
    "# is the mask that I need? keys are ignored?\n",
    "print(f\"wrong mask: \\n {mask}\")\n",
    "#  mask = 2 1 3 -> b prepended before broadcasting (1!!!) h (remains since already 2) t (broadcasted from 1) d (remains since already 3) \n",
    "print(f\"wrong mask broadcast: \\n {mask.broadcast_to([2, 2, 3, 3])}\") \n",
    "a = self_attention_masked(x, x, x, mask=mask)\n",
    "print(f\"wrong a: \\n {a}\" )\n",
    "print(f\"wrong a.shape: \\n {a.shape}\")\n",
    "# leads to wrong attention since the shape of mask is wrong 2 1 3 \n",
    "\n",
    "# correct mask\n",
    "# mask 2 batches 3 timeseries\n",
    "mask = torch.ones([2, 3])\n",
    "mask[0, 2] = 0\n",
    "mask[1, 2] = 0\n",
    "mask[1, 1] = 0\n",
    "mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "print(f\"mask: \\n {mask}\")\n",
    "#  mask = 2 1 1 3 -> b (remains already 2) h (broadcasted from 1) t (broadcasted from 1) d (remains since already 3) \n",
    "print(f\"mask broadcast: \\n {mask.broadcast_to([2, 2, 3, 3])}\") \n",
    "a = self_attention_masked(x, x, x, mask=mask)\n",
    "print(f\"a: \\n {a}\" )\n",
    "print(f\"a.shape: \\n {a.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1c6a367-2547-4d72-be99-19bbc1023c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: \n",
      " tensor([[[[0.9857, 0.7291, 0.6403, 0.0374],\n",
      "          [0.7394, 0.3984, 0.7374, 0.5068]],\n",
      "\n",
      "         [[0.5068, 0.0564, 0.7493, 0.8834],\n",
      "          [0.8811, 0.7136, 0.0284, 0.0695]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.4021, 0.0263, 0.4238, 0.1005],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.9573, 0.5267,   -inf],\n",
      "          [0.5267, 0.8009,   -inf],\n",
      "          [0.3987, 0.5829,   -inf]],\n",
      "\n",
      "         [[0.7530, 0.4960,   -inf],\n",
      "          [0.4960, 0.6457,   -inf],\n",
      "          [0.6563, 0.3645,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.1761,   -inf,   -inf],\n",
      "          [0.2928,   -inf,   -inf],\n",
      "          [0.2094,   -inf,   -inf]],\n",
      "\n",
      "         [[0.4272,   -inf,   -inf],\n",
      "          [0.3417,   -inf,   -inf],\n",
      "          [0.4465,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6060, 0.3940, 0.0000],\n",
      "          [0.4319, 0.5681, 0.0000],\n",
      "          [0.4541, 0.5459, 0.0000]],\n",
      "\n",
      "         [[0.5639, 0.4361, 0.0000],\n",
      "          [0.4627, 0.5373, 0.0000],\n",
      "          [0.5724, 0.4276, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "a: \n",
      " tensor([[[[0.7970, 0.4641, 0.6832, 0.3707],\n",
      "          [0.7136, 0.3470, 0.7022, 0.5180],\n",
      "          [0.7243, 0.3619, 0.6998, 0.4992]],\n",
      "\n",
      "         [[0.8012, 0.5359, 0.4282, 0.3161],\n",
      "          [0.8155, 0.5678, 0.3564, 0.2718],\n",
      "          [0.8000, 0.5332, 0.4343, 0.3198]]],\n",
      "\n",
      "\n",
      "        [[[0.4021, 0.0263, 0.4238, 0.1005],\n",
      "          [0.4021, 0.0263, 0.4238, 0.1005],\n",
      "          [0.4021, 0.0263, 0.4238, 0.1005]],\n",
      "\n",
      "         [[0.1994, 0.8508, 0.2777, 0.1168],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168],\n",
      "          [0.1994, 0.8508, 0.2777, 0.1168]]]])\n",
      "a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n",
      "test: \n",
      " tensor([[[0.0348, 0.7315, 0.3807, 0.8198],\n",
      "         [0.5546, 0.4272, 0.6644, 0.2668],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.9416, 0.9090, 0.5338, 0.5090],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "test_v: \n",
      " tensor([[[[0.0348, 0.7315],\n",
      "          [0.3807, 0.8198]],\n",
      "\n",
      "         [[0.5546, 0.4272],\n",
      "          [0.6644, 0.2668]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.9416, 0.9090],\n",
      "          [0.5338, 0.5090]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]]])\n",
      "test_perm: \n",
      " tensor([[[[0.0348, 0.7315],\n",
      "          [0.5546, 0.4272],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3807, 0.8198],\n",
      "          [0.6644, 0.2668],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.9416, 0.9090],\n",
      "          [0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5338, 0.5090],\n",
      "          [0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]]])\n",
      "test_k: \n",
      " tensor([[[0.0862, 0.6751, 0.2700, 0.7639],\n",
      "         [0.9896, 0.2597, 0.7853, 0.5585],\n",
      "         [  -inf,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        [[0.3901, 0.5323, 0.5353, 0.4364],\n",
      "         [  -inf,   -inf,   -inf,   -inf],\n",
      "         [  -inf,   -inf,   -inf,   -inf]]])\n",
      "test_k_view: \n",
      " tensor([[[[0.0862, 0.6751],\n",
      "          [0.2700, 0.7639]],\n",
      "\n",
      "         [[0.9896, 0.2597],\n",
      "          [0.7853, 0.5585]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.3901, 0.5323],\n",
      "          [0.5353, 0.4364]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]]]])\n",
      "test_k_perm: \n",
      " tensor([[[[0.0862, 0.6751],\n",
      "          [0.9896, 0.2597],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[0.2700, 0.7639],\n",
      "          [0.7853, 0.5585],\n",
      "          [  -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.3901, 0.5323],\n",
      "          [  -inf,   -inf],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[0.5353, 0.4364],\n",
      "          [  -inf,   -inf],\n",
      "          [  -inf,   -inf]]]])\n",
      "q * k: \n",
      " tensor([[[[0.4632, 0.2606,   -inf],\n",
      "          [0.2606, 1.0467,   -inf],\n",
      "          [0.5549, 0.7406,   -inf]],\n",
      "\n",
      "         [[0.6564, 0.6387,   -inf],\n",
      "          [0.6387, 0.9286,   -inf],\n",
      "          [0.3339, 0.6635,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.4355,   -inf,   -inf],\n",
      "          [0.7508,   -inf,   -inf],\n",
      "          [0.4205,   -inf,   -inf]],\n",
      "\n",
      "         [[0.4770,   -inf,   -inf],\n",
      "          [0.7872,   -inf,   -inf],\n",
      "          [0.3938,   -inf,   -inf]]]])\n"
     ]
    }
   ],
   "source": [
    "# mask is equal to making keys on masked places 0:\n",
    "# the result in terms of masked symbols is the same\n",
    "k = x.clone()\n",
    "k[0, 2, 0, :] = float(\"-inf\")\n",
    "k[0, 2, 1, :] = float(\"-inf\")\n",
    "k[1, 2, 0, :] = float(\"-inf\")\n",
    "k[1, 1, 0, :] = float(\"-inf\")\n",
    "k[1, 2, 1, :] = float(\"-inf\")\n",
    "k[1, 1, 1, :] = float(\"-inf\")\n",
    "print(f\"k: \\n {k}\")\n",
    "a = self_attention_masked(x, k, x)\n",
    "print(f\"a: \\n {a}\" )\n",
    "print(f\"a.shape: \\n {a.shape}\")\n",
    "# a is the same shape as if mask was applied in q * k:\n",
    "\n",
    "test = torch.rand([2, 3, 4])\n",
    "test[0, 2, :] = 0\n",
    "test[1, 1, :] = 0\n",
    "test[1, 2, :] = 0\n",
    "\n",
    "print(f\"test: \\n {test}\")\n",
    "test_v = test.view(2, 3, 2, 2)\n",
    "print(f\"test_v: \\n {test_v}\")\n",
    "test_perm = test_v.permute(0, 2, 1, 3)\n",
    "print(f\"test_perm: \\n {test_perm}\")\n",
    "\n",
    "# or like that:\n",
    "test_q = torch.rand([2, 3, 4])\n",
    "test_k = test_q.clone()\n",
    "test_k[0, 2, :] = float(\"-inf\")\n",
    "test_k[1, 1, :] = float(\"-inf\")\n",
    "test_k[1, 2, :] = float(\"-inf\")\n",
    "print(f\"test_k: \\n {test_k}\")\n",
    "\n",
    "test_q_view = test_q.view(2, 3, 2, 2)\n",
    "test_k_view = test_k.view(2, 3, 2, 2)\n",
    "print(f\"test_k_view: \\n {test_k_view}\")\n",
    "test_q_perm = test_q_view.permute(0, 2, 1, 3)\n",
    "test_k_perm = test_k_view.permute(0, 2, 1, 3)\n",
    "print(f\"test_k_perm: \\n {test_k_perm}\")\n",
    "print(f\"q * k: \\n {torch.einsum(\"bhtd, bhsd -> bhts\", test_q_perm, test_k_perm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90465ec8-787f-409e-977a-30c566450515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.8186e-01, 6.4062e-01, 1.9850e-01, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [7.0082e-01, 9.3461e-01, 4.5837e-01, 7.5353e-01, 1.0000e+02, 1.0000e+02],\n",
      "        [5.2100e-01, 2.6563e-01, 7.7681e-01, 6.7967e-01, 1.0554e-01, 1.0000e+02],\n",
      "        [1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [8.5110e-02, 7.2043e-01, 4.4257e-01, 6.6892e-01, 4.1118e-01, 9.9156e-02]])\n",
      "tensor([[1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_padding_mask(x, pad_token):\n",
    "    # x: b t shape\n",
    "    mask = torch.ones_like(x)\n",
    "    return mask.masked_fill(x == pad_token, 0)\n",
    "\n",
    "x = torch.rand(5, 6)\n",
    "x[0, -3:] = 100\n",
    "x[1, -2:] = 100\n",
    "x[2, -1] = 100\n",
    "x[3, :] = 100\n",
    "print(x)\n",
    "print(build_padding_mask(x, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647bfc41-5717-4c39-92d5-6d1ba132f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_causal_mask(x):\n",
    "    # x: b t shape\n",
    "    m = torch.ones_like(x)\n",
    "    return torch.tril(m)\n",
    "x = torch.rand(5, 6)\n",
    "\n",
    "print(build_causal_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6702b0c-11f5-4326-989e-d2b76a77dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.5627e-01, 1.9587e-01, 3.2327e-02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [1.2564e-01, 1.4291e-01, 2.9585e-01, 7.7335e-02, 3.9172e-01, 1.0000e+02],\n",
      "        [7.5887e-01, 6.5872e-01, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [8.3057e-01, 1.9838e-01, 4.1828e-01, 7.9825e-01, 3.7982e-01, 3.1589e-01]])\n",
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def merge_masks(m1, m2):\n",
    "    return m1 * m2\n",
    "\n",
    "x = torch.rand(5, 6)\n",
    "x[0, -3:] = 100\n",
    "x[1, -1] = 100\n",
    "x[2, -4:] = 100\n",
    "x[3, :] = 100\n",
    "print(x)\n",
    "m1 = build_padding_mask(x, 100)\n",
    "m2 = build_causal_mask(x)\n",
    "print(merge_masks(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c167748-72fb-40b3-9e6d-7755fa12bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def reshape_mask(mask):\n",
    "    # b t -> b 1 1 t (to be broadcastable to b h t t)\n",
    "    return mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "x = torch.rand(2, 3)\n",
    "print(reshape_mask(build_causal_mask(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "336c48b9-29d0-4f4e-9d67-a12ddc566634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([4, 2, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0823,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1181,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0663,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0437,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1643,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0333,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0413,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0197,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0091,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0641,    -inf,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1610, -0.0980,    -inf,    -inf,    -inf],\n",
      "          [-0.1552, -0.1273,    -inf,    -inf,    -inf],\n",
      "          [-0.0323, -0.1289,    -inf,    -inf,    -inf],\n",
      "          [-0.1566, -0.1981,    -inf,    -inf,    -inf],\n",
      "          [-0.1091, -0.1297,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0723, -0.0847,    -inf,    -inf,    -inf],\n",
      "          [ 0.0083, -0.0230,    -inf,    -inf,    -inf],\n",
      "          [-0.0427, -0.0953,    -inf,    -inf,    -inf],\n",
      "          [-0.0325, -0.0646,    -inf,    -inf,    -inf],\n",
      "          [-0.0982, -0.0750,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2442, -0.1579, -0.2729,    -inf,    -inf],\n",
      "          [-0.1786, -0.1249, -0.1812,    -inf,    -inf],\n",
      "          [-0.1866, -0.0998, -0.2097,    -inf,    -inf],\n",
      "          [-0.2592, -0.1782, -0.2708,    -inf,    -inf],\n",
      "          [-0.1384, -0.0866, -0.1513,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1261, -0.0424,  0.0525,    -inf,    -inf],\n",
      "          [-0.0804, -0.0420,  0.0328,    -inf,    -inf],\n",
      "          [-0.1139, -0.0420,  0.0475,    -inf,    -inf],\n",
      "          [-0.1198, -0.0569,  0.0490,    -inf,    -inf],\n",
      "          [-0.0603, -0.0440,  0.0237,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2228, -0.0610, -0.2996, -0.2026,    -inf],\n",
      "          [-0.0314, -0.0349, -0.1178, -0.0457,    -inf],\n",
      "          [-0.2537, -0.0252, -0.2032, -0.2105,    -inf],\n",
      "          [-0.1336, -0.0094, -0.1336, -0.0775,    -inf],\n",
      "          [-0.1605,  0.0012, -0.1071, -0.0994,    -inf]],\n",
      "\n",
      "         [[-0.0280, -0.0251, -0.0683,  0.1486,    -inf],\n",
      "          [-0.0261, -0.0149, -0.0252,  0.0052,    -inf],\n",
      "          [-0.0097, -0.0101, -0.0653,  0.1946,    -inf],\n",
      "          [ 0.0018, -0.0475, -0.0395,  0.1470,    -inf],\n",
      "          [-0.0220, -0.0376, -0.0391,  0.0686,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4842, 0.5158, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4930, 0.5070, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5241, 0.4759, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5104, 0.4896, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5051, 0.4949, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5031, 0.4969, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5078, 0.4922, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5131, 0.4869, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5080, 0.4920, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4942, 0.5058, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3266, 0.3560, 0.3174, 0.0000, 0.0000],\n",
      "          [0.3276, 0.3457, 0.3267, 0.0000, 0.0000],\n",
      "          [0.3260, 0.3555, 0.3185, 0.0000, 0.0000],\n",
      "          [0.3254, 0.3529, 0.3217, 0.0000, 0.0000],\n",
      "          [0.3289, 0.3464, 0.3247, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3046, 0.3312, 0.3642, 0.0000, 0.0000],\n",
      "          [0.3166, 0.3290, 0.3545, 0.0000, 0.0000],\n",
      "          [0.3077, 0.3307, 0.3616, 0.0000, 0.0000],\n",
      "          [0.3078, 0.3278, 0.3644, 0.0000, 0.0000],\n",
      "          [0.3222, 0.3274, 0.3504, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2426, 0.2852, 0.2247, 0.2475, 0.0000],\n",
      "          [0.2564, 0.2555, 0.2352, 0.2528, 0.0000],\n",
      "          [0.2297, 0.2887, 0.2416, 0.2399, 0.0000],\n",
      "          [0.2387, 0.2702, 0.2387, 0.2524, 0.0000],\n",
      "          [0.2329, 0.2738, 0.2457, 0.2476, 0.0000]],\n",
      "\n",
      "         [[0.2406, 0.2413, 0.2311, 0.2870, 0.0000],\n",
      "          [0.2473, 0.2501, 0.2475, 0.2551, 0.0000],\n",
      "          [0.2397, 0.2396, 0.2267, 0.2940, 0.0000],\n",
      "          [0.2458, 0.2340, 0.2359, 0.2842, 0.0000],\n",
      "          [0.2462, 0.2423, 0.2420, 0.2695, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[-0.2101, -0.2636,  0.2375, -0.4576, -0.0342, -0.4634],\n",
      "         [-0.2101, -0.2636,  0.2375, -0.4576, -0.0342, -0.4634],\n",
      "         [-0.2101, -0.2636,  0.2375, -0.4576, -0.0342, -0.4634],\n",
      "         [-0.2101, -0.2636,  0.2375, -0.4576, -0.0342, -0.4634],\n",
      "         [-0.2101, -0.2636,  0.2375, -0.4576, -0.0342, -0.4634]],\n",
      "\n",
      "        [[-0.3414, -0.1059,  0.1884, -0.5915,  0.0519, -0.6010],\n",
      "         [-0.3413, -0.1047,  0.1877, -0.5930,  0.0518, -0.6016],\n",
      "         [-0.3411, -0.1012,  0.1860, -0.5980,  0.0521, -0.6037],\n",
      "         [-0.3413, -0.1030,  0.1869, -0.5957,  0.0522, -0.6027],\n",
      "         [-0.3417, -0.1045,  0.1881, -0.5949,  0.0533, -0.6023]],\n",
      "\n",
      "        [[-0.2656, -0.4631,  0.2162, -0.4075,  0.0960, -0.4059],\n",
      "         [-0.2679, -0.4654,  0.2179, -0.4050,  0.0972, -0.4057],\n",
      "         [-0.2661, -0.4634,  0.2165, -0.4073,  0.0965, -0.4060],\n",
      "         [-0.2660, -0.4639,  0.2167, -0.4067,  0.0961, -0.4056],\n",
      "         [-0.2684, -0.4658,  0.2180, -0.4051,  0.0982, -0.4059]],\n",
      "\n",
      "        [[-0.2394, -0.3634,  0.1562, -0.5485,  0.0722, -0.4278],\n",
      "         [-0.2435, -0.3676,  0.1603, -0.5454,  0.0745, -0.4251],\n",
      "         [-0.2392, -0.3641,  0.1565, -0.5447,  0.0719, -0.4287],\n",
      "         [-0.2416, -0.3681,  0.1577, -0.5446,  0.0733, -0.4262],\n",
      "         [-0.2434, -0.3675,  0.1594, -0.5426,  0.0751, -0.4281]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([4, 2, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0823,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1181,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0663,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0437,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1643,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0333,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0413,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0197,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0091,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0641,    -inf,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1610, -0.0980,    -inf,    -inf,    -inf],\n",
      "          [-0.1552, -0.1273,    -inf,    -inf,    -inf],\n",
      "          [-0.0323, -0.1289,    -inf,    -inf,    -inf],\n",
      "          [-0.1566, -0.1981,    -inf,    -inf,    -inf],\n",
      "          [-0.1091, -0.1297,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0723, -0.0847,    -inf,    -inf,    -inf],\n",
      "          [ 0.0083, -0.0230,    -inf,    -inf,    -inf],\n",
      "          [-0.0427, -0.0953,    -inf,    -inf,    -inf],\n",
      "          [-0.0325, -0.0646,    -inf,    -inf,    -inf],\n",
      "          [-0.0982, -0.0750,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2442, -0.1579, -0.2729,    -inf,    -inf],\n",
      "          [-0.1786, -0.1249, -0.1812,    -inf,    -inf],\n",
      "          [-0.1866, -0.0998, -0.2097,    -inf,    -inf],\n",
      "          [-0.2592, -0.1782, -0.2708,    -inf,    -inf],\n",
      "          [-0.1384, -0.0866, -0.1513,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1261, -0.0424,  0.0525,    -inf,    -inf],\n",
      "          [-0.0804, -0.0420,  0.0328,    -inf,    -inf],\n",
      "          [-0.1139, -0.0420,  0.0475,    -inf,    -inf],\n",
      "          [-0.1198, -0.0569,  0.0490,    -inf,    -inf],\n",
      "          [-0.0603, -0.0440,  0.0237,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2228, -0.0610, -0.2996, -0.2026,    -inf],\n",
      "          [-0.0314, -0.0349, -0.1178, -0.0457,    -inf],\n",
      "          [-0.2537, -0.0252, -0.2032, -0.2105,    -inf],\n",
      "          [-0.1336, -0.0094, -0.1336, -0.0775,    -inf],\n",
      "          [-0.1605,  0.0012, -0.1071, -0.0994,    -inf]],\n",
      "\n",
      "         [[-0.0280, -0.0251, -0.0683,  0.1486,    -inf],\n",
      "          [-0.0261, -0.0149, -0.0252,  0.0052,    -inf],\n",
      "          [-0.0097, -0.0101, -0.0653,  0.1946,    -inf],\n",
      "          [ 0.0018, -0.0475, -0.0395,  0.1470,    -inf],\n",
      "          [-0.0220, -0.0376, -0.0391,  0.0686,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4842, 0.5158, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4930, 0.5070, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5241, 0.4759, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5104, 0.4896, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5051, 0.4949, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5031, 0.4969, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5078, 0.4922, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5131, 0.4869, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5080, 0.4920, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4942, 0.5058, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3266, 0.3560, 0.3174, 0.0000, 0.0000],\n",
      "          [0.3276, 0.3457, 0.3267, 0.0000, 0.0000],\n",
      "          [0.3260, 0.3555, 0.3185, 0.0000, 0.0000],\n",
      "          [0.3254, 0.3529, 0.3217, 0.0000, 0.0000],\n",
      "          [0.3289, 0.3464, 0.3247, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3046, 0.3312, 0.3642, 0.0000, 0.0000],\n",
      "          [0.3166, 0.3290, 0.3545, 0.0000, 0.0000],\n",
      "          [0.3077, 0.3307, 0.3616, 0.0000, 0.0000],\n",
      "          [0.3078, 0.3278, 0.3644, 0.0000, 0.0000],\n",
      "          [0.3222, 0.3274, 0.3504, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2426, 0.2852, 0.2247, 0.2475, 0.0000],\n",
      "          [0.2564, 0.2555, 0.2352, 0.2528, 0.0000],\n",
      "          [0.2297, 0.2887, 0.2416, 0.2399, 0.0000],\n",
      "          [0.2387, 0.2702, 0.2387, 0.2524, 0.0000],\n",
      "          [0.2329, 0.2738, 0.2457, 0.2476, 0.0000]],\n",
      "\n",
      "         [[0.2406, 0.2413, 0.2311, 0.2870, 0.0000],\n",
      "          [0.2473, 0.2501, 0.2475, 0.2551, 0.0000],\n",
      "          [0.2397, 0.2396, 0.2267, 0.2940, 0.0000],\n",
      "          [0.2458, 0.2340, 0.2359, 0.2842, 0.0000],\n",
      "          [0.2462, 0.2423, 0.2420, 0.2695, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MHSAMasked(nn.Module):\n",
    "    def __init__(self, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        assert d % h == 0\n",
    "        self.d = d\n",
    "        self.dh = d // h\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(self.d, self.d)\n",
    "        self.wk = nn.Linear(self.d, self.d)\n",
    "        self.wv = nn.Linear(self.d, self.d)\n",
    "        self.wo = nn.Linear(self.d, self.d)\n",
    " \n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        # q and k/v might be of different sizes if lengths of decoder and encoders inputs are different\n",
    "        bq, tq, dq = q.size()\n",
    "        bk, tk, dk = k.size()\n",
    "        wq = self.wq(q)\n",
    "        wk = self.wk(k)\n",
    "        wv = self.wv(v)\n",
    "        wq = wq.view(bq, tq, self.h, self.dh)\n",
    "        wk = wk.view(bk, tk, self.h, self.dh)\n",
    "        wv = wv.view(bk, tk, self.h, self.dh)\n",
    "        # b, t, h, dh\n",
    "        # if changing from 4 dim -> 3 dim: b*h, t, dh\n",
    "        # wq = wq.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wk = wk.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wv = wv.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # another option 4 dim -> 3 dim\n",
    "        # wq = wq.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wk = wk.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wv = wv.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # changing the number of dims is not necessary as @ supports 4 dims\n",
    "        attn = self_attention_masked(wq, wk, wv, mask=mask)\n",
    "        # b * h, t, dh\n",
    "        # attn = attn.view(b, self.h, t, self.dh).permute(0, 2, 1, 3).reshape(b, t, d)\n",
    "        attn = attn.view(bq, self.h, tq, self.dh).transpose(1, 2).contiguous().view(bq, tq, dq)\n",
    "        wo = self.wo(attn)\n",
    "        return wo\n",
    "        # # 1 2 3 4\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # return F.relu(self.conv2(x))\n",
    "\n",
    "mhsa_masked = MHSAMasked(h = 2, d = 6)\n",
    "x = torch.rand(4, 5)\n",
    "mask = reshape_mask(build_causal_mask(x))\n",
    "print(mask)\n",
    "x = torch.rand(4, 5, 6)\n",
    "print(mhsa_masked(x, x, x, mask=mask))\n",
    "print(mhsa_masked(x, x, x, mask=mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729ae6f8-a3f8-4386-837d-f1e67f022b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22d0cd6d-12f4-44f0-b8b9-62a18a6d2f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0290,  0.0526,    -inf],\n",
      "          [-0.1071, -0.0288,    -inf],\n",
      "          [-0.0313,  0.0395,    -inf]],\n",
      "\n",
      "         [[ 0.1718,  0.1367,    -inf],\n",
      "          [ 0.2660,  0.2261,    -inf],\n",
      "          [ 0.2388,  0.1550,    -inf]],\n",
      "\n",
      "         [[-0.0152,  0.1000,    -inf],\n",
      "          [-0.0247, -0.0017,    -inf],\n",
      "          [-0.0012, -0.0629,    -inf]],\n",
      "\n",
      "         [[-0.0116, -0.0373,    -inf],\n",
      "          [-0.0524, -0.0300,    -inf],\n",
      "          [-0.0198, -0.0917,    -inf]],\n",
      "\n",
      "         [[-0.0982, -0.0242,    -inf],\n",
      "          [-0.1178, -0.0027,    -inf],\n",
      "          [-0.0132,  0.0302,    -inf]],\n",
      "\n",
      "         [[-0.0034, -0.0034,    -inf],\n",
      "          [-0.0394, -0.0643,    -inf],\n",
      "          [-0.1337, -0.0938,    -inf]],\n",
      "\n",
      "         [[-0.0652, -0.0678,    -inf],\n",
      "          [-0.1324, -0.1568,    -inf],\n",
      "          [-0.1193, -0.1518,    -inf]],\n",
      "\n",
      "         [[-0.1068,  0.0435,    -inf],\n",
      "          [-0.1516, -0.0182,    -inf],\n",
      "          [-0.1953, -0.0652,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0840,    -inf,    -inf],\n",
      "          [ 0.1013,    -inf,    -inf],\n",
      "          [ 0.0138,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2298,    -inf,    -inf],\n",
      "          [ 0.1777,    -inf,    -inf],\n",
      "          [ 0.2527,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2170,    -inf,    -inf],\n",
      "          [ 0.1559,    -inf,    -inf],\n",
      "          [ 0.0633,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0381,    -inf,    -inf],\n",
      "          [ 0.0110,    -inf,    -inf],\n",
      "          [-0.0352,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0404,    -inf,    -inf],\n",
      "          [-0.1185,    -inf,    -inf],\n",
      "          [-0.0529,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0685,    -inf,    -inf],\n",
      "          [-0.0936,    -inf,    -inf],\n",
      "          [-0.0401,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0399,    -inf,    -inf],\n",
      "          [-0.0119,    -inf,    -inf],\n",
      "          [-0.1243,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0671,    -inf,    -inf],\n",
      "          [-0.0584,    -inf,    -inf],\n",
      "          [-0.0113,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4941, 0.5059, 0.0000],\n",
      "          [0.4804, 0.5196, 0.0000],\n",
      "          [0.4823, 0.5177, 0.0000]],\n",
      "\n",
      "         [[0.5088, 0.4912, 0.0000],\n",
      "          [0.5100, 0.4900, 0.0000],\n",
      "          [0.5209, 0.4791, 0.0000]],\n",
      "\n",
      "         [[0.4712, 0.5288, 0.0000],\n",
      "          [0.4942, 0.5058, 0.0000],\n",
      "          [0.5154, 0.4846, 0.0000]],\n",
      "\n",
      "         [[0.5064, 0.4936, 0.0000],\n",
      "          [0.4944, 0.5056, 0.0000],\n",
      "          [0.5180, 0.4820, 0.0000]],\n",
      "\n",
      "         [[0.4815, 0.5185, 0.0000],\n",
      "          [0.4713, 0.5287, 0.0000],\n",
      "          [0.4891, 0.5109, 0.0000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.0000],\n",
      "          [0.5062, 0.4938, 0.0000],\n",
      "          [0.4900, 0.5100, 0.0000]],\n",
      "\n",
      "         [[0.5006, 0.4994, 0.0000],\n",
      "          [0.5061, 0.4939, 0.0000],\n",
      "          [0.5081, 0.4919, 0.0000]],\n",
      "\n",
      "         [[0.4625, 0.5375, 0.0000],\n",
      "          [0.4667, 0.5333, 0.0000],\n",
      "          [0.4675, 0.5325, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSAMasked(d, h)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, self_mask=None):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.attn_dropout(self.mhsa(x, x, x, mask=self_mask))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "encoder_layer = EncoderLayer()\n",
    "self_mask = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0]]), pad_token=0)\n",
    "self_mask = reshape_mask(self_mask)\n",
    "x = torch.rand(2, 3, 512)\n",
    "\n",
    "encoder_layer(x, self_mask=self_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e48412b-a00c-45e5-829f-441a7df2318e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0803, -0.1262,    -inf],\n",
      "          [-0.5837,  0.9467,    -inf],\n",
      "          [-0.0425,  0.4973,    -inf]],\n",
      "\n",
      "         [[-0.2168, -0.1899,    -inf],\n",
      "          [-0.4836,  0.0629,    -inf],\n",
      "          [ 0.4864,  0.2861,    -inf]],\n",
      "\n",
      "         [[-0.5599,  0.0706,    -inf],\n",
      "          [ 0.0283,  0.1414,    -inf],\n",
      "          [ 0.2566,  0.1005,    -inf]],\n",
      "\n",
      "         [[-0.1452, -0.6408,    -inf],\n",
      "          [ 0.0286, -0.6266,    -inf],\n",
      "          [ 0.7881,  0.4475,    -inf]],\n",
      "\n",
      "         [[ 0.2094,  0.5539,    -inf],\n",
      "          [-0.2821, -0.1401,    -inf],\n",
      "          [-0.0837, -0.3041,    -inf]],\n",
      "\n",
      "         [[ 0.2413, -0.4109,    -inf],\n",
      "          [ 0.1411, -0.4013,    -inf],\n",
      "          [ 0.7659, -0.4850,    -inf]],\n",
      "\n",
      "         [[ 0.3142,  0.2689,    -inf],\n",
      "          [-0.6572,  0.0899,    -inf],\n",
      "          [-0.4500,  0.6181,    -inf]],\n",
      "\n",
      "         [[-0.4630,  1.2604,    -inf],\n",
      "          [-0.0337,  0.1610,    -inf],\n",
      "          [-0.2285,  0.7066,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0476,    -inf,    -inf],\n",
      "          [-0.4576,    -inf,    -inf],\n",
      "          [-0.2751,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5996,    -inf,    -inf],\n",
      "          [-0.1321,    -inf,    -inf],\n",
      "          [-0.0102,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3954,    -inf,    -inf],\n",
      "          [-0.0083,    -inf,    -inf],\n",
      "          [ 0.0982,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3918,    -inf,    -inf],\n",
      "          [-0.7186,    -inf,    -inf],\n",
      "          [-0.9337,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.8958,    -inf,    -inf],\n",
      "          [-0.4206,    -inf,    -inf],\n",
      "          [-0.3580,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1890,    -inf,    -inf],\n",
      "          [-0.4536,    -inf,    -inf],\n",
      "          [-0.6455,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.7558,    -inf,    -inf],\n",
      "          [ 0.1498,    -inf,    -inf],\n",
      "          [ 0.0397,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5453,    -inf,    -inf],\n",
      "          [ 0.2354,    -inf,    -inf],\n",
      "          [ 0.0567,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5115, 0.4885, 0.0000],\n",
      "          [0.1779, 0.8221, 0.0000],\n",
      "          [0.3682, 0.6318, 0.0000]],\n",
      "\n",
      "         [[0.4933, 0.5067, 0.0000],\n",
      "          [0.3667, 0.6333, 0.0000],\n",
      "          [0.5499, 0.4501, 0.0000]],\n",
      "\n",
      "         [[0.3474, 0.6526, 0.0000],\n",
      "          [0.4717, 0.5283, 0.0000],\n",
      "          [0.5390, 0.4610, 0.0000]],\n",
      "\n",
      "         [[0.6214, 0.3786, 0.0000],\n",
      "          [0.6582, 0.3418, 0.0000],\n",
      "          [0.5843, 0.4157, 0.0000]],\n",
      "\n",
      "         [[0.4147, 0.5853, 0.0000],\n",
      "          [0.4646, 0.5354, 0.0000],\n",
      "          [0.5549, 0.4451, 0.0000]],\n",
      "\n",
      "         [[0.6575, 0.3425, 0.0000],\n",
      "          [0.6324, 0.3676, 0.0000],\n",
      "          [0.7775, 0.2225, 0.0000]],\n",
      "\n",
      "         [[0.5113, 0.4887, 0.0000],\n",
      "          [0.3214, 0.6786, 0.0000],\n",
      "          [0.2558, 0.7442, 0.0000]],\n",
      "\n",
      "         [[0.1514, 0.8486, 0.0000],\n",
      "          [0.4515, 0.5485, 0.0000],\n",
      "          [0.2819, 0.7181, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.4441,  0.3401,    -inf],\n",
      "          [-0.2397, -0.4385,    -inf],\n",
      "          [ 0.1368,  0.1824,    -inf]],\n",
      "\n",
      "         [[ 0.6305,  0.1112,    -inf],\n",
      "          [ 0.3315, -0.0723,    -inf],\n",
      "          [ 0.4321, -0.2066,    -inf]],\n",
      "\n",
      "         [[ 0.2620,  0.2820,    -inf],\n",
      "          [ 0.0759,  0.1538,    -inf],\n",
      "          [ 0.3872,  0.4057,    -inf]],\n",
      "\n",
      "         [[-0.1142,  0.2303,    -inf],\n",
      "          [-0.2259, -0.3534,    -inf],\n",
      "          [-0.0959,  0.1024,    -inf]],\n",
      "\n",
      "         [[ 0.2365, -0.4847,    -inf],\n",
      "          [ 0.3252, -0.8112,    -inf],\n",
      "          [-0.0502, -0.3747,    -inf]],\n",
      "\n",
      "         [[-0.0554,  0.1316,    -inf],\n",
      "          [-0.3572, -0.2011,    -inf],\n",
      "          [-0.0614, -0.6991,    -inf]],\n",
      "\n",
      "         [[-0.2579, -0.0921,    -inf],\n",
      "          [ 0.1193, -0.0861,    -inf],\n",
      "          [ 0.3535,  0.0691,    -inf]],\n",
      "\n",
      "         [[-0.2868, -0.6939,    -inf],\n",
      "          [ 0.0289, -0.1557,    -inf],\n",
      "          [-0.5318, -0.2563,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0515,    -inf,    -inf],\n",
      "          [-0.0538,    -inf,    -inf],\n",
      "          [-0.5111,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0524,    -inf,    -inf],\n",
      "          [ 0.0652,    -inf,    -inf],\n",
      "          [-0.5814,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1304,    -inf,    -inf],\n",
      "          [-0.3603,    -inf,    -inf],\n",
      "          [ 0.0710,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0103,    -inf,    -inf],\n",
      "          [-0.6266,    -inf,    -inf],\n",
      "          [-0.4278,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2390,    -inf,    -inf],\n",
      "          [-0.4861,    -inf,    -inf],\n",
      "          [ 0.0669,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.7349,    -inf,    -inf],\n",
      "          [ 0.0278,    -inf,    -inf],\n",
      "          [ 1.1458,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2964,    -inf,    -inf],\n",
      "          [ 0.0365,    -inf,    -inf],\n",
      "          [-0.0094,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0859,    -inf,    -inf],\n",
      "          [ 0.2896,    -inf,    -inf],\n",
      "          [-0.1006,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3134, 0.6866, 0.0000],\n",
      "          [0.5495, 0.4505, 0.0000],\n",
      "          [0.4886, 0.5114, 0.0000]],\n",
      "\n",
      "         [[0.6270, 0.3730, 0.0000],\n",
      "          [0.5996, 0.4004, 0.0000],\n",
      "          [0.6545, 0.3455, 0.0000]],\n",
      "\n",
      "         [[0.4950, 0.5050, 0.0000],\n",
      "          [0.4805, 0.5195, 0.0000],\n",
      "          [0.4954, 0.5046, 0.0000]],\n",
      "\n",
      "         [[0.4147, 0.5853, 0.0000],\n",
      "          [0.5318, 0.4682, 0.0000],\n",
      "          [0.4506, 0.5494, 0.0000]],\n",
      "\n",
      "         [[0.6729, 0.3271, 0.0000],\n",
      "          [0.7570, 0.2430, 0.0000],\n",
      "          [0.5804, 0.4196, 0.0000]],\n",
      "\n",
      "         [[0.4534, 0.5466, 0.0000],\n",
      "          [0.4610, 0.5390, 0.0000],\n",
      "          [0.6542, 0.3458, 0.0000]],\n",
      "\n",
      "         [[0.4586, 0.5414, 0.0000],\n",
      "          [0.5512, 0.4488, 0.0000],\n",
      "          [0.5706, 0.4294, 0.0000]],\n",
      "\n",
      "         [[0.6004, 0.3996, 0.0000],\n",
      "          [0.5460, 0.4540, 0.0000],\n",
      "          [0.4316, 0.5684, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1053, -0.2476,    -inf],\n",
      "          [-0.1049,  0.0174,    -inf],\n",
      "          [-0.1471,  0.0635,    -inf]],\n",
      "\n",
      "         [[ 0.1969, -0.3201,    -inf],\n",
      "          [ 0.1868, -0.2365,    -inf],\n",
      "          [ 0.1356,  0.3211,    -inf]],\n",
      "\n",
      "         [[ 0.0540,  0.3238,    -inf],\n",
      "          [ 0.4965,  0.2452,    -inf],\n",
      "          [ 0.4026,  0.0705,    -inf]],\n",
      "\n",
      "         [[ 0.1913, -0.4812,    -inf],\n",
      "          [ 0.3297,  0.3240,    -inf],\n",
      "          [ 0.0995,  0.0197,    -inf]],\n",
      "\n",
      "         [[ 0.1464, -0.1162,    -inf],\n",
      "          [ 0.3493, -0.5167,    -inf],\n",
      "          [-0.1577, -0.3596,    -inf]],\n",
      "\n",
      "         [[-0.0167,  0.4278,    -inf],\n",
      "          [ 0.1088,  0.0167,    -inf],\n",
      "          [-0.1848,  0.1236,    -inf]],\n",
      "\n",
      "         [[ 0.5859,  0.6214,    -inf],\n",
      "          [-0.1855,  0.2491,    -inf],\n",
      "          [ 0.1735,  0.0716,    -inf]],\n",
      "\n",
      "         [[ 0.2068,  0.2412,    -inf],\n",
      "          [ 0.3005, -0.2408,    -inf],\n",
      "          [-0.0261, -0.2903,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1167,    -inf,    -inf],\n",
      "          [ 0.2609,    -inf,    -inf],\n",
      "          [ 0.5823,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1941,    -inf,    -inf],\n",
      "          [-0.4027,    -inf,    -inf],\n",
      "          [-0.6787,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0327,    -inf,    -inf],\n",
      "          [-0.3896,    -inf,    -inf],\n",
      "          [-0.6427,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4053,    -inf,    -inf],\n",
      "          [-0.0706,    -inf,    -inf],\n",
      "          [-0.3825,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4628,    -inf,    -inf],\n",
      "          [-0.6443,    -inf,    -inf],\n",
      "          [-0.7133,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5087,    -inf,    -inf],\n",
      "          [ 0.3082,    -inf,    -inf],\n",
      "          [-0.1649,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3145,    -inf,    -inf],\n",
      "          [-0.4511,    -inf,    -inf],\n",
      "          [ 0.1262,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1400,    -inf,    -inf],\n",
      "          [ 0.2499,    -inf,    -inf],\n",
      "          [ 0.1519,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5355, 0.4645, 0.0000],\n",
      "          [0.4695, 0.5305, 0.0000],\n",
      "          [0.4475, 0.5525, 0.0000]],\n",
      "\n",
      "         [[0.6265, 0.3735, 0.0000],\n",
      "          [0.6043, 0.3957, 0.0000],\n",
      "          [0.4538, 0.5462, 0.0000]],\n",
      "\n",
      "         [[0.4330, 0.5670, 0.0000],\n",
      "          [0.5625, 0.4375, 0.0000],\n",
      "          [0.5823, 0.4177, 0.0000]],\n",
      "\n",
      "         [[0.6621, 0.3379, 0.0000],\n",
      "          [0.5014, 0.4986, 0.0000],\n",
      "          [0.5199, 0.4801, 0.0000]],\n",
      "\n",
      "         [[0.5653, 0.4347, 0.0000],\n",
      "          [0.7039, 0.2961, 0.0000],\n",
      "          [0.5503, 0.4497, 0.0000]],\n",
      "\n",
      "         [[0.3907, 0.6093, 0.0000],\n",
      "          [0.5230, 0.4770, 0.0000],\n",
      "          [0.4235, 0.5765, 0.0000]],\n",
      "\n",
      "         [[0.4911, 0.5089, 0.0000],\n",
      "          [0.3930, 0.6070, 0.0000],\n",
      "          [0.5255, 0.4745, 0.0000]],\n",
      "\n",
      "         [[0.4914, 0.5086, 0.0000],\n",
      "          [0.6321, 0.3679, 0.0000],\n",
      "          [0.5657, 0.4343, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1320, -0.3563,    -inf],\n",
      "          [-0.0995, -0.2240,    -inf],\n",
      "          [-0.4556, -0.3105,    -inf]],\n",
      "\n",
      "         [[-0.0609,  0.2147,    -inf],\n",
      "          [ 0.1536, -0.6364,    -inf],\n",
      "          [-0.1112, -0.0698,    -inf]],\n",
      "\n",
      "         [[ 0.3367,  0.1870,    -inf],\n",
      "          [-0.0087,  0.3469,    -inf],\n",
      "          [-0.0156,  0.3259,    -inf]],\n",
      "\n",
      "         [[ 0.1804,  0.5844,    -inf],\n",
      "          [ 0.2212,  0.0684,    -inf],\n",
      "          [-0.4769,  0.2561,    -inf]],\n",
      "\n",
      "         [[-0.3112,  0.0315,    -inf],\n",
      "          [ 0.0245,  0.4718,    -inf],\n",
      "          [ 0.0665, -0.0034,    -inf]],\n",
      "\n",
      "         [[-0.0280,  0.0547,    -inf],\n",
      "          [ 0.0264,  0.2192,    -inf],\n",
      "          [ 0.1737,  0.1636,    -inf]],\n",
      "\n",
      "         [[ 0.3872,  0.0757,    -inf],\n",
      "          [ 0.4477,  0.7138,    -inf],\n",
      "          [ 0.2706, -0.0512,    -inf]],\n",
      "\n",
      "         [[-0.0231, -0.6529,    -inf],\n",
      "          [-0.2458, -0.1777,    -inf],\n",
      "          [ 0.1731,  0.0530,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1571,    -inf,    -inf],\n",
      "          [-0.3811,    -inf,    -inf],\n",
      "          [ 0.3462,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6493,    -inf,    -inf],\n",
      "          [-0.0822,    -inf,    -inf],\n",
      "          [-0.1877,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1277,    -inf,    -inf],\n",
      "          [-0.1018,    -inf,    -inf],\n",
      "          [-0.0675,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2069,    -inf,    -inf],\n",
      "          [ 0.0716,    -inf,    -inf],\n",
      "          [ 0.5981,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2047,    -inf,    -inf],\n",
      "          [-0.2540,    -inf,    -inf],\n",
      "          [ 0.3105,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1956,    -inf,    -inf],\n",
      "          [ 0.4263,    -inf,    -inf],\n",
      "          [-0.0038,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1496,    -inf,    -inf],\n",
      "          [-0.0410,    -inf,    -inf],\n",
      "          [-0.4718,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1486,    -inf,    -inf],\n",
      "          [ 0.0762,    -inf,    -inf],\n",
      "          [ 0.1788,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5558, 0.4442, 0.0000],\n",
      "          [0.5311, 0.4689, 0.0000],\n",
      "          [0.4638, 0.5362, 0.0000]],\n",
      "\n",
      "         [[0.4315, 0.5685, 0.0000],\n",
      "          [0.6878, 0.3122, 0.0000],\n",
      "          [0.4897, 0.5103, 0.0000]],\n",
      "\n",
      "         [[0.5374, 0.4626, 0.0000],\n",
      "          [0.4120, 0.5880, 0.0000],\n",
      "          [0.4155, 0.5845, 0.0000]],\n",
      "\n",
      "         [[0.4003, 0.5997, 0.0000],\n",
      "          [0.5381, 0.4619, 0.0000],\n",
      "          [0.3245, 0.6755, 0.0000]],\n",
      "\n",
      "         [[0.4152, 0.5848, 0.0000],\n",
      "          [0.3900, 0.6100, 0.0000],\n",
      "          [0.5175, 0.4825, 0.0000]],\n",
      "\n",
      "         [[0.4793, 0.5207, 0.0000],\n",
      "          [0.4520, 0.5480, 0.0000],\n",
      "          [0.5025, 0.4975, 0.0000]],\n",
      "\n",
      "         [[0.5773, 0.4227, 0.0000],\n",
      "          [0.4339, 0.5661, 0.0000],\n",
      "          [0.5798, 0.4202, 0.0000]],\n",
      "\n",
      "         [[0.6525, 0.3475, 0.0000],\n",
      "          [0.4830, 0.5170, 0.0000],\n",
      "          [0.5300, 0.4700, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 3.0325e-02, -1.6148e-02,        -inf],\n",
      "          [-4.9329e-02,  5.7409e-02,        -inf],\n",
      "          [ 3.8798e-01,  2.2448e-01,        -inf]],\n",
      "\n",
      "         [[ 4.1817e-01,  3.0750e-02,        -inf],\n",
      "          [-3.2152e-02,  1.5812e-01,        -inf],\n",
      "          [-2.2953e-01, -3.3295e-01,        -inf]],\n",
      "\n",
      "         [[ 7.1041e-01,  4.1880e-01,        -inf],\n",
      "          [ 7.5787e-02,  1.5156e-01,        -inf],\n",
      "          [ 4.4018e-01, -3.8676e-01,        -inf]],\n",
      "\n",
      "         [[ 5.1618e-01,  4.6951e-03,        -inf],\n",
      "          [ 6.7886e-01, -2.6849e-01,        -inf],\n",
      "          [ 6.2368e-01,  2.8307e-01,        -inf]],\n",
      "\n",
      "         [[ 2.5884e-01, -3.4513e-01,        -inf],\n",
      "          [ 5.2972e-01, -3.5635e-01,        -inf],\n",
      "          [-2.3309e-01, -1.0463e+00,        -inf]],\n",
      "\n",
      "         [[ 3.6331e-01, -1.9668e-02,        -inf],\n",
      "          [-4.0558e-01,  1.1091e-01,        -inf],\n",
      "          [-2.4280e-02, -1.5896e-02,        -inf]],\n",
      "\n",
      "         [[ 1.9483e-01,  2.1267e-01,        -inf],\n",
      "          [ 3.0284e-01,  1.9233e-01,        -inf],\n",
      "          [ 3.2630e-01,  1.6877e-01,        -inf]],\n",
      "\n",
      "         [[ 7.3736e-03,  9.2405e-03,        -inf],\n",
      "          [-1.1358e-01, -2.7162e-04,        -inf],\n",
      "          [-2.2756e-01, -1.6531e-01,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[-7.4465e-01,        -inf,        -inf],\n",
      "          [-5.6380e-01,        -inf,        -inf],\n",
      "          [ 3.4307e-02,        -inf,        -inf]],\n",
      "\n",
      "         [[ 9.0897e-02,        -inf,        -inf],\n",
      "          [ 1.9457e-01,        -inf,        -inf],\n",
      "          [-2.8390e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.0840e-01,        -inf,        -inf],\n",
      "          [-3.9800e-01,        -inf,        -inf],\n",
      "          [-6.2051e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.8472e-01,        -inf,        -inf],\n",
      "          [-1.7412e-02,        -inf,        -inf],\n",
      "          [ 1.9444e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.4617e-02,        -inf,        -inf],\n",
      "          [ 5.3589e-01,        -inf,        -inf],\n",
      "          [ 3.5385e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.3235e-01,        -inf,        -inf],\n",
      "          [-4.1511e-01,        -inf,        -inf],\n",
      "          [-8.9377e-02,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.7676e-01,        -inf,        -inf],\n",
      "          [ 3.4395e-01,        -inf,        -inf],\n",
      "          [ 2.3054e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.9938e-01,        -inf,        -inf],\n",
      "          [ 5.2743e-01,        -inf,        -inf],\n",
      "          [ 2.1082e-01,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5116, 0.4884, 0.0000],\n",
      "          [0.4733, 0.5267, 0.0000],\n",
      "          [0.5408, 0.4592, 0.0000]],\n",
      "\n",
      "         [[0.5957, 0.4043, 0.0000],\n",
      "          [0.4526, 0.5474, 0.0000],\n",
      "          [0.5258, 0.4742, 0.0000]],\n",
      "\n",
      "         [[0.5724, 0.4276, 0.0000],\n",
      "          [0.4811, 0.5189, 0.0000],\n",
      "          [0.6957, 0.3043, 0.0000]],\n",
      "\n",
      "         [[0.6252, 0.3748, 0.0000],\n",
      "          [0.7206, 0.2794, 0.0000],\n",
      "          [0.5843, 0.4157, 0.0000]],\n",
      "\n",
      "         [[0.6466, 0.3534, 0.0000],\n",
      "          [0.7081, 0.2919, 0.0000],\n",
      "          [0.6928, 0.3072, 0.0000]],\n",
      "\n",
      "         [[0.5946, 0.4054, 0.0000],\n",
      "          [0.3737, 0.6263, 0.0000],\n",
      "          [0.4979, 0.5021, 0.0000]],\n",
      "\n",
      "         [[0.4955, 0.5045, 0.0000],\n",
      "          [0.5276, 0.4724, 0.0000],\n",
      "          [0.5393, 0.4607, 0.0000]],\n",
      "\n",
      "         [[0.4995, 0.5005, 0.0000],\n",
      "          [0.4717, 0.5283, 0.0000],\n",
      "          [0.4844, 0.5156, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0171, -0.3120,    -inf],\n",
      "          [ 0.1782,  0.8342,    -inf],\n",
      "          [-0.2187,  0.2769,    -inf]],\n",
      "\n",
      "         [[-0.4531,  0.2919,    -inf],\n",
      "          [-0.0470, -0.2313,    -inf],\n",
      "          [-0.1474,  0.0363,    -inf]],\n",
      "\n",
      "         [[-0.0823,  0.5740,    -inf],\n",
      "          [ 0.1703, -0.1064,    -inf],\n",
      "          [ 0.4640,  0.0325,    -inf]],\n",
      "\n",
      "         [[ 0.3356,  0.0628,    -inf],\n",
      "          [ 0.6005,  0.2002,    -inf],\n",
      "          [ 0.5699,  0.1567,    -inf]],\n",
      "\n",
      "         [[-0.3993, -0.4734,    -inf],\n",
      "          [ 0.0334,  0.0261,    -inf],\n",
      "          [-0.2648, -0.3094,    -inf]],\n",
      "\n",
      "         [[ 0.3936,  0.7429,    -inf],\n",
      "          [ 0.4465,  0.4687,    -inf],\n",
      "          [-0.1879,  0.0256,    -inf]],\n",
      "\n",
      "         [[ 0.2248,  0.2408,    -inf],\n",
      "          [ 0.5522,  0.1306,    -inf],\n",
      "          [-0.1481, -0.1362,    -inf]],\n",
      "\n",
      "         [[-0.1693, -0.6848,    -inf],\n",
      "          [-0.1823, -0.3424,    -inf],\n",
      "          [-0.4937, -0.6608,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.3936,    -inf,    -inf],\n",
      "          [-0.3344,    -inf,    -inf],\n",
      "          [-0.3958,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0049,    -inf,    -inf],\n",
      "          [-0.2091,    -inf,    -inf],\n",
      "          [ 0.1812,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0891,    -inf,    -inf],\n",
      "          [ 0.1316,    -inf,    -inf],\n",
      "          [ 0.0521,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1375,    -inf,    -inf],\n",
      "          [ 0.1992,    -inf,    -inf],\n",
      "          [ 0.3266,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0239,    -inf,    -inf],\n",
      "          [ 0.3835,    -inf,    -inf],\n",
      "          [ 0.3965,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2406,    -inf,    -inf],\n",
      "          [-0.1075,    -inf,    -inf],\n",
      "          [ 0.1570,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3982,    -inf,    -inf],\n",
      "          [-0.4928,    -inf,    -inf],\n",
      "          [-0.0029,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3572,    -inf,    -inf],\n",
      "          [ 0.1629,    -inf,    -inf],\n",
      "          [-0.2656,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5816, 0.4184, 0.0000],\n",
      "          [0.3416, 0.6584, 0.0000],\n",
      "          [0.3786, 0.6214, 0.0000]],\n",
      "\n",
      "         [[0.3219, 0.6781, 0.0000],\n",
      "          [0.5459, 0.4541, 0.0000],\n",
      "          [0.4542, 0.5458, 0.0000]],\n",
      "\n",
      "         [[0.3416, 0.6584, 0.0000],\n",
      "          [0.5688, 0.4312, 0.0000],\n",
      "          [0.6062, 0.3938, 0.0000]],\n",
      "\n",
      "         [[0.5678, 0.4322, 0.0000],\n",
      "          [0.5988, 0.4012, 0.0000],\n",
      "          [0.6018, 0.3982, 0.0000]],\n",
      "\n",
      "         [[0.5185, 0.4815, 0.0000],\n",
      "          [0.5018, 0.4982, 0.0000],\n",
      "          [0.5111, 0.4889, 0.0000]],\n",
      "\n",
      "         [[0.4136, 0.5864, 0.0000],\n",
      "          [0.4944, 0.5056, 0.0000],\n",
      "          [0.4468, 0.5532, 0.0000]],\n",
      "\n",
      "         [[0.4960, 0.5040, 0.0000],\n",
      "          [0.6039, 0.3961, 0.0000],\n",
      "          [0.4970, 0.5030, 0.0000]],\n",
      "\n",
      "         [[0.6261, 0.3739, 0.0000],\n",
      "          [0.5400, 0.4600, 0.0000],\n",
      "          [0.5417, 0.4583, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Encoder(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [EncoderLayer(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, x, self_mask = None):\n",
    "        b, t = x.size()\n",
    "        x = self.embed(x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, self_mask=self_mask)\n",
    "        return x\n",
    "\n",
    "encoder = Encoder()\n",
    "x = torch.randint(0, 2**13, (2, 3))\n",
    "self_mask = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0]]), pad_token=0)\n",
    "self_mask = reshape_mask(self_mask)\n",
    "encoder(x, self_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7785e51c-c88e-4ad2-ad66-4117fbb1a52c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_mask: \n",
      " tensor([[1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0]])\n",
      "cross_mask: \n",
      " tensor([[[[1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 2.6476e-03,        -inf,        -inf],\n",
      "          [ 3.9293e-02,        -inf,        -inf],\n",
      "          [ 3.0088e-02,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.8792e-02,        -inf,        -inf],\n",
      "          [-9.6770e-05,        -inf,        -inf],\n",
      "          [-7.5240e-03,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8202e-02,        -inf,        -inf],\n",
      "          [ 6.0391e-02,        -inf,        -inf],\n",
      "          [ 4.1730e-02,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.2263e-02,        -inf,        -inf],\n",
      "          [ 5.2906e-02,        -inf,        -inf],\n",
      "          [ 2.4623e-02,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1940e-02,  3.7628e-02,        -inf],\n",
      "          [ 7.4598e-02,  8.3658e-02,        -inf],\n",
      "          [ 2.8784e-02,  1.5011e-02,        -inf]],\n",
      "\n",
      "         [[-5.6719e-02,  1.9277e-03,        -inf],\n",
      "          [-2.5101e-02,  2.3789e-03,        -inf],\n",
      "          [-5.6550e-02,  3.7040e-02,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5011, 0.4989, 0.0000],\n",
      "          [0.4977, 0.5023, 0.0000],\n",
      "          [0.5034, 0.4966, 0.0000]],\n",
      "\n",
      "         [[0.4853, 0.5147, 0.0000],\n",
      "          [0.4931, 0.5069, 0.0000],\n",
      "          [0.4766, 0.5234, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0784,  0.0846,  0.2342],\n",
      "          [-0.4537, -0.4880,  0.0777],\n",
      "          [ 0.4838,  0.3125, -0.0682]],\n",
      "\n",
      "         [[ 0.2458,  0.1931, -0.0697],\n",
      "          [ 0.2478,  0.2124,  0.0954],\n",
      "          [ 0.2429,  0.2179, -0.3589]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0113,    -inf,    -inf],\n",
      "          [ 0.2465,    -inf,    -inf],\n",
      "          [ 0.4321,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0440,    -inf,    -inf],\n",
      "          [ 0.1208,    -inf,    -inf],\n",
      "          [-0.5255,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2528,  0.3455,    -inf],\n",
      "          [ 0.2421,  0.4127,    -inf],\n",
      "          [ 0.3743,  0.5048,    -inf]],\n",
      "\n",
      "         [[ 0.1225,  0.2581,    -inf],\n",
      "          [ 0.0515, -0.0521,    -inf],\n",
      "          [-0.0871, -0.0871,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3150, 0.3169, 0.3681],\n",
      "          [0.2727, 0.2635, 0.4639],\n",
      "          [0.4135, 0.3484, 0.2381]],\n",
      "\n",
      "         [[0.3734, 0.3542, 0.2724],\n",
      "          [0.3541, 0.3418, 0.3041],\n",
      "          [0.3963, 0.3865, 0.2171]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4768, 0.5232, 0.0000],\n",
      "          [0.4575, 0.5425, 0.0000],\n",
      "          [0.4674, 0.5326, 0.0000]],\n",
      "\n",
      "         [[0.4661, 0.5339, 0.0000],\n",
      "          [0.5259, 0.4741, 0.0000],\n",
      "          [0.5000, 0.5000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoderLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSAMasked(d=d, h=h)\n",
    "        self.attn_norm = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.mhca = MHSAMasked(d=d, h=h)\n",
    "        self.cross_attn_norm = nn.LayerNorm(d)\n",
    "        self.cross_attn_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(d)\n",
    "        \n",
    "\n",
    "    def forward(self, dec_x, enc_x, self_mask=None, cross_mask=None):\n",
    "        # self_mask is merged decoders padding and causal masks\n",
    "        # cross_mask is equal to endcoders padding mask because we don't want to attend to encoded padded tokens\n",
    "        b, t, d = dec_x.size()\n",
    "        x = dec_x + self.attn_dropout(self.mhsa(dec_x, dec_x, dec_x, mask=self_mask))\n",
    "        x = self.attn_norm(x)\n",
    "\n",
    "        x = x + self.cross_attn_dropout(self.mhca(x, enc_x, enc_x, mask=cross_mask))\n",
    "        x = self.cross_attn_norm(x)\n",
    "        \n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "decoder_layer = DecoderLayer(h=2, d=16)\n",
    "x = torch.rand(3, 3, 16)\n",
    "y = torch.rand(3, 3, 16)\n",
    "self_mask1 = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "self_mask2 = build_causal_mask(torch.tensor([[2, 2, 0], [2, 0, 0], [2, 2, 0]]))\n",
    "self_mask = merge_masks(self_mask1, self_mask2)\n",
    "print(f\"self_mask: \\n {self_mask}\")\n",
    "self_mask = reshape_mask(self_mask)\n",
    "\n",
    "cross_mask = build_padding_mask(torch.tensor([[2, 2, 2], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "cross_mask = reshape_mask(cross_mask)\n",
    "print(f\"cross_mask: \\n {cross_mask}\")\n",
    "decoder_layer(x, y, self_mask=self_mask, cross_mask=cross_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826a55e4-da2a-42e0-847d-14d0c7774cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_mask: \n",
      " tensor([[1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0]])\n",
      "cross_mask: \n",
      " tensor([[[[1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-1.0749,    -inf,    -inf],\n",
      "          [-0.4137,    -inf,    -inf],\n",
      "          [-0.1183,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1288,    -inf,    -inf],\n",
      "          [-0.8952,    -inf,    -inf],\n",
      "          [-0.7050,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1889,    -inf,    -inf],\n",
      "          [ 0.6978,    -inf,    -inf],\n",
      "          [ 1.0497,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5553,    -inf,    -inf],\n",
      "          [-0.4653,    -inf,    -inf],\n",
      "          [-0.5273,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0230, -0.2875,    -inf],\n",
      "          [ 0.3267, -0.7232,    -inf],\n",
      "          [ 0.5471, -0.3151,    -inf]],\n",
      "\n",
      "         [[-0.6063, -0.5643,    -inf],\n",
      "          [ 0.2344, -0.4607,    -inf],\n",
      "          [-0.8175,  0.6083,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5657, 0.4343, 0.0000],\n",
      "          [0.7407, 0.2593, 0.0000],\n",
      "          [0.7031, 0.2969, 0.0000]],\n",
      "\n",
      "         [[0.4895, 0.5105, 0.0000],\n",
      "          [0.6671, 0.3329, 0.0000],\n",
      "          [0.1938, 0.8062, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1083,  0.2033,  0.1942],\n",
      "          [-0.0668,  0.1415,  0.1482],\n",
      "          [-0.2879, -0.0165, -0.1639]],\n",
      "\n",
      "         [[ 0.1333, -0.0024, -0.1335],\n",
      "          [ 0.0719,  0.2069,  0.1197],\n",
      "          [ 0.0503,  0.0302, -0.0191]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1772,    -inf,    -inf],\n",
      "          [-0.0512,    -inf,    -inf],\n",
      "          [-0.0604,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1460,    -inf,    -inf],\n",
      "          [ 0.2937,    -inf,    -inf],\n",
      "          [ 0.0593,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2391,  0.3532,    -inf],\n",
      "          [ 0.1149,  0.1339,    -inf],\n",
      "          [-0.2683, -0.1750,    -inf]],\n",
      "\n",
      "         [[ 0.0995,  0.0046,    -inf],\n",
      "          [ 0.0701,  0.0522,    -inf],\n",
      "          [ 0.1519,  0.0497,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2689, 0.3672, 0.3639],\n",
      "          [0.2881, 0.3548, 0.3572],\n",
      "          [0.2904, 0.3809, 0.3287]],\n",
      "\n",
      "         [[0.3789, 0.3309, 0.2902],\n",
      "          [0.3131, 0.3584, 0.3285],\n",
      "          [0.3433, 0.3365, 0.3203]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4715, 0.5285, 0.0000],\n",
      "          [0.4952, 0.5048, 0.0000],\n",
      "          [0.4767, 0.5233, 0.0000]],\n",
      "\n",
      "         [[0.5237, 0.4763, 0.0000],\n",
      "          [0.5045, 0.4955, 0.0000],\n",
      "          [0.5255, 0.4745, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0793,    -inf,    -inf],\n",
      "          [-0.2313,    -inf,    -inf],\n",
      "          [-0.4759,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1083,    -inf,    -inf],\n",
      "          [-0.2096,    -inf,    -inf],\n",
      "          [-0.3263,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6709,    -inf,    -inf],\n",
      "          [ 0.3068,    -inf,    -inf],\n",
      "          [ 0.3586,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2483,    -inf,    -inf],\n",
      "          [-0.1936,    -inf,    -inf],\n",
      "          [-0.1081,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0669,  0.3470,    -inf],\n",
      "          [ 0.1874,  0.2008,    -inf],\n",
      "          [-0.2351,  0.3948,    -inf]],\n",
      "\n",
      "         [[ 0.2773, -0.0187,    -inf],\n",
      "          [-0.3467,  0.1747,    -inf],\n",
      "          [-0.0318,  0.2006,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4304, 0.5696, 0.0000],\n",
      "          [0.4966, 0.5034, 0.0000],\n",
      "          [0.3476, 0.6524, 0.0000]],\n",
      "\n",
      "         [[0.5735, 0.4265, 0.0000],\n",
      "          [0.3725, 0.6275, 0.0000],\n",
      "          [0.4421, 0.5579, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2139, -0.1365, -0.1345],\n",
      "          [ 0.0665,  0.2349,  0.1707],\n",
      "          [ 0.0551,  0.1354,  0.0643]],\n",
      "\n",
      "         [[ 0.3006, -0.0681,  0.2953],\n",
      "          [ 0.1106,  0.0047,  0.1388],\n",
      "          [ 0.0812,  0.0657,  0.1155]]],\n",
      "\n",
      "\n",
      "        [[[-0.0869,    -inf,    -inf],\n",
      "          [-0.1420,    -inf,    -inf],\n",
      "          [-0.1168,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1542,    -inf,    -inf],\n",
      "          [ 0.0898,    -inf,    -inf],\n",
      "          [ 0.1369,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1452, -0.1354,    -inf],\n",
      "          [-0.0306, -0.1171,    -inf],\n",
      "          [-0.0438, -0.1553,    -inf]],\n",
      "\n",
      "         [[-0.2051, -0.1881,    -inf],\n",
      "          [ 0.1541,  0.0224,    -inf],\n",
      "          [ 0.2343,  0.1461,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3161, 0.3416, 0.3423],\n",
      "          [0.3037, 0.3593, 0.3370],\n",
      "          [0.3233, 0.3504, 0.3263]],\n",
      "\n",
      "         [[0.3723, 0.2575, 0.3703],\n",
      "          [0.3415, 0.3072, 0.3513],\n",
      "          [0.3312, 0.3261, 0.3427]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4975, 0.5025, 0.0000],\n",
      "          [0.5216, 0.4784, 0.0000],\n",
      "          [0.5278, 0.4722, 0.0000]],\n",
      "\n",
      "         [[0.4957, 0.5043, 0.0000],\n",
      "          [0.5329, 0.4671, 0.0000],\n",
      "          [0.5220, 0.4780, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Decoder(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [DecoderLayer(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, dec_x, enc_x, self_mask=None, cross_mask=None):\n",
    "        b, t = dec_x.size()\n",
    "        x = self.embed(dec_x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_x, self_mask=self_mask, cross_mask=cross_mask)\n",
    "        return x\n",
    "\n",
    "    def get_embed_weights(self):\n",
    "        return self.embed.weight\n",
    "\n",
    "decoder = Decoder(vocab_size=32, n=2, d=16, h=2)\n",
    "# x = torch.randint(0, 32, (2, 3))\n",
    "x = torch.tensor([[15, 7, 0], [10, 0, 0], [1, 3, 0]])\n",
    "y = torch.rand(3, 3, 16)\n",
    "\n",
    "self_mask1 = build_padding_mask(x, pad_token=0)\n",
    "self_mask2 = build_causal_mask(x)\n",
    "self_mask = merge_masks(self_mask1, self_mask2)\n",
    "print(f\"self_mask: \\n {self_mask}\")\n",
    "self_mask = reshape_mask(self_mask)\n",
    "\n",
    "cross_mask = build_padding_mask(torch.tensor([[2, 2, 2], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "cross_mask = reshape_mask(cross_mask)\n",
    "print(f\"cross_mask: \\n {cross_mask}\")\n",
    "print(decoder(x, y, self_mask=self_mask, cross_mask=cross_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b5aba42-4209-4fbb-8cc9-a9e8a0236e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Output(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, d: int = 512, ff_weight = None):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Linear(d, vocab_size)\n",
    "        # weight tying with the decoder embedding\n",
    "        if ff_weight is not None:\n",
    "            self.ff.weight = ff_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2477aec-7287-498b-bf31-cbb0bdfe154d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_mask: \n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 0, 0]])\n",
      "dec_mask: \n",
      " tensor([[1, 0, 0, 0],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 1, 1, 0]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.2182,  1.4764,  0.3400],\n",
      "          [ 1.2922,  1.9110,  0.7214],\n",
      "          [ 0.2941,  0.0643, -0.1778]],\n",
      "\n",
      "         [[-0.0115, -0.0088, -0.1482],\n",
      "          [-0.4553, -0.3255, -0.4281],\n",
      "          [-0.2283, -1.7122, -0.9400]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3308,  0.2568,    -inf],\n",
      "          [ 0.1895,  0.1410,    -inf],\n",
      "          [ 0.3867,  0.4825,    -inf]],\n",
      "\n",
      "         [[-0.2505, -0.2779,    -inf],\n",
      "          [-0.0279, -0.0726,    -inf],\n",
      "          [-0.3503, -0.3737,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0320,    -inf,    -inf],\n",
      "          [ 0.2436,    -inf,    -inf],\n",
      "          [ 0.1757,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3702,    -inf,    -inf],\n",
      "          [-0.2347,    -inf,    -inf],\n",
      "          [-0.1736,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3690, 0.4777, 0.1533],\n",
      "          [0.2922, 0.5426, 0.1651],\n",
      "          [0.4135, 0.3286, 0.2579]],\n",
      "\n",
      "         [[0.3478, 0.3488, 0.3034],\n",
      "          [0.3158, 0.3596, 0.3245],\n",
      "          [0.5822, 0.1320, 0.2858]]],\n",
      "\n",
      "\n",
      "        [[[0.5185, 0.4815, 0.0000],\n",
      "          [0.5121, 0.4879, 0.0000],\n",
      "          [0.4761, 0.5239, 0.0000]],\n",
      "\n",
      "         [[0.5068, 0.4932, 0.0000],\n",
      "          [0.5112, 0.4888, 0.0000],\n",
      "          [0.5058, 0.4942, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0938, -0.6424, -0.4292],\n",
      "          [-0.5312, -0.2455,  0.5253],\n",
      "          [ 0.0223,  0.8354,  0.6609]],\n",
      "\n",
      "         [[ 0.2182, -0.4055, -0.5626],\n",
      "          [ 0.2835, -0.0418, -0.2880],\n",
      "          [-0.2336,  0.2159,  0.3558]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0045,  0.1721,    -inf],\n",
      "          [ 0.0060,  0.1832,    -inf],\n",
      "          [-0.0786, -0.1576,    -inf]],\n",
      "\n",
      "         [[ 0.4151,  0.5821,    -inf],\n",
      "          [ 0.5437,  0.6682,    -inf],\n",
      "          [-0.5089, -0.4635,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.5283,    -inf,    -inf],\n",
      "          [-0.2089,    -inf,    -inf],\n",
      "          [ 0.0272,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1579,    -inf,    -inf],\n",
      "          [-0.2248,    -inf,    -inf],\n",
      "          [-0.1086,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4827, 0.2312, 0.2861],\n",
      "          [0.1920, 0.2556, 0.5524],\n",
      "          [0.1942, 0.4380, 0.3678]],\n",
      "\n",
      "         [[0.5015, 0.2688, 0.2297],\n",
      "          [0.4372, 0.3158, 0.2469],\n",
      "          [0.2288, 0.3587, 0.4125]]],\n",
      "\n",
      "\n",
      "        [[[0.4582, 0.5418, 0.0000],\n",
      "          [0.4558, 0.5442, 0.0000],\n",
      "          [0.5197, 0.4803, 0.0000]],\n",
      "\n",
      "         [[0.4584, 0.5416, 0.0000],\n",
      "          [0.4689, 0.5311, 0.0000],\n",
      "          [0.4887, 0.5113, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0930,    -inf,    -inf,    -inf],\n",
      "          [-0.1815,    -inf,    -inf,    -inf],\n",
      "          [-0.2880,    -inf,    -inf,    -inf],\n",
      "          [-0.1543,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1754,    -inf,    -inf,    -inf],\n",
      "          [ 0.5781,    -inf,    -inf,    -inf],\n",
      "          [ 0.3429,    -inf,    -inf,    -inf],\n",
      "          [ 0.4232,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.3454,    -inf,    -inf,    -inf],\n",
      "          [-0.5371,    -inf,    -inf,    -inf],\n",
      "          [-0.5754,    -inf,    -inf,    -inf],\n",
      "          [-0.3028,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1876,    -inf,    -inf,    -inf],\n",
      "          [ 0.2534,    -inf,    -inf,    -inf],\n",
      "          [ 0.3452,    -inf,    -inf,    -inf],\n",
      "          [ 0.2890,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1564, -0.1291, -0.7823,    -inf],\n",
      "          [-0.0321,  0.1035, -1.0808,    -inf],\n",
      "          [ 0.0801, -0.2831,  0.4780,    -inf],\n",
      "          [-0.1852, -0.6110,  0.3275,    -inf]],\n",
      "\n",
      "         [[ 0.0677, -1.0044,  1.0910,    -inf],\n",
      "          [-0.5210, -0.8928, -1.5689,    -inf],\n",
      "          [ 1.6329,  0.5429,  1.4989,    -inf],\n",
      "          [ 1.2845,  0.0420,  0.9991,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4667, 0.3508, 0.1825, 0.0000],\n",
      "          [0.4007, 0.4589, 0.1404, 0.0000],\n",
      "          [0.3140, 0.2184, 0.4675, 0.0000],\n",
      "          [0.3009, 0.1966, 0.5025, 0.0000]],\n",
      "\n",
      "         [[0.2424, 0.0830, 0.6746, 0.0000],\n",
      "          [0.4902, 0.3380, 0.1719, 0.0000],\n",
      "          [0.4523, 0.1521, 0.3956, 0.0000],\n",
      "          [0.4901, 0.1415, 0.3684, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.4012, -0.3603, -0.3345],\n",
      "          [-0.1476, -0.2727,  0.1476],\n",
      "          [ 0.3724,  0.4904, -0.1954],\n",
      "          [ 0.4443,  0.4858, -0.3096]],\n",
      "\n",
      "         [[ 0.6101,  0.0297, -0.2571],\n",
      "          [ 0.1322,  0.0295,  0.1329],\n",
      "          [-0.0548,  0.6916,  0.3689],\n",
      "          [-0.3291,  0.7023,  0.5164]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0958, -0.1330,    -inf],\n",
      "          [-0.0223, -0.1363,    -inf],\n",
      "          [ 0.3523,  0.1468,    -inf],\n",
      "          [ 0.5223,  0.3783,    -inf]],\n",
      "\n",
      "         [[ 0.4928,  0.4296,    -inf],\n",
      "          [ 0.2396,  0.2319,    -inf],\n",
      "          [ 0.3285,  0.3028,    -inf],\n",
      "          [ 0.3380,  0.2608,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2275,    -inf,    -inf],\n",
      "          [-0.3571,    -inf,    -inf],\n",
      "          [ 0.2183,    -inf,    -inf],\n",
      "          [ 0.2900,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2677,    -inf,    -inf],\n",
      "          [ 0.0278,    -inf,    -inf],\n",
      "          [ 0.0049,    -inf,    -inf],\n",
      "          [ 0.0165,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3215, 0.3349, 0.3436],\n",
      "          [0.3100, 0.2735, 0.4165],\n",
      "          [0.3715, 0.4180, 0.2105],\n",
      "          [0.3979, 0.4148, 0.1872]],\n",
      "\n",
      "         [[0.5051, 0.2827, 0.2122],\n",
      "          [0.3445, 0.3108, 0.3447],\n",
      "          [0.2156, 0.4549, 0.3294],\n",
      "          [0.1630, 0.4573, 0.3797]]],\n",
      "\n",
      "\n",
      "        [[[0.5569, 0.4431, 0.0000],\n",
      "          [0.5285, 0.4715, 0.0000],\n",
      "          [0.5512, 0.4488, 0.0000],\n",
      "          [0.5360, 0.4640, 0.0000]],\n",
      "\n",
      "         [[0.5158, 0.4842, 0.0000],\n",
      "          [0.5019, 0.4981, 0.0000],\n",
      "          [0.5064, 0.4936, 0.0000],\n",
      "          [0.5193, 0.4807, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0818,    -inf,    -inf,    -inf],\n",
      "          [ 0.0185,    -inf,    -inf,    -inf],\n",
      "          [-0.2151,    -inf,    -inf,    -inf],\n",
      "          [-0.3690,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2512,    -inf,    -inf,    -inf],\n",
      "          [ 0.0572,    -inf,    -inf,    -inf],\n",
      "          [ 0.0645,    -inf,    -inf,    -inf],\n",
      "          [ 0.0217,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2040,    -inf,    -inf,    -inf],\n",
      "          [-0.6309,    -inf,    -inf,    -inf],\n",
      "          [-0.3742,    -inf,    -inf,    -inf],\n",
      "          [-0.4636,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0500,    -inf,    -inf,    -inf],\n",
      "          [-0.0415,    -inf,    -inf,    -inf],\n",
      "          [ 0.0491,    -inf,    -inf,    -inf],\n",
      "          [ 0.2002,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0489,  0.0027,  0.0329,    -inf],\n",
      "          [-0.1955,  0.2815, -0.0815,    -inf],\n",
      "          [-0.1456, -0.4718, -0.2601,    -inf],\n",
      "          [-0.1397, -0.5396,  0.3464,    -inf]],\n",
      "\n",
      "         [[-0.3083, -0.2844, -0.1651,    -inf],\n",
      "          [-0.0376, -0.1486,  0.2405,    -inf],\n",
      "          [-0.2446, -0.0679, -0.2977,    -inf],\n",
      "          [ 0.0211,  0.1579, -0.1103,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3186, 0.3355, 0.3458, 0.0000],\n",
      "          [0.2679, 0.4317, 0.3003, 0.0000],\n",
      "          [0.3826, 0.2761, 0.3412, 0.0000],\n",
      "          [0.3034, 0.2034, 0.4933, 0.0000]],\n",
      "\n",
      "         [[0.3146, 0.3223, 0.3631, 0.0000],\n",
      "          [0.3110, 0.2783, 0.4107, 0.0000],\n",
      "          [0.3183, 0.3798, 0.3019, 0.0000],\n",
      "          [0.3307, 0.3792, 0.2900, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-1.2597e-01,  5.5892e-05,  6.4758e-02],\n",
      "          [ 2.7918e-01,  1.9465e-01, -2.7041e-02],\n",
      "          [-2.0897e-01, -1.2750e-01,  1.2265e-01],\n",
      "          [-4.2258e-01, -2.0354e-01,  1.9222e-01]],\n",
      "\n",
      "         [[ 7.3790e-02,  6.0728e-02, -6.7351e-02],\n",
      "          [ 1.9131e-01,  4.3280e-01,  2.0361e-01],\n",
      "          [ 9.2601e-02, -4.0411e-01, -4.4253e-01],\n",
      "          [ 1.5760e-01, -4.3771e-01, -4.6935e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0380e-01,  5.7813e-02,        -inf],\n",
      "          [-2.1889e-01, -1.4071e-01,        -inf],\n",
      "          [-9.1705e-02, -4.9734e-02,        -inf],\n",
      "          [-7.8269e-02, -4.0125e-02,        -inf]],\n",
      "\n",
      "         [[-2.7447e-01, -3.3822e-01,        -inf],\n",
      "          [ 4.9209e-02,  8.1655e-02,        -inf],\n",
      "          [-9.0313e-02, -3.6953e-02,        -inf],\n",
      "          [-3.2764e-02,  1.4543e-02,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[-2.1321e-01,        -inf,        -inf],\n",
      "          [ 3.3159e-01,        -inf,        -inf],\n",
      "          [-3.6109e-01,        -inf,        -inf],\n",
      "          [-1.7243e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.6736e-01,        -inf,        -inf],\n",
      "          [ 9.9434e-03,        -inf,        -inf],\n",
      "          [ 5.0837e-01,        -inf,        -inf],\n",
      "          [ 4.8492e-01,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2990, 0.3392, 0.3618],\n",
      "          [0.3766, 0.3461, 0.2773],\n",
      "          [0.2875, 0.3119, 0.4006],\n",
      "          [0.2442, 0.3041, 0.4517]],\n",
      "\n",
      "         [[0.3502, 0.3457, 0.3041],\n",
      "          [0.3044, 0.3875, 0.3081],\n",
      "          [0.4558, 0.2773, 0.2669],\n",
      "          [0.4795, 0.2644, 0.2561]]],\n",
      "\n",
      "\n",
      "        [[[0.5115, 0.4885, 0.0000],\n",
      "          [0.4805, 0.5195, 0.0000],\n",
      "          [0.4895, 0.5105, 0.0000],\n",
      "          [0.4905, 0.5095, 0.0000]],\n",
      "\n",
      "         [[0.5159, 0.4841, 0.0000],\n",
      "          [0.4919, 0.5081, 0.0000],\n",
      "          [0.4867, 0.5133, 0.0000],\n",
      "          [0.4882, 0.5118, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8, embed_tying=True):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size=vocab_size, n=n, d=d, h=h)\n",
    "        self.decoder = Decoder(vocab_size=vocab_size, n=n, d=d, h=h)\n",
    "        if embed_tying:\n",
    "            self.output = Output(vocab_size=vocab_size, d=d, ff_weight = self.decoder.get_embed_weights())\n",
    "        else:\n",
    "            self.output = Output(vocab_size=vocab_size, d=d)\n",
    "\n",
    "    def forward(self, enc_x, dec_x, enc_mask=None, dec_mask=None):\n",
    "        encoded = self.encoder(enc_x, enc_mask)\n",
    "        decoded = self.decoder(dec_x=dec_x, enc_x=encoded, self_mask=dec_mask, cross_mask=enc_mask)\n",
    "        return self.output(decoded)\n",
    "\n",
    "transformer = Transformer(vocab_size=32, n=2, d=16, h=2, embed_tying=False)\n",
    "enc_x = torch.tensor([[15, 7, 3], [10, 10, 0], [1, 0, 0]])\n",
    "dec_x = torch.tensor([[21, 8, 0, 0], [25, 0, 0, 0], [8, 1, 2, 3]])\n",
    "# dec_x = torch.tensor([[21, 8], [25, 0], [8, 1]])\n",
    "\n",
    "enc_mask = build_padding_mask(enc_x, pad_token=0)\n",
    "print(f\"enc_mask: \\n {enc_mask}\")\n",
    "enc_mask = reshape_mask(enc_mask)\n",
    "\n",
    "dec_mask1 = build_padding_mask(dec_x, pad_token=0)\n",
    "dec_mask2 = build_causal_mask(dec_x)\n",
    "dec_mask = merge_masks(dec_mask1, dec_mask2)\n",
    "print(f\"dec_mask: \\n {dec_mask}\")\n",
    "dec_mask = reshape_mask(dec_mask)\n",
    "\n",
    "print(transformer(enc_x, dec_x, enc_mask=enc_mask, dec_mask=dec_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f69bab-e9a5-44a7-af1d-f294f62d3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a06c43eb-c348-4905-9384-1b28378435b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  9906,   4435, 100257, 100257, 100257],\n",
      "        [  2028,    374,    264,   4382,  11914],\n",
      "        [  7979, 100257, 100257, 100257, 100257]])\n",
      "tensor([[ 82681, 100257, 100257, 100257],\n",
      "        [    34,  17771,   6316,  17571],\n",
      "        [ 23380, 100257, 100257, 100257]])\n",
      "enc_mask: \n",
      " tensor([[1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 0, 0, 0, 0]])\n",
      "dec_mask: \n",
      " tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 0, 0, 0]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-1.2155e-01,  2.8055e-01,        -inf,        -inf,        -inf],\n",
      "          [-2.5560e-01,  3.5178e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.3659e-03,  3.8009e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.2051e-01,  9.6084e-04,        -inf,        -inf,        -inf],\n",
      "          [-3.6533e-01,  3.3893e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 5.7374e-01, -2.6784e-01,        -inf,        -inf,        -inf],\n",
      "          [-6.6826e-01, -6.0375e-01,        -inf,        -inf,        -inf],\n",
      "          [ 9.5406e-01, -6.5507e-01,        -inf,        -inf,        -inf],\n",
      "          [ 7.4121e-01, -5.9528e-01,        -inf,        -inf,        -inf],\n",
      "          [ 7.2849e-01, -5.9188e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 8.2939e-01, -4.8066e-01,        -inf,        -inf,        -inf],\n",
      "          [ 8.7839e-01,  4.8904e-01,        -inf,        -inf,        -inf],\n",
      "          [ 5.5161e-01,  3.9838e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.0213e-01,  4.8589e-02,        -inf,        -inf,        -inf],\n",
      "          [ 4.5424e-01,  7.4053e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-5.8137e-02,  8.5098e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.3224e-02,  2.1860e-01,        -inf,        -inf,        -inf],\n",
      "          [-2.9946e-01,  3.8284e-01,        -inf,        -inf,        -inf],\n",
      "          [-3.3079e-01,  1.2317e-01,        -inf,        -inf,        -inf],\n",
      "          [-5.2965e-01, -3.2547e-03,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[-9.7949e-02,  1.7140e-03, -9.9943e-02,  4.2339e-01,  6.9889e-01],\n",
      "          [-1.3035e-01, -4.0709e-01, -6.0442e-01, -3.5991e-01, -3.7426e-01],\n",
      "          [ 2.4704e-01, -4.5431e-01, -3.6219e-01,  5.1794e-01,  4.7438e-01],\n",
      "          [ 5.9567e-01, -3.5154e-01, -1.2162e+00, -1.0226e-01,  1.4194e-01],\n",
      "          [ 8.0594e-01,  2.4469e-02,  2.8483e-01,  2.4581e-01,  2.3915e-01]],\n",
      "\n",
      "         [[-5.8088e-01,  3.2166e-01, -8.5560e-01, -4.3370e-01,  2.1238e-01],\n",
      "          [-1.3002e-01, -2.3793e-01, -5.8281e-01,  4.9780e-01,  5.3047e-02],\n",
      "          [-3.6970e-01, -3.0552e-01, -2.1907e-01, -3.8163e-01, -1.6169e-01],\n",
      "          [-6.7769e-01, -3.8359e-02, -1.8446e-01,  2.1566e-01,  3.2418e-01],\n",
      "          [-3.0362e-01, -7.7516e-01,  1.9818e-01, -9.6123e-01, -3.0273e-02]],\n",
      "\n",
      "         [[ 1.1830e+00, -6.5148e-01, -8.1550e-01, -4.6388e-01,  2.7544e-01],\n",
      "          [ 5.9106e-01,  2.3358e-01,  4.3077e-01,  5.4196e-01,  8.9259e-01],\n",
      "          [ 2.7249e-01,  5.0441e-01, -2.2763e-02,  3.6646e-01, -3.9803e-01],\n",
      "          [ 9.7070e-01,  1.1446e-01,  1.8436e+00,  1.0769e+00,  1.1755e+00],\n",
      "          [-4.5226e-01, -9.8045e-02,  4.6995e-01,  6.6237e-01, -5.6952e-04]],\n",
      "\n",
      "         [[-5.8880e-01,  2.4835e-01, -2.7555e-01,  2.0865e-01,  3.5521e-01],\n",
      "          [ 4.0948e-01,  4.5584e-01, -2.5101e-01, -1.3351e-01, -1.8648e-01],\n",
      "          [ 2.4515e-01,  8.2283e-01, -3.0779e-01,  4.6973e-01, -7.7387e-02],\n",
      "          [ 1.9992e-01, -2.9506e-01, -3.4135e-01,  1.0857e+00, -5.8916e-01],\n",
      "          [ 6.2077e-01,  3.2866e-01, -1.6775e-01, -4.8819e-01, -1.9844e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7545e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.8272e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.3911e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.4379e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.3753e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-8.9859e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.4632e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.5805e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.8791e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.9959e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.6232e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.5404e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.0943e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-8.9033e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.0016e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.1625e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.1917e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-6.2181e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.8597e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-7.7960e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4008, 0.5992, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3527, 0.6473, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4058, 0.5942, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4697, 0.5303, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3309, 0.6691, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6988, 0.3012, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4839, 0.5161, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8333, 0.1667, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7919, 0.2081, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7892, 0.2108, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7875, 0.2125, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5961, 0.4039, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5382, 0.4618, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5383, 0.4617, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5939, 0.4061, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.2872, 0.7128, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4563, 0.5437, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3357, 0.6643, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3884, 0.6116, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3714, 0.6286, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1427, 0.1577, 0.1425, 0.2404, 0.3167],\n",
      "          [0.2526, 0.1915, 0.1572, 0.2008, 0.1979],\n",
      "          [0.2171, 0.1077, 0.1181, 0.2847, 0.2725],\n",
      "          [0.3726, 0.1445, 0.0609, 0.1854, 0.2367],\n",
      "          [0.3135, 0.1435, 0.1862, 0.1790, 0.1778]],\n",
      "\n",
      "         [[0.1317, 0.3247, 0.1000, 0.1525, 0.2911],\n",
      "          [0.1783, 0.1601, 0.1134, 0.3341, 0.2141],\n",
      "          [0.1835, 0.1957, 0.2134, 0.1814, 0.2260],\n",
      "          [0.1031, 0.1954, 0.1688, 0.2519, 0.2808],\n",
      "          [0.1958, 0.1222, 0.3233, 0.1014, 0.2573]],\n",
      "\n",
      "         [[0.5287, 0.0844, 0.0717, 0.1019, 0.2133],\n",
      "          [0.2060, 0.1441, 0.1755, 0.1961, 0.2784],\n",
      "          [0.2167, 0.2732, 0.1613, 0.2380, 0.1108],\n",
      "          [0.1624, 0.0690, 0.3887, 0.1806, 0.1993],\n",
      "          [0.1046, 0.1491, 0.2631, 0.3189, 0.1643]],\n",
      "\n",
      "         [[0.1056, 0.2440, 0.1445, 0.2345, 0.2715],\n",
      "          [0.2706, 0.2834, 0.1398, 0.1572, 0.1491],\n",
      "          [0.1875, 0.3341, 0.1079, 0.2347, 0.1358],\n",
      "          [0.1972, 0.1202, 0.1148, 0.4782, 0.0896],\n",
      "          [0.3365, 0.2512, 0.1529, 0.1110, 0.1483]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-3.3832e-01, -2.9628e-01,        -inf,        -inf,        -inf],\n",
      "          [-5.6804e-04, -6.4775e-01,        -inf,        -inf,        -inf],\n",
      "          [-3.9027e-02,  3.6442e-01,        -inf,        -inf,        -inf],\n",
      "          [-8.9117e-03,  3.2728e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.2956e-01,  2.4830e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.9000e-01, -3.8680e-01,        -inf,        -inf,        -inf],\n",
      "          [-4.4280e-01, -2.3327e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.0033e-01,  5.8170e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.6640e-02,  3.7537e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.2258e-01,  6.8265e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.1547e-01, -3.6854e-01,        -inf,        -inf,        -inf],\n",
      "          [ 9.8057e-02, -1.8890e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.6875e-01, -5.3116e-01,        -inf,        -inf,        -inf],\n",
      "          [ 8.5462e-02, -3.5148e-01,        -inf,        -inf,        -inf],\n",
      "          [ 7.5698e-02, -5.3455e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 7.5076e-02, -3.7666e-01,        -inf,        -inf,        -inf],\n",
      "          [ 6.7299e-02, -1.5294e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.2450e-01, -7.5913e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.6508e-01, -8.1996e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.1443e-01, -5.9629e-01,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3804e-02,  2.2876e-01, -2.1730e-01, -4.2039e-01,  1.4063e-01],\n",
      "          [-1.2206e-01, -1.8083e-01, -5.4255e-01, -5.1868e-01, -2.9996e-01],\n",
      "          [-8.9040e-02,  1.7391e-01,  2.4926e-01,  4.5605e-01,  3.7368e-02],\n",
      "          [ 3.9709e-01,  7.4561e-01,  4.4812e-01,  3.4775e-01,  3.0871e-01],\n",
      "          [ 8.1515e-02,  3.7781e-01,  2.3645e-01,  7.1709e-01,  3.1231e-01]],\n",
      "\n",
      "         [[ 1.3801e-01, -1.7001e-01,  7.0117e-02,  2.2628e-01,  1.5088e-01],\n",
      "          [-5.2752e-01, -1.7514e-01, -3.7320e-01, -1.5845e-01, -3.0119e-01],\n",
      "          [-5.2012e-02,  2.9628e-01,  4.6614e-02,  3.5064e-02, -6.3523e-02],\n",
      "          [ 3.0037e-01,  2.1562e-01, -6.0543e-01,  2.3343e-01,  1.0220e-01],\n",
      "          [ 3.2438e-01,  4.2251e-01,  1.5731e-01,  3.6533e-01, -1.2282e-01]],\n",
      "\n",
      "         [[ 3.6305e-01,  1.7071e-01,  9.9116e-01,  2.6561e-01,  7.8656e-01],\n",
      "          [ 5.0798e-02, -2.0299e-01,  2.4862e-01,  2.0138e-01,  4.1735e-02],\n",
      "          [ 1.2218e-01, -2.5178e-01,  1.6699e-01, -9.7119e-02,  1.3344e-01],\n",
      "          [ 4.7231e-01, -1.0910e-02,  1.9567e-01, -4.3891e-01, -2.2146e-01],\n",
      "          [ 4.4491e-01, -4.2632e-01, -3.5809e-03, -2.1182e-01,  5.0539e-01]],\n",
      "\n",
      "         [[ 2.0017e-01, -3.5822e-01, -4.4465e-01,  5.8213e-02,  1.8870e-01],\n",
      "          [-6.3016e-02, -1.4155e-02,  3.9432e-01, -6.8768e-01, -4.0246e-01],\n",
      "          [-3.0864e-01,  1.0732e-01, -1.2220e-01, -3.3187e-01,  1.7895e-01],\n",
      "          [-1.8979e-01, -1.2954e-01, -2.4268e-01, -4.1223e-01, -3.6864e-02],\n",
      "          [-8.5298e-01, -5.8960e-01, -2.7589e-01, -1.9150e-01, -3.6567e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2942e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.1923e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.9021e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.0341e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.4256e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.7233e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.7154e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.1723e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.3002e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.6293e-02,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.4578e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.5571e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-9.8654e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.0001e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-8.3357e-02,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.9046e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.8415e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.0549e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.0245e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.2331e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4895, 0.5105, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6564, 0.3436, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4005, 0.5995, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4167, 0.5833, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4704, 0.5296, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5242, 0.4758, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4478, 0.5522, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3819, 0.6181, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4161, 0.5839, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3635, 0.6365, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6646, 0.3354, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5713, 0.4287, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6682, 0.3318, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6075, 0.3925, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6480, 0.3520, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6111, 0.3889, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5548, 0.4452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7278, 0.2722, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7659, 0.2341, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7332, 0.2668, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2126, 0.2558, 0.1637, 0.1336, 0.2342],\n",
      "          [0.2434, 0.2295, 0.1598, 0.1637, 0.2037],\n",
      "          [0.1524, 0.1982, 0.2137, 0.2628, 0.1729],\n",
      "          [0.1874, 0.2655, 0.1972, 0.1784, 0.1715],\n",
      "          [0.1501, 0.2019, 0.1753, 0.2835, 0.1891]],\n",
      "\n",
      "         [[0.2094, 0.1539, 0.1957, 0.2288, 0.2122],\n",
      "          [0.1590, 0.2262, 0.1855, 0.2300, 0.1994],\n",
      "          [0.1786, 0.2530, 0.1971, 0.1948, 0.1765],\n",
      "          [0.2452, 0.2253, 0.0991, 0.2293, 0.2011],\n",
      "          [0.2160, 0.2382, 0.1827, 0.2250, 0.1381]],\n",
      "\n",
      "         [[0.1630, 0.1345, 0.3055, 0.1479, 0.2490],\n",
      "          [0.1942, 0.1507, 0.2367, 0.2258, 0.1925],\n",
      "          [0.2199, 0.1513, 0.2299, 0.1766, 0.2224],\n",
      "          [0.3052, 0.1882, 0.2314, 0.1227, 0.1525],\n",
      "          [0.2749, 0.1150, 0.1755, 0.1425, 0.2920]],\n",
      "\n",
      "         [[0.2530, 0.1447, 0.1327, 0.2195, 0.2501],\n",
      "          [0.2050, 0.2153, 0.3239, 0.1098, 0.1460],\n",
      "          [0.1581, 0.2396, 0.1905, 0.1544, 0.2574],\n",
      "          [0.2009, 0.2134, 0.1906, 0.1609, 0.2342],\n",
      "          [0.1308, 0.1702, 0.2329, 0.2534, 0.2129]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-2.0982e-01, -3.8134e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.5468e-01,  9.8491e-02,        -inf,        -inf,        -inf],\n",
      "          [-2.1967e-02,  5.7888e-02,        -inf,        -inf,        -inf],\n",
      "          [-6.5592e-02, -1.3547e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.3544e-01, -5.2337e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.9960e-01,  2.7265e-02,        -inf,        -inf,        -inf],\n",
      "          [ 7.8342e-01,  3.4001e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.4610e-01, -1.2807e-01,        -inf,        -inf,        -inf],\n",
      "          [ 7.6858e-01,  1.1437e-01,        -inf,        -inf,        -inf],\n",
      "          [ 5.1705e-01, -2.7719e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-4.7737e-01, -5.4825e-01,        -inf,        -inf,        -inf],\n",
      "          [-4.5562e-01, -7.5421e-01,        -inf,        -inf,        -inf],\n",
      "          [-4.7449e-02,  2.4939e-01,        -inf,        -inf,        -inf],\n",
      "          [-8.1453e-02,  1.5150e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.7910e-01,  1.5026e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.3915e-01,  1.6420e-01,        -inf,        -inf,        -inf],\n",
      "          [ 7.3696e-02,  6.0861e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.8626e-02,  2.7831e-01,        -inf,        -inf,        -inf],\n",
      "          [ 7.5963e-02,  2.6091e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.7007e-01,  4.3324e-01,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2775e-01, -2.9921e-01, -3.3554e-01, -5.6245e-01,  8.3025e-02],\n",
      "          [ 3.0092e-01, -8.9164e-01, -6.0934e-02,  1.4920e-01,  1.1417e-01],\n",
      "          [ 2.4639e-01, -2.4239e-01,  3.6380e-01, -1.3945e-01,  3.3803e-01],\n",
      "          [ 6.4001e-01, -1.3561e-02,  2.4596e-01,  1.1216e-01,  9.5992e-02],\n",
      "          [ 1.0105e-01, -6.6419e-01,  3.2768e-01, -4.5655e-01,  7.6190e-02]],\n",
      "\n",
      "         [[ 4.9086e-01, -1.5909e-01, -9.0408e-02,  2.4200e-01, -2.2874e-01],\n",
      "          [ 1.2354e-01,  1.9515e-01,  1.0004e-01, -3.2477e-02,  7.8316e-02],\n",
      "          [ 1.6814e-01, -4.2752e-01,  3.6007e-01, -5.1791e-02, -2.7358e-01],\n",
      "          [ 2.4982e-01,  1.8265e-01,  1.9273e-01,  1.3583e-01,  1.0808e-01],\n",
      "          [-2.2840e-01, -1.7615e-01,  2.0489e-01,  4.0996e-01, -1.0334e-01]],\n",
      "\n",
      "         [[ 3.8446e-01,  2.3942e-02,  3.8762e-01,  1.3225e-01,  1.2548e-01],\n",
      "          [ 8.0147e-01,  5.3589e-01,  5.6677e-01, -8.5864e-02,  3.5950e-01],\n",
      "          [-3.4526e-05,  1.0044e-01,  2.6442e-01, -3.6405e-01, -1.5522e-01],\n",
      "          [-3.4992e-01, -3.0424e-01, -1.0851e-01, -1.0092e-01, -4.0076e-01],\n",
      "          [-4.4555e-02,  1.2675e-01,  2.7186e-01, -6.9429e-02, -7.9624e-02]],\n",
      "\n",
      "         [[ 5.5063e-02,  3.1625e-01, -8.5018e-01, -5.6261e-02,  1.5020e-01],\n",
      "          [-4.6914e-02,  1.9060e-01, -5.7963e-01,  4.4133e-01,  7.5926e-01],\n",
      "          [ 6.8117e-01,  4.6233e-01,  2.9718e-01,  4.0090e-01,  1.3781e-01],\n",
      "          [ 4.9208e-02, -4.3482e-02, -3.8438e-02,  2.9400e-01, -1.5081e-02],\n",
      "          [ 2.6282e-01,  1.0359e-01,  3.2874e-02,  1.8267e-01,  1.3170e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9163e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.0998e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.1245e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.6910e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.2344e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 4.0248e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.3980e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 4.1221e-03,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-7.0072e-03,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.2559e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-4.7141e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.8438e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.0977e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.9586e-04,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.2220e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.0994e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 4.5240e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 6.0273e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 4.0389e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.4233e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5428, 0.4572, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5140, 0.4860, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4800, 0.5200, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5175, 0.4825, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4792, 0.5208, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5920, 0.4080, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6091, 0.3909, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6397, 0.3603, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6580, 0.3420, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6329, 0.3671, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5177, 0.4823, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5741, 0.4259, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4263, 0.5737, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4420, 0.5580, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4184, 0.5816, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3768, 0.6232, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3694, 0.6306, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4263, 0.5737, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4539, 0.5461, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4346, 0.5654, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2875, 0.1697, 0.1637, 0.1304, 0.2487],\n",
      "          [0.2711, 0.0823, 0.1888, 0.2329, 0.2249],\n",
      "          [0.2215, 0.1359, 0.2491, 0.1506, 0.2428],\n",
      "          [0.2972, 0.1546, 0.2004, 0.1753, 0.1725],\n",
      "          [0.2343, 0.1090, 0.2939, 0.1342, 0.2286]],\n",
      "\n",
      "         [[0.2987, 0.1559, 0.1670, 0.2329, 0.1454],\n",
      "          [0.2057, 0.2209, 0.2009, 0.1760, 0.1966],\n",
      "          [0.2376, 0.1310, 0.2879, 0.1907, 0.1528],\n",
      "          [0.2155, 0.2015, 0.2036, 0.1923, 0.1870],\n",
      "          [0.1510, 0.1591, 0.2329, 0.2859, 0.1711]],\n",
      "\n",
      "         [[0.2353, 0.1641, 0.2361, 0.1829, 0.1816],\n",
      "          [0.2768, 0.2123, 0.2189, 0.1140, 0.1779],\n",
      "          [0.2016, 0.2229, 0.2627, 0.1401, 0.1726],\n",
      "          [0.1801, 0.1885, 0.2293, 0.2310, 0.1712],\n",
      "          [0.1818, 0.2158, 0.2495, 0.1774, 0.1756]],\n",
      "\n",
      "         [[0.2129, 0.2764, 0.0861, 0.1905, 0.2341],\n",
      "          [0.1487, 0.1886, 0.0873, 0.2423, 0.3330],\n",
      "          [0.2617, 0.2103, 0.1783, 0.1977, 0.1520],\n",
      "          [0.1983, 0.1808, 0.1817, 0.2533, 0.1860],\n",
      "          [0.2248, 0.1917, 0.1787, 0.2075, 0.1972]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.6838,    -inf,    -inf,    -inf],\n",
      "          [ 0.8053,    -inf,    -inf,    -inf],\n",
      "          [ 0.1996,    -inf,    -inf,    -inf],\n",
      "          [ 0.5839,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2143,    -inf,    -inf,    -inf],\n",
      "          [ 0.0992,    -inf,    -inf,    -inf],\n",
      "          [ 0.2858,    -inf,    -inf,    -inf],\n",
      "          [ 0.3776,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2575,    -inf,    -inf,    -inf],\n",
      "          [-1.3346,    -inf,    -inf,    -inf],\n",
      "          [-0.9142,    -inf,    -inf,    -inf],\n",
      "          [-1.4446,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.8314,    -inf,    -inf,    -inf],\n",
      "          [-0.0264,    -inf,    -inf,    -inf],\n",
      "          [-0.0588,    -inf,    -inf,    -inf],\n",
      "          [ 0.1586,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.4410, -0.0877,    -inf,    -inf],\n",
      "          [ 0.2824,  1.1108,    -inf,    -inf],\n",
      "          [ 0.0162,  0.3292,    -inf,    -inf],\n",
      "          [-0.6434,  0.3739,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0563,  1.0128,    -inf,    -inf],\n",
      "          [-0.2575,  0.2901,    -inf,    -inf],\n",
      "          [ 0.5065,  0.1082,    -inf,    -inf],\n",
      "          [-0.5159,  0.4601,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1016, -0.4231,    -inf,    -inf],\n",
      "          [ 0.2079,  0.0083,    -inf,    -inf],\n",
      "          [-0.1140, -0.1743,    -inf,    -inf],\n",
      "          [ 0.2574,  0.2526,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0615, -0.2108,    -inf,    -inf],\n",
      "          [-0.2455,  0.2993,    -inf,    -inf],\n",
      "          [-0.3045,  0.8125,    -inf,    -inf],\n",
      "          [ 0.1512,  0.0567,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0424,    -inf,    -inf,    -inf],\n",
      "          [ 0.5812,    -inf,    -inf,    -inf],\n",
      "          [ 0.8334,    -inf,    -inf,    -inf],\n",
      "          [ 0.7099,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4848,    -inf,    -inf,    -inf],\n",
      "          [-0.8120,    -inf,    -inf,    -inf],\n",
      "          [-0.5940,    -inf,    -inf,    -inf],\n",
      "          [-0.6195,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.7910,    -inf,    -inf,    -inf],\n",
      "          [ 0.0800,    -inf,    -inf,    -inf],\n",
      "          [ 0.1347,    -inf,    -inf,    -inf],\n",
      "          [ 0.0797,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1047,    -inf,    -inf,    -inf],\n",
      "          [ 0.1686,    -inf,    -inf,    -inf],\n",
      "          [-0.1411,    -inf,    -inf,    -inf],\n",
      "          [-0.3888,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4126, 0.5874, 0.0000, 0.0000],\n",
      "          [0.3040, 0.6960, 0.0000, 0.0000],\n",
      "          [0.4224, 0.5776, 0.0000, 0.0000],\n",
      "          [0.2655, 0.7345, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.2556, 0.7444, 0.0000, 0.0000],\n",
      "          [0.3664, 0.6336, 0.0000, 0.0000],\n",
      "          [0.5983, 0.4017, 0.0000, 0.0000],\n",
      "          [0.2737, 0.7263, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6282, 0.3718, 0.0000, 0.0000],\n",
      "          [0.5497, 0.4503, 0.0000, 0.0000],\n",
      "          [0.5151, 0.4849, 0.0000, 0.0000],\n",
      "          [0.5012, 0.4988, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5373, 0.4627, 0.0000, 0.0000],\n",
      "          [0.3671, 0.6329, 0.0000, 0.0000],\n",
      "          [0.2466, 0.7534, 0.0000, 0.0000],\n",
      "          [0.5236, 0.4764, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-2.8929e-01, -2.6976e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.6198e-01, -2.4289e-01,        -inf,        -inf,        -inf],\n",
      "          [-2.1376e-01, -3.3139e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.9353e-01, -2.3995e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.0715e-01,  1.5523e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.4526e-01,  3.1034e-01,        -inf,        -inf,        -inf],\n",
      "          [-5.2108e-01,  2.3926e-01,        -inf,        -inf,        -inf],\n",
      "          [-3.0576e-01,  2.1774e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.1211e-01, -2.2326e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.7188e-01,  7.6083e-02,        -inf,        -inf,        -inf],\n",
      "          [ 4.8837e-01,  3.8428e-02,        -inf,        -inf,        -inf],\n",
      "          [ 3.2263e-01,  2.0496e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.7889e-01,  3.2631e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.9014e-01,  3.5105e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.3366e-01,  3.1573e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.3948e-01,  2.9172e-01,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3511e-01,  4.6180e-02, -1.3165e-01, -2.4887e-01, -1.3120e-01],\n",
      "          [ 3.1520e-01, -7.7234e-02, -3.8343e-01, -1.6981e-01,  1.1195e-02],\n",
      "          [ 5.8403e-01,  6.3435e-01,  3.7941e-01,  7.5814e-01,  1.3416e-01],\n",
      "          [ 4.8395e-01,  4.9617e-01,  3.0414e-01,  8.3415e-01,  2.8024e-01]],\n",
      "\n",
      "         [[ 2.0368e-01, -4.0801e-01,  2.5275e-01,  4.0108e-03, -7.8089e-02],\n",
      "          [ 1.4016e-01,  2.2985e-01,  3.9087e-01,  4.2433e-01,  1.8946e-01],\n",
      "          [-2.9362e-01, -2.6066e-01, -3.7734e-01,  4.5613e-02, -4.7204e-01],\n",
      "          [ 4.2622e-01,  5.6519e-01,  5.4695e-01,  2.0683e-01, -1.3125e-01]],\n",
      "\n",
      "         [[-2.9159e-01,  1.8989e-02, -8.1148e-02, -4.4431e-01,  1.2155e-01],\n",
      "          [-6.3311e-01,  1.7633e-02, -3.1166e-01,  5.1437e-02, -1.0680e-01],\n",
      "          [-4.1155e-02, -3.5333e-02, -9.3159e-02,  2.5332e-01,  1.6344e-01],\n",
      "          [ 3.0948e-01,  2.2204e-01,  3.1300e-01, -1.4548e-01,  2.2130e-01]],\n",
      "\n",
      "         [[ 2.6487e-01,  9.0257e-02,  5.8109e-01,  5.5374e-01,  3.8305e-01],\n",
      "          [ 3.2536e-01,  4.5534e-04,  3.0363e-02, -3.6872e-01, -3.8277e-02],\n",
      "          [-4.2106e-02, -3.2219e-01,  3.9968e-01,  5.4611e-01,  5.5719e-01],\n",
      "          [ 1.1221e-01,  1.3165e-01,  2.2908e-02, -8.6790e-02, -3.8969e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4489e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.2141e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.7729e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.4462e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.5638e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 8.1349e-04,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.8376e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.2274e-02,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.6477e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.3329e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.0168e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.9269e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.4031e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.1997e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.0576e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.9583e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4951, 0.5049, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5202, 0.4798, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5294, 0.4706, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5116, 0.4884, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4348, 0.5652, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3880, 0.6120, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3186, 0.6814, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3720, 0.6280, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6072, 0.3928, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5239, 0.4761, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6106, 0.3894, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5294, 0.4706, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4632, 0.5368, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5098, 0.4902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4546, 0.5454, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5369, 0.4631, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3014, 0.2043, 0.1710, 0.1521, 0.1711],\n",
      "          [0.2836, 0.1915, 0.1410, 0.1746, 0.2092],\n",
      "          [0.2130, 0.2240, 0.1736, 0.2535, 0.1358],\n",
      "          [0.1967, 0.1992, 0.1644, 0.2792, 0.1605]],\n",
      "\n",
      "         [[0.2400, 0.1302, 0.2521, 0.1966, 0.1811],\n",
      "          [0.1737, 0.1900, 0.2232, 0.2308, 0.1824],\n",
      "          [0.1925, 0.1990, 0.1771, 0.2703, 0.1611],\n",
      "          [0.2149, 0.2470, 0.2425, 0.1726, 0.1231]],\n",
      "\n",
      "         [[0.1676, 0.2286, 0.2068, 0.1438, 0.2533],\n",
      "          [0.1254, 0.2405, 0.1730, 0.2487, 0.2123],\n",
      "          [0.1810, 0.1821, 0.1718, 0.2430, 0.2221],\n",
      "          [0.2237, 0.2050, 0.2245, 0.1419, 0.2048]],\n",
      "\n",
      "         [[0.1763, 0.1481, 0.2419, 0.2353, 0.1984],\n",
      "          [0.2731, 0.1973, 0.2033, 0.1364, 0.1898],\n",
      "          [0.1442, 0.1090, 0.2244, 0.2597, 0.2626],\n",
      "          [0.2294, 0.2339, 0.2098, 0.1880, 0.1389]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0077,    -inf,    -inf,    -inf],\n",
      "          [-0.2973,    -inf,    -inf,    -inf],\n",
      "          [-0.1217,    -inf,    -inf,    -inf],\n",
      "          [-0.1576,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0350,    -inf,    -inf,    -inf],\n",
      "          [-0.0753,    -inf,    -inf,    -inf],\n",
      "          [-0.1967,    -inf,    -inf,    -inf],\n",
      "          [-0.2929,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2369,    -inf,    -inf,    -inf],\n",
      "          [ 0.0305,    -inf,    -inf,    -inf],\n",
      "          [ 0.2760,    -inf,    -inf,    -inf],\n",
      "          [ 0.1380,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3957,    -inf,    -inf,    -inf],\n",
      "          [-0.3547,    -inf,    -inf,    -inf],\n",
      "          [-0.1768,    -inf,    -inf,    -inf],\n",
      "          [-0.2801,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2128, -0.1950,    -inf,    -inf],\n",
      "          [-0.1162, -0.2686,    -inf,    -inf],\n",
      "          [ 0.1156,  0.1226,    -inf,    -inf],\n",
      "          [-0.1693, -0.3945,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1216,  0.1640,    -inf,    -inf],\n",
      "          [-0.5656,  0.3205,    -inf,    -inf],\n",
      "          [-0.0504, -0.3772,    -inf,    -inf],\n",
      "          [-0.1791, -0.2406,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6033,  0.4817,    -inf,    -inf],\n",
      "          [ 0.2168,  0.5387,    -inf,    -inf],\n",
      "          [ 0.4346, -0.0811,    -inf,    -inf],\n",
      "          [ 0.1321,  0.0940,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0506, -0.2164,    -inf,    -inf],\n",
      "          [ 0.1090, -0.2031,    -inf,    -inf],\n",
      "          [ 0.8121, -0.4082,    -inf,    -inf],\n",
      "          [ 0.5144, -0.7803,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-1.0473,    -inf,    -inf,    -inf],\n",
      "          [-0.6110,    -inf,    -inf,    -inf],\n",
      "          [-0.5468,    -inf,    -inf,    -inf],\n",
      "          [-0.4843,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0698,    -inf,    -inf,    -inf],\n",
      "          [ 0.1667,    -inf,    -inf,    -inf],\n",
      "          [ 0.5268,    -inf,    -inf,    -inf],\n",
      "          [ 0.5394,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0016,    -inf,    -inf,    -inf],\n",
      "          [ 0.3346,    -inf,    -inf,    -inf],\n",
      "          [ 0.1580,    -inf,    -inf,    -inf],\n",
      "          [ 0.3647,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1948,    -inf,    -inf,    -inf],\n",
      "          [-0.4886,    -inf,    -inf,    -inf],\n",
      "          [-0.2354,    -inf,    -inf,    -inf],\n",
      "          [-0.3226,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4955, 0.5045, 0.0000, 0.0000],\n",
      "          [0.5380, 0.4620, 0.0000, 0.0000],\n",
      "          [0.4982, 0.5018, 0.0000, 0.0000],\n",
      "          [0.5561, 0.4439, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4894, 0.5106, 0.0000, 0.0000],\n",
      "          [0.2919, 0.7081, 0.0000, 0.0000],\n",
      "          [0.5810, 0.4190, 0.0000, 0.0000],\n",
      "          [0.5154, 0.4846, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5304, 0.4696, 0.0000, 0.0000],\n",
      "          [0.4202, 0.5798, 0.0000, 0.0000],\n",
      "          [0.6261, 0.3739, 0.0000, 0.0000],\n",
      "          [0.5095, 0.4905, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5663, 0.4337, 0.0000, 0.0000],\n",
      "          [0.5774, 0.4226, 0.0000, 0.0000],\n",
      "          [0.7721, 0.2279, 0.0000, 0.0000],\n",
      "          [0.7849, 0.2151, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4514, -0.1200,    -inf,    -inf,    -inf],\n",
      "          [ 0.1797, -0.0223,    -inf,    -inf,    -inf],\n",
      "          [ 0.1011, -0.0643,    -inf,    -inf,    -inf],\n",
      "          [ 0.4328, -0.2892,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1457, -0.3609,    -inf,    -inf,    -inf],\n",
      "          [ 0.3317, -0.1660,    -inf,    -inf,    -inf],\n",
      "          [ 0.3318, -0.0218,    -inf,    -inf,    -inf],\n",
      "          [ 0.1561, -0.0943,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1819,  0.1987,    -inf,    -inf,    -inf],\n",
      "          [-0.1384, -0.4024,    -inf,    -inf,    -inf],\n",
      "          [ 0.0187, -0.1654,    -inf,    -inf,    -inf],\n",
      "          [ 0.0373, -0.4949,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5722,  0.2935,    -inf,    -inf,    -inf],\n",
      "          [ 0.2620,  0.0380,    -inf,    -inf,    -inf],\n",
      "          [ 0.1681,  0.1513,    -inf,    -inf,    -inf],\n",
      "          [ 0.2220,  0.1577,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2816, -0.0634, -0.5403, -0.1386, -0.2423],\n",
      "          [-0.2232,  0.0992,  0.0989, -0.0478,  0.0864],\n",
      "          [-0.0977,  0.1508, -0.1013,  0.1637,  0.0989],\n",
      "          [-0.3933,  0.2703,  0.0107,  0.0314,  0.3124]],\n",
      "\n",
      "         [[-0.0362, -0.0412, -0.1285, -0.0060, -0.0537],\n",
      "          [-0.1025, -0.5073, -0.4900, -0.0658, -0.6987],\n",
      "          [-0.0667, -0.0071, -0.3317, -0.0115, -0.1492],\n",
      "          [ 0.2125, -0.4996,  0.0203,  0.1765,  0.0159]],\n",
      "\n",
      "         [[ 0.3745,  0.0432, -0.0124,  0.1408,  0.4652],\n",
      "          [-0.3815, -0.0020, -0.4932, -0.2268, -0.4931],\n",
      "          [-0.1146, -0.2606, -0.1066, -0.0529, -0.2241],\n",
      "          [-0.1127, -0.3274,  0.0282,  0.0659,  0.1881]],\n",
      "\n",
      "         [[-0.3983, -0.2992,  0.4311,  0.4670,  0.1974],\n",
      "          [-0.5391, -0.0560, -0.0233,  0.1286,  0.0570],\n",
      "          [ 0.0299, -0.1537, -0.0507,  0.6587, -0.1328],\n",
      "          [-0.0025,  0.0575,  0.0057,  0.6171, -0.2669]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4052,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2318,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0437,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3647,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4508,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6796,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6144,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.7499,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3689,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2641,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.5263,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4675,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5139,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.4790,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.6188,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2410,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6391, 0.3609, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5503, 0.4497, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5413, 0.4587, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6731, 0.3269, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5536, 0.4464, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6219, 0.3781, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5875, 0.4125, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5623, 0.4377, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4958, 0.5042, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5656, 0.4344, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5459, 0.4541, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6300, 0.3700, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5692, 0.4308, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5558, 0.4442, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5042, 0.4958, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5161, 0.4839, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1919, 0.2388, 0.1482, 0.2215, 0.1996],\n",
      "          [0.1584, 0.2186, 0.2185, 0.1887, 0.2158],\n",
      "          [0.1726, 0.2213, 0.1720, 0.2241, 0.2101],\n",
      "          [0.1251, 0.2429, 0.1874, 0.1913, 0.2534]],\n",
      "\n",
      "         [[0.2032, 0.2022, 0.1853, 0.2095, 0.1997],\n",
      "          [0.2542, 0.1696, 0.1725, 0.2637, 0.1400],\n",
      "          [0.2081, 0.2208, 0.1596, 0.2199, 0.1916],\n",
      "          [0.2438, 0.1196, 0.2012, 0.2352, 0.2003]],\n",
      "\n",
      "         [[0.2334, 0.1676, 0.1585, 0.1848, 0.2556],\n",
      "          [0.1846, 0.2698, 0.1651, 0.2155, 0.1651],\n",
      "          [0.2069, 0.1788, 0.2086, 0.2201, 0.1855],\n",
      "          [0.1817, 0.1466, 0.2092, 0.2172, 0.2454]],\n",
      "\n",
      "         [[0.1165, 0.1286, 0.2669, 0.2767, 0.2113],\n",
      "          [0.1241, 0.2011, 0.2078, 0.2419, 0.2252],\n",
      "          [0.1825, 0.1519, 0.1683, 0.3422, 0.1551],\n",
      "          [0.1756, 0.1864, 0.1770, 0.3262, 0.1348]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2238,    -inf,    -inf,    -inf],\n",
      "          [-0.1131,    -inf,    -inf,    -inf],\n",
      "          [ 0.0604,    -inf,    -inf,    -inf],\n",
      "          [-0.0883,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0749,    -inf,    -inf,    -inf],\n",
      "          [-0.2379,    -inf,    -inf,    -inf],\n",
      "          [-0.2043,    -inf,    -inf,    -inf],\n",
      "          [ 0.0500,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1150,    -inf,    -inf,    -inf],\n",
      "          [ 0.3627,    -inf,    -inf,    -inf],\n",
      "          [ 0.3493,    -inf,    -inf,    -inf],\n",
      "          [ 0.5892,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2434,    -inf,    -inf,    -inf],\n",
      "          [-0.2651,    -inf,    -inf,    -inf],\n",
      "          [-0.3074,    -inf,    -inf,    -inf],\n",
      "          [-0.2452,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6209,  0.1215,    -inf,    -inf],\n",
      "          [-0.2251,  0.0773,    -inf,    -inf],\n",
      "          [-0.1331,  0.0976,    -inf,    -inf],\n",
      "          [-0.0797, -0.2191,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0617,  0.0175,    -inf,    -inf],\n",
      "          [-0.8593, -0.4154,    -inf,    -inf],\n",
      "          [ 0.0084, -0.2604,    -inf,    -inf],\n",
      "          [-0.2270, -0.0776,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6965,  0.2217,    -inf,    -inf],\n",
      "          [ 0.3010,  0.0606,    -inf,    -inf],\n",
      "          [ 0.0737, -0.5327,    -inf,    -inf],\n",
      "          [ 0.4010,  0.5985,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3646,  0.2613,    -inf,    -inf],\n",
      "          [-0.0219,  0.4018,    -inf,    -inf],\n",
      "          [ 0.2329,  0.5885,    -inf,    -inf],\n",
      "          [-0.5156, -0.0186,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.5520,    -inf,    -inf,    -inf],\n",
      "          [-0.1901,    -inf,    -inf,    -inf],\n",
      "          [-0.2409,    -inf,    -inf,    -inf],\n",
      "          [-0.2554,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.6748,    -inf,    -inf,    -inf],\n",
      "          [-0.8660,    -inf,    -inf,    -inf],\n",
      "          [-0.4327,    -inf,    -inf,    -inf],\n",
      "          [-0.5444,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0012,    -inf,    -inf,    -inf],\n",
      "          [ 0.0832,    -inf,    -inf,    -inf],\n",
      "          [ 0.2216,    -inf,    -inf,    -inf],\n",
      "          [ 0.3218,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0812,    -inf,    -inf,    -inf],\n",
      "          [-0.5231,    -inf,    -inf,    -inf],\n",
      "          [-0.4535,    -inf,    -inf,    -inf],\n",
      "          [-0.3640,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.6223, 0.3777, 0.0000, 0.0000],\n",
      "          [0.4250, 0.5750, 0.0000, 0.0000],\n",
      "          [0.4426, 0.5574, 0.0000, 0.0000],\n",
      "          [0.5348, 0.4652, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4802, 0.5198, 0.0000, 0.0000],\n",
      "          [0.3908, 0.6092, 0.0000, 0.0000],\n",
      "          [0.5668, 0.4332, 0.0000, 0.0000],\n",
      "          [0.4627, 0.5373, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6165, 0.3835, 0.0000, 0.0000],\n",
      "          [0.5598, 0.4402, 0.0000, 0.0000],\n",
      "          [0.6471, 0.3529, 0.0000, 0.0000],\n",
      "          [0.4508, 0.5492, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3484, 0.6516, 0.0000, 0.0000],\n",
      "          [0.3956, 0.6044, 0.0000, 0.0000],\n",
      "          [0.4120, 0.5880, 0.0000, 0.0000],\n",
      "          [0.3783, 0.6217, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3205,  0.2673,    -inf,    -inf,    -inf],\n",
      "          [ 0.3867,  0.0935,    -inf,    -inf,    -inf],\n",
      "          [ 0.4815,  0.1775,    -inf,    -inf,    -inf],\n",
      "          [ 0.3495,  0.3272,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3950, -0.5622,    -inf,    -inf,    -inf],\n",
      "          [-0.4708, -0.0709,    -inf,    -inf,    -inf],\n",
      "          [-0.7713, -0.2750,    -inf,    -inf,    -inf],\n",
      "          [-0.7371, -0.3976,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0036,  0.0036,    -inf,    -inf,    -inf],\n",
      "          [-0.4729, -0.0478,    -inf,    -inf,    -inf],\n",
      "          [-0.2306,  0.2106,    -inf,    -inf,    -inf],\n",
      "          [-0.4261, -0.0356,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0989,  0.3047,    -inf,    -inf,    -inf],\n",
      "          [-0.3185, -0.2166,    -inf,    -inf,    -inf],\n",
      "          [-0.3650, -0.4169,    -inf,    -inf,    -inf],\n",
      "          [-0.1867, -0.1894,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.4658,  0.0182, -0.0629, -0.0986, -0.3182],\n",
      "          [-0.3808, -0.0610, -0.1438, -0.6364,  0.2335],\n",
      "          [-0.0447, -0.3045,  0.0468, -0.2582,  0.2157],\n",
      "          [ 0.1396, -0.3351,  0.3583, -0.0763,  0.0404]],\n",
      "\n",
      "         [[-0.3900, -0.4212, -0.2224,  0.1960, -0.0728],\n",
      "          [ 0.3691, -0.2288, -0.2912,  0.0253, -0.1126],\n",
      "          [ 0.2404, -0.2831,  0.1010, -0.0431, -0.0916],\n",
      "          [ 0.4559, -0.1608, -0.4821, -0.2547, -0.3697]],\n",
      "\n",
      "         [[ 0.6513, -0.1976,  0.3433,  0.5419,  0.5761],\n",
      "          [ 0.3991,  0.0039,  0.4860,  0.6552,  0.6622],\n",
      "          [ 0.4374, -0.2980,  0.6137,  0.2787,  0.6796],\n",
      "          [ 0.7617,  0.1476,  0.2026,  0.1200,  0.3707]],\n",
      "\n",
      "         [[ 0.2076, -0.0824, -0.5126,  0.8612,  0.0682],\n",
      "          [ 0.3498,  0.4626, -0.4248,  0.7111,  0.2897],\n",
      "          [ 0.2502,  0.1725,  0.0307,  0.6181,  0.0883],\n",
      "          [ 0.2981, -0.0457, -0.2440,  0.4112,  0.3305]]],\n",
      "\n",
      "\n",
      "        [[[-0.7186,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4087,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.5189,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4524,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2804,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2265,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4124,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.3216,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1899,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0996,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1026,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0547,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4675,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4939,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4312,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.3529,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5133, 0.4867, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5728, 0.4272, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5754, 0.4246, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5056, 0.4944, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5417, 0.4583, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4013, 0.5987, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3784, 0.6216, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4159, 0.5841, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3953, 0.6047, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3915, 0.6085, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4036, 0.5964, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4487, 0.5513, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4746, 0.5254, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5130, 0.4870, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5007, 0.4993, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1488, 0.2414, 0.2226, 0.2148, 0.1724],\n",
      "          [0.1596, 0.2197, 0.2022, 0.1236, 0.2949],\n",
      "          [0.2011, 0.1551, 0.2204, 0.1624, 0.2609],\n",
      "          [0.2184, 0.1359, 0.2718, 0.1760, 0.1978]],\n",
      "\n",
      "         [[0.1582, 0.1533, 0.1870, 0.2842, 0.2172],\n",
      "          [0.2947, 0.1621, 0.1523, 0.2089, 0.1820],\n",
      "          [0.2543, 0.1506, 0.2212, 0.1915, 0.1824],\n",
      "          [0.3496, 0.1887, 0.1368, 0.1718, 0.1531]],\n",
      "\n",
      "         [[0.2508, 0.1073, 0.1843, 0.2248, 0.2327],\n",
      "          [0.1867, 0.1257, 0.2036, 0.2412, 0.2428],\n",
      "          [0.2084, 0.0999, 0.2485, 0.1778, 0.2655],\n",
      "          [0.3016, 0.1632, 0.1724, 0.1588, 0.2040]],\n",
      "\n",
      "         [[0.1989, 0.1488, 0.0968, 0.3824, 0.1730],\n",
      "          [0.2017, 0.2258, 0.0930, 0.2895, 0.1900],\n",
      "          [0.1991, 0.1842, 0.1598, 0.2876, 0.1693],\n",
      "          [0.2251, 0.1596, 0.1309, 0.2520, 0.2325]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "output shape: torch.Size([3, 4, 100277])\n",
      "softmaxed[0, 0, :10]: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)\n",
      "predicted: \n",
      " tensor([[ 82681, 100257, 100257, 100257],\n",
      "        [    34,  17771,   6316,  17571],\n",
      "        [ 23380, 100257, 100257, 100257]])\n",
      "predicted decoded: \n",
      " ['Bonjour<|endoftext|><|endoftext|><|endoftext|>', \"C'est une phrase\", 'START<|endoftext|><|endoftext|><|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "sents = [\"Hello World\", \"This is a simple sentence\", \"Me\"]\n",
    "encoded_sents = [encoding.encode(s) for s in sents]\n",
    "enc_x = pad_sequence([torch.tensor(es) for es in encoded_sents], batch_first=True, padding_value=encoding.eot_token)\n",
    "print(enc_x)\n",
    "dec_sents = [\"Bonjour\", \"C'est une phrase\", \"START\"]\n",
    "dec_encoded_sents = [encoding.encode(s) for s in dec_sents]\n",
    "dec_x = pad_sequence([torch.tensor(es) for es in dec_encoded_sents], batch_first=True, padding_value=encoding.eot_token)\n",
    "print(dec_x)\n",
    "\n",
    "transformer = Transformer(vocab_size=encoding.n_vocab, n=3, d=256, h=4)\n",
    "\n",
    "enc_mask = build_padding_mask(enc_x, pad_token=100257)\n",
    "print(f\"enc_mask: \\n {enc_mask}\")\n",
    "enc_mask = reshape_mask(enc_mask)\n",
    "\n",
    "dec_mask1 = build_padding_mask(dec_x, pad_token=100257)\n",
    "dec_mask2 = build_causal_mask(dec_x)\n",
    "dec_mask = merge_masks(dec_mask1, dec_mask2)\n",
    "print(f\"dec_mask: \\n {dec_mask}\")\n",
    "dec_mask = reshape_mask(dec_mask)\n",
    "\n",
    "output = transformer(enc_x, dec_x, enc_mask=enc_mask, dec_mask=dec_mask)\n",
    "print(f\"output shape: {output.shape}\")\n",
    "softmaxed = F.softmax(output, dim=-1)\n",
    "print(f\"softmaxed[0, 0, :10]: {softmaxed[0, 0, :10]}\")\n",
    "predicted = softmaxed.argmax(dim=-1)\n",
    "print(f\"predicted: \\n {predicted}\")\n",
    "\n",
    "predicted_list = predicted.tolist()\n",
    "predicted_decoded = [encoding.decode(l) for l in predicted_list]\n",
    "print(f\"predicted decoded: \\n {predicted_decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "693b16e4-6684-4dbb-b21b-8c3650a10bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0444, -0.4916,  0.0421,  0.0309, -0.6455],\n",
      "          [-0.5642, -0.2418, -0.6000, -0.3910,  0.1223],\n",
      "          [-0.7563, -0.6709, -0.6949,  0.4502, -0.5530],\n",
      "          [-0.9588,  0.1864,  0.0130, -0.3373, -0.6868],\n",
      "          [-0.1787,  0.8517,  0.0945, -0.6182,  0.1224]],\n",
      "\n",
      "         [[-0.5480,  0.3953, -0.1576, -0.0710, -0.0051],\n",
      "          [ 0.1514,  0.4362, -0.5188, -0.0307, -0.4017],\n",
      "          [ 0.4295,  0.4128,  0.1835,  0.0398,  0.3154],\n",
      "          [ 0.9346,  1.3585,  0.3010,  0.1890, -0.5747],\n",
      "          [ 0.8918,  0.7975,  0.6512,  0.3392,  0.2650]],\n",
      "\n",
      "         [[-0.1668,  0.0657, -0.4285, -0.0558, -0.4906],\n",
      "          [ 0.6594,  0.2603, -0.4549, -0.5408,  0.8364],\n",
      "          [ 1.0529,  0.5128, -0.0778, -0.1687,  0.3484],\n",
      "          [ 0.9814,  0.5878,  0.7433, -0.0950,  0.9049],\n",
      "          [ 0.3427,  0.8149,  0.1604,  0.2167,  0.5411]],\n",
      "\n",
      "         [[ 0.6841,  0.1972,  0.2608,  0.8136,  0.6876],\n",
      "          [ 0.2523,  0.5672, -0.1115,  0.5798,  0.3621],\n",
      "          [ 1.1886,  0.5940, -0.1762,  1.0837,  0.5443],\n",
      "          [ 0.4385, -0.4754,  0.0872, -0.0415, -0.0387],\n",
      "          [ 0.1010,  0.1317, -0.7307,  0.5343,  0.6463]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2296, 0.1468, 0.2503, 0.2475, 0.1258],\n",
      "          [0.1533, 0.2117, 0.1480, 0.1823, 0.3047],\n",
      "          [0.1295, 0.1411, 0.1377, 0.4329, 0.1587],\n",
      "          [0.1004, 0.3156, 0.2653, 0.1869, 0.1318],\n",
      "          [0.1406, 0.3940, 0.1848, 0.0906, 0.1900]],\n",
      "\n",
      "         [[0.1194, 0.3066, 0.1764, 0.1923, 0.2054],\n",
      "          [0.2353, 0.3128, 0.1204, 0.1961, 0.1353],\n",
      "          [0.2307, 0.2269, 0.1804, 0.1562, 0.2058],\n",
      "          [0.2664, 0.4070, 0.1414, 0.1264, 0.0589],\n",
      "          [0.2627, 0.2391, 0.2066, 0.1512, 0.1404]],\n",
      "\n",
      "         [[0.2052, 0.2590, 0.1580, 0.2293, 0.1485],\n",
      "          [0.2862, 0.1920, 0.0939, 0.0862, 0.3416],\n",
      "          [0.3711, 0.2162, 0.1198, 0.1094, 0.1835],\n",
      "          [0.2681, 0.1809, 0.2113, 0.0914, 0.2484],\n",
      "          [0.1806, 0.2895, 0.1505, 0.1592, 0.2202]],\n",
      "\n",
      "         [[0.2267, 0.1393, 0.1485, 0.2580, 0.2275],\n",
      "          [0.1796, 0.2460, 0.1248, 0.2492, 0.2004],\n",
      "          [0.3093, 0.1707, 0.0790, 0.2785, 0.1624],\n",
      "          [0.2990, 0.1199, 0.2105, 0.1850, 0.1856],\n",
      "          [0.1744, 0.1798, 0.0759, 0.2690, 0.3009]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 3.6020e-01, -1.4597e-01,  1.8546e-01, -2.6000e-02, -7.3826e-02],\n",
      "          [ 2.7139e-01, -4.9392e-01,  4.6479e-02, -1.8175e-01, -6.0681e-01],\n",
      "          [ 2.0189e-03, -3.4814e-01, -1.5026e-01, -2.2343e-01, -1.9591e-01],\n",
      "          [ 3.4045e-01,  1.3911e-01, -1.6062e-02,  1.7379e-01, -2.5467e-01],\n",
      "          [ 6.4764e-01, -2.7230e-02,  1.1665e-01, -1.3454e-01,  3.1366e-01]],\n",
      "\n",
      "         [[ 6.7960e-04,  6.5776e-03,  7.2008e-01, -2.3831e-01, -1.0625e-01],\n",
      "          [ 3.3943e-01,  1.2698e-01,  3.9566e-01, -2.1845e-01, -3.0309e-01],\n",
      "          [-1.2321e-02, -4.5521e-02,  5.3787e-01,  1.5380e-01,  1.0925e-01],\n",
      "          [-9.5634e-02, -3.2275e-01,  2.5132e-02, -5.6525e-01, -3.6644e-01],\n",
      "          [ 1.6760e-02,  5.3768e-02,  1.1859e-01, -2.2239e-01,  1.0826e-02]],\n",
      "\n",
      "         [[-1.9523e-01,  7.0580e-01,  3.9629e-01,  2.9200e-01,  2.0352e-01],\n",
      "          [ 2.4789e-02, -2.3665e-01, -6.7815e-02, -3.7825e-01, -3.3244e-01],\n",
      "          [-2.6460e-01,  5.1623e-01,  1.2381e-01,  1.9334e-01,  1.5001e-01],\n",
      "          [ 4.7494e-02,  8.7943e-02,  1.4268e-01, -3.4272e-02, -3.3683e-01],\n",
      "          [-1.1084e-01, -1.8256e-01, -6.0059e-02, -8.3207e-02,  3.1317e-02]],\n",
      "\n",
      "         [[-3.5316e-01,  1.6118e-01, -5.8902e-01,  1.5583e-02,  1.3548e-01],\n",
      "          [-1.1539e-01, -1.6121e-01, -3.4372e-01, -2.2575e-01,  7.5372e-02],\n",
      "          [-2.6714e-01,  1.0269e-01, -1.0736e-01,  1.4791e-01, -5.0760e-02],\n",
      "          [-1.5553e-01, -2.5994e-01, -6.2301e-01, -3.2009e-01, -2.0988e-01],\n",
      "          [ 9.4537e-02, -2.8529e-01, -3.1539e-01, -4.0314e-02,  4.0511e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2653, 0.1599, 0.2227, 0.1803, 0.1719],\n",
      "          [0.3017, 0.1403, 0.2409, 0.1917, 0.1254],\n",
      "          [0.2391, 0.1685, 0.2053, 0.1909, 0.1962],\n",
      "          [0.2554, 0.2088, 0.1788, 0.2162, 0.1408],\n",
      "          [0.3057, 0.1557, 0.1798, 0.1398, 0.2189]],\n",
      "\n",
      "         [[0.1741, 0.1751, 0.3574, 0.1371, 0.1564],\n",
      "          [0.2522, 0.2039, 0.2668, 0.1444, 0.1327],\n",
      "          [0.1664, 0.1609, 0.2884, 0.1964, 0.1879],\n",
      "          [0.2318, 0.1847, 0.2616, 0.1450, 0.1768],\n",
      "          [0.2030, 0.2106, 0.2248, 0.1598, 0.2018]],\n",
      "\n",
      "         [[0.1192, 0.2936, 0.2154, 0.1941, 0.1777],\n",
      "          [0.2470, 0.1901, 0.2251, 0.1650, 0.1728],\n",
      "          [0.1290, 0.2816, 0.1902, 0.2039, 0.1953],\n",
      "          [0.2108, 0.2195, 0.2319, 0.1943, 0.1435],\n",
      "          [0.1937, 0.1803, 0.2037, 0.1991, 0.2232]],\n",
      "\n",
      "         [[0.1529, 0.2558, 0.1208, 0.2211, 0.2493],\n",
      "          [0.2059, 0.1967, 0.1639, 0.1844, 0.2492],\n",
      "          [0.1568, 0.2270, 0.1840, 0.2375, 0.1947],\n",
      "          [0.2313, 0.2084, 0.1449, 0.1962, 0.2191],\n",
      "          [0.2181, 0.1492, 0.1447, 0.1906, 0.2975]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.8896, -0.4852,  0.2030, -0.4397, -0.2698],\n",
      "          [ 0.1827,  0.0779,  0.2882,  0.1717,  0.1295],\n",
      "          [ 0.4727, -0.1044,  0.7132,  0.3675, -0.0892],\n",
      "          [-0.3073,  0.3274, -0.0435, -0.1021, -0.0943],\n",
      "          [-0.0603,  0.1829,  0.0665, -0.1109, -0.0279]],\n",
      "\n",
      "         [[-0.5178, -0.0582,  0.3062, -0.3069, -0.2468],\n",
      "          [ 0.1438,  0.2569, -0.1943,  0.2329, -0.2349],\n",
      "          [-0.5928,  0.0900, -0.2228, -0.5661, -0.2310],\n",
      "          [ 0.4007,  0.1495,  0.2271,  0.0682,  0.0368],\n",
      "          [ 0.0369, -0.2031,  0.0590, -0.1027, -0.0657]],\n",
      "\n",
      "         [[ 0.4342,  0.6201,  0.2411, -0.0127,  0.5334],\n",
      "          [ 0.1565,  0.2598,  0.2707,  0.5538,  0.4583],\n",
      "          [ 0.2979,  0.3815, -0.0515, -0.5382,  0.2008],\n",
      "          [-0.0665, -0.0241,  0.1322, -0.1319,  0.4696],\n",
      "          [ 0.2694,  0.3536,  0.1434,  0.0252,  0.2662]],\n",
      "\n",
      "         [[-0.5526, -0.5541, -0.2138, -0.0490, -0.4051],\n",
      "          [-0.2130, -0.5852, -0.5754, -0.2373, -0.6705],\n",
      "          [-0.7443, -0.6406, -0.1959,  0.1724,  0.3166],\n",
      "          [-0.5558, -0.7160,  0.0617,  0.4104,  0.0239],\n",
      "          [-0.5683, -0.1169, -0.6735, -0.1403, -0.0146]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4284, 0.1083, 0.2156, 0.1134, 0.1344],\n",
      "          [0.2021, 0.1820, 0.2246, 0.1998, 0.1916],\n",
      "          [0.2324, 0.1305, 0.2955, 0.2092, 0.1325],\n",
      "          [0.1503, 0.2835, 0.1957, 0.1845, 0.1860],\n",
      "          [0.1854, 0.2364, 0.2104, 0.1762, 0.1915]],\n",
      "\n",
      "         [[0.1350, 0.2137, 0.3077, 0.1667, 0.1770],\n",
      "          [0.2169, 0.2429, 0.1547, 0.2371, 0.1485],\n",
      "          [0.1451, 0.2873, 0.2101, 0.1491, 0.2084],\n",
      "          [0.2481, 0.1930, 0.2086, 0.1779, 0.1724],\n",
      "          [0.2183, 0.1717, 0.2232, 0.1898, 0.1970]],\n",
      "\n",
      "         [[0.2095, 0.2523, 0.1727, 0.1340, 0.2314],\n",
      "          [0.1647, 0.1827, 0.1847, 0.2451, 0.2228],\n",
      "          [0.2420, 0.2630, 0.1706, 0.1049, 0.2196],\n",
      "          [0.1692, 0.1766, 0.2064, 0.1585, 0.2893],\n",
      "          [0.2105, 0.2290, 0.1856, 0.1649, 0.2099]],\n",
      "\n",
      "         [[0.1609, 0.1607, 0.2258, 0.2662, 0.1865],\n",
      "          [0.2504, 0.1726, 0.1743, 0.2444, 0.1584],\n",
      "          [0.1083, 0.1202, 0.1875, 0.2710, 0.3130],\n",
      "          [0.1232, 0.1049, 0.2284, 0.3237, 0.2199],\n",
      "          [0.1483, 0.2328, 0.1335, 0.2275, 0.2580]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.9102]],\n",
      "\n",
      "         [[ 0.2097]],\n",
      "\n",
      "         [[-0.7147]],\n",
      "\n",
      "         [[ 0.6357]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2946,  0.4420, -0.4618,  0.6568,  0.3166]],\n",
      "\n",
      "         [[-0.4822, -0.3030, -0.0371, -0.4457, -0.5650]],\n",
      "\n",
      "         [[-0.1097,  0.0542,  0.0980,  0.2036,  0.2191]],\n",
      "\n",
      "         [[-0.1727,  0.2132, -0.1557, -0.0441, -0.2159]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1966, 0.2278, 0.0923, 0.2824, 0.2010]],\n",
      "\n",
      "         [[0.1750, 0.2093, 0.2731, 0.1815, 0.1611]],\n",
      "\n",
      "         [[0.1622, 0.1911, 0.1996, 0.2219, 0.2253]],\n",
      "\n",
      "         [[0.1791, 0.2635, 0.1822, 0.2037, 0.1715]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2517]],\n",
      "\n",
      "         [[-0.0377]],\n",
      "\n",
      "         [[-0.6775]],\n",
      "\n",
      "         [[-0.6229]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1473,  0.1951, -0.0987, -0.5008, -0.0014]],\n",
      "\n",
      "         [[ 0.0765,  0.6766,  0.0581, -0.2141,  0.0781]],\n",
      "\n",
      "         [[ 0.1829, -0.0872, -0.2244,  0.0601,  0.1675]],\n",
      "\n",
      "         [[-0.3433, -0.2436, -0.2269, -0.2811, -0.3861]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1881, 0.2649, 0.1974, 0.1321, 0.2176]],\n",
      "\n",
      "         [[0.1801, 0.3281, 0.1768, 0.1347, 0.1804]],\n",
      "\n",
      "         [[0.2327, 0.1776, 0.1548, 0.2058, 0.2291]],\n",
      "\n",
      "         [[0.1905, 0.2104, 0.2140, 0.2027, 0.1825]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2330]],\n",
      "\n",
      "         [[ 0.0271]],\n",
      "\n",
      "         [[-0.2119]],\n",
      "\n",
      "         [[ 0.5091]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.4324,  0.0321, -0.5336,  0.3344, -0.2088]],\n",
      "\n",
      "         [[ 0.3085,  0.8908, -0.4613,  0.1214, -0.0906]],\n",
      "\n",
      "         [[ 0.5401,  0.1848, -0.1658,  0.1062, -0.1278]],\n",
      "\n",
      "         [[-0.0147, -0.5250,  0.1686,  0.1137,  0.0451]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1450, 0.2307, 0.1310, 0.3121, 0.1813]],\n",
      "\n",
      "         [[0.2104, 0.3766, 0.0974, 0.1745, 0.1411]],\n",
      "\n",
      "         [[0.2980, 0.2089, 0.1471, 0.1931, 0.1528]],\n",
      "\n",
      "         [[0.2000, 0.1201, 0.2402, 0.2274, 0.2123]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0983, -0.3308, -0.1697, -0.2698, -0.6474],\n",
      "          [-0.1506,  0.4354, -0.6289, -0.9394, -0.0252],\n",
      "          [-0.8303, -0.7559, -0.1593, -0.0065, -0.2436],\n",
      "          [-0.6180, -0.0492, -0.1236, -0.2611, -0.5280],\n",
      "          [-0.3102,  0.9262,  0.2896, -0.3280, -0.2444]],\n",
      "\n",
      "         [[ 0.0391,  0.9127, -0.5544, -0.3802, -0.1223],\n",
      "          [-0.0158,  0.2884, -0.0896,  0.5699, -0.0671],\n",
      "          [ 0.1835,  0.1810, -0.1704, -0.2586,  0.3041],\n",
      "          [ 0.7295,  1.2013, -0.4466,  0.8440, -0.5637],\n",
      "          [ 1.2049,  1.2136, -0.3423,  0.1835,  0.1232]],\n",
      "\n",
      "         [[ 0.0115, -0.0387, -0.2984, -0.1944, -0.1506],\n",
      "          [ 0.5657,  0.0125, -0.1724, -0.2931,  0.8273],\n",
      "          [ 0.8572,  0.1782,  0.4481, -0.0395,  0.2118],\n",
      "          [ 0.9211,  0.0396,  0.9743,  0.2023,  0.5085],\n",
      "          [ 0.6269,  0.9587,  0.0157, -0.0815,  0.0997]],\n",
      "\n",
      "         [[ 0.4947,  0.2536, -0.0051,  0.4403,  0.8122],\n",
      "          [ 0.3257,  0.5094,  0.0465,  0.3200,  0.6236],\n",
      "          [ 0.0926,  0.0266, -0.5299,  0.3895,  0.2169],\n",
      "          [ 0.5500,  0.0975,  0.3550,  0.3969,  0.5041],\n",
      "          [ 0.0321,  0.3867, -0.7371,  0.3249,  1.0418]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2413, 0.1913, 0.2247, 0.2033, 0.1394],\n",
      "          [0.1998, 0.3590, 0.1239, 0.0908, 0.2265],\n",
      "          [0.1233, 0.1328, 0.2412, 0.2810, 0.2217],\n",
      "          [0.1443, 0.2549, 0.2366, 0.2062, 0.1579],\n",
      "          [0.1203, 0.4141, 0.2191, 0.1181, 0.1284]],\n",
      "\n",
      "         [[0.1833, 0.4390, 0.1012, 0.1205, 0.1559],\n",
      "          [0.1658, 0.2248, 0.1540, 0.2978, 0.1575],\n",
      "          [0.2237, 0.2231, 0.1570, 0.1438, 0.2524],\n",
      "          [0.2322, 0.3722, 0.0716, 0.2603, 0.0637],\n",
      "          [0.3424, 0.3454, 0.0729, 0.1233, 0.1161]],\n",
      "\n",
      "         [[0.2299, 0.2187, 0.1687, 0.1872, 0.1955],\n",
      "          [0.2649, 0.1523, 0.1266, 0.1122, 0.3440],\n",
      "          [0.3222, 0.1634, 0.2140, 0.1314, 0.1690],\n",
      "          [0.2764, 0.1145, 0.2915, 0.1347, 0.1830],\n",
      "          [0.2488, 0.3467, 0.1350, 0.1225, 0.1469]],\n",
      "\n",
      "         [[0.2122, 0.1667, 0.1287, 0.2009, 0.2915],\n",
      "          [0.1887, 0.2268, 0.1427, 0.1876, 0.2542],\n",
      "          [0.2020, 0.1891, 0.1084, 0.2718, 0.2287],\n",
      "          [0.2341, 0.1489, 0.1926, 0.2009, 0.2236],\n",
      "          [0.1434, 0.2044, 0.0664, 0.1922, 0.3936]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3063,  0.2397,  0.0080, -0.1998,  0.2199],\n",
      "          [ 0.6244,  0.1088, -0.0657,  0.0375, -0.5490],\n",
      "          [-0.0017, -0.0097, -0.2993, -0.0084,  0.0291],\n",
      "          [ 0.3237,  0.0135, -0.0018, -0.1098, -0.6422],\n",
      "          [ 0.4807, -0.2532,  0.0925, -0.2667,  0.1173]],\n",
      "\n",
      "         [[-0.2438,  0.0271,  0.5279,  0.0186,  0.1501],\n",
      "          [ 0.3230, -0.2261,  0.6574, -0.1957, -0.1155],\n",
      "          [-0.4381,  0.3168,  0.2424,  0.3657,  0.3929],\n",
      "          [-0.0683,  0.2341,  0.5541, -0.0590,  0.1003],\n",
      "          [-0.1151,  0.0858,  0.0752,  0.0641,  0.0991]],\n",
      "\n",
      "         [[-0.2540,  0.5458,  0.3653,  0.4665,  0.2709],\n",
      "          [ 0.4814, -0.1238,  0.1091, -0.4141, -0.3636],\n",
      "          [-0.2059, -0.0418,  0.2194,  0.2007,  0.1494],\n",
      "          [ 0.0412,  0.1075,  0.3920,  0.2391, -0.0413],\n",
      "          [-0.0332,  0.1173, -0.1311, -0.2689, -0.1496]],\n",
      "\n",
      "         [[-0.3311,  0.4823, -0.2482, -0.1449,  0.3757],\n",
      "          [ 0.4437,  0.0112,  0.0164,  0.4482,  0.1777],\n",
      "          [ 0.0801,  0.0911,  0.1410,  0.2291,  0.2881],\n",
      "          [ 0.1379, -0.2285, -0.1670, -0.3998, -0.2270],\n",
      "          [ 0.2227,  0.1521, -0.3284,  0.0242,  0.2883]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2382, 0.2229, 0.1768, 0.1436, 0.2185],\n",
      "          [0.3374, 0.2015, 0.1692, 0.1876, 0.1044],\n",
      "          [0.2101, 0.2084, 0.1560, 0.2087, 0.2167],\n",
      "          [0.2870, 0.2104, 0.2073, 0.1860, 0.1092],\n",
      "          [0.3006, 0.1443, 0.2039, 0.1423, 0.2090]],\n",
      "\n",
      "         [[0.1378, 0.1807, 0.2981, 0.1791, 0.2043],\n",
      "          [0.2373, 0.1370, 0.3315, 0.1412, 0.1530],\n",
      "          [0.1038, 0.2209, 0.2050, 0.2319, 0.2383],\n",
      "          [0.1560, 0.2111, 0.2907, 0.1575, 0.1847],\n",
      "          [0.1704, 0.2084, 0.2062, 0.2039, 0.2112]],\n",
      "\n",
      "         [[0.1133, 0.2520, 0.2104, 0.2328, 0.1915],\n",
      "          [0.3254, 0.1777, 0.2243, 0.1329, 0.1398],\n",
      "          [0.1507, 0.1775, 0.2306, 0.2263, 0.2150],\n",
      "          [0.1777, 0.1899, 0.2523, 0.2166, 0.1636],\n",
      "          [0.2106, 0.2448, 0.1909, 0.1663, 0.1874]],\n",
      "\n",
      "         [[0.1320, 0.2978, 0.1434, 0.1590, 0.2677],\n",
      "          [0.2456, 0.1594, 0.1602, 0.2467, 0.1882],\n",
      "          [0.1830, 0.1850, 0.1944, 0.2124, 0.2253],\n",
      "          [0.2696, 0.1869, 0.1988, 0.1575, 0.1872],\n",
      "          [0.2275, 0.2120, 0.1311, 0.1865, 0.2429]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.8640, -0.3822,  0.4415, -0.0222,  0.2750],\n",
      "          [-0.0228,  0.2220,  0.2915, -0.2198,  0.2699],\n",
      "          [ 0.5263, -0.2507,  0.3154, -0.1575,  0.1059],\n",
      "          [-0.3288,  0.1091,  0.1471, -0.0593, -0.1952],\n",
      "          [-0.3961, -0.0686, -0.0750, -0.5743,  0.3281]],\n",
      "\n",
      "         [[-0.4447, -0.2471,  0.0744, -0.3130, -0.1962],\n",
      "          [ 0.0576,  0.1817,  0.3529,  0.0852,  0.1749],\n",
      "          [-0.5157,  0.0485, -0.1419, -0.5504,  0.0140],\n",
      "          [-0.2986,  0.1920, -0.0563, -0.0862, -0.0330],\n",
      "          [-0.3590, -0.4010, -0.3822, -0.2804,  0.2687]],\n",
      "\n",
      "         [[ 0.4242,  0.5449,  0.6199, -0.0372,  0.4680],\n",
      "          [ 0.2652,  0.5984,  0.2021,  0.0207,  0.5387],\n",
      "          [ 0.5966,  0.8185,  0.3749, -0.3577,  0.7131],\n",
      "          [-0.1183,  0.4463,  0.6883,  0.1107,  0.4305],\n",
      "          [ 0.1729,  0.4513,  0.4887,  0.4629,  0.2516]],\n",
      "\n",
      "         [[-0.3644, -0.5172, -0.2101, -0.1133, -0.5256],\n",
      "          [-0.5043, -0.7268, -0.6463, -0.2147, -0.4967],\n",
      "          [-0.7942, -0.2177, -0.4745,  0.0933,  0.0242],\n",
      "          [ 0.0195, -0.1749, -0.2643,  0.3269,  0.3557],\n",
      "          [-0.4739, -0.0249, -0.7642,  0.1628, -0.0019]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3436, 0.0988, 0.2252, 0.1416, 0.1907],\n",
      "          [0.1722, 0.2199, 0.2358, 0.1414, 0.2307],\n",
      "          [0.2914, 0.1340, 0.2360, 0.1471, 0.1914],\n",
      "          [0.1513, 0.2344, 0.2435, 0.1980, 0.1729],\n",
      "          [0.1500, 0.2081, 0.2068, 0.1255, 0.3095]],\n",
      "\n",
      "         [[0.1582, 0.1927, 0.2658, 0.1804, 0.2028],\n",
      "          [0.1777, 0.2011, 0.2387, 0.1827, 0.1998],\n",
      "          [0.1454, 0.2557, 0.2114, 0.1405, 0.2470],\n",
      "          [0.1551, 0.2533, 0.1976, 0.1918, 0.2023],\n",
      "          [0.1698, 0.1628, 0.1659, 0.1836, 0.3180]],\n",
      "\n",
      "         [[0.1992, 0.2248, 0.2423, 0.1256, 0.2081],\n",
      "          [0.1841, 0.2569, 0.1728, 0.1442, 0.2420],\n",
      "          [0.2194, 0.2739, 0.1758, 0.0845, 0.2465],\n",
      "          [0.1252, 0.2202, 0.2805, 0.1574, 0.2167],\n",
      "          [0.1636, 0.2162, 0.2244, 0.2187, 0.1770]],\n",
      "\n",
      "         [[0.1937, 0.1663, 0.2261, 0.2490, 0.1649],\n",
      "          [0.1995, 0.1597, 0.1731, 0.2666, 0.2011],\n",
      "          [0.1130, 0.2011, 0.1555, 0.2744, 0.2561],\n",
      "          [0.1874, 0.1543, 0.1411, 0.2549, 0.2623],\n",
      "          [0.1469, 0.2301, 0.1099, 0.2776, 0.2355]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.9349, -0.7853],\n",
      "          [-1.0878, -1.1926]],\n",
      "\n",
      "         [[ 0.2239,  0.1245],\n",
      "          [-0.0210, -0.0261]],\n",
      "\n",
      "         [[-0.3889, -0.4495],\n",
      "          [-0.1816, -0.2075]],\n",
      "\n",
      "         [[ 0.8329,  0.7030],\n",
      "          [ 0.5995,  0.4734]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4627, 0.5373],\n",
      "          [0.5262, 0.4738]],\n",
      "\n",
      "         [[0.5248, 0.4752],\n",
      "          [0.5013, 0.4987]],\n",
      "\n",
      "         [[0.5151, 0.4849],\n",
      "          [0.5065, 0.4935]],\n",
      "\n",
      "         [[0.5324, 0.4676],\n",
      "          [0.5315, 0.4685]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0169,  0.2128, -0.4000,  0.5251,  0.3965],\n",
      "          [ 0.2295,  0.1727, -0.3287,  0.4004,  0.4093]],\n",
      "\n",
      "         [[-0.6252, -0.2813, -0.3531, -0.5448, -0.7347],\n",
      "          [-0.3307, -0.2541,  0.2920, -0.1940, -0.3924]],\n",
      "\n",
      "         [[-0.1754,  0.0349, -0.1962,  0.1526, -0.0080],\n",
      "          [-0.2071, -0.1356, -0.0913,  0.2574,  0.0848]],\n",
      "\n",
      "         [[ 0.0268,  0.3549, -0.0422,  0.1185, -0.3864],\n",
      "          [-0.2002,  0.0656, -0.2544, -0.3337, -0.6081]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1620, 0.2039, 0.1105, 0.2786, 0.2450],\n",
      "          [0.2041, 0.1928, 0.1168, 0.2421, 0.2443]],\n",
      "\n",
      "         [[0.1753, 0.2473, 0.2302, 0.1900, 0.1572],\n",
      "          [0.1658, 0.1790, 0.3091, 0.1901, 0.1559]],\n",
      "\n",
      "         [[0.1729, 0.2134, 0.1693, 0.2400, 0.2044],\n",
      "          [0.1632, 0.1753, 0.1833, 0.2597, 0.2185]],\n",
      "\n",
      "         [[0.1969, 0.2733, 0.1838, 0.2158, 0.1302],\n",
      "          [0.2087, 0.2722, 0.1977, 0.1826, 0.1388]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2825, -0.1044],\n",
      "          [ 0.0505,  0.1639]],\n",
      "\n",
      "         [[ 0.1265,  0.0045],\n",
      "          [ 0.1447, -0.2801]],\n",
      "\n",
      "         [[-0.6061, -0.1625],\n",
      "          [-0.5452, -0.2522]],\n",
      "\n",
      "         [[-0.4505, -0.6961],\n",
      "          [-0.5478, -0.6817]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4556, 0.5444],\n",
      "          [0.4717, 0.5283]],\n",
      "\n",
      "         [[0.5305, 0.4695],\n",
      "          [0.6046, 0.3954]],\n",
      "\n",
      "         [[0.3909, 0.6091],\n",
      "          [0.4273, 0.5727]],\n",
      "\n",
      "         [[0.5611, 0.4389],\n",
      "          [0.5334, 0.4666]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3339,  0.1776, -0.1526, -0.6262,  0.1802],\n",
      "          [ 0.1801,  0.2796, -0.3017, -0.4741,  0.3112]],\n",
      "\n",
      "         [[ 0.1894,  0.3651, -0.0411,  0.0045,  0.3534],\n",
      "          [ 0.3401,  0.0963, -0.1623, -0.0295, -0.1119]],\n",
      "\n",
      "         [[ 0.1158, -0.0717,  0.0674, -0.2091, -0.3716],\n",
      "          [ 0.4091,  0.0836, -0.2578, -0.1990, -0.0698]],\n",
      "\n",
      "         [[ 0.0267,  0.2419,  0.0153, -0.1329, -0.3813],\n",
      "          [-0.2259,  0.1163, -0.2890, -0.1074, -0.3888]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2695, 0.2305, 0.1657, 0.1032, 0.2311],\n",
      "          [0.2282, 0.2521, 0.1410, 0.1186, 0.2602]],\n",
      "\n",
      "         [[0.2002, 0.2386, 0.1590, 0.1664, 0.2358],\n",
      "          [0.2691, 0.2109, 0.1628, 0.1860, 0.1712]],\n",
      "\n",
      "         [[0.2428, 0.2013, 0.2313, 0.1754, 0.1491],\n",
      "          [0.2942, 0.2124, 0.1510, 0.1601, 0.1822]],\n",
      "\n",
      "         [[0.2107, 0.2613, 0.2083, 0.1796, 0.1401],\n",
      "          [0.1879, 0.2645, 0.1764, 0.2115, 0.1596]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2389,  0.3197],\n",
      "          [ 0.1415,  0.2755]],\n",
      "\n",
      "         [[ 0.1201, -0.0505],\n",
      "          [-0.1647, -0.3657]],\n",
      "\n",
      "         [[-0.5342, -0.5480],\n",
      "          [-0.4296, -0.4400]],\n",
      "\n",
      "         [[ 0.0867,  0.0434],\n",
      "          [-0.0973, -0.0747]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4798, 0.5202],\n",
      "          [0.4666, 0.5334]],\n",
      "\n",
      "         [[0.5425, 0.4575],\n",
      "          [0.5501, 0.4499]],\n",
      "\n",
      "         [[0.5035, 0.4965],\n",
      "          [0.5026, 0.4974]],\n",
      "\n",
      "         [[0.5108, 0.4892],\n",
      "          [0.4943, 0.5057]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-2.1958e-01,  3.1331e-01, -2.5418e-01,  2.0098e-01,  5.2325e-03],\n",
      "          [-5.4265e-01, -1.1348e-01, -5.0607e-01, -4.7604e-02, -2.5008e-01]],\n",
      "\n",
      "         [[ 4.8682e-01,  8.1972e-01, -3.3258e-01,  1.3023e-01,  2.8960e-01],\n",
      "          [ 3.4704e-01,  6.7240e-01, -4.8759e-01,  8.1679e-04,  1.4009e-01]],\n",
      "\n",
      "         [[ 2.6438e-01, -2.2836e-01,  7.7107e-02, -9.7703e-02,  1.4337e-01],\n",
      "          [ 2.6678e-01, -4.7184e-01,  1.0074e-01,  2.0594e-01, -1.5226e-01]],\n",
      "\n",
      "         [[-2.0600e-01, -2.1939e-01, -1.6725e-01, -2.9382e-02, -1.5918e-02],\n",
      "          [-3.3712e-01, -2.9763e-01,  8.7281e-02,  2.4152e-01,  2.9458e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1552, 0.2644, 0.1499, 0.2363, 0.1943],\n",
      "          [0.1526, 0.2344, 0.1583, 0.2503, 0.2044]],\n",
      "\n",
      "         [[0.2295, 0.3202, 0.1012, 0.1607, 0.1884],\n",
      "          [0.2305, 0.3191, 0.1000, 0.1630, 0.1874]],\n",
      "\n",
      "         [[0.2486, 0.1519, 0.2061, 0.1731, 0.2203],\n",
      "          [0.2549, 0.1218, 0.2159, 0.2398, 0.1676]],\n",
      "\n",
      "         [[0.1842, 0.1818, 0.1915, 0.2198, 0.2228],\n",
      "          [0.1382, 0.1438, 0.2113, 0.2466, 0.2600]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2123, -0.2039, -0.0156, -0.6594, -0.6437],\n",
      "          [-0.0813,  0.1638, -0.7272, -0.7668,  0.4938],\n",
      "          [-0.3988, -0.6912,  0.1683,  0.1366, -0.1414],\n",
      "          [-0.3730,  0.3252, -0.2619, -0.6752, -0.3017],\n",
      "          [-0.7661,  0.0797,  0.2742, -0.1670, -0.1059]],\n",
      "\n",
      "         [[-0.2285,  0.7105, -0.3654,  0.0055, -0.1327],\n",
      "          [-0.1354,  0.5890, -0.0693,  0.5045, -0.8314],\n",
      "          [ 0.3848,  0.1542,  0.2434, -0.0499,  0.3961],\n",
      "          [ 0.8929,  1.5074,  0.2175,  0.6440, -0.2600],\n",
      "          [ 0.6696,  0.8664,  0.0901,  0.1687,  0.2441]],\n",
      "\n",
      "         [[ 0.0834, -0.1973, -0.1721, -0.1405, -0.1960],\n",
      "          [ 0.7608,  0.1883, -0.8344, -0.1786,  1.3853],\n",
      "          [ 0.9079,  0.3873,  0.0539, -0.3962,  0.3284],\n",
      "          [ 0.9291,  0.2818,  0.8956,  0.2720,  0.7662],\n",
      "          [-0.0091,  0.8700, -0.1892,  0.3576,  0.2442]],\n",
      "\n",
      "         [[ 0.8437,  0.5750,  0.2268,  0.4479,  0.5743],\n",
      "          [ 0.0499,  0.5721,  0.0338,  0.4771,  0.3025],\n",
      "          [ 1.2329,  0.7414, -0.4659,  0.7114,  0.2736],\n",
      "          [ 0.2596, -0.0039,  0.2695,  0.0431, -0.1338],\n",
      "          [ 0.0980,  0.1383, -0.4281,  0.6357,  0.5343]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2215, 0.2234, 0.2696, 0.1416, 0.1439],\n",
      "          [0.1967, 0.2514, 0.1031, 0.0991, 0.3496],\n",
      "          [0.1536, 0.1146, 0.2708, 0.2623, 0.1987],\n",
      "          [0.1683, 0.3384, 0.1881, 0.1244, 0.1808],\n",
      "          [0.1009, 0.2350, 0.2854, 0.1836, 0.1952]],\n",
      "\n",
      "         [[0.1472, 0.3764, 0.1284, 0.1860, 0.1620],\n",
      "          [0.1532, 0.3162, 0.1637, 0.2905, 0.0764],\n",
      "          [0.2314, 0.1838, 0.2009, 0.1498, 0.2341],\n",
      "          [0.2246, 0.4152, 0.1143, 0.1751, 0.0709],\n",
      "          [0.2477, 0.3016, 0.1388, 0.1501, 0.1619]],\n",
      "\n",
      "         [[0.2448, 0.1849, 0.1896, 0.1957, 0.1851],\n",
      "          [0.2484, 0.1402, 0.0504, 0.0971, 0.4639],\n",
      "          [0.3507, 0.2084, 0.1493, 0.0952, 0.1965],\n",
      "          [0.2592, 0.1357, 0.2506, 0.1343, 0.2202],\n",
      "          [0.1434, 0.3453, 0.1197, 0.2069, 0.1847]],\n",
      "\n",
      "         [[0.2673, 0.2043, 0.1442, 0.1799, 0.2042],\n",
      "          [0.1541, 0.2597, 0.1516, 0.2362, 0.1984],\n",
      "          [0.3608, 0.2207, 0.0660, 0.2142, 0.1382],\n",
      "          [0.2348, 0.1804, 0.2372, 0.1891, 0.1585],\n",
      "          [0.1698, 0.1767, 0.1003, 0.2906, 0.2626]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 2.7370e-01,  1.2263e-01,  8.7545e-02, -5.6183e-01,  1.3719e-01],\n",
      "          [ 6.3417e-01, -2.6459e-01, -4.6628e-02, -2.8629e-01, -4.0541e-01],\n",
      "          [ 5.3206e-02, -2.4877e-01, -4.9080e-01, -2.0899e-01, -3.7432e-01],\n",
      "          [ 5.4914e-01,  3.8726e-02,  1.9417e-01,  8.3410e-02, -3.4760e-01],\n",
      "          [ 5.9692e-01, -4.4643e-01,  3.1776e-01, -1.7139e-01,  7.3098e-02]],\n",
      "\n",
      "         [[ 3.5490e-02,  1.2100e-01,  4.0794e-01,  2.1326e-01,  3.3865e-01],\n",
      "          [ 2.8804e-01, -2.6861e-02,  1.3754e-01, -2.6581e-01, -1.1654e-01],\n",
      "          [-1.3830e-01, -1.5112e-02, -2.4262e-02,  6.6993e-02, -4.5474e-03],\n",
      "          [-1.4268e-01, -1.9598e-01,  2.9965e-01, -4.4724e-01,  1.3420e-01],\n",
      "          [ 8.8779e-02,  2.0097e-01,  2.4641e-01,  2.3805e-01,  1.4220e-01]],\n",
      "\n",
      "         [[-1.8380e-01,  8.3724e-01,  3.3035e-01,  4.9757e-01,  9.0408e-02],\n",
      "          [ 2.2479e-01, -4.3613e-02,  2.9939e-01, -2.5848e-01,  2.8376e-01],\n",
      "          [-2.3391e-01,  2.3729e-01,  2.5381e-01,  3.7059e-01,  1.4917e-01],\n",
      "          [ 1.8620e-01,  3.0328e-01,  2.2478e-01,  1.5762e-01,  1.0449e-01],\n",
      "          [-1.9675e-03,  3.1128e-02, -2.9674e-01, -2.6121e-01, -6.7664e-02]],\n",
      "\n",
      "         [[-4.3250e-01,  3.6899e-01, -3.5531e-01, -1.3611e-01,  1.9768e-01],\n",
      "          [ 1.0416e-01, -3.4413e-01, -1.6478e-02,  2.2658e-01,  4.6960e-02],\n",
      "          [ 1.1826e-01,  3.3357e-02, -3.1248e-02,  5.7502e-01, -3.5440e-05],\n",
      "          [-1.2502e-01, -3.0050e-01, -9.8802e-02, -3.0384e-01, -2.3713e-01],\n",
      "          [ 4.4620e-01,  3.6655e-01, -4.2384e-01, -8.9600e-02,  6.0085e-02]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2503, 0.2152, 0.2077, 0.1085, 0.2183],\n",
      "          [0.3752, 0.1527, 0.1899, 0.1495, 0.1327],\n",
      "          [0.2673, 0.1976, 0.1551, 0.2056, 0.1743],\n",
      "          [0.2997, 0.1799, 0.2101, 0.1881, 0.1222],\n",
      "          [0.3160, 0.1113, 0.2390, 0.1466, 0.1871]],\n",
      "\n",
      "         [[0.1642, 0.1789, 0.2383, 0.1962, 0.2224],\n",
      "          [0.2610, 0.1905, 0.2245, 0.1500, 0.1741],\n",
      "          [0.1778, 0.2012, 0.1993, 0.2184, 0.2033],\n",
      "          [0.1798, 0.1705, 0.2799, 0.1326, 0.2372],\n",
      "          [0.1816, 0.2032, 0.2127, 0.2109, 0.1916]],\n",
      "\n",
      "         [[0.1144, 0.3176, 0.1913, 0.2261, 0.1505],\n",
      "          [0.2213, 0.1692, 0.2384, 0.1365, 0.2347],\n",
      "          [0.1328, 0.2128, 0.2163, 0.2431, 0.1949],\n",
      "          [0.1977, 0.2223, 0.2055, 0.1922, 0.1822],\n",
      "          [0.2229, 0.2304, 0.1660, 0.1720, 0.2087]],\n",
      "\n",
      "         [[0.1328, 0.2959, 0.1434, 0.1786, 0.2493],\n",
      "          [0.2174, 0.1389, 0.1927, 0.2457, 0.2053],\n",
      "          [0.1906, 0.1751, 0.1641, 0.3009, 0.1693],\n",
      "          [0.2176, 0.1826, 0.2234, 0.1820, 0.1945],\n",
      "          [0.2772, 0.2560, 0.1161, 0.1622, 0.1884]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.1486e+00, -2.3639e-01,  1.7781e-01, -3.4935e-01, -1.3452e-01],\n",
      "          [ 1.9000e-01,  3.8145e-01,  4.9461e-01, -1.0701e-01,  3.0068e-01],\n",
      "          [ 6.3678e-01, -2.3305e-01,  7.1115e-01,  2.4072e-01,  8.3272e-02],\n",
      "          [-4.7621e-01,  1.6770e-01,  2.0406e-01, -2.6358e-01, -2.0985e-01],\n",
      "          [-2.3494e-01,  1.1944e-01,  1.2801e-01, -4.4962e-01,  2.5426e-01]],\n",
      "\n",
      "         [[-6.4566e-01, -2.4721e-01,  2.2342e-01,  1.1492e-01, -2.1216e-01],\n",
      "          [ 1.6069e-01, -2.5170e-02,  4.2269e-01,  1.3708e-01,  1.2546e-01],\n",
      "          [-4.9428e-01,  3.2939e-01, -2.6280e-01, -5.1746e-01, -1.2007e-01],\n",
      "          [-5.2600e-01, -3.7315e-02,  1.0606e-01,  8.4034e-02,  1.2288e-01],\n",
      "          [-3.2262e-01, -3.7729e-01, -1.7618e-01,  1.7871e-01,  3.7063e-01]],\n",
      "\n",
      "         [[ 5.2373e-01,  2.2568e-01,  6.3057e-01,  1.5382e-01,  1.6182e-01],\n",
      "          [ 3.6341e-01,  6.0960e-01,  2.8268e-01,  3.5529e-01,  4.6162e-01],\n",
      "          [ 2.2436e-01,  4.4123e-01,  1.4640e-01, -7.4521e-02,  6.4348e-01],\n",
      "          [ 9.3375e-02,  2.6550e-01,  1.9745e-01,  1.8480e-01,  4.0177e-01],\n",
      "          [ 1.7550e-01,  5.2165e-01,  3.1815e-01,  4.7086e-01,  6.0739e-01]],\n",
      "\n",
      "         [[-1.0856e-01, -3.5004e-01, -1.8714e-01, -4.0460e-01, -5.3114e-01],\n",
      "          [-4.2746e-01, -5.6735e-01, -6.4011e-01, -2.6066e-01, -4.7989e-01],\n",
      "          [-5.2180e-01, -9.1778e-02, -2.5857e-01, -1.1546e-01,  1.5581e-01],\n",
      "          [-1.7415e-01, -1.1152e-01, -6.4212e-02,  4.6008e-01,  2.9085e-02],\n",
      "          [-8.9519e-02,  4.5695e-01, -4.9626e-01,  6.7283e-02, -6.5689e-04]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4695, 0.1175, 0.1778, 0.1050, 0.1301],\n",
      "          [0.1843, 0.2231, 0.2499, 0.1369, 0.2058],\n",
      "          [0.2671, 0.1119, 0.2877, 0.1797, 0.1536],\n",
      "          [0.1348, 0.2566, 0.2661, 0.1667, 0.1759],\n",
      "          [0.1587, 0.2262, 0.2282, 0.1280, 0.2589]],\n",
      "\n",
      "         [[0.1169, 0.1741, 0.2787, 0.2500, 0.1803],\n",
      "          [0.1972, 0.1637, 0.2562, 0.1926, 0.1903],\n",
      "          [0.1435, 0.3269, 0.1808, 0.1402, 0.2086],\n",
      "          [0.1210, 0.1972, 0.2276, 0.2227, 0.2315],\n",
      "          [0.1480, 0.1401, 0.1714, 0.2444, 0.2961]],\n",
      "\n",
      "         [[0.2357, 0.1750, 0.2623, 0.1628, 0.1641],\n",
      "          [0.1888, 0.2415, 0.1742, 0.1873, 0.2083],\n",
      "          [0.1842, 0.2288, 0.1704, 0.1366, 0.2801],\n",
      "          [0.1738, 0.2064, 0.1928, 0.1904, 0.2366],\n",
      "          [0.1550, 0.2191, 0.1788, 0.2083, 0.2388]],\n",
      "\n",
      "         [[0.2434, 0.1912, 0.2250, 0.1810, 0.1595],\n",
      "          [0.2080, 0.1808, 0.1681, 0.2457, 0.1974],\n",
      "          [0.1368, 0.2103, 0.1780, 0.2054, 0.2694],\n",
      "          [0.1589, 0.1692, 0.1774, 0.2997, 0.1948],\n",
      "          [0.1768, 0.3054, 0.1177, 0.2068, 0.1932]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.6338, -0.6986, -0.9414, -0.6746],\n",
      "          [-0.8268, -0.8104, -0.7216, -0.8103],\n",
      "          [-0.6653, -0.6905, -0.6542, -0.7239],\n",
      "          [-0.9647, -0.9906, -0.7808, -0.9177]],\n",
      "\n",
      "         [[ 0.0094, -0.2152, -0.1958, -0.0718],\n",
      "          [ 0.3612,  0.0777, -0.1209,  0.1521],\n",
      "          [ 0.2364,  0.1013, -0.0295,  0.1400],\n",
      "          [ 0.3204,  0.2336,  0.0625,  0.0115]],\n",
      "\n",
      "         [[-0.7158, -0.5121, -0.7536, -0.5836],\n",
      "          [-0.5685, -0.4613, -0.4481, -0.3886],\n",
      "          [-0.5363, -0.4433, -0.4708, -0.3102],\n",
      "          [-1.0461, -0.9407, -1.1549, -1.1165]],\n",
      "\n",
      "         [[ 0.4592,  0.5625,  0.3117,  0.3586],\n",
      "          [ 0.7697,  0.8195,  0.6678,  0.7264],\n",
      "          [ 0.7218,  0.8436,  0.4559,  0.6312],\n",
      "          [ 1.3384,  1.2889,  0.8734,  1.0962]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2753, 0.2580, 0.2024, 0.2643],\n",
      "          [0.2413, 0.2453, 0.2681, 0.2453],\n",
      "          [0.2545, 0.2482, 0.2573, 0.2400],\n",
      "          [0.2367, 0.2307, 0.2845, 0.2481]],\n",
      "\n",
      "         [[0.2829, 0.2260, 0.2304, 0.2608],\n",
      "          [0.3143, 0.2367, 0.1941, 0.2550],\n",
      "          [0.2818, 0.2462, 0.2160, 0.2559],\n",
      "          [0.2921, 0.2678, 0.2257, 0.2145]],\n",
      "\n",
      "         [[0.2309, 0.2831, 0.2224, 0.2636],\n",
      "          [0.2253, 0.2508, 0.2541, 0.2697],\n",
      "          [0.2263, 0.2484, 0.2416, 0.2837],\n",
      "          [0.2538, 0.2820, 0.2276, 0.2365]],\n",
      "\n",
      "         [[0.2580, 0.2861, 0.2226, 0.2333],\n",
      "          [0.2556, 0.2687, 0.2309, 0.2448],\n",
      "          [0.2625, 0.2965, 0.2012, 0.2398],\n",
      "          [0.2972, 0.2828, 0.1867, 0.2333]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0927,  0.1786,  0.0220,  0.3866,  0.4112],\n",
      "          [ 0.0663,  0.2363,  0.0193,  0.5172,  0.3340],\n",
      "          [-0.1559,  0.3886, -0.0144,  0.3953,  0.2481],\n",
      "          [-0.0143,  0.2187,  0.0113,  0.0829,  0.3828]],\n",
      "\n",
      "         [[-0.3971, -0.0885,  0.4715, -0.5170, -0.4351],\n",
      "          [-0.2624, -0.1593,  0.3642, -0.4525, -0.2953],\n",
      "          [-0.2554,  0.0044,  0.3147, -0.5446, -0.5511],\n",
      "          [-0.5315, -0.1459, -0.1206, -0.5955, -0.5524]],\n",
      "\n",
      "         [[-0.0245,  0.1309,  0.0045,  0.0882,  0.3762],\n",
      "          [-0.0258,  0.1828, -0.1247,  0.0997, -0.0996],\n",
      "          [-0.2769, -0.0972, -0.1610,  0.0554,  0.1994],\n",
      "          [ 0.1428,  0.0344, -0.1017,  0.0395,  0.1200]],\n",
      "\n",
      "         [[-0.0158,  0.1783,  0.1012,  0.0806, -0.2756],\n",
      "          [-0.3151,  0.2811,  0.0761,  0.1443, -0.1775],\n",
      "          [ 0.0433,  0.2464,  0.0781,  0.0208,  0.0715],\n",
      "          [-0.1782,  0.0744,  0.0017, -0.0013, -0.0614]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1743, 0.1899, 0.1624, 0.2338, 0.2396],\n",
      "          [0.1662, 0.1970, 0.1586, 0.2609, 0.2172],\n",
      "          [0.1407, 0.2425, 0.1620, 0.2441, 0.2107],\n",
      "          [0.1701, 0.2148, 0.1745, 0.1875, 0.2531]],\n",
      "\n",
      "         [[0.1516, 0.2065, 0.3614, 0.1345, 0.1460],\n",
      "          [0.1732, 0.1920, 0.3241, 0.1432, 0.1676],\n",
      "          [0.1799, 0.2333, 0.3182, 0.1347, 0.1339],\n",
      "          [0.1696, 0.2494, 0.2558, 0.1591, 0.1661]],\n",
      "\n",
      "         [[0.1721, 0.2011, 0.1772, 0.1927, 0.2570],\n",
      "          [0.1923, 0.2369, 0.1742, 0.2180, 0.1786],\n",
      "          [0.1581, 0.1892, 0.1776, 0.2204, 0.2546],\n",
      "          [0.2193, 0.1968, 0.1717, 0.1978, 0.2144]],\n",
      "\n",
      "         [[0.1919, 0.2330, 0.2157, 0.2113, 0.1480],\n",
      "          [0.1424, 0.2584, 0.2105, 0.2254, 0.1634],\n",
      "          [0.1899, 0.2326, 0.1966, 0.1856, 0.1953],\n",
      "          [0.1724, 0.2219, 0.2063, 0.2057, 0.1937]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1709, -0.1349, -0.0349, -0.4252],\n",
      "          [-0.2433, -0.2415, -0.1135, -0.4409],\n",
      "          [-0.1767, -0.1063, -0.0301, -0.4252],\n",
      "          [-0.1559, -0.1740,  0.0015, -0.4052]],\n",
      "\n",
      "         [[-0.0846, -0.1239, -0.1147, -0.1495],\n",
      "          [ 0.1542,  0.0654,  0.1146, -0.0532],\n",
      "          [ 0.0327,  0.0560,  0.1296, -0.0459],\n",
      "          [-0.0488, -0.1004, -0.0103, -0.2298]],\n",
      "\n",
      "         [[-0.4677, -0.5747, -0.2611, -0.2640],\n",
      "          [-0.5144, -0.5559, -0.3223, -0.4034],\n",
      "          [-0.4973, -0.5881, -0.3581, -0.3925],\n",
      "          [-0.4822, -0.5190, -0.4085, -0.4564]],\n",
      "\n",
      "         [[-0.6416, -0.7195, -0.6645, -0.4233],\n",
      "          [-0.5376, -0.6280, -0.5724, -0.4009],\n",
      "          [-0.6490, -0.7161, -0.6266, -0.3309],\n",
      "          [-0.6206, -0.6125, -0.4453, -0.2794]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2527, 0.2619, 0.2895, 0.1959],\n",
      "          [0.2525, 0.2529, 0.2874, 0.2072],\n",
      "          [0.2493, 0.2675, 0.2887, 0.1945],\n",
      "          [0.2543, 0.2498, 0.2977, 0.1982]],\n",
      "\n",
      "         [[0.2585, 0.2485, 0.2508, 0.2422],\n",
      "          [0.2711, 0.2480, 0.2606, 0.2203],\n",
      "          [0.2469, 0.2527, 0.2721, 0.2283],\n",
      "          [0.2616, 0.2484, 0.2718, 0.2183]],\n",
      "\n",
      "         [[0.2297, 0.2064, 0.2824, 0.2816],\n",
      "          [0.2332, 0.2237, 0.2826, 0.2605],\n",
      "          [0.2396, 0.2188, 0.2754, 0.2661],\n",
      "          [0.2459, 0.2370, 0.2647, 0.2523]],\n",
      "\n",
      "         [[0.2412, 0.2231, 0.2357, 0.3000],\n",
      "          [0.2484, 0.2269, 0.2399, 0.2848],\n",
      "          [0.2308, 0.2158, 0.2361, 0.3173],\n",
      "          [0.2171, 0.2189, 0.2587, 0.3054]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1025,  0.1601, -0.2289, -0.0935, -0.1531],\n",
      "          [ 0.0826,  0.2286, -0.2396, -0.4464, -0.2673],\n",
      "          [ 0.0850,  0.3485, -0.0110, -0.2153, -0.3718],\n",
      "          [ 0.0151,  0.5130, -0.4208, -0.6191, -0.6877]],\n",
      "\n",
      "         [[-0.1637,  0.6759,  0.2105, -0.0425,  0.3102],\n",
      "          [ 0.0671,  0.3969,  0.3253, -0.1115, -0.0981],\n",
      "          [-0.1581,  0.5470,  0.0478, -0.0937, -0.0342],\n",
      "          [ 0.1053,  0.4273,  0.0687, -0.1203, -0.0961]],\n",
      "\n",
      "         [[ 0.3972,  0.4530,  0.3210,  0.1128,  0.0246],\n",
      "          [ 0.3114,  0.4120,  0.0116, -0.0497, -0.2139],\n",
      "          [ 0.2182,  0.5324,  0.1861, -0.4480, -0.2685],\n",
      "          [ 0.1914,  0.1272,  0.1066, -0.2856, -0.1970]],\n",
      "\n",
      "         [[-0.3615, -0.3794, -0.0153, -0.4566, -0.3207],\n",
      "          [-0.4403, -0.3630, -0.1662, -0.5751, -0.5098],\n",
      "          [-0.1842, -0.2230, -0.0558, -0.4834, -0.1369],\n",
      "          [-0.3971, -0.0555,  0.0094, -0.4548, -0.1975]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2286, 0.2422, 0.1641, 0.1879, 0.1771],\n",
      "          [0.2395, 0.2771, 0.1735, 0.1411, 0.1688],\n",
      "          [0.2182, 0.2839, 0.1982, 0.1616, 0.1382],\n",
      "          [0.2316, 0.3811, 0.1498, 0.1228, 0.1147]],\n",
      "\n",
      "         [[0.1333, 0.3086, 0.1937, 0.1504, 0.2140],\n",
      "          [0.1862, 0.2590, 0.2411, 0.1558, 0.1579],\n",
      "          [0.1550, 0.3137, 0.1904, 0.1653, 0.1755],\n",
      "          [0.2016, 0.2782, 0.1944, 0.1609, 0.1649]],\n",
      "\n",
      "         [[0.2260, 0.2389, 0.2094, 0.1700, 0.1557],\n",
      "          [0.2418, 0.2674, 0.1792, 0.1685, 0.1430],\n",
      "          [0.2239, 0.3066, 0.2168, 0.1150, 0.1376],\n",
      "          [0.2407, 0.2257, 0.2211, 0.1494, 0.1632]],\n",
      "\n",
      "         [[0.1870, 0.1837, 0.2644, 0.1701, 0.1948],\n",
      "          [0.1922, 0.2077, 0.2528, 0.1680, 0.1793],\n",
      "          [0.2046, 0.1968, 0.2326, 0.1516, 0.2145],\n",
      "          [0.1646, 0.2317, 0.2472, 0.1554, 0.2010]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2494,  0.1051,  0.2901,  0.3513],\n",
      "          [ 0.3225,  0.0411,  0.4465,  0.2874],\n",
      "          [ 0.3316,  0.1395,  0.4868,  0.4607],\n",
      "          [ 0.2080, -0.0717,  0.3126,  0.2020]],\n",
      "\n",
      "         [[ 0.0115, -0.1228, -0.1660, -0.1637],\n",
      "          [ 0.0987, -0.1936, -0.1070, -0.1762],\n",
      "          [-0.2031, -0.3426, -0.2287, -0.3521],\n",
      "          [ 0.0229, -0.2029, -0.0294, -0.1148]],\n",
      "\n",
      "         [[-0.5099, -0.3730, -0.4765, -0.4709],\n",
      "          [-0.3596, -0.3818, -0.3140, -0.4569],\n",
      "          [-0.4970, -0.4239, -0.4536, -0.4936],\n",
      "          [-0.5549, -0.4225, -0.3023, -0.3573]],\n",
      "\n",
      "         [[-0.0527, -0.2450, -0.2042,  0.1424],\n",
      "          [ 0.0422, -0.0081, -0.0558,  0.2348],\n",
      "          [-0.1261, -0.2941, -0.3322, -0.0631],\n",
      "          [-0.0967, -0.0126, -0.0816,  0.1025]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2491, 0.2156, 0.2595, 0.2758],\n",
      "          [0.2596, 0.1959, 0.2939, 0.2506],\n",
      "          [0.2421, 0.1998, 0.2827, 0.2754],\n",
      "          [0.2590, 0.1958, 0.2876, 0.2575]],\n",
      "\n",
      "         [[0.2816, 0.2462, 0.2358, 0.2364],\n",
      "          [0.3012, 0.2248, 0.2452, 0.2288],\n",
      "          [0.2698, 0.2347, 0.2630, 0.2325],\n",
      "          [0.2764, 0.2205, 0.2623, 0.2408]],\n",
      "\n",
      "         [[0.2369, 0.2717, 0.2450, 0.2464],\n",
      "          [0.2543, 0.2487, 0.2662, 0.2307],\n",
      "          [0.2425, 0.2609, 0.2533, 0.2433],\n",
      "          [0.2152, 0.2456, 0.2770, 0.2622]],\n",
      "\n",
      "         [[0.2564, 0.2116, 0.2204, 0.3117],\n",
      "          [0.2457, 0.2337, 0.2228, 0.2979],\n",
      "          [0.2685, 0.2270, 0.2185, 0.2860],\n",
      "          [0.2313, 0.2516, 0.2348, 0.2823]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-5.9106e-01,  1.9226e-01, -2.4584e-01,  6.7024e-02, -1.2126e-01],\n",
      "          [-6.6096e-01, -1.9306e-01, -2.8277e-01,  3.6592e-01, -1.2969e-01],\n",
      "          [-5.2472e-01, -9.4156e-02, -2.3411e-01,  1.4819e-01, -1.7496e-01],\n",
      "          [-6.6323e-01, -1.1625e-01, -5.8538e-02,  2.8121e-01, -3.1796e-01]],\n",
      "\n",
      "         [[ 1.8513e-01,  9.5700e-01, -4.5881e-01, -2.1280e-01,  6.9371e-02],\n",
      "          [ 4.6861e-02,  7.9186e-01, -4.5211e-01, -3.0826e-01, -7.0279e-02],\n",
      "          [ 8.4058e-02,  8.4624e-01, -3.3953e-01,  8.0804e-02, -9.8286e-02],\n",
      "          [ 2.1440e-01,  7.0554e-01, -3.5415e-01, -1.8292e-01,  1.6032e-01]],\n",
      "\n",
      "         [[ 3.7799e-01, -1.0240e-01,  1.1327e-01,  5.8846e-03, -1.5890e-01],\n",
      "          [ 6.1563e-01, -1.4514e-01,  2.1822e-01,  1.0445e-01, -5.5960e-02],\n",
      "          [ 6.5585e-01, -1.4130e-01,  5.3839e-02, -1.2516e-01, -1.5493e-01],\n",
      "          [ 5.2890e-01, -8.4404e-02, -2.0460e-01, -4.2626e-03, -6.0915e-02]],\n",
      "\n",
      "         [[-4.4987e-05, -1.4119e-01, -7.8088e-02, -1.7503e-01,  8.6478e-03],\n",
      "          [-1.2175e-01, -1.1376e-01,  9.0420e-02, -1.6626e-01, -6.8096e-02],\n",
      "          [ 1.8054e-01, -2.3487e-01,  2.8027e-02,  7.6140e-02, -8.9553e-03],\n",
      "          [ 7.3186e-02, -9.9458e-02, -1.1021e-01,  9.0352e-03,  1.6551e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1230, 0.2692, 0.1737, 0.2375, 0.1967],\n",
      "          [0.1170, 0.1867, 0.1707, 0.3266, 0.1990],\n",
      "          [0.1379, 0.2120, 0.1843, 0.2702, 0.1956],\n",
      "          [0.1171, 0.2023, 0.2143, 0.3010, 0.1653]],\n",
      "\n",
      "         [[0.1904, 0.4120, 0.1000, 0.1279, 0.1696],\n",
      "          [0.1885, 0.3971, 0.1145, 0.1322, 0.1677],\n",
      "          [0.1777, 0.3808, 0.1163, 0.1771, 0.1481],\n",
      "          [0.2075, 0.3390, 0.1175, 0.1394, 0.1965]],\n",
      "\n",
      "         [[0.2732, 0.1690, 0.2097, 0.1883, 0.1597],\n",
      "          [0.3077, 0.1438, 0.2068, 0.1845, 0.1572],\n",
      "          [0.3447, 0.1553, 0.1888, 0.1579, 0.1532],\n",
      "          [0.3162, 0.1712, 0.1518, 0.1855, 0.1753]],\n",
      "\n",
      "         [[0.2154, 0.1871, 0.1993, 0.1809, 0.2173],\n",
      "          [0.1903, 0.1918, 0.2352, 0.1820, 0.2007],\n",
      "          [0.2355, 0.1554, 0.2022, 0.2121, 0.1948],\n",
      "          [0.2124, 0.1787, 0.1768, 0.1992, 0.2329]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2986,  0.1827, -0.2165, -0.1652, -0.5472],\n",
      "          [-1.0089,  0.3804, -0.6770, -0.2439, -0.0037],\n",
      "          [-0.4344, -0.5246, -0.0629,  0.4030,  0.1941],\n",
      "          [-0.6778,  0.2178,  0.0580, -0.2503, -0.4641],\n",
      "          [-0.0750,  0.6896, -0.2766, -0.6125, -0.0652]],\n",
      "\n",
      "         [[-0.2393,  0.5946, -0.0793, -0.0327,  0.0142],\n",
      "          [ 0.1110,  0.5029, -0.4950,  0.0468, -0.6508],\n",
      "          [ 0.3190,  0.5585,  0.1072,  0.1982,  0.2054],\n",
      "          [ 0.6025,  1.7233,  0.5788,  0.6646, -0.3411],\n",
      "          [ 0.6188,  0.8624,  0.0852,  0.3282,  0.2134]],\n",
      "\n",
      "         [[-0.1054, -0.2859, -0.3653, -0.4626, -0.5866],\n",
      "          [ 0.5379, -0.0293, -0.4517, -0.1013,  1.2852],\n",
      "          [ 0.7919,  0.6799,  0.1648, -0.1063,  0.2458],\n",
      "          [ 0.4712,  0.3250,  0.5391,  0.0977,  0.7091],\n",
      "          [-0.1633,  0.8438, -0.0277,  0.3907,  0.0629]],\n",
      "\n",
      "         [[ 0.5607,  0.8465,  0.1283,  0.6482,  1.0075],\n",
      "          [-0.0817,  0.6895,  0.0254,  0.4520,  0.1938],\n",
      "          [ 0.8438,  0.3817, -0.6688,  0.5280,  0.6105],\n",
      "          [ 0.1741, -0.3065,  0.2937,  0.2498,  0.2706],\n",
      "          [-0.0990,  0.2232, -0.8138,  0.2010,  0.2329]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2820, 0.2511, 0.1685, 0.1773, 0.1210],\n",
      "          [0.0886, 0.3555, 0.1235, 0.1904, 0.2421],\n",
      "          [0.1325, 0.1210, 0.1921, 0.3060, 0.2484],\n",
      "          [0.1204, 0.2948, 0.2512, 0.1846, 0.1490],\n",
      "          [0.1799, 0.3864, 0.1470, 0.1051, 0.1816]],\n",
      "\n",
      "         [[0.1430, 0.3292, 0.1678, 0.1758, 0.1842],\n",
      "          [0.2257, 0.3340, 0.1231, 0.2117, 0.1054],\n",
      "          [0.2058, 0.2615, 0.1665, 0.1824, 0.1837],\n",
      "          [0.1539, 0.4721, 0.1503, 0.1638, 0.0599],\n",
      "          [0.2338, 0.2983, 0.1371, 0.1748, 0.1559]],\n",
      "\n",
      "         [[0.2549, 0.2128, 0.1965, 0.1783, 0.1575],\n",
      "          [0.2184, 0.1239, 0.0812, 0.1153, 0.4612],\n",
      "          [0.2929, 0.2618, 0.1564, 0.1193, 0.1696],\n",
      "          [0.2045, 0.1766, 0.2188, 0.1407, 0.2593],\n",
      "          [0.1270, 0.3476, 0.1454, 0.2209, 0.1592]],\n",
      "\n",
      "         [[0.1775, 0.2362, 0.1152, 0.1937, 0.2775],\n",
      "          [0.1370, 0.2963, 0.1525, 0.2337, 0.1805],\n",
      "          [0.2966, 0.1869, 0.0654, 0.2163, 0.2349],\n",
      "          [0.2030, 0.1256, 0.2288, 0.2190, 0.2236],\n",
      "          [0.1782, 0.2459, 0.0872, 0.2405, 0.2483]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2594,  0.1873, -0.0805, -0.2372,  0.0267],\n",
      "          [ 0.2214, -0.3058, -0.3246, -0.5089, -0.5649],\n",
      "          [-0.1704,  0.0211, -0.4134, -0.2893, -0.1387],\n",
      "          [ 0.5394,  0.1155,  0.3388,  0.0630, -0.2861],\n",
      "          [ 0.1282, -0.3309,  0.0148, -0.1938,  0.2489]],\n",
      "\n",
      "         [[ 0.3416,  0.3280,  0.5739,  0.3233,  0.1404],\n",
      "          [ 0.6256, -0.0029,  0.1455, -0.3788, -0.0259],\n",
      "          [-0.3500,  0.2162,  0.0221,  0.1663, -0.0642],\n",
      "          [-0.1854,  0.0255,  0.5434, -0.4496,  0.1912],\n",
      "          [ 0.3977,  0.2716,  0.2338,  0.0499,  0.3578]],\n",
      "\n",
      "         [[ 0.2702,  0.7726,  0.6437,  0.2757, -0.0659],\n",
      "          [ 0.0928, -0.0524,  0.1916, -0.4370, -0.0921],\n",
      "          [-0.7193,  0.1545,  0.0356,  0.1587,  0.2263],\n",
      "          [-0.3071,  0.1019,  0.3470,  0.0747,  0.1788],\n",
      "          [-0.0333,  0.6200,  0.1866, -0.0937,  0.4712]],\n",
      "\n",
      "         [[-0.2930,  0.4980, -0.1720, -0.3969,  0.1891],\n",
      "          [-0.0721, -0.2411, -0.0160,  0.2718, -0.1496],\n",
      "          [ 0.0721, -0.1110,  0.2882,  0.3003,  0.0528],\n",
      "          [-0.1870, -0.0969, -0.1757, -0.0970,  0.0957],\n",
      "          [-0.1152,  0.2324, -0.2246, -0.0393, -0.0565]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2473, 0.2301, 0.1761, 0.1505, 0.1960],\n",
      "          [0.3219, 0.1900, 0.1865, 0.1551, 0.1466],\n",
      "          [0.2034, 0.2464, 0.1596, 0.1806, 0.2100],\n",
      "          [0.2832, 0.1853, 0.2317, 0.1758, 0.1240],\n",
      "          [0.2284, 0.1443, 0.2039, 0.1656, 0.2577]],\n",
      "\n",
      "         [[0.1981, 0.1954, 0.2499, 0.1945, 0.1620],\n",
      "          [0.3290, 0.1755, 0.2036, 0.1205, 0.1715],\n",
      "          [0.1385, 0.2440, 0.2010, 0.2321, 0.1844],\n",
      "          [0.1531, 0.1890, 0.3173, 0.1175, 0.2231],\n",
      "          [0.2274, 0.2005, 0.1930, 0.1606, 0.2185]],\n",
      "\n",
      "         [[0.1717, 0.2837, 0.2494, 0.1726, 0.1227],\n",
      "          [0.2279, 0.1971, 0.2515, 0.1342, 0.1894],\n",
      "          [0.0952, 0.2281, 0.2025, 0.2291, 0.2451],\n",
      "          [0.1330, 0.2002, 0.2558, 0.1948, 0.2162],\n",
      "          [0.1478, 0.2841, 0.1842, 0.1391, 0.2448]],\n",
      "\n",
      "         [[0.1459, 0.3218, 0.1646, 0.1315, 0.2363],\n",
      "          [0.1909, 0.1612, 0.2019, 0.2693, 0.1767],\n",
      "          [0.1883, 0.1568, 0.2337, 0.2366, 0.1847],\n",
      "          [0.1809, 0.1980, 0.1830, 0.1980, 0.2401],\n",
      "          [0.1834, 0.2597, 0.1644, 0.1979, 0.1945]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.1349, -0.2467, -0.2143, -0.4702, -0.3978],\n",
      "          [-0.0454,  0.3553,  0.4477, -0.0086,  0.5846],\n",
      "          [ 0.4995, -0.4370,  0.5553, -0.2602,  0.2407],\n",
      "          [-0.4566,  0.4324,  0.2037, -0.1860, -0.2055],\n",
      "          [-0.3697,  0.3775,  0.0249, -0.3044,  0.3013]],\n",
      "\n",
      "         [[-0.5890, -0.4270,  0.4317, -0.3698, -0.1115],\n",
      "          [ 0.6899, -0.0204,  0.4677,  0.2051, -0.2620],\n",
      "          [-0.4464,  0.3085, -0.0058, -0.1739,  0.2403],\n",
      "          [-0.3202,  0.1015, -0.0441,  0.2022,  0.0963],\n",
      "          [-0.4750, -0.2378, -0.4341,  0.1836,  0.3858]],\n",
      "\n",
      "         [[ 0.3769,  0.5784,  0.5381, -0.3135,  0.4374],\n",
      "          [-0.2027,  0.4258,  0.1203,  0.1817,  0.5434],\n",
      "          [ 0.1464,  0.4527,  0.4228, -0.4762,  0.1599],\n",
      "          [ 0.0210,  0.3608,  0.3695, -0.2076,  0.2360],\n",
      "          [ 0.3585,  0.4103,  0.2581,  0.2296,  0.1545]],\n",
      "\n",
      "         [[ 0.3156, -0.6132,  0.2853, -0.0161, -0.4032],\n",
      "          [-0.3888, -0.5035, -0.5633, -0.3348, -0.5071],\n",
      "          [-0.5280, -0.1210, -0.1925,  0.3323,  0.1357],\n",
      "          [-0.3400,  0.0550, -0.1975,  0.3709, -0.0465],\n",
      "          [-0.1643,  0.0958, -0.2203,  0.0039,  0.0425]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5188, 0.1303, 0.1346, 0.1042, 0.1120],\n",
      "          [0.1419, 0.2119, 0.2324, 0.1473, 0.2665],\n",
      "          [0.2711, 0.1063, 0.2866, 0.1268, 0.2092],\n",
      "          [0.1256, 0.3055, 0.2430, 0.1646, 0.1614],\n",
      "          [0.1313, 0.2771, 0.1948, 0.1401, 0.2568]],\n",
      "\n",
      "         [[0.1281, 0.1506, 0.3554, 0.1595, 0.2065],\n",
      "          [0.3036, 0.1492, 0.2431, 0.1869, 0.1172],\n",
      "          [0.1253, 0.2665, 0.1947, 0.1645, 0.2490],\n",
      "          [0.1419, 0.2164, 0.1871, 0.2393, 0.2153],\n",
      "          [0.1315, 0.1667, 0.1369, 0.2540, 0.3109]],\n",
      "\n",
      "         [[0.2015, 0.2465, 0.2368, 0.1010, 0.2141],\n",
      "          [0.1277, 0.2393, 0.1763, 0.1875, 0.2692],\n",
      "          [0.1913, 0.2599, 0.2522, 0.1027, 0.1939],\n",
      "          [0.1707, 0.2398, 0.2419, 0.1358, 0.2117],\n",
      "          [0.2149, 0.2264, 0.1944, 0.1890, 0.1753]],\n",
      "\n",
      "         [[0.2801, 0.1106, 0.2717, 0.2010, 0.1365],\n",
      "          [0.2139, 0.1907, 0.1796, 0.2258, 0.1900],\n",
      "          [0.1218, 0.1831, 0.1704, 0.2880, 0.2366],\n",
      "          [0.1426, 0.2116, 0.1644, 0.2902, 0.1912],\n",
      "          [0.1768, 0.2293, 0.1672, 0.2092, 0.2174]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[-6.7771e-01, -8.2619e-01, -8.2893e-01, -8.6848e-01, -1.0192e+00,\n",
      "           -7.9605e-01, -8.1676e-01, -1.0501e+00],\n",
      "          [-7.1991e-01, -7.7929e-01, -8.8248e-01, -9.3866e-01, -1.0168e+00,\n",
      "           -6.6490e-01, -7.1654e-01, -8.8902e-01],\n",
      "          [-1.0360e+00, -1.0551e+00, -1.0379e+00, -1.1587e+00, -1.2639e+00,\n",
      "           -1.0563e+00, -1.0695e+00, -1.1833e+00],\n",
      "          [-1.0395e+00, -9.7941e-01, -1.0579e+00, -1.1562e+00, -1.4357e+00,\n",
      "           -1.2437e+00, -1.2284e+00, -1.2070e+00],\n",
      "          [-1.1258e+00, -9.1316e-01, -8.8437e-01, -9.7056e-01, -1.1780e+00,\n",
      "           -1.1351e+00, -1.2546e+00, -1.2707e+00],\n",
      "          [-5.3312e-01, -4.5477e-01, -5.8793e-01, -5.7690e-01, -8.3462e-01,\n",
      "           -6.3545e-01, -7.1554e-01, -8.3564e-01],\n",
      "          [-6.6828e-01, -5.3794e-01, -5.3998e-01, -4.6072e-01, -8.0225e-01,\n",
      "           -5.6146e-01, -7.8343e-01, -8.6504e-01],\n",
      "          [-9.7631e-01, -8.2423e-01, -8.3187e-01, -8.8134e-01, -1.0297e+00,\n",
      "           -1.0377e+00, -1.1726e+00, -1.1947e+00]],\n",
      "\n",
      "         [[-2.2760e-02, -8.3287e-02,  1.9738e-01,  4.9457e-02, -3.5097e-02,\n",
      "           -1.7992e-01,  1.3905e-01,  3.0331e-02],\n",
      "          [-4.0225e-01, -3.1672e-01, -2.4720e-01, -4.5214e-01, -4.4328e-01,\n",
      "           -6.2589e-01, -2.9402e-01, -3.8059e-01],\n",
      "          [-4.1271e-02, -6.3223e-02,  9.2450e-02,  3.6725e-02,  6.3224e-02,\n",
      "           -1.3369e-01, -6.2862e-02, -4.4811e-02],\n",
      "          [ 1.5781e-01,  2.1164e-01,  3.5354e-01,  4.0455e-01,  2.9433e-01,\n",
      "            1.1118e-01,  3.1025e-01,  3.1483e-01],\n",
      "          [-1.9792e-01, -1.2051e-01, -2.1546e-01, -9.2471e-02, -2.7714e-01,\n",
      "           -3.4520e-01, -7.4488e-02, -9.1737e-02],\n",
      "          [-9.4613e-02, -1.6974e-02,  1.0998e-03,  6.1248e-02, -1.1581e-01,\n",
      "           -1.9389e-01,  5.9564e-02,  1.0838e-01],\n",
      "          [ 4.2480e-02, -6.9220e-02, -2.6422e-02,  1.2225e-02, -9.6209e-02,\n",
      "           -2.5713e-01,  9.3233e-02,  1.2343e-02],\n",
      "          [ 7.3424e-02,  1.5940e-02,  1.2247e-01,  3.6384e-02,  9.1258e-02,\n",
      "           -1.4252e-01,  1.7066e-01,  1.8015e-01]],\n",
      "\n",
      "         [[-5.1883e-01, -3.8135e-01, -7.6039e-01, -5.8805e-01, -5.8079e-01,\n",
      "           -7.8903e-01, -1.1162e+00, -5.6490e-01],\n",
      "          [-6.6387e-01, -5.7853e-01, -7.6328e-01, -5.5594e-01, -4.9984e-01,\n",
      "           -7.5187e-01, -8.1395e-01, -4.9657e-01],\n",
      "          [-5.4265e-01, -3.9296e-01, -7.0065e-01, -5.1771e-01, -4.9201e-01,\n",
      "           -5.7558e-01, -7.7141e-01, -4.0793e-01],\n",
      "          [-8.5020e-01, -6.1922e-01, -9.6667e-01, -7.4194e-01, -7.2327e-01,\n",
      "           -8.1353e-01, -1.0575e+00, -7.6256e-01],\n",
      "          [-8.5178e-01, -5.4780e-01, -9.3842e-01, -7.5272e-01, -6.9773e-01,\n",
      "           -8.0159e-01, -1.0818e+00, -6.5796e-01],\n",
      "          [-7.3999e-01, -5.4645e-01, -9.7673e-01, -8.2584e-01, -8.9144e-01,\n",
      "           -8.3255e-01, -1.0605e+00, -7.8666e-01],\n",
      "          [-6.1973e-01, -4.4367e-01, -7.5149e-01, -7.1413e-01, -7.2788e-01,\n",
      "           -7.2095e-01, -1.0298e+00, -6.6831e-01],\n",
      "          [-5.9090e-01, -4.1782e-01, -7.2599e-01, -6.7365e-01, -8.0472e-01,\n",
      "           -8.2853e-01, -9.6878e-01, -6.7392e-01]],\n",
      "\n",
      "         [[ 3.4363e-01,  4.6455e-01,  7.1020e-01,  5.4328e-01,  2.9209e-01,\n",
      "            5.0017e-01,  1.3598e-01,  5.2294e-01],\n",
      "          [ 4.4598e-01,  5.1367e-01,  7.6096e-01,  6.3316e-01,  4.0265e-01,\n",
      "            6.1416e-01,  2.9346e-01,  7.3060e-01],\n",
      "          [ 5.2950e-01,  6.4973e-01,  9.4257e-01,  8.1460e-01,  6.5590e-01,\n",
      "            8.3698e-01,  6.2660e-01,  1.1138e+00],\n",
      "          [ 4.4430e-01,  6.8523e-01,  8.6755e-01,  7.5577e-01,  5.8956e-01,\n",
      "            7.3659e-01,  5.5619e-01,  1.0056e+00],\n",
      "          [ 3.3437e-01,  4.9217e-01,  8.7839e-01,  7.5947e-01,  4.8829e-01,\n",
      "            6.8226e-01,  3.7616e-01,  6.5923e-01],\n",
      "          [ 4.5297e-01,  5.3184e-01,  9.5615e-01,  8.2358e-01,  5.1757e-01,\n",
      "            7.5951e-01,  4.6329e-01,  8.8365e-01],\n",
      "          [ 6.9756e-01,  8.3731e-01,  1.2316e+00,  1.0635e+00,  8.0663e-01,\n",
      "            9.9124e-01,  6.0336e-01,  1.0375e+00],\n",
      "          [ 5.9671e-01,  6.2195e-01,  8.5908e-01,  7.6326e-01,  4.7861e-01,\n",
      "            7.9440e-01,  3.5587e-01,  8.6151e-01]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1491, 0.1285, 0.1282, 0.1232, 0.1060, 0.1325, 0.1298, 0.1028],\n",
      "          [0.1381, 0.1301, 0.1173, 0.1109, 0.1026, 0.1459, 0.1385, 0.1166],\n",
      "          [0.1339, 0.1313, 0.1336, 0.1184, 0.1066, 0.1312, 0.1295, 0.1155],\n",
      "          [0.1409, 0.1497, 0.1384, 0.1254, 0.0948, 0.1149, 0.1167, 0.1192],\n",
      "          [0.1196, 0.1479, 0.1522, 0.1397, 0.1135, 0.1185, 0.1051, 0.1035],\n",
      "          [0.1389, 0.1502, 0.1315, 0.1329, 0.1027, 0.1254, 0.1157, 0.1026],\n",
      "          [0.1219, 0.1388, 0.1385, 0.1500, 0.1066, 0.1356, 0.1086, 0.1001],\n",
      "          [0.1260, 0.1468, 0.1456, 0.1386, 0.1195, 0.1185, 0.1036, 0.1013]],\n",
      "\n",
      "         [[0.1200, 0.1129, 0.1495, 0.1290, 0.1185, 0.1025, 0.1411, 0.1265],\n",
      "          [0.1234, 0.1344, 0.1441, 0.1174, 0.1184, 0.0987, 0.1375, 0.1261],\n",
      "          [0.1220, 0.1193, 0.1394, 0.1319, 0.1354, 0.1112, 0.1194, 0.1215],\n",
      "          [0.1113, 0.1174, 0.1353, 0.1424, 0.1276, 0.1062, 0.1296, 0.1302],\n",
      "          [0.1219, 0.1317, 0.1198, 0.1354, 0.1126, 0.1052, 0.1379, 0.1355],\n",
      "          [0.1159, 0.1253, 0.1276, 0.1355, 0.1135, 0.1050, 0.1353, 0.1420],\n",
      "          [0.1346, 0.1203, 0.1256, 0.1305, 0.1171, 0.0997, 0.1416, 0.1306],\n",
      "          [0.1251, 0.1181, 0.1313, 0.1205, 0.1273, 0.1008, 0.1378, 0.1391]],\n",
      "\n",
      "         [[0.1414, 0.1622, 0.1110, 0.1319, 0.1329, 0.1079, 0.0778, 0.1350],\n",
      "          [0.1213, 0.1321, 0.1098, 0.1351, 0.1429, 0.1111, 0.1044, 0.1434],\n",
      "          [0.1250, 0.1452, 0.1067, 0.1282, 0.1315, 0.1210, 0.0994, 0.1430],\n",
      "          [0.1199, 0.1510, 0.1067, 0.1336, 0.1361, 0.1244, 0.0974, 0.1309],\n",
      "          [0.1162, 0.1575, 0.1066, 0.1283, 0.1356, 0.1222, 0.0924, 0.1411],\n",
      "          [0.1357, 0.1646, 0.1071, 0.1245, 0.1166, 0.1237, 0.0985, 0.1295],\n",
      "          [0.1352, 0.1612, 0.1185, 0.1230, 0.1213, 0.1222, 0.0897, 0.1288],\n",
      "          [0.1392, 0.1655, 0.1216, 0.1281, 0.1124, 0.1097, 0.0954, 0.1281]],\n",
      "\n",
      "         [[0.1121, 0.1265, 0.1617, 0.1369, 0.1065, 0.1311, 0.0911, 0.1341],\n",
      "          [0.1114, 0.1192, 0.1527, 0.1344, 0.1067, 0.1318, 0.0957, 0.1481],\n",
      "          [0.0965, 0.1089, 0.1459, 0.1284, 0.1095, 0.1313, 0.1064, 0.1731],\n",
      "          [0.0949, 0.1208, 0.1450, 0.1296, 0.1098, 0.1272, 0.1062, 0.1664],\n",
      "          [0.0959, 0.1122, 0.1651, 0.1466, 0.1118, 0.1357, 0.0999, 0.1326],\n",
      "          [0.0984, 0.1065, 0.1628, 0.1426, 0.1050, 0.1337, 0.0995, 0.1514],\n",
      "          [0.0993, 0.1142, 0.1694, 0.1432, 0.1108, 0.1332, 0.0904, 0.1395],\n",
      "          [0.1149, 0.1178, 0.1494, 0.1357, 0.1021, 0.1400, 0.0903, 0.1497]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0113,  0.3242, -0.2924,  0.4160,  0.1979],\n",
      "          [ 0.3051,  0.3259, -0.1052,  0.3264,  0.3822],\n",
      "          [-0.0604,  0.5780, -0.1002,  0.3252,  0.5492],\n",
      "          [ 0.0132,  0.1973, -0.1034,  0.1652,  0.5423],\n",
      "          [ 0.1083,  0.3548, -0.3171,  0.1049,  0.4049],\n",
      "          [ 0.0687,  0.3039, -0.3712,  0.0677,  0.4422],\n",
      "          [ 0.0443,  0.4262, -0.2050,  0.0939,  0.4873],\n",
      "          [-0.0954,  0.3305, -0.3121,  0.1893,  0.3119]],\n",
      "\n",
      "         [[-0.3140, -0.1414, -0.2310, -0.4672, -0.4681],\n",
      "          [-0.2047, -0.0369, -0.2650, -0.6917, -0.5063],\n",
      "          [-0.3978, -0.0756, -0.2241, -0.7286, -0.6302],\n",
      "          [-0.4746, -0.0710, -0.2028, -0.7836, -0.7096],\n",
      "          [-0.3133, -0.2307, -0.2781, -0.6771, -0.4065],\n",
      "          [-0.4826, -0.2368, -0.2766, -0.6501, -0.5205],\n",
      "          [-0.5493, -0.1159, -0.1568, -0.6788, -0.3456],\n",
      "          [-0.6514, -0.3727, -0.2564, -0.6704, -0.4788]],\n",
      "\n",
      "         [[-0.0547,  0.2422, -0.2333,  0.2107,  0.0982],\n",
      "          [ 0.1060,  0.2175, -0.2823,  0.3486,  0.2005],\n",
      "          [ 0.0373,  0.3233, -0.0356,  0.3469,  0.0172],\n",
      "          [ 0.0854,  0.1101, -0.1194,  0.4511,  0.0857],\n",
      "          [-0.0348,  0.1359, -0.0493,  0.4432,  0.1905],\n",
      "          [ 0.1141,  0.3558, -0.0867,  0.1821,  0.0193],\n",
      "          [-0.1895,  0.2999, -0.2324,  0.2660, -0.0658],\n",
      "          [-0.1180,  0.4319, -0.2864,  0.3740, -0.0379]],\n",
      "\n",
      "         [[-0.0607,  0.2070, -0.0970, -0.0153, -0.3551],\n",
      "          [-0.2175,  0.1615,  0.0414, -0.1205, -0.0861],\n",
      "          [-0.2719,  0.0577,  0.0884,  0.2139, -0.0094],\n",
      "          [-0.1256,  0.1915, -0.0027,  0.3213,  0.0996],\n",
      "          [-0.2852, -0.0428, -0.0026,  0.2404, -0.1452],\n",
      "          [-0.3808, -0.0477, -0.1042,  0.0306, -0.0770],\n",
      "          [-0.2400,  0.0030,  0.1109,  0.3028, -0.0282],\n",
      "          [-0.1643,  0.2637,  0.1907,  0.0641, -0.1347]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1721, 0.2354, 0.1271, 0.2580, 0.2074],\n",
      "          [0.2089, 0.2133, 0.1386, 0.2134, 0.2257],\n",
      "          [0.1396, 0.2643, 0.1341, 0.2053, 0.2568],\n",
      "          [0.1680, 0.2019, 0.1495, 0.1955, 0.2851],\n",
      "          [0.1896, 0.2426, 0.1239, 0.1889, 0.2550],\n",
      "          [0.1865, 0.2360, 0.1201, 0.1863, 0.2710],\n",
      "          [0.1709, 0.2503, 0.1332, 0.1796, 0.2661],\n",
      "          [0.1621, 0.2482, 0.1305, 0.2155, 0.2436]],\n",
      "\n",
      "         [[0.2004, 0.2381, 0.2177, 0.1719, 0.1718],\n",
      "          [0.2233, 0.2641, 0.2102, 0.1372, 0.1652],\n",
      "          [0.1968, 0.2716, 0.2342, 0.1414, 0.1560],\n",
      "          [0.1875, 0.2807, 0.2460, 0.1376, 0.1482],\n",
      "          [0.2115, 0.2297, 0.2191, 0.1470, 0.1927],\n",
      "          [0.1881, 0.2405, 0.2311, 0.1591, 0.1811],\n",
      "          [0.1632, 0.2517, 0.2416, 0.1434, 0.2001],\n",
      "          [0.1674, 0.2211, 0.2484, 0.1642, 0.1989]],\n",
      "\n",
      "         [[0.1769, 0.2381, 0.1480, 0.2307, 0.2062],\n",
      "          [0.1934, 0.2162, 0.1312, 0.2465, 0.2126],\n",
      "          [0.1784, 0.2375, 0.1659, 0.2432, 0.1749],\n",
      "          [0.1893, 0.1941, 0.1543, 0.2729, 0.1894],\n",
      "          [0.1656, 0.1965, 0.1632, 0.2672, 0.2075],\n",
      "          [0.1972, 0.2511, 0.1613, 0.2111, 0.1793],\n",
      "          [0.1588, 0.2590, 0.1521, 0.2504, 0.1797],\n",
      "          [0.1588, 0.2752, 0.1342, 0.2597, 0.1721]],\n",
      "\n",
      "         [[0.1975, 0.2582, 0.1905, 0.2067, 0.1471],\n",
      "          [0.1667, 0.2435, 0.2160, 0.1837, 0.1901],\n",
      "          [0.1481, 0.2060, 0.2124, 0.2408, 0.1926],\n",
      "          [0.1582, 0.2173, 0.1789, 0.2474, 0.1982],\n",
      "          [0.1552, 0.1978, 0.2059, 0.2625, 0.1785],\n",
      "          [0.1520, 0.2121, 0.2005, 0.2294, 0.2060],\n",
      "          [0.1503, 0.1917, 0.2135, 0.2587, 0.1858],\n",
      "          [0.1601, 0.2456, 0.2283, 0.2012, 0.1649]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1649, -0.4290, -0.1172, -0.1470, -0.3854, -0.4838, -0.2265,\n",
      "           -0.2346],\n",
      "          [-0.0898, -0.3039, -0.0265, -0.0676, -0.2523, -0.3396, -0.1673,\n",
      "           -0.1955],\n",
      "          [-0.1795, -0.5082, -0.1987, -0.1415, -0.4839, -0.4640, -0.2996,\n",
      "           -0.2591],\n",
      "          [-0.1179, -0.4481, -0.2331, -0.1861, -0.6001, -0.4450, -0.2460,\n",
      "           -0.2622],\n",
      "          [-0.2749, -0.6326, -0.3982, -0.4508, -0.6947, -0.6701, -0.5017,\n",
      "           -0.5317],\n",
      "          [-0.2762, -0.5088, -0.3819, -0.3719, -0.6093, -0.6006, -0.5214,\n",
      "           -0.5496],\n",
      "          [-0.1610, -0.4142, -0.2230, -0.2308, -0.4827, -0.4995, -0.3158,\n",
      "           -0.3987],\n",
      "          [-0.0698, -0.4594, -0.1981, -0.1448, -0.5226, -0.5626, -0.3991,\n",
      "           -0.2959]],\n",
      "\n",
      "         [[-0.1267, -0.0256, -0.1237, -0.1077,  0.1902,  0.0787,  0.1114,\n",
      "           -0.0176],\n",
      "          [-0.2296, -0.1253, -0.0300, -0.0435,  0.2300,  0.0555,  0.1272,\n",
      "           -0.0953],\n",
      "          [-0.0312,  0.0256,  0.0366,  0.0558,  0.2316,  0.1113,  0.1203,\n",
      "            0.0551],\n",
      "          [-0.0462,  0.0598,  0.1760,  0.1424,  0.3612,  0.2497,  0.3257,\n",
      "            0.1581],\n",
      "          [ 0.0591,  0.1095,  0.3174,  0.3022,  0.4150,  0.3435,  0.3607,\n",
      "            0.2596],\n",
      "          [-0.0181,  0.0825,  0.2268,  0.2430,  0.3782,  0.2624,  0.3164,\n",
      "            0.1335],\n",
      "          [-0.0971, -0.0670,  0.0712,  0.1035,  0.1569,  0.0072,  0.1635,\n",
      "            0.0543],\n",
      "          [-0.0285, -0.0986,  0.1564,  0.2081,  0.3053,  0.1146,  0.2957,\n",
      "            0.1403]],\n",
      "\n",
      "         [[-0.4893, -0.7958, -0.5795, -0.3500, -0.3351, -0.5214, -0.5509,\n",
      "           -0.5344],\n",
      "          [-0.2715, -0.6311, -0.3917, -0.1893, -0.2933, -0.5280, -0.4934,\n",
      "           -0.4899],\n",
      "          [-0.2052, -0.5625, -0.3378, -0.1040, -0.1149, -0.4097, -0.3704,\n",
      "           -0.3737],\n",
      "          [-0.3245, -0.7070, -0.4088, -0.1904, -0.3194, -0.4617, -0.3765,\n",
      "           -0.2990],\n",
      "          [-0.5101, -0.8108, -0.6164, -0.3432, -0.3643, -0.5330, -0.5201,\n",
      "           -0.5042],\n",
      "          [-0.3033, -0.6205, -0.4367, -0.1120, -0.2094, -0.4199, -0.4201,\n",
      "           -0.4540],\n",
      "          [-0.3628, -0.6893, -0.4502, -0.1710, -0.1792, -0.4121, -0.4310,\n",
      "           -0.3342],\n",
      "          [-0.4541, -0.7455, -0.4645, -0.2099, -0.4094, -0.6265, -0.5617,\n",
      "           -0.4765]],\n",
      "\n",
      "         [[-0.6655, -0.8335, -0.6229, -0.2202, -0.6226, -0.4296, -0.4140,\n",
      "           -0.5009],\n",
      "          [-0.4418, -0.5170, -0.3908, -0.1785, -0.3901, -0.1854, -0.1674,\n",
      "           -0.3518],\n",
      "          [-0.5791, -0.8364, -0.6490, -0.3735, -0.6644, -0.5031, -0.4868,\n",
      "           -0.5983],\n",
      "          [-0.3877, -0.5745, -0.4434, -0.2269, -0.4407, -0.3071, -0.2718,\n",
      "           -0.4455],\n",
      "          [-0.5573, -0.6651, -0.4824, -0.2100, -0.4698, -0.3565, -0.4076,\n",
      "           -0.4731],\n",
      "          [-0.4457, -0.5247, -0.3296, -0.1152, -0.3814, -0.1669, -0.2407,\n",
      "           -0.3397],\n",
      "          [-0.4277, -0.4459, -0.2630, -0.0058, -0.2938, -0.1711, -0.1460,\n",
      "           -0.2685],\n",
      "          [-0.7258, -0.8554, -0.6013, -0.3454, -0.6285, -0.4856, -0.4088,\n",
      "           -0.6151]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1382, 0.1061, 0.1449, 0.1407, 0.1108, 0.1004, 0.1299, 0.1289],\n",
      "          [0.1361, 0.1098, 0.1450, 0.1391, 0.1157, 0.1060, 0.1259, 0.1224],\n",
      "          [0.1421, 0.1023, 0.1393, 0.1476, 0.1048, 0.1069, 0.1260, 0.1312],\n",
      "          [0.1509, 0.1084, 0.1345, 0.1409, 0.0932, 0.1088, 0.1327, 0.1306],\n",
      "          [0.1581, 0.1106, 0.1398, 0.1326, 0.1039, 0.1065, 0.1261, 0.1223],\n",
      "          [0.1519, 0.1204, 0.1366, 0.1380, 0.1089, 0.1098, 0.1189, 0.1156],\n",
      "          [0.1485, 0.1153, 0.1396, 0.1385, 0.1077, 0.1059, 0.1272, 0.1171],\n",
      "          [0.1600, 0.1084, 0.1408, 0.1485, 0.1018, 0.0978, 0.1151, 0.1277]],\n",
      "\n",
      "         [[0.1097, 0.1214, 0.1101, 0.1118, 0.1506, 0.1348, 0.1392, 0.1224],\n",
      "          [0.0998, 0.1108, 0.1218, 0.1202, 0.1580, 0.1327, 0.1426, 0.1141],\n",
      "          [0.1120, 0.1186, 0.1199, 0.1222, 0.1457, 0.1292, 0.1303, 0.1221],\n",
      "          [0.0991, 0.1102, 0.1237, 0.1196, 0.1489, 0.1332, 0.1437, 0.1215],\n",
      "          [0.1005, 0.1057, 0.1301, 0.1281, 0.1434, 0.1335, 0.1359, 0.1228],\n",
      "          [0.0995, 0.1100, 0.1271, 0.1292, 0.1479, 0.1317, 0.1390, 0.1158],\n",
      "          [0.1076, 0.1109, 0.1273, 0.1315, 0.1387, 0.1194, 0.1396, 0.1252],\n",
      "          [0.1051, 0.0979, 0.1264, 0.1331, 0.1467, 0.1212, 0.1453, 0.1244]],\n",
      "\n",
      "         [[0.1277, 0.0940, 0.1167, 0.1468, 0.1490, 0.1237, 0.1201, 0.1221],\n",
      "          [0.1423, 0.0993, 0.1262, 0.1545, 0.1392, 0.1101, 0.1140, 0.1144],\n",
      "          [0.1373, 0.0960, 0.1202, 0.1519, 0.1503, 0.1119, 0.1164, 0.1160],\n",
      "          [0.1316, 0.0898, 0.1210, 0.1505, 0.1323, 0.1148, 0.1250, 0.1350],\n",
      "          [0.1258, 0.0931, 0.1131, 0.1486, 0.1455, 0.1229, 0.1245, 0.1265],\n",
      "          [0.1324, 0.0964, 0.1159, 0.1603, 0.1454, 0.1178, 0.1178, 0.1139],\n",
      "          [0.1255, 0.0906, 0.1150, 0.1521, 0.1508, 0.1195, 0.1173, 0.1292],\n",
      "          [0.1286, 0.0961, 0.1273, 0.1642, 0.1345, 0.1082, 0.1155, 0.1257]],\n",
      "\n",
      "         [[0.1084, 0.0916, 0.1131, 0.1692, 0.1132, 0.1372, 0.1394, 0.1278],\n",
      "          [0.1107, 0.1026, 0.1165, 0.1440, 0.1165, 0.1430, 0.1456, 0.1211],\n",
      "          [0.1249, 0.0965, 0.1164, 0.1534, 0.1146, 0.1347, 0.1369, 0.1225],\n",
      "          [0.1242, 0.1031, 0.1175, 0.1459, 0.1178, 0.1347, 0.1395, 0.1173],\n",
      "          [0.1117, 0.1003, 0.1204, 0.1581, 0.1219, 0.1365, 0.1297, 0.1215],\n",
      "          [0.1091, 0.1008, 0.1225, 0.1518, 0.1163, 0.1442, 0.1339, 0.1213],\n",
      "          [0.1040, 0.1021, 0.1226, 0.1585, 0.1188, 0.1344, 0.1378, 0.1219],\n",
      "          [0.1071, 0.0941, 0.1213, 0.1567, 0.1180, 0.1362, 0.1470, 0.1196]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2239, -0.0384, -0.4451, -0.4918, -0.3998],\n",
      "          [-0.1993,  0.0357, -0.1880, -0.1915, -0.3515],\n",
      "          [-0.1032,  0.1277, -0.2748, -0.5235, -0.2288],\n",
      "          [ 0.0545,  0.3212, -0.3322, -0.2249, -0.1184],\n",
      "          [-0.0028,  0.3560, -0.3824, -0.3563, -0.5357],\n",
      "          [-0.0909,  0.1443, -0.4068, -0.6565, -0.5919],\n",
      "          [-0.2354, -0.0371, -0.3984, -0.9186, -0.5826],\n",
      "          [-0.0852,  0.2037, -0.4139, -0.6296, -0.2110]],\n",
      "\n",
      "         [[-0.2339,  0.1805, -0.1195,  0.0325,  0.3301],\n",
      "          [-0.0788,  0.1882, -0.1859,  0.0385,  0.1432],\n",
      "          [ 0.2003,  0.2084, -0.2431, -0.0436,  0.1806],\n",
      "          [ 0.1707,  0.3065, -0.1251,  0.0444,  0.0940],\n",
      "          [ 0.1333,  0.1774, -0.1127,  0.0913,  0.0976],\n",
      "          [ 0.0273,  0.3606, -0.0935,  0.1980,  0.2612],\n",
      "          [-0.0038,  0.4355, -0.1202, -0.0054,  0.2585],\n",
      "          [ 0.1079,  0.2280, -0.1872,  0.0511,  0.2617]],\n",
      "\n",
      "         [[-0.0180, -0.1570,  0.3271, -0.1473,  0.0794],\n",
      "          [ 0.0636,  0.0886,  0.0931,  0.1058,  0.2170],\n",
      "          [-0.0126,  0.0761,  0.2496, -0.1918,  0.0533],\n",
      "          [ 0.1030,  0.2629,  0.1973, -0.2598,  0.2056],\n",
      "          [ 0.0309,  0.0464, -0.2474, -0.4488,  0.0722],\n",
      "          [ 0.0230,  0.1009,  0.1534, -0.2986,  0.1030],\n",
      "          [-0.1646,  0.0567, -0.0105, -0.2888, -0.0965],\n",
      "          [ 0.1403, -0.0335, -0.0250, -0.3173, -0.0562]],\n",
      "\n",
      "         [[-0.2017,  0.3691,  0.1439, -0.2909, -0.0241],\n",
      "          [-0.0752,  0.4472,  0.3587, -0.2533, -0.1338],\n",
      "          [-0.0880,  0.1718,  0.0692, -0.2674, -0.5219],\n",
      "          [-0.1943,  0.2287,  0.1384, -0.3411, -0.2470],\n",
      "          [-0.2315,  0.3611,  0.0396, -0.5674, -0.1103],\n",
      "          [-0.1030,  0.3842, -0.0237, -0.5810, -0.3652],\n",
      "          [-0.3810,  0.3728, -0.0658, -0.6331, -0.2758],\n",
      "          [-0.3735,  0.3595, -0.1750, -0.6420, -0.3446]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2170, 0.2612, 0.1739, 0.1660, 0.1820],\n",
      "          [0.1944, 0.2460, 0.1967, 0.1960, 0.1670],\n",
      "          [0.2155, 0.2714, 0.1815, 0.1415, 0.1900],\n",
      "          [0.2182, 0.2849, 0.1482, 0.1650, 0.1836],\n",
      "          [0.2270, 0.3250, 0.1553, 0.1594, 0.1332],\n",
      "          [0.2399, 0.3035, 0.1749, 0.1363, 0.1454],\n",
      "          [0.2336, 0.2848, 0.1985, 0.1180, 0.1651],\n",
      "          [0.2214, 0.2956, 0.1594, 0.1285, 0.1952]],\n",
      "\n",
      "         [[0.1493, 0.2260, 0.1674, 0.1949, 0.2624],\n",
      "          [0.1793, 0.2342, 0.1611, 0.2016, 0.2239],\n",
      "          [0.2265, 0.2284, 0.1454, 0.1775, 0.2221],\n",
      "          [0.2129, 0.2439, 0.1584, 0.1877, 0.1972],\n",
      "          [0.2105, 0.2200, 0.1646, 0.2018, 0.2031],\n",
      "          [0.1745, 0.2435, 0.1546, 0.2070, 0.2205],\n",
      "          [0.1742, 0.2703, 0.1551, 0.1739, 0.2265],\n",
      "          [0.2007, 0.2263, 0.1494, 0.1896, 0.2340]],\n",
      "\n",
      "         [[0.1900, 0.1653, 0.2683, 0.1669, 0.2094],\n",
      "          [0.1900, 0.1948, 0.1957, 0.1981, 0.2215],\n",
      "          [0.1888, 0.2063, 0.2454, 0.1578, 0.2017],\n",
      "          [0.1970, 0.2312, 0.2165, 0.1371, 0.2183],\n",
      "          [0.2255, 0.2291, 0.1707, 0.1396, 0.2351],\n",
      "          [0.1989, 0.2150, 0.2266, 0.1442, 0.2154],\n",
      "          [0.1863, 0.2324, 0.2173, 0.1645, 0.1994],\n",
      "          [0.2414, 0.2029, 0.2046, 0.1528, 0.1983]],\n",
      "\n",
      "         [[0.1589, 0.2813, 0.2246, 0.1454, 0.1898],\n",
      "          [0.1664, 0.2806, 0.2568, 0.1393, 0.1569],\n",
      "          [0.2020, 0.2619, 0.2364, 0.1688, 0.1309],\n",
      "          [0.1744, 0.2662, 0.2433, 0.1506, 0.1655],\n",
      "          [0.1677, 0.3033, 0.2199, 0.1198, 0.1893],\n",
      "          [0.1961, 0.3192, 0.2123, 0.1216, 0.1509],\n",
      "          [0.1567, 0.3329, 0.2147, 0.1217, 0.1740],\n",
      "          [0.1641, 0.3415, 0.2001, 0.1254, 0.1689]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3379,  0.3770,  0.3409,  0.1881,  0.3943,  0.3153,  0.2753,\n",
      "            0.2184],\n",
      "          [ 0.3588,  0.4721,  0.4170,  0.3690,  0.4837,  0.5466,  0.3389,\n",
      "            0.2267],\n",
      "          [ 0.6037,  0.6347,  0.5984,  0.4220,  0.5000,  0.5124,  0.4424,\n",
      "            0.3129],\n",
      "          [ 0.3841,  0.5827,  0.5690,  0.3271,  0.4784,  0.4055,  0.3409,\n",
      "            0.2841],\n",
      "          [ 0.4596,  0.5841,  0.4976,  0.3594,  0.4828,  0.4527,  0.4725,\n",
      "            0.4109],\n",
      "          [ 0.3778,  0.5210,  0.4747,  0.3638,  0.4302,  0.4042,  0.3936,\n",
      "            0.3793],\n",
      "          [ 0.4327,  0.6945,  0.4277,  0.3618,  0.6117,  0.5746,  0.4178,\n",
      "            0.3696],\n",
      "          [ 0.4008,  0.6916,  0.5090,  0.3890,  0.5950,  0.5430,  0.3599,\n",
      "            0.4186]],\n",
      "\n",
      "         [[ 0.2016,  0.1771,  0.1782,  0.0324,  0.1993,  0.1699,  0.1155,\n",
      "            0.0893],\n",
      "          [-0.1570, -0.1229,  0.1406, -0.0392, -0.0263, -0.0625, -0.1549,\n",
      "           -0.1414],\n",
      "          [-0.2268, -0.2066, -0.0139, -0.1603, -0.1741, -0.2019, -0.2413,\n",
      "           -0.2108],\n",
      "          [-0.1499,  0.0955,  0.1340, -0.0648, -0.0541,  0.0323, -0.1096,\n",
      "           -0.0580],\n",
      "          [-0.2090,  0.0125,  0.2267, -0.0178,  0.0448,  0.0328, -0.0717,\n",
      "            0.0321],\n",
      "          [-0.0550,  0.1470,  0.0942,  0.0147,  0.0124,  0.0765, -0.0360,\n",
      "            0.0455],\n",
      "          [ 0.0203,  0.1281,  0.1966,  0.0568,  0.0673,  0.1388,  0.0828,\n",
      "            0.1495],\n",
      "          [-0.1544,  0.1144,  0.1121, -0.0694,  0.0207, -0.0185, -0.0487,\n",
      "            0.0225]],\n",
      "\n",
      "         [[-0.4637, -0.2938, -0.3409, -0.2251, -0.2991, -0.2276, -0.0705,\n",
      "           -0.1978],\n",
      "          [-0.4909, -0.5650, -0.5555, -0.2631, -0.4725, -0.3220, -0.0892,\n",
      "           -0.4300],\n",
      "          [-0.4531, -0.4034, -0.4664, -0.3702, -0.3840, -0.1533, -0.0202,\n",
      "           -0.2943],\n",
      "          [-0.6660, -0.5758, -0.5777, -0.5029, -0.5606, -0.3346, -0.2523,\n",
      "           -0.4877],\n",
      "          [-0.3468, -0.3334, -0.3310, -0.2156, -0.3205, -0.0997, -0.1450,\n",
      "           -0.2120],\n",
      "          [-0.5574, -0.4774, -0.5588, -0.3820, -0.5316, -0.3405, -0.2031,\n",
      "           -0.4510],\n",
      "          [-0.6172, -0.5525, -0.5522, -0.4715, -0.4347, -0.3039, -0.1777,\n",
      "           -0.4345],\n",
      "          [-0.5241, -0.4861, -0.5634, -0.4883, -0.4919, -0.3127, -0.2178,\n",
      "           -0.4354]],\n",
      "\n",
      "         [[ 0.1211, -0.1927, -0.1514, -0.1981,  0.0083, -0.1162, -0.0711,\n",
      "           -0.1839],\n",
      "          [ 0.2145, -0.1364, -0.0745, -0.0480,  0.1165,  0.0403, -0.1479,\n",
      "           -0.1065],\n",
      "          [ 0.2928, -0.0406,  0.0140,  0.0722,  0.0500,  0.0938,  0.0222,\n",
      "           -0.0236],\n",
      "          [ 0.2093, -0.0976, -0.1298, -0.0164,  0.0007,  0.0069, -0.0242,\n",
      "           -0.0121],\n",
      "          [ 0.3377,  0.0274,  0.1803,  0.1658,  0.1317,  0.2045,  0.0478,\n",
      "           -0.0068],\n",
      "          [ 0.1464, -0.0399,  0.0299, -0.0079,  0.0809,  0.0794,  0.0757,\n",
      "           -0.0513],\n",
      "          [ 0.2811,  0.0108,  0.1667,  0.0596,  0.1515,  0.1003,  0.0713,\n",
      "           -0.0188],\n",
      "          [ 0.2052,  0.0223,  0.1090,  0.1011,  0.2428,  0.1806,  0.1002,\n",
      "            0.0024]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1288, 0.1339, 0.1291, 0.1109, 0.1362, 0.1259, 0.1209, 0.1143],\n",
      "          [0.1192, 0.1335, 0.1264, 0.1205, 0.1351, 0.1439, 0.1169, 0.1045],\n",
      "          [0.1375, 0.1418, 0.1368, 0.1147, 0.1239, 0.1255, 0.1170, 0.1028],\n",
      "          [0.1198, 0.1461, 0.1441, 0.1131, 0.1316, 0.1223, 0.1147, 0.1084],\n",
      "          [0.1241, 0.1405, 0.1289, 0.1123, 0.1270, 0.1232, 0.1257, 0.1182],\n",
      "          [0.1199, 0.1384, 0.1321, 0.1182, 0.1264, 0.1231, 0.1218, 0.1201],\n",
      "          [0.1177, 0.1529, 0.1171, 0.1096, 0.1407, 0.1356, 0.1159, 0.1105],\n",
      "          [0.1138, 0.1522, 0.1268, 0.1125, 0.1382, 0.1312, 0.1093, 0.1159]],\n",
      "\n",
      "         [[0.1320, 0.1288, 0.1290, 0.1115, 0.1317, 0.1279, 0.1211, 0.1180],\n",
      "          [0.1141, 0.1181, 0.1537, 0.1284, 0.1301, 0.1254, 0.1144, 0.1159],\n",
      "          [0.1189, 0.1214, 0.1472, 0.1271, 0.1254, 0.1219, 0.1172, 0.1209],\n",
      "          [0.1095, 0.1399, 0.1454, 0.1192, 0.1205, 0.1314, 0.1140, 0.1200],\n",
      "          [0.1001, 0.1250, 0.1548, 0.1212, 0.1291, 0.1275, 0.1149, 0.1274],\n",
      "          [0.1137, 0.1392, 0.1320, 0.1220, 0.1217, 0.1297, 0.1159, 0.1258],\n",
      "          [0.1147, 0.1277, 0.1368, 0.1189, 0.1202, 0.1291, 0.1221, 0.1305],\n",
      "          [0.1070, 0.1400, 0.1397, 0.1165, 0.1275, 0.1226, 0.1189, 0.1277]],\n",
      "\n",
      "         [[0.1019, 0.1207, 0.1152, 0.1293, 0.1201, 0.1290, 0.1509, 0.1329],\n",
      "          [0.1126, 0.1046, 0.1056, 0.1414, 0.1147, 0.1333, 0.1682, 0.1197],\n",
      "          [0.1080, 0.1135, 0.1066, 0.1173, 0.1157, 0.1458, 0.1665, 0.1266],\n",
      "          [0.1044, 0.1143, 0.1141, 0.1229, 0.1160, 0.1455, 0.1580, 0.1248],\n",
      "          [0.1131, 0.1146, 0.1149, 0.1289, 0.1161, 0.1448, 0.1383, 0.1294],\n",
      "          [0.1101, 0.1193, 0.1100, 0.1313, 0.1130, 0.1368, 0.1570, 0.1225],\n",
      "          [0.1040, 0.1110, 0.1110, 0.1204, 0.1249, 0.1423, 0.1615, 0.1249],\n",
      "          [0.1142, 0.1186, 0.1098, 0.1184, 0.1179, 0.1411, 0.1551, 0.1248]],\n",
      "\n",
      "         [[0.1547, 0.1130, 0.1178, 0.1124, 0.1382, 0.1220, 0.1277, 0.1141],\n",
      "          [0.1565, 0.1102, 0.1172, 0.1204, 0.1419, 0.1315, 0.1089, 0.1135],\n",
      "          [0.1570, 0.1125, 0.1188, 0.1259, 0.1231, 0.1286, 0.1198, 0.1144],\n",
      "          [0.1546, 0.1138, 0.1101, 0.1234, 0.1255, 0.1263, 0.1224, 0.1239],\n",
      "          [0.1521, 0.1115, 0.1299, 0.1281, 0.1238, 0.1331, 0.1138, 0.1078],\n",
      "          [0.1389, 0.1153, 0.1236, 0.1190, 0.1301, 0.1299, 0.1294, 0.1140],\n",
      "          [0.1488, 0.1135, 0.1327, 0.1192, 0.1307, 0.1242, 0.1206, 0.1102],\n",
      "          [0.1356, 0.1130, 0.1232, 0.1222, 0.1408, 0.1323, 0.1221, 0.1107]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.4197,  0.1290, -0.5927,  0.1072, -0.0202],\n",
      "          [-0.5984, -0.3373, -0.4530,  0.2289, -0.2393],\n",
      "          [-0.5035, -0.2332, -0.3203,  0.3879, -0.2548],\n",
      "          [-0.3854, -0.1530, -0.1894,  0.3759, -0.2316],\n",
      "          [-0.2355, -0.4325,  0.0155,  0.4050, -0.0900],\n",
      "          [-0.5053, -0.4245, -0.1067,  0.3496, -0.3053],\n",
      "          [-0.3675, -0.1201, -0.1739,  0.4062, -0.2256],\n",
      "          [-0.5297, -0.3552, -0.0185,  0.3435, -0.2037]],\n",
      "\n",
      "         [[ 0.2002,  1.1450, -0.3710,  0.2932,  0.0623],\n",
      "          [ 0.0863,  1.2164, -0.6197,  0.1280, -0.1442],\n",
      "          [ 0.1337,  0.8556, -0.5975,  0.0039, -0.3261],\n",
      "          [ 0.0752,  1.0766, -0.3640, -0.0869, -0.3979],\n",
      "          [ 0.2036,  0.8973, -0.5342,  0.0122, -0.2899],\n",
      "          [-0.0607,  0.8578, -0.4374,  0.0041, -0.4195],\n",
      "          [-0.2728,  0.9310, -0.5824,  0.0296, -0.3570],\n",
      "          [ 0.0502,  1.0140, -0.5548,  0.1518, -0.3569]],\n",
      "\n",
      "         [[ 0.1311, -0.2901,  0.1246, -0.2979, -0.1376],\n",
      "          [ 0.0235, -0.0700,  0.1852, -0.1005, -0.1947],\n",
      "          [ 0.2288, -0.1066,  0.0093, -0.1124,  0.1050],\n",
      "          [ 0.1793, -0.0240,  0.1556,  0.0733,  0.1634],\n",
      "          [ 0.0347, -0.0060, -0.0591, -0.0964,  0.2639],\n",
      "          [ 0.4154, -0.1038,  0.0533, -0.0816,  0.1968],\n",
      "          [ 0.1893, -0.0986, -0.1086, -0.3105,  0.1559],\n",
      "          [ 0.2867, -0.0297, -0.1278, -0.1086,  0.0821]],\n",
      "\n",
      "         [[-0.1945, -0.0604,  0.2758,  0.5233,  0.3121],\n",
      "          [-0.1763, -0.0588,  0.0584,  0.3268,  0.3801],\n",
      "          [-0.1650, -0.1524,  0.0138,  0.2938,  0.2196],\n",
      "          [-0.2863, -0.2184, -0.0363,  0.2396,  0.1395],\n",
      "          [-0.0750, -0.0630, -0.0527,  0.2793,  0.2621],\n",
      "          [ 0.1364, -0.0173, -0.3897,  0.1158,  0.0795],\n",
      "          [-0.1944, -0.1236, -0.0223,  0.1675,  0.2894],\n",
      "          [-0.0424,  0.1021, -0.1107,  0.1547,  0.1471]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1480, 0.2562, 0.1245, 0.2507, 0.2207],\n",
      "          [0.1394, 0.1810, 0.1612, 0.3188, 0.1996],\n",
      "          [0.1383, 0.1812, 0.1661, 0.3372, 0.1773],\n",
      "          [0.1474, 0.1859, 0.1793, 0.3155, 0.1719],\n",
      "          [0.1623, 0.1333, 0.2086, 0.3080, 0.1877],\n",
      "          [0.1399, 0.1517, 0.2085, 0.3290, 0.1709],\n",
      "          [0.1467, 0.1879, 0.1781, 0.3181, 0.1691],\n",
      "          [0.1309, 0.1559, 0.2183, 0.3135, 0.1814]],\n",
      "\n",
      "         [[0.1638, 0.4213, 0.0925, 0.1797, 0.1427],\n",
      "          [0.1556, 0.4818, 0.0768, 0.1622, 0.1236],\n",
      "          [0.1980, 0.4076, 0.0953, 0.1739, 0.1250],\n",
      "          [0.1712, 0.4661, 0.1104, 0.1456, 0.1067],\n",
      "          [0.2034, 0.4071, 0.0973, 0.1680, 0.1242],\n",
      "          [0.1679, 0.4206, 0.1152, 0.1791, 0.1173],\n",
      "          [0.1363, 0.4541, 0.1000, 0.1844, 0.1253],\n",
      "          [0.1683, 0.4413, 0.0919, 0.1863, 0.1120]],\n",
      "\n",
      "         [[0.2460, 0.1614, 0.2444, 0.1602, 0.1880],\n",
      "          [0.2095, 0.1908, 0.2463, 0.1851, 0.1684],\n",
      "          [0.2432, 0.1739, 0.1952, 0.1729, 0.2149],\n",
      "          [0.2138, 0.1745, 0.2088, 0.1923, 0.2105],\n",
      "          [0.1998, 0.1918, 0.1819, 0.1752, 0.2513],\n",
      "          [0.2700, 0.1607, 0.1880, 0.1643, 0.2170],\n",
      "          [0.2459, 0.1844, 0.1826, 0.1492, 0.2379],\n",
      "          [0.2579, 0.1879, 0.1704, 0.1737, 0.2102]],\n",
      "\n",
      "         [[0.1342, 0.1534, 0.2147, 0.2750, 0.2227],\n",
      "          [0.1473, 0.1657, 0.1863, 0.2437, 0.2570],\n",
      "          [0.1598, 0.1618, 0.1910, 0.2527, 0.2347],\n",
      "          [0.1520, 0.1627, 0.1952, 0.2573, 0.2328],\n",
      "          [0.1706, 0.1727, 0.1745, 0.2432, 0.2390],\n",
      "          [0.2287, 0.1961, 0.1351, 0.2240, 0.2160],\n",
      "          [0.1582, 0.1699, 0.1880, 0.2273, 0.2567],\n",
      "          [0.1813, 0.2095, 0.1693, 0.2208, 0.2191]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1672, -0.4040,  0.0758, -0.5961, -0.4528],\n",
      "          [-0.1268,  0.2191, -0.8032, -0.3677,  0.1866],\n",
      "          [-0.0142, -0.7621, -0.0130, -0.0726, -0.4379],\n",
      "          [-0.3720,  0.1223, -0.1268, -0.5366, -0.3565],\n",
      "          [-0.0370,  0.5704, -0.1739, -0.3460, -0.2878]],\n",
      "\n",
      "         [[-0.3236,  0.8577, -0.0978, -0.0890,  0.2987],\n",
      "          [-0.0750,  0.4721, -0.6540,  0.3716, -0.1454],\n",
      "          [ 0.1980,  0.1252,  0.0137,  0.1497,  0.1757],\n",
      "          [ 0.7009,  1.2132,  0.1146,  0.6648, -0.5233],\n",
      "          [ 0.7470,  0.9497, -0.0152,  0.1720,  0.0868]],\n",
      "\n",
      "         [[ 0.1851, -0.0486, -0.4915, -0.1501,  0.0097],\n",
      "          [ 0.8931,  0.0759, -0.9466, -0.5195,  1.0260],\n",
      "          [ 0.7924,  0.6005,  0.2611, -0.3554, -0.0411],\n",
      "          [ 0.8616,  0.1744,  0.6186,  0.1211,  0.3207],\n",
      "          [ 0.1256,  0.6980,  0.0579, -0.2164, -0.0064]],\n",
      "\n",
      "         [[ 0.9364,  0.7718,  0.6230,  0.5792,  0.6902],\n",
      "          [ 0.5574,  0.4842, -0.3135,  0.5752, -0.0197],\n",
      "          [ 1.3100,  0.6018, -0.0904,  1.1105,  0.3149],\n",
      "          [ 0.2179,  0.0830,  0.0461,  0.3040,  0.1200],\n",
      "          [ 0.0014,  0.3969, -0.6444,  0.4622,  0.6087]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2872, 0.1622, 0.2621, 0.1339, 0.1545],\n",
      "          [0.1970, 0.2784, 0.1002, 0.1548, 0.2695],\n",
      "          [0.2455, 0.1162, 0.2459, 0.2316, 0.1607],\n",
      "          [0.1730, 0.2836, 0.2210, 0.1467, 0.1757],\n",
      "          [0.1916, 0.3517, 0.1671, 0.1406, 0.1491]],\n",
      "\n",
      "         [[0.1157, 0.3772, 0.1451, 0.1464, 0.2157],\n",
      "          [0.1729, 0.2988, 0.0969, 0.2702, 0.1611],\n",
      "          [0.2131, 0.1982, 0.1772, 0.2031, 0.2084],\n",
      "          [0.2230, 0.3722, 0.1241, 0.2151, 0.0656],\n",
      "          [0.2652, 0.3248, 0.1237, 0.1492, 0.1370]],\n",
      "\n",
      "         [[0.2594, 0.2054, 0.1319, 0.1856, 0.2177],\n",
      "          [0.3349, 0.1479, 0.0532, 0.0815, 0.3825],\n",
      "          [0.3159, 0.2608, 0.1857, 0.1003, 0.1373],\n",
      "          [0.2988, 0.1503, 0.2344, 0.1425, 0.1740],\n",
      "          [0.1889, 0.3348, 0.1765, 0.1342, 0.1655]],\n",
      "\n",
      "         [[0.2463, 0.2089, 0.1800, 0.1723, 0.1925],\n",
      "          [0.2546, 0.2366, 0.1066, 0.2592, 0.1430],\n",
      "          [0.3416, 0.1682, 0.0842, 0.2798, 0.1263],\n",
      "          [0.2122, 0.1854, 0.1787, 0.2313, 0.1924],\n",
      "          [0.1555, 0.2310, 0.0815, 0.2465, 0.2854]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 5.2615e-01, -4.5263e-02,  3.7146e-01,  5.0447e-02,  1.5903e-02],\n",
      "          [ 6.3795e-01, -3.7748e-02,  3.3830e-02, -2.4683e-01, -4.6263e-01],\n",
      "          [-5.4948e-03, -2.5587e-01, -4.4964e-01,  4.8616e-02, -2.5271e-01],\n",
      "          [ 2.4666e-01, -1.0201e-04,  1.8249e-02,  2.3441e-03, -7.8147e-02],\n",
      "          [ 5.9836e-01, -2.6179e-01,  2.9894e-01, -3.6940e-01,  1.7282e-01]],\n",
      "\n",
      "         [[ 1.3587e-01,  3.1194e-01,  5.9784e-01,  2.9840e-01,  3.6493e-01],\n",
      "          [ 3.0598e-01,  1.7902e-01,  4.9848e-01, -9.5709e-02, -2.7393e-02],\n",
      "          [-2.2184e-01, -5.8714e-02,  4.3701e-01,  8.6063e-02,  2.0991e-01],\n",
      "          [-2.1606e-01, -2.5528e-02,  2.9200e-01, -4.3967e-01, -1.9335e-01],\n",
      "          [ 1.2461e-01,  3.6282e-01,  3.2369e-01,  2.3182e-03,  1.8077e-01]],\n",
      "\n",
      "         [[ 2.9186e-02,  7.6020e-01,  5.4308e-01,  1.8552e-01,  7.0452e-03],\n",
      "          [ 2.1924e-01,  1.9730e-01,  1.5079e-01, -5.7251e-01,  9.1086e-04],\n",
      "          [ 4.4908e-02,  2.1410e-01,  3.2887e-02,  4.2856e-02,  1.5939e-01],\n",
      "          [-2.4015e-02, -1.1050e-01,  4.2002e-02,  1.9108e-01,  1.9368e-01],\n",
      "          [ 2.4460e-01,  5.7388e-01,  9.1761e-02, -3.2907e-01,  2.2165e-02]],\n",
      "\n",
      "         [[-5.7944e-01,  2.3363e-01, -1.3517e-01, -1.8921e-01,  3.8502e-01],\n",
      "          [ 1.4341e-01, -2.4271e-01, -2.2892e-02,  3.8667e-01, -1.9584e-01],\n",
      "          [-3.5875e-02, -6.4191e-02, -2.1365e-02,  5.8234e-01,  2.2133e-01],\n",
      "          [ 3.8121e-02, -2.0388e-01, -1.9053e-01, -2.4868e-01,  5.5483e-02],\n",
      "          [ 1.2324e-01,  9.9372e-02, -4.4491e-01,  7.1376e-02,  2.9084e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2745, 0.1550, 0.2351, 0.1706, 0.1648],\n",
      "          [0.3570, 0.1817, 0.1951, 0.1474, 0.1188],\n",
      "          [0.2349, 0.1829, 0.1507, 0.2480, 0.1835],\n",
      "          [0.2449, 0.1914, 0.1949, 0.1918, 0.1770],\n",
      "          [0.3127, 0.1323, 0.2318, 0.1188, 0.2043]],\n",
      "\n",
      "         [[0.1609, 0.1919, 0.2554, 0.1893, 0.2024],\n",
      "          [0.2233, 0.1967, 0.2707, 0.1494, 0.1600],\n",
      "          [0.1426, 0.1679, 0.2757, 0.1941, 0.2197],\n",
      "          [0.1756, 0.2125, 0.2919, 0.1404, 0.1796],\n",
      "          [0.1841, 0.2336, 0.2246, 0.1629, 0.1947]],\n",
      "\n",
      "         [[0.1450, 0.3012, 0.2424, 0.1695, 0.1418],\n",
      "          [0.2399, 0.2347, 0.2240, 0.1087, 0.1928],\n",
      "          [0.1890, 0.2238, 0.1867, 0.1886, 0.2119],\n",
      "          [0.1829, 0.1677, 0.1953, 0.2267, 0.2273],\n",
      "          [0.2168, 0.3014, 0.1861, 0.1222, 0.1736]],\n",
      "\n",
      "         [[0.1122, 0.2529, 0.1749, 0.1657, 0.2943],\n",
      "          [0.2215, 0.1506, 0.1876, 0.2825, 0.1578],\n",
      "          [0.1630, 0.1584, 0.1654, 0.3024, 0.2108],\n",
      "          [0.2299, 0.1805, 0.1829, 0.1726, 0.2340],\n",
      "          [0.2139, 0.2089, 0.1212, 0.2031, 0.2529]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 7.2735e-01, -4.8038e-01, -4.1927e-04, -1.3225e-01,  1.2525e-01],\n",
      "          [ 1.3801e-01,  5.0423e-01,  3.2190e-01, -1.6689e-01,  2.2997e-01],\n",
      "          [ 5.9174e-01, -3.0775e-01,  3.8079e-01,  1.3106e-01,  1.9404e-01],\n",
      "          [-3.5433e-01,  3.5334e-01, -1.1299e-01, -3.2687e-01, -1.8931e-01],\n",
      "          [-2.5673e-01,  3.9348e-01,  1.3361e-01, -3.5494e-01,  3.0870e-01]],\n",
      "\n",
      "         [[-1.2872e-01, -3.2141e-01,  2.8106e-01,  1.2726e-01, -1.0450e-01],\n",
      "          [ 1.2885e-01,  1.7821e-02,  1.2288e-02,  2.0717e-01,  1.0432e-01],\n",
      "          [-4.5164e-01,  2.3567e-01, -4.8520e-01, -4.2871e-01,  3.9443e-02],\n",
      "          [-1.5497e-01,  9.6091e-03,  1.4624e-01, -9.9797e-02, -5.3824e-03],\n",
      "          [-1.1512e-01, -2.4371e-01, -2.0771e-01,  1.4286e-01,  2.0677e-01]],\n",
      "\n",
      "         [[ 7.9269e-01,  7.1519e-01,  7.7416e-01,  1.3870e-01,  2.8599e-01],\n",
      "          [ 2.2705e-01,  4.4178e-01,  4.6661e-01, -8.9231e-02,  3.7695e-01],\n",
      "          [ 7.9353e-01,  5.4052e-01,  3.9763e-01, -4.6525e-01,  3.1422e-02],\n",
      "          [-1.1596e-01,  3.1387e-01,  4.2672e-01, -1.8591e-01,  5.3641e-01],\n",
      "          [ 5.1083e-01,  4.8213e-01,  5.3674e-01,  2.0263e-01,  4.3892e-01]],\n",
      "\n",
      "         [[-2.7341e-01, -4.9522e-01, -2.7106e-01, -3.3316e-01, -2.8139e-01],\n",
      "          [-4.5812e-01, -6.9298e-01, -6.1256e-01, -2.9023e-01, -6.8145e-01],\n",
      "          [-3.8215e-01, -3.8059e-01, -1.6427e-01, -7.2965e-03,  6.3525e-02],\n",
      "          [ 2.6712e-01, -2.7145e-03, -2.3609e-01,  4.3116e-01,  2.7828e-01],\n",
      "          [-7.5119e-02, -1.0666e-01, -3.9976e-01, -1.6950e-01, -3.6943e-02]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3633, 0.1086, 0.1754, 0.1538, 0.1989],\n",
      "          [0.1826, 0.2633, 0.2194, 0.1346, 0.2001],\n",
      "          [0.2841, 0.1156, 0.2301, 0.1793, 0.1909],\n",
      "          [0.1536, 0.3117, 0.1956, 0.1579, 0.1812],\n",
      "          [0.1416, 0.2714, 0.2093, 0.1284, 0.2493]],\n",
      "\n",
      "         [[0.1771, 0.1460, 0.2668, 0.2287, 0.1814],\n",
      "          [0.2065, 0.1848, 0.1838, 0.2233, 0.2015],\n",
      "          [0.1512, 0.3007, 0.1462, 0.1547, 0.2471],\n",
      "          [0.1740, 0.2051, 0.2351, 0.1838, 0.2020],\n",
      "          [0.1830, 0.1609, 0.1668, 0.2368, 0.2525]],\n",
      "\n",
      "         [[0.2482, 0.2297, 0.2436, 0.1290, 0.1495],\n",
      "          [0.1852, 0.2295, 0.2353, 0.1350, 0.2151],\n",
      "          [0.3125, 0.2426, 0.2103, 0.0887, 0.1458],\n",
      "          [0.1406, 0.2162, 0.2420, 0.1311, 0.2700],\n",
      "          [0.2144, 0.2084, 0.2201, 0.1576, 0.1996]],\n",
      "\n",
      "         [[0.2111, 0.1691, 0.2116, 0.1988, 0.2094],\n",
      "          [0.2160, 0.1708, 0.1851, 0.2555, 0.1727],\n",
      "          [0.1597, 0.1600, 0.1986, 0.2323, 0.2494],\n",
      "          [0.2194, 0.1675, 0.1327, 0.2585, 0.2219],\n",
      "          [0.2155, 0.2088, 0.1558, 0.1961, 0.2239]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[-1.1939e+00, -1.2988e+00, -1.2041e+00,  ..., -8.5262e-01,\n",
      "           -1.0041e+00, -1.3193e+00],\n",
      "          [-9.1661e-01, -9.4798e-01, -8.7889e-01,  ..., -6.7267e-01,\n",
      "           -7.7384e-01, -1.0091e+00],\n",
      "          [-1.2840e+00, -1.2697e+00, -1.0906e+00,  ..., -8.4483e-01,\n",
      "           -9.8480e-01, -1.1486e+00],\n",
      "          ...,\n",
      "          [-6.3522e-01, -6.6799e-01, -3.7808e-01,  ..., -1.6531e-01,\n",
      "           -4.0516e-01, -4.7227e-01],\n",
      "          [-7.2644e-01, -8.1170e-01, -6.1501e-01,  ..., -4.7388e-01,\n",
      "           -6.4880e-01, -7.9745e-01],\n",
      "          [-1.8310e-01, -2.8635e-01, -8.3519e-02,  ..., -3.1618e-02,\n",
      "           -2.6205e-01, -4.1227e-01]],\n",
      "\n",
      "         [[ 2.7079e-01, -2.6338e-02,  9.6140e-02,  ...,  1.0007e-01,\n",
      "           -1.1123e-01, -3.7697e-02],\n",
      "          [ 2.1231e-01,  3.9292e-02,  1.5856e-01,  ...,  2.0585e-01,\n",
      "           -4.4682e-02,  7.8765e-02],\n",
      "          [ 1.6178e-01, -7.9584e-02, -5.0233e-02,  ..., -1.0707e-01,\n",
      "           -3.6368e-01, -1.7801e-01],\n",
      "          ...,\n",
      "          [ 4.3293e-01,  1.5533e-01,  2.1861e-01,  ...,  2.1059e-01,\n",
      "            2.5872e-01,  3.8016e-01],\n",
      "          [ 1.2056e-01, -4.3657e-02, -1.5186e-01,  ..., -2.7047e-02,\n",
      "           -1.0119e-01,  8.5533e-04],\n",
      "          [-2.2013e-01, -3.2449e-01, -3.6617e-01,  ..., -1.5430e-01,\n",
      "           -2.6098e-01, -2.4229e-01]],\n",
      "\n",
      "         [[-6.7811e-01, -4.2304e-01, -3.2239e-01,  ..., -1.0827e+00,\n",
      "           -9.0579e-01, -1.0432e+00],\n",
      "          [-3.6607e-01, -7.0149e-02, -3.8880e-02,  ..., -8.7514e-01,\n",
      "           -5.1273e-01, -7.0441e-01],\n",
      "          [-8.7073e-01, -6.1990e-01, -3.9384e-01,  ..., -1.0008e+00,\n",
      "           -6.3530e-01, -8.3987e-01],\n",
      "          ...,\n",
      "          [-6.6675e-01, -5.5543e-01, -4.5050e-01,  ..., -8.9246e-01,\n",
      "           -6.7088e-01, -8.5255e-01],\n",
      "          [-9.1927e-01, -6.3241e-01, -6.4938e-01,  ..., -1.0509e+00,\n",
      "           -7.1428e-01, -8.5553e-01],\n",
      "          [-7.2962e-01, -5.5948e-01, -5.3919e-01,  ..., -8.5790e-01,\n",
      "           -5.9599e-01, -7.3811e-01]],\n",
      "\n",
      "         [[ 6.1928e-01,  3.8422e-01,  3.7158e-01,  ...,  5.6977e-01,\n",
      "            6.1058e-01,  5.5150e-01],\n",
      "          [ 7.9100e-01,  5.9172e-01,  6.1452e-01,  ...,  6.4756e-01,\n",
      "            6.7572e-01,  6.2696e-01],\n",
      "          [ 6.3097e-01,  4.7759e-01,  5.7622e-01,  ...,  4.9317e-01,\n",
      "            5.2509e-01,  4.7848e-01],\n",
      "          ...,\n",
      "          [ 3.5974e-01,  2.0294e-01,  1.9629e-01,  ...,  3.2520e-01,\n",
      "            4.7775e-01,  3.8948e-01],\n",
      "          [ 7.0119e-01,  4.0621e-01,  2.1721e-01,  ...,  6.0751e-01,\n",
      "            5.6071e-01,  4.1576e-01],\n",
      "          [ 5.7057e-01,  5.0779e-01,  4.0450e-01,  ...,  6.5148e-01,\n",
      "            4.9513e-01,  4.0974e-01]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0530, 0.0477, 0.0525,  ..., 0.0746, 0.0641, 0.0468],\n",
      "          [0.0524, 0.0508, 0.0545,  ..., 0.0669, 0.0605, 0.0478],\n",
      "          [0.0453, 0.0460, 0.0550,  ..., 0.0704, 0.0612, 0.0519],\n",
      "          ...,\n",
      "          [0.0492, 0.0477, 0.0637,  ..., 0.0788, 0.0620, 0.0580],\n",
      "          [0.0548, 0.0504, 0.0613,  ..., 0.0706, 0.0593, 0.0511],\n",
      "          [0.0602, 0.0543, 0.0665,  ..., 0.0700, 0.0556, 0.0479]],\n",
      "\n",
      "         [[0.0776, 0.0576, 0.0651,  ..., 0.0654, 0.0529, 0.0570],\n",
      "          [0.0698, 0.0587, 0.0662,  ..., 0.0694, 0.0540, 0.0611],\n",
      "          [0.0803, 0.0631, 0.0650,  ..., 0.0614, 0.0475, 0.0572],\n",
      "          ...,\n",
      "          [0.0715, 0.0542, 0.0577,  ..., 0.0573, 0.0601, 0.0679],\n",
      "          [0.0715, 0.0606, 0.0544,  ..., 0.0616, 0.0572, 0.0634],\n",
      "          [0.0613, 0.0553, 0.0530,  ..., 0.0655, 0.0589, 0.0600]],\n",
      "\n",
      "         [[0.0636, 0.0821, 0.0908,  ..., 0.0425, 0.0507, 0.0442],\n",
      "          [0.0644, 0.0865, 0.0893,  ..., 0.0387, 0.0556, 0.0459],\n",
      "          [0.0519, 0.0667, 0.0836,  ..., 0.0456, 0.0657, 0.0535],\n",
      "          ...,\n",
      "          [0.0618, 0.0691, 0.0768,  ..., 0.0493, 0.0616, 0.0513],\n",
      "          [0.0533, 0.0710, 0.0698,  ..., 0.0467, 0.0654, 0.0568],\n",
      "          [0.0557, 0.0660, 0.0674,  ..., 0.0490, 0.0637, 0.0552]],\n",
      "\n",
      "         [[0.0719, 0.0568, 0.0561,  ..., 0.0684, 0.0713, 0.0672],\n",
      "          [0.0739, 0.0606, 0.0619,  ..., 0.0640, 0.0659, 0.0627],\n",
      "          [0.0683, 0.0586, 0.0647,  ..., 0.0595, 0.0615, 0.0587],\n",
      "          ...,\n",
      "          [0.0621, 0.0531, 0.0527,  ..., 0.0600, 0.0699, 0.0640],\n",
      "          [0.0802, 0.0597, 0.0494,  ..., 0.0730, 0.0697, 0.0603],\n",
      "          [0.0649, 0.0609, 0.0550,  ..., 0.0704, 0.0602, 0.0552]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-1.2445e-01,  3.3286e-01, -1.7617e-01,  4.1142e-01,  2.6423e-01],\n",
      "          [ 7.0649e-02,  5.2151e-01,  5.7635e-02,  5.6940e-01,  2.2106e-01],\n",
      "          [-3.8166e-03,  4.1222e-01, -4.1285e-02,  3.2641e-01,  3.2433e-01],\n",
      "          [-1.5868e-01,  3.8738e-01, -1.2092e-01,  2.5538e-01,  4.2787e-01],\n",
      "          [-5.4732e-02,  4.8567e-01, -2.2273e-01,  2.5073e-01,  5.0843e-01],\n",
      "          [-3.5330e-01,  2.9423e-01, -5.2156e-01,  8.4618e-02,  5.4135e-01],\n",
      "          [-3.6657e-02,  2.9635e-01, -4.3531e-01, -3.2824e-02,  3.7448e-01],\n",
      "          [-3.8597e-01,  3.9328e-01, -4.8097e-01,  1.3849e-01,  3.8600e-01],\n",
      "          [-4.2806e-01,  3.9243e-01, -5.2479e-01,  1.3932e-01,  2.7975e-01],\n",
      "          [-2.0001e-01,  3.4365e-01, -3.5247e-01, -2.8269e-02,  2.5206e-01],\n",
      "          [-3.0754e-01,  1.7894e-01, -5.9619e-01,  2.7398e-01,  1.5119e-01],\n",
      "          [-3.2917e-01,  2.3748e-01, -5.4536e-01,  2.2880e-01,  2.4923e-01],\n",
      "          [-2.7916e-01,  1.4159e-01, -5.1278e-01,  1.3920e-01,  4.0293e-01],\n",
      "          [-3.2423e-01,  2.8774e-01, -4.5323e-01,  3.4882e-01,  2.2026e-01],\n",
      "          [-3.2631e-01,  2.1624e-01, -2.6022e-01,  3.0579e-01,  3.1642e-01],\n",
      "          [-2.5419e-01,  1.3137e-01, -3.9505e-01,  3.3386e-01,  3.5634e-01]],\n",
      "\n",
      "         [[-9.6190e-01, -3.5260e-01,  7.4975e-02, -6.9690e-01, -6.6611e-01],\n",
      "          [-7.0550e-01, -5.7574e-01, -6.5806e-02, -6.9196e-01, -5.4824e-01],\n",
      "          [-5.6222e-01, -2.1724e-01,  1.8840e-02, -5.9549e-01, -5.0879e-01],\n",
      "          [-8.0978e-01, -3.9885e-01,  1.0475e-02, -6.6253e-01, -6.4652e-01],\n",
      "          [-6.7257e-01, -4.2931e-01,  1.1945e-01, -5.6418e-01, -6.1033e-01],\n",
      "          [-7.0275e-01, -3.6424e-01,  3.7891e-02, -5.2652e-01, -5.4788e-01],\n",
      "          [-6.5607e-01, -4.2353e-01, -3.2870e-02, -4.2497e-01, -5.5782e-01],\n",
      "          [-4.9620e-01, -4.8254e-01, -4.2670e-03, -4.7103e-01, -4.1594e-01],\n",
      "          [-5.0322e-01, -3.6760e-01,  1.1895e-01, -5.4245e-01, -4.3153e-01],\n",
      "          [-5.1726e-01, -2.7195e-01, -1.4316e-01, -5.2350e-01, -3.0981e-01],\n",
      "          [-3.0748e-01, -3.1852e-01, -7.5027e-03, -5.6596e-01, -3.7005e-01],\n",
      "          [-5.1013e-01, -4.0811e-01, -1.2265e-01, -6.9629e-01, -4.7921e-01],\n",
      "          [-2.3975e-01, -1.3330e-01, -2.7620e-02, -7.0380e-01, -3.9077e-01],\n",
      "          [-1.9553e-01, -3.6345e-01, -1.7014e-01, -7.8819e-01, -4.7381e-01],\n",
      "          [-2.8267e-01, -2.6213e-01,  2.4192e-02, -5.0817e-01, -4.4158e-01],\n",
      "          [-2.4459e-01, -2.5752e-01,  8.2478e-04, -5.0245e-01, -2.0710e-01]],\n",
      "\n",
      "         [[-1.9501e-01,  2.4326e-01,  1.0607e-01,  1.5820e-01, -1.8694e-02],\n",
      "          [-1.5620e-01,  2.7862e-01, -8.2171e-03,  1.8429e-01,  8.8936e-02],\n",
      "          [-9.7361e-02,  2.9982e-01,  1.7433e-01,  2.4480e-01, -2.5125e-03],\n",
      "          [-1.8031e-01,  1.0998e-01,  1.6862e-02,  1.2335e-01,  5.1827e-03],\n",
      "          [ 1.5174e-01,  1.5920e-01,  1.8713e-01,  8.2507e-02,  1.4718e-01],\n",
      "          [-1.5146e-02,  1.1608e-01, -8.4067e-02,  1.3040e-02, -4.7921e-02],\n",
      "          [-1.1254e-01,  2.5019e-01,  2.1141e-02, -1.8013e-01,  8.6970e-02],\n",
      "          [-1.4325e-01,  2.4536e-01, -1.0019e-01, -6.5662e-02, -1.1821e-01],\n",
      "          [-1.4699e-01,  1.4643e-01, -7.5252e-02,  1.2881e-01, -1.6567e-01],\n",
      "          [-5.9954e-01,  1.2317e-01, -1.1563e-02,  2.4083e-01, -1.9465e-01],\n",
      "          [-2.7996e-01,  3.0044e-01, -1.4221e-01,  4.9592e-02, -1.0412e-01],\n",
      "          [-2.3115e-01,  4.3147e-01, -3.4332e-02, -9.7786e-02, -6.0861e-02],\n",
      "          [-2.3211e-01,  2.7115e-01, -2.2720e-01,  2.3328e-01, -5.4221e-02],\n",
      "          [-6.9623e-02,  4.8800e-01, -9.3760e-03,  3.6387e-01, -3.4670e-02],\n",
      "          [-1.6616e-01,  4.1988e-01, -1.9458e-01,  1.7982e-01,  1.4849e-01],\n",
      "          [-1.2599e-01,  3.3346e-01, -9.7300e-02,  1.4568e-01,  6.9273e-02]],\n",
      "\n",
      "         [[-3.7354e-02,  2.2307e-01, -7.4260e-02, -3.6441e-01, -4.6794e-01],\n",
      "          [-2.8376e-01,  1.4620e-01, -5.3845e-03, -7.8813e-02, -1.4760e-01],\n",
      "          [-1.2023e-01,  5.1269e-02, -1.2990e-01,  1.6429e-02, -1.5376e-01],\n",
      "          [-4.3528e-01, -9.1172e-03, -2.0541e-01, -6.6924e-02, -2.0735e-01],\n",
      "          [-3.3409e-01,  1.0611e-01, -6.6062e-02,  1.0127e-01,  3.0011e-03],\n",
      "          [ 3.7744e-02, -9.8266e-02, -2.1213e-01, -1.7099e-02, -1.4411e-01],\n",
      "          [ 6.2100e-02, -1.7097e-01, -2.9426e-01,  9.5560e-03, -2.1359e-01],\n",
      "          [-3.4102e-01,  6.5821e-02, -1.2257e-01, -1.9334e-01, -1.5365e-01],\n",
      "          [-1.0405e-01, -1.3423e-01,  8.8791e-02,  3.6661e-03, -5.0368e-02],\n",
      "          [-1.4527e-01,  9.0793e-02, -2.0576e-02, -7.3759e-02, -3.1082e-02],\n",
      "          [-2.7821e-01, -1.1129e-01, -8.7162e-02, -1.0133e-01, -1.6706e-01],\n",
      "          [-1.6762e-01,  7.8572e-02,  1.1940e-01,  8.6643e-02, -5.7125e-02],\n",
      "          [-3.0202e-01,  2.4312e-01, -4.9286e-03,  6.3222e-02, -8.4451e-02],\n",
      "          [-3.8651e-01,  3.2288e-01, -7.2399e-02, -1.0017e-01, -1.3502e-01],\n",
      "          [-1.6833e-01,  2.6321e-01,  1.1787e-01,  2.5169e-01,  3.2645e-02],\n",
      "          [-1.8237e-01,  6.9362e-03, -2.6729e-01, -7.0879e-02, -5.7543e-02]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1490, 0.2353, 0.1414, 0.2546, 0.2197],\n",
      "          [0.1571, 0.2466, 0.1551, 0.2587, 0.1826],\n",
      "          [0.1598, 0.2422, 0.1539, 0.2223, 0.2218],\n",
      "          [0.1413, 0.2440, 0.1468, 0.2138, 0.2541],\n",
      "          [0.1498, 0.2572, 0.1266, 0.2033, 0.2631],\n",
      "          [0.1290, 0.2465, 0.1090, 0.1999, 0.3156],\n",
      "          [0.1793, 0.2501, 0.1203, 0.1799, 0.2704],\n",
      "          [0.1259, 0.2744, 0.1145, 0.2127, 0.2725],\n",
      "          [0.1254, 0.2849, 0.1139, 0.2212, 0.2546],\n",
      "          [0.1577, 0.2717, 0.1354, 0.1873, 0.2479],\n",
      "          [0.1482, 0.2411, 0.1111, 0.2651, 0.2345],\n",
      "          [0.1409, 0.2483, 0.1135, 0.2461, 0.2512],\n",
      "          [0.1468, 0.2236, 0.1162, 0.2230, 0.2904],\n",
      "          [0.1350, 0.2490, 0.1187, 0.2646, 0.2327],\n",
      "          [0.1321, 0.2272, 0.1411, 0.2485, 0.2511],\n",
      "          [0.1432, 0.2106, 0.1244, 0.2579, 0.2638]],\n",
      "\n",
      "         [[0.1204, 0.2214, 0.3395, 0.1569, 0.1618],\n",
      "          [0.1608, 0.1831, 0.3049, 0.1630, 0.1882],\n",
      "          [0.1607, 0.2269, 0.2874, 0.1555, 0.1695],\n",
      "          [0.1405, 0.2120, 0.3192, 0.1628, 0.1655],\n",
      "          [0.1501, 0.1914, 0.3314, 0.1673, 0.1597],\n",
      "          [0.1458, 0.2045, 0.3057, 0.1739, 0.1702],\n",
      "          [0.1541, 0.1944, 0.2874, 0.1941, 0.1700],\n",
      "          [0.1737, 0.1761, 0.2840, 0.1781, 0.1882],\n",
      "          [0.1655, 0.1895, 0.3082, 0.1591, 0.1777],\n",
      "          [0.1679, 0.2146, 0.2441, 0.1669, 0.2066],\n",
      "          [0.1980, 0.1958, 0.2673, 0.1529, 0.1860],\n",
      "          [0.1837, 0.2035, 0.2707, 0.1525, 0.1895],\n",
      "          [0.2067, 0.2300, 0.2556, 0.1300, 0.1778],\n",
      "          [0.2392, 0.2022, 0.2453, 0.1322, 0.1811],\n",
      "          [0.1988, 0.2029, 0.2702, 0.1586, 0.1696],\n",
      "          [0.1970, 0.1945, 0.2518, 0.1522, 0.2045]],\n",
      "\n",
      "         [[0.1534, 0.2378, 0.2073, 0.2184, 0.1830],\n",
      "          [0.1566, 0.2418, 0.1815, 0.2201, 0.2000],\n",
      "          [0.1585, 0.2359, 0.2080, 0.2232, 0.1743],\n",
      "          [0.1636, 0.2187, 0.1992, 0.2216, 0.1969],\n",
      "          [0.2011, 0.2026, 0.2084, 0.1877, 0.2002],\n",
      "          [0.1972, 0.2249, 0.1841, 0.2029, 0.1909],\n",
      "          [0.1743, 0.2506, 0.1993, 0.1630, 0.2128],\n",
      "          [0.1778, 0.2622, 0.1856, 0.1921, 0.1823],\n",
      "          [0.1750, 0.2347, 0.1880, 0.2306, 0.1718],\n",
      "          [0.1153, 0.2374, 0.2075, 0.2671, 0.1728],\n",
      "          [0.1534, 0.2742, 0.1761, 0.2133, 0.1829],\n",
      "          [0.1542, 0.2991, 0.1877, 0.1762, 0.1828],\n",
      "          [0.1551, 0.2566, 0.1559, 0.2471, 0.1853],\n",
      "          [0.1566, 0.2735, 0.1663, 0.2415, 0.1621],\n",
      "          [0.1526, 0.2742, 0.1483, 0.2157, 0.2091],\n",
      "          [0.1629, 0.2578, 0.1676, 0.2137, 0.1980]],\n",
      "\n",
      "         [[0.2159, 0.2801, 0.2080, 0.1557, 0.1403],\n",
      "          [0.1605, 0.2467, 0.2120, 0.1970, 0.1839],\n",
      "          [0.1890, 0.2244, 0.1872, 0.2167, 0.1828],\n",
      "          [0.1541, 0.2359, 0.1939, 0.2227, 0.1935],\n",
      "          [0.1469, 0.2282, 0.1921, 0.2271, 0.2058],\n",
      "          [0.2256, 0.1969, 0.1757, 0.2136, 0.1881],\n",
      "          [0.2381, 0.1886, 0.1667, 0.2259, 0.1807],\n",
      "          [0.1636, 0.2458, 0.2036, 0.1897, 0.1973],\n",
      "          [0.1869, 0.1813, 0.2266, 0.2081, 0.1972],\n",
      "          [0.1788, 0.2264, 0.2025, 0.1920, 0.2004],\n",
      "          [0.1753, 0.2072, 0.2123, 0.2093, 0.1960],\n",
      "          [0.1662, 0.2126, 0.2214, 0.2143, 0.1856],\n",
      "          [0.1480, 0.2554, 0.1993, 0.2133, 0.1840],\n",
      "          [0.1425, 0.2896, 0.1950, 0.1897, 0.1832],\n",
      "          [0.1512, 0.2327, 0.2012, 0.2301, 0.1848],\n",
      "          [0.1859, 0.2247, 0.1708, 0.2079, 0.2107]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3729, -0.4321, -0.4237,  ..., -0.6251, -0.5949, -0.4343],\n",
      "          [-0.3922, -0.5722, -0.4730,  ..., -0.6265, -0.6211, -0.4348],\n",
      "          [-0.4322, -0.4555, -0.4394,  ..., -0.7162, -0.6814, -0.6387],\n",
      "          ...,\n",
      "          [ 0.0144, -0.1360, -0.1615,  ...,  0.0090, -0.1233, -0.0068],\n",
      "          [-0.1339, -0.2330, -0.2665,  ..., -0.2857, -0.2516, -0.1654],\n",
      "          [-0.0855, -0.1227, -0.1926,  ..., -0.2358, -0.3545, -0.0464]],\n",
      "\n",
      "         [[-0.0164, -0.0883,  0.1525,  ..., -0.0207,  0.1979,  0.2615],\n",
      "          [ 0.0028, -0.0622,  0.1232,  ...,  0.1222,  0.3265,  0.3993],\n",
      "          [ 0.0968,  0.0512,  0.2208,  ...,  0.3082,  0.5202,  0.6411],\n",
      "          ...,\n",
      "          [ 0.1021,  0.0513,  0.1318,  ...,  0.4366,  0.4084,  0.5082],\n",
      "          [-0.0020, -0.0119, -0.0017,  ...,  0.2304,  0.2998,  0.5158],\n",
      "          [ 0.1126,  0.1182,  0.1570,  ...,  0.2360,  0.4243,  0.5839]],\n",
      "\n",
      "         [[-0.6185, -0.6261, -0.7059,  ..., -0.3399, -0.2505, -0.3573],\n",
      "          [-0.4874, -0.5262, -0.6552,  ..., -0.2942, -0.2936, -0.3714],\n",
      "          [-0.4809, -0.5904, -0.7873,  ..., -0.3868, -0.3660, -0.3787],\n",
      "          ...,\n",
      "          [-0.5418, -0.5858, -0.6785,  ..., -0.1831, -0.0876, -0.1861],\n",
      "          [-0.6360, -0.6701, -0.7839,  ..., -0.3635, -0.2389, -0.2873],\n",
      "          [-0.6244, -0.6344, -0.7037,  ..., -0.3295, -0.2582, -0.3434]],\n",
      "\n",
      "         [[-0.5324, -0.4522, -0.5405,  ..., -0.4065, -0.5080, -0.3395],\n",
      "          [-0.5554, -0.5098, -0.6448,  ..., -0.6221, -0.6064, -0.4004],\n",
      "          [-0.6209, -0.4809, -0.6396,  ..., -0.5550, -0.7362, -0.5508],\n",
      "          ...,\n",
      "          [-0.8077, -0.6423, -0.7624,  ..., -0.7752, -0.9331, -0.8549],\n",
      "          [-0.6662, -0.5397, -0.6243,  ..., -0.5707, -0.7657, -0.6220],\n",
      "          [-0.6289, -0.5044, -0.6119,  ..., -0.6166, -0.7067, -0.5816]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0689, 0.0650, 0.0655,  ..., 0.0536, 0.0552, 0.0648],\n",
      "          [0.0699, 0.0584, 0.0645,  ..., 0.0553, 0.0556, 0.0670],\n",
      "          [0.0698, 0.0682, 0.0693,  ..., 0.0526, 0.0544, 0.0568],\n",
      "          ...,\n",
      "          [0.0667, 0.0574, 0.0560,  ..., 0.0664, 0.0581, 0.0653],\n",
      "          [0.0706, 0.0640, 0.0619,  ..., 0.0607, 0.0628, 0.0684],\n",
      "          [0.0687, 0.0661, 0.0617,  ..., 0.0591, 0.0525, 0.0714]],\n",
      "\n",
      "         [[0.0586, 0.0546, 0.0694,  ..., 0.0584, 0.0726, 0.0774],\n",
      "          [0.0562, 0.0527, 0.0634,  ..., 0.0634, 0.0777, 0.0836],\n",
      "          [0.0512, 0.0489, 0.0580,  ..., 0.0632, 0.0782, 0.0882],\n",
      "          ...,\n",
      "          [0.0552, 0.0524, 0.0568,  ..., 0.0771, 0.0749, 0.0828],\n",
      "          [0.0545, 0.0540, 0.0546,  ..., 0.0688, 0.0737, 0.0915],\n",
      "          [0.0562, 0.0565, 0.0587,  ..., 0.0636, 0.0767, 0.0900]],\n",
      "\n",
      "         [[0.0498, 0.0494, 0.0456,  ..., 0.0657, 0.0719, 0.0646],\n",
      "          [0.0546, 0.0526, 0.0462,  ..., 0.0663, 0.0663, 0.0614],\n",
      "          [0.0605, 0.0542, 0.0445,  ..., 0.0665, 0.0679, 0.0670],\n",
      "          ...,\n",
      "          [0.0480, 0.0460, 0.0419,  ..., 0.0687, 0.0756, 0.0685],\n",
      "          [0.0499, 0.0483, 0.0431,  ..., 0.0656, 0.0743, 0.0708],\n",
      "          [0.0508, 0.0503, 0.0469,  ..., 0.0683, 0.0733, 0.0673]],\n",
      "\n",
      "         [[0.0559, 0.0606, 0.0555,  ..., 0.0634, 0.0573, 0.0678],\n",
      "          [0.0594, 0.0622, 0.0543,  ..., 0.0556, 0.0564, 0.0693],\n",
      "          [0.0565, 0.0650, 0.0554,  ..., 0.0603, 0.0503, 0.0606],\n",
      "          ...,\n",
      "          [0.0561, 0.0662, 0.0587,  ..., 0.0579, 0.0495, 0.0535],\n",
      "          [0.0542, 0.0615, 0.0565,  ..., 0.0596, 0.0490, 0.0566],\n",
      "          [0.0559, 0.0633, 0.0568,  ..., 0.0565, 0.0517, 0.0586]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1730,  0.1739, -0.2963, -0.2974, -0.2446],\n",
      "          [ 0.1324,  0.2260, -0.3560, -0.2434, -0.2228],\n",
      "          [ 0.2481,  0.3531, -0.2562, -0.3418, -0.3253],\n",
      "          [ 0.2391,  0.3764, -0.4585, -0.3642, -0.1444],\n",
      "          [ 0.0738,  0.3580, -0.3459, -0.4081, -0.3248],\n",
      "          [ 0.0219,  0.1536, -0.3739, -0.5376, -0.3666],\n",
      "          [-0.1463,  0.1185, -0.6175, -0.7094, -0.8563],\n",
      "          [ 0.1365,  0.2851, -0.2451, -0.7310, -0.3728],\n",
      "          [ 0.0957,  0.1309, -0.2474, -0.6053, -0.4950],\n",
      "          [ 0.2490,  0.2082, -0.1708, -0.3824, -0.3691],\n",
      "          [ 0.4043,  0.3612, -0.0263, -0.4311, -0.2767],\n",
      "          [ 0.1427,  0.1843, -0.2280, -0.4318, -0.4738],\n",
      "          [ 0.0947,  0.3659, -0.1360, -0.1938, -0.2918],\n",
      "          [ 0.0051,  0.2071,  0.0075, -0.4307, -0.2505],\n",
      "          [-0.1996,  0.2495, -0.2272, -0.5036, -0.5802],\n",
      "          [-0.2888,  0.2411, -0.1423, -0.3827, -0.3406]],\n",
      "\n",
      "         [[-0.0741,  0.2464, -0.1798,  0.0521,  0.0437],\n",
      "          [ 0.0905,  0.4039, -0.0765, -0.0333,  0.1207],\n",
      "          [ 0.2570,  0.3421, -0.0443, -0.1401, -0.0076],\n",
      "          [ 0.2341,  0.1584, -0.1429, -0.1242,  0.1643],\n",
      "          [ 0.1481,  0.3664, -0.1672, -0.1076, -0.0194],\n",
      "          [ 0.0726,  0.4037, -0.1825, -0.0905,  0.3131],\n",
      "          [ 0.0258,  0.3370, -0.0875, -0.0378,  0.1564],\n",
      "          [-0.0461,  0.2460, -0.2728, -0.0372,  0.1918],\n",
      "          [-0.1279,  0.4768, -0.1459, -0.0177,  0.3245],\n",
      "          [-0.1062,  0.3275,  0.1164, -0.0293,  0.1874],\n",
      "          [ 0.0237,  0.2697,  0.0799, -0.1537,  0.2367],\n",
      "          [ 0.0834,  0.4346,  0.0753, -0.0743,  0.2366],\n",
      "          [-0.2767,  0.0792, -0.0439, -0.3568,  0.0047],\n",
      "          [ 0.0542,  0.2455, -0.0371, -0.2355,  0.1884],\n",
      "          [-0.0135,  0.2770, -0.0009,  0.0314,  0.1825],\n",
      "          [-0.0276,  0.1453, -0.1691, -0.5127, -0.0140]],\n",
      "\n",
      "         [[ 0.0236,  0.0271, -0.0321, -0.1678, -0.0718],\n",
      "          [ 0.0783,  0.0139, -0.3524, -0.1327, -0.2285],\n",
      "          [ 0.2241,  0.0622, -0.1300, -0.3207, -0.1639],\n",
      "          [ 0.2674,  0.0922, -0.2578, -0.0339, -0.0537],\n",
      "          [ 0.0777,  0.0287, -0.2076, -0.4694, -0.2772],\n",
      "          [ 0.3585,  0.2055, -0.1279, -0.4371,  0.0609],\n",
      "          [-0.0272,  0.1559, -0.2552, -0.4459, -0.2190],\n",
      "          [ 0.3193, -0.0493, -0.3289, -0.5179, -0.1994],\n",
      "          [ 0.4508, -0.0357, -0.1434, -0.6107, -0.3510],\n",
      "          [ 0.2492,  0.0019, -0.1743, -0.6368, -0.3870],\n",
      "          [ 0.3971,  0.2332, -0.2557, -0.2591, -0.2898],\n",
      "          [-0.1091, -0.1025, -0.1338, -0.5968, -0.4216],\n",
      "          [ 0.1071, -0.0929, -0.1527, -0.3912, -0.2215],\n",
      "          [ 0.1890,  0.1137,  0.0270, -0.0258,  0.0043],\n",
      "          [ 0.1634, -0.0239, -0.1838, -0.1011, -0.0576],\n",
      "          [ 0.2240, -0.0376, -0.0635, -0.2888, -0.1407]],\n",
      "\n",
      "         [[ 0.0431,  0.0109, -0.1681,  0.0452, -0.3068],\n",
      "          [-0.1189, -0.0693, -0.1341, -0.0614, -0.4174],\n",
      "          [-0.0537,  0.0630, -0.0089, -0.0497, -0.5492],\n",
      "          [-0.1702, -0.1398, -0.0079,  0.0231, -0.5130],\n",
      "          [-0.1299,  0.0402, -0.1249, -0.3855, -0.4776],\n",
      "          [-0.2096,  0.0738, -0.0410, -0.1461, -0.2558],\n",
      "          [ 0.0268,  0.3129, -0.0539, -0.1544, -0.2470],\n",
      "          [-0.1035,  0.0695, -0.2823, -0.4568, -0.3286],\n",
      "          [-0.2379, -0.1489, -0.0228, -0.2060, -0.5991],\n",
      "          [-0.2264, -0.3983, -0.1601, -0.4225, -0.6451],\n",
      "          [-0.1318, -0.0488, -0.2839, -0.2251, -0.4483],\n",
      "          [-0.1329, -0.0635, -0.3113, -0.4503, -0.4512],\n",
      "          [-0.2067, -0.0560, -0.1554, -0.0336, -0.3474],\n",
      "          [-0.0863, -0.0115, -0.2607, -0.2028, -0.5570],\n",
      "          [-0.1641, -0.1487, -0.0866, -0.1877, -0.4733],\n",
      "          [-0.1914, -0.1068, -0.1989, -0.0427, -0.3061]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2558, 0.2560, 0.1600, 0.1598, 0.1685],\n",
      "          [0.2439, 0.2679, 0.1497, 0.1675, 0.1710],\n",
      "          [0.2609, 0.2898, 0.1576, 0.1447, 0.1471],\n",
      "          [0.2582, 0.2962, 0.1285, 0.1412, 0.1759],\n",
      "          [0.2339, 0.3108, 0.1538, 0.1445, 0.1570],\n",
      "          [0.2461, 0.2807, 0.1657, 0.1406, 0.1669],\n",
      "          [0.2507, 0.3267, 0.1565, 0.1428, 0.1233],\n",
      "          [0.2588, 0.3003, 0.1767, 0.1087, 0.1555],\n",
      "          [0.2635, 0.2729, 0.1870, 0.1307, 0.1459],\n",
      "          [0.2711, 0.2603, 0.1782, 0.1442, 0.1461],\n",
      "          [0.2819, 0.2700, 0.1833, 0.1222, 0.1427],\n",
      "          [0.2607, 0.2718, 0.1800, 0.1468, 0.1407],\n",
      "          [0.2205, 0.2893, 0.1751, 0.1653, 0.1498],\n",
      "          [0.2152, 0.2633, 0.2157, 0.1392, 0.1666],\n",
      "          [0.2016, 0.3158, 0.1961, 0.1487, 0.1378],\n",
      "          [0.1749, 0.2972, 0.2025, 0.1593, 0.1661]],\n",
      "\n",
      "         [[0.1806, 0.2488, 0.1625, 0.2049, 0.2032],\n",
      "          [0.1950, 0.2668, 0.1650, 0.1723, 0.2010],\n",
      "          [0.2343, 0.2551, 0.1733, 0.1575, 0.1798],\n",
      "          [0.2356, 0.2184, 0.1616, 0.1647, 0.2197],\n",
      "          [0.2177, 0.2708, 0.1588, 0.1686, 0.1841],\n",
      "          [0.1891, 0.2633, 0.1465, 0.1606, 0.2405],\n",
      "          [0.1874, 0.2558, 0.1673, 0.1759, 0.2136],\n",
      "          [0.1847, 0.2474, 0.1472, 0.1864, 0.2343],\n",
      "          [0.1538, 0.2816, 0.1511, 0.1717, 0.2418],\n",
      "          [0.1609, 0.2483, 0.2011, 0.1738, 0.2159],\n",
      "          [0.1848, 0.2363, 0.1955, 0.1548, 0.2287],\n",
      "          [0.1841, 0.2615, 0.1826, 0.1572, 0.2145],\n",
      "          [0.1684, 0.2404, 0.2126, 0.1555, 0.2232],\n",
      "          [0.1994, 0.2414, 0.1820, 0.1492, 0.2280],\n",
      "          [0.1782, 0.2383, 0.1804, 0.1864, 0.2168],\n",
      "          [0.2134, 0.2537, 0.1852, 0.1314, 0.2163]],\n",
      "\n",
      "         [[0.2135, 0.2142, 0.2019, 0.1763, 0.1941],\n",
      "          [0.2419, 0.2269, 0.1573, 0.1959, 0.1780],\n",
      "          [0.2624, 0.2232, 0.1842, 0.1522, 0.1780],\n",
      "          [0.2567, 0.2154, 0.1518, 0.1899, 0.1862],\n",
      "          [0.2510, 0.2390, 0.1887, 0.1452, 0.1760],\n",
      "          [0.2727, 0.2340, 0.1677, 0.1231, 0.2025],\n",
      "          [0.2232, 0.2680, 0.1777, 0.1468, 0.1842],\n",
      "          [0.3084, 0.2133, 0.1613, 0.1335, 0.1836],\n",
      "          [0.3377, 0.2076, 0.1864, 0.1168, 0.1515],\n",
      "          [0.2961, 0.2312, 0.1939, 0.1221, 0.1567],\n",
      "          [0.2949, 0.2503, 0.1535, 0.1530, 0.1484],\n",
      "          [0.2311, 0.2326, 0.2254, 0.1419, 0.1690],\n",
      "          [0.2553, 0.2090, 0.1969, 0.1551, 0.1838],\n",
      "          [0.2265, 0.2100, 0.1926, 0.1827, 0.1883],\n",
      "          [0.2436, 0.2020, 0.1721, 0.1870, 0.1953],\n",
      "          [0.2622, 0.2019, 0.1967, 0.1570, 0.1821]],\n",
      "\n",
      "         [[0.2230, 0.2159, 0.1805, 0.2234, 0.1571],\n",
      "          [0.2067, 0.2173, 0.2036, 0.2190, 0.1534],\n",
      "          [0.2091, 0.2350, 0.2187, 0.2099, 0.1274],\n",
      "          [0.1949, 0.2009, 0.2293, 0.2365, 0.1383],\n",
      "          [0.2141, 0.2538, 0.2151, 0.1658, 0.1512],\n",
      "          [0.1808, 0.2400, 0.2140, 0.1926, 0.1726],\n",
      "          [0.2062, 0.2746, 0.1903, 0.1721, 0.1568],\n",
      "          [0.2210, 0.2627, 0.1848, 0.1552, 0.1764],\n",
      "          [0.1975, 0.2159, 0.2449, 0.2039, 0.1377],\n",
      "          [0.2278, 0.1918, 0.2434, 0.1872, 0.1498],\n",
      "          [0.2181, 0.2370, 0.1873, 0.1987, 0.1589],\n",
      "          [0.2291, 0.2456, 0.1917, 0.1668, 0.1667],\n",
      "          [0.1896, 0.2205, 0.1996, 0.2255, 0.1648],\n",
      "          [0.2256, 0.2431, 0.1895, 0.2008, 0.1409],\n",
      "          [0.2080, 0.2113, 0.2248, 0.2032, 0.1527],\n",
      "          [0.1948, 0.2120, 0.1934, 0.2261, 0.1737]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4791,  0.4592,  0.2355,  ...,  0.6086,  0.4189,  0.6271],\n",
      "          [ 0.4734,  0.4722,  0.2384,  ...,  0.5988,  0.4891,  0.7078],\n",
      "          [ 0.3982,  0.5078,  0.2187,  ...,  0.4045,  0.2992,  0.4539],\n",
      "          ...,\n",
      "          [ 0.6726,  0.6982,  0.3919,  ...,  0.8248,  0.7635,  0.7416],\n",
      "          [ 0.6585,  0.7256,  0.4297,  ...,  0.8573,  0.8162,  0.7096],\n",
      "          [ 0.6157,  0.7359,  0.4522,  ...,  0.8067,  0.7590,  0.7344]],\n",
      "\n",
      "         [[ 0.2906,  0.4149,  0.3133,  ...,  0.1800,  0.1967,  0.2104],\n",
      "          [ 0.2079,  0.3368,  0.1829,  ..., -0.0220,  0.0704,  0.0617],\n",
      "          [-0.1198, -0.0326, -0.0780,  ...,  0.0653, -0.0922, -0.0546],\n",
      "          ...,\n",
      "          [ 0.0698,  0.0665,  0.0685,  ...,  0.0149,  0.0187,  0.0724],\n",
      "          [ 0.0482,  0.0855, -0.0324,  ..., -0.1981, -0.0888, -0.1686],\n",
      "          [-0.0719, -0.0961, -0.1977,  ..., -0.2643, -0.2514, -0.2466]],\n",
      "\n",
      "         [[-0.3715, -0.2754, -0.4127,  ..., -0.1281, -0.1862, -0.2591],\n",
      "          [-0.4857, -0.5304, -0.5317,  ..., -0.2285, -0.3179, -0.4936],\n",
      "          [-0.5451, -0.6053, -0.5176,  ..., -0.3028, -0.3920, -0.5347],\n",
      "          ...,\n",
      "          [-0.4196, -0.2686, -0.2733,  ..., -0.3078, -0.4298, -0.4929],\n",
      "          [-0.8861, -0.6897, -0.7140,  ..., -0.6139, -0.6027, -0.6720],\n",
      "          [-0.6205, -0.4471, -0.4642,  ..., -0.4401, -0.4368, -0.5859]],\n",
      "\n",
      "         [[ 0.1671,  0.1196,  0.0501,  ...,  0.3174,  0.0402, -0.0779],\n",
      "          [ 0.1381,  0.0564,  0.0016,  ...,  0.2036, -0.0673, -0.1800],\n",
      "          [ 0.1644,  0.0355, -0.0521,  ...,  0.3042, -0.0601, -0.0607],\n",
      "          ...,\n",
      "          [-0.1673, -0.1859, -0.3566,  ..., -0.0010, -0.2603, -0.3890],\n",
      "          [ 0.0020, -0.0155, -0.1470,  ...,  0.1893, -0.1893, -0.1945],\n",
      "          [ 0.0231,  0.0665, -0.2391,  ...,  0.2095, -0.0553, -0.2401]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0671, 0.0658, 0.0526,  ..., 0.0764, 0.0632, 0.0779],\n",
      "          [0.0658, 0.0657, 0.0520,  ..., 0.0746, 0.0669, 0.0832],\n",
      "          [0.0639, 0.0713, 0.0534,  ..., 0.0643, 0.0579, 0.0676],\n",
      "          ...,\n",
      "          [0.0610, 0.0626, 0.0461,  ..., 0.0711, 0.0669, 0.0654],\n",
      "          [0.0625, 0.0668, 0.0497,  ..., 0.0762, 0.0731, 0.0657],\n",
      "          [0.0603, 0.0680, 0.0512,  ..., 0.0730, 0.0696, 0.0679]],\n",
      "\n",
      "         [[0.0614, 0.0696, 0.0628,  ..., 0.0550, 0.0559, 0.0567],\n",
      "          [0.0612, 0.0697, 0.0597,  ..., 0.0487, 0.0534, 0.0529],\n",
      "          [0.0543, 0.0593, 0.0567,  ..., 0.0654, 0.0559, 0.0580],\n",
      "          ...,\n",
      "          [0.0568, 0.0566, 0.0567,  ..., 0.0538, 0.0540, 0.0570],\n",
      "          [0.0621, 0.0644, 0.0572,  ..., 0.0485, 0.0541, 0.0500],\n",
      "          [0.0653, 0.0637, 0.0576,  ..., 0.0539, 0.0546, 0.0548]],\n",
      "\n",
      "         [[0.0491, 0.0541, 0.0471,  ..., 0.0626, 0.0591, 0.0549],\n",
      "          [0.0514, 0.0492, 0.0491,  ..., 0.0665, 0.0608, 0.0510],\n",
      "          [0.0516, 0.0486, 0.0531,  ..., 0.0658, 0.0602, 0.0522],\n",
      "          ...,\n",
      "          [0.0518, 0.0602, 0.0599,  ..., 0.0579, 0.0513, 0.0481],\n",
      "          [0.0455, 0.0554, 0.0541,  ..., 0.0598, 0.0604, 0.0564],\n",
      "          [0.0484, 0.0575, 0.0566,  ..., 0.0579, 0.0581, 0.0501]],\n",
      "\n",
      "         [[0.0718, 0.0684, 0.0638,  ..., 0.0834, 0.0632, 0.0562],\n",
      "          [0.0747, 0.0688, 0.0652,  ..., 0.0798, 0.0608, 0.0543],\n",
      "          [0.0733, 0.0644, 0.0590,  ..., 0.0843, 0.0585, 0.0585],\n",
      "          ...,\n",
      "          [0.0665, 0.0652, 0.0550,  ..., 0.0785, 0.0606, 0.0532],\n",
      "          [0.0690, 0.0678, 0.0595,  ..., 0.0833, 0.0570, 0.0567],\n",
      "          [0.0688, 0.0718, 0.0529,  ..., 0.0829, 0.0636, 0.0529]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1872,  0.0362, -0.2796,  0.3471, -0.2104],\n",
      "          [-0.2978,  0.0422, -0.2652,  0.5440, -0.0465],\n",
      "          [-0.3439, -0.2520, -0.3371,  0.3457, -0.2693],\n",
      "          [-0.2537,  0.1294, -0.4572,  0.4937, -0.2480],\n",
      "          [-0.4467, -0.1503, -0.3508,  0.3945, -0.3145],\n",
      "          [-0.3061,  0.0041, -0.1308,  0.2426, -0.2443],\n",
      "          [-0.1848, -0.3287, -0.1780,  0.1886, -0.3792],\n",
      "          [-0.5762, -0.4076, -0.3345,  0.3368, -0.3832],\n",
      "          [-0.7136, -0.2847, -0.4560,  0.1036, -0.2780],\n",
      "          [-0.3669, -0.4725, -0.4090, -0.0373, -0.3275],\n",
      "          [-0.5520, -0.4014, -0.4772,  0.2449, -0.5348],\n",
      "          [-0.3633, -0.3719, -0.2705,  0.1874, -0.3365],\n",
      "          [-0.3146, -0.2445, -0.3416,  0.2458, -0.3834],\n",
      "          [-0.3297, -0.2008, -0.1493,  0.3871, -0.4726],\n",
      "          [-0.3437,  0.0360, -0.5580,  0.2344, -0.5127],\n",
      "          [-0.4622, -0.0187, -0.6852,  0.0767, -0.5575]],\n",
      "\n",
      "         [[ 0.1350,  0.9847, -0.6294,  0.2069, -0.0979],\n",
      "          [ 0.0993,  0.8430, -0.7101,  0.0974, -0.1976],\n",
      "          [ 0.1611,  1.1088, -0.6395,  0.1905, -0.1496],\n",
      "          [ 0.3750,  1.0270, -0.4398, -0.0309, -0.2282],\n",
      "          [ 0.2339,  1.1409, -0.3319,  0.2844,  0.1535],\n",
      "          [ 0.1134,  0.9378, -0.4253,  0.2153, -0.2496],\n",
      "          [ 0.1405,  0.8144, -0.1702,  0.3246, -0.1421],\n",
      "          [ 0.0963,  1.0896, -0.3924,  0.1977, -0.1265],\n",
      "          [ 0.2089,  1.1213, -0.4783,  0.4830,  0.1198],\n",
      "          [ 0.0168,  0.9110, -0.4791,  0.4444, -0.0260],\n",
      "          [ 0.3387,  1.3188, -0.4695,  0.2593, -0.0324],\n",
      "          [ 0.2949,  1.0841, -0.5310,  0.3891, -0.0351],\n",
      "          [ 0.0230,  0.9384, -0.5301,  0.0942, -0.1132],\n",
      "          [ 0.0345,  1.0320, -0.3295,  0.1722, -0.1896],\n",
      "          [ 0.1660,  0.9977, -0.3858,  0.2876,  0.2749],\n",
      "          [ 0.1767,  0.8168, -0.5477,  0.3405,  0.3083]],\n",
      "\n",
      "         [[ 0.3528, -0.2764,  0.0787, -0.1560,  0.0446],\n",
      "          [ 0.2985, -0.3791, -0.0200,  0.0294, -0.0537],\n",
      "          [ 0.3730, -0.2782,  0.0391,  0.0627,  0.0093],\n",
      "          [ 0.4349, -0.0572,  0.0723, -0.0066,  0.1194],\n",
      "          [ 0.4131, -0.3527,  0.1186,  0.1303,  0.1693],\n",
      "          [ 0.5194, -0.1426,  0.1289,  0.1691,  0.1235],\n",
      "          [ 0.3544, -0.3435,  0.1556,  0.0491,  0.2452],\n",
      "          [ 0.4761, -0.0480, -0.0775, -0.0686,  0.1107],\n",
      "          [ 0.5133, -0.1386, -0.1691, -0.0048, -0.0289],\n",
      "          [ 0.3379, -0.2138,  0.0083, -0.0834, -0.0118],\n",
      "          [ 0.3153, -0.2297, -0.0470, -0.2156,  0.0897],\n",
      "          [ 0.3609, -0.3037, -0.1042, -0.2017,  0.1230],\n",
      "          [ 0.3424, -0.0843,  0.2651, -0.1236, -0.0538],\n",
      "          [ 0.2929, -0.1443,  0.2989, -0.0655,  0.2223],\n",
      "          [ 0.3288, -0.2782, -0.0095, -0.0498, -0.0054],\n",
      "          [ 0.1510, -0.3891,  0.0941,  0.1830, -0.0170]],\n",
      "\n",
      "         [[-0.0390, -0.1324, -0.0624, -0.0595, -0.1393],\n",
      "          [-0.0444, -0.2028, -0.1256,  0.0366, -0.0165],\n",
      "          [ 0.0431, -0.2642,  0.0225,  0.0887,  0.0455],\n",
      "          [-0.0587, -0.2562,  0.0043,  0.1389,  0.2155],\n",
      "          [ 0.0933, -0.1002, -0.1636,  0.0296,  0.0756],\n",
      "          [ 0.2793, -0.1627, -0.2427, -0.0727,  0.1654],\n",
      "          [ 0.1873, -0.0271, -0.3007, -0.1820, -0.0116],\n",
      "          [ 0.2612, -0.1383, -0.2001,  0.0708,  0.1255],\n",
      "          [ 0.1324, -0.2421, -0.0031, -0.0564,  0.2048],\n",
      "          [-0.0527, -0.3101,  0.1240,  0.1398,  0.1587],\n",
      "          [ 0.0214, -0.0319, -0.0215,  0.0883,  0.0859],\n",
      "          [-0.0837, -0.0343,  0.0659,  0.0956,  0.1435],\n",
      "          [-0.0112,  0.0399, -0.2926, -0.1188, -0.0385],\n",
      "          [-0.1902, -0.2880,  0.0913,  0.3423,  0.1483],\n",
      "          [-0.1290, -0.0138, -0.0178,  0.1204,  0.1245],\n",
      "          [-0.1892, -0.2326, -0.1389,  0.1620,  0.0227]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1711, 0.2139, 0.1560, 0.2919, 0.1672],\n",
      "          [0.1420, 0.1994, 0.1467, 0.3294, 0.1825],\n",
      "          [0.1620, 0.1776, 0.1631, 0.3228, 0.1745],\n",
      "          [0.1562, 0.2292, 0.1275, 0.3299, 0.1571],\n",
      "          [0.1448, 0.1947, 0.1594, 0.3358, 0.1653],\n",
      "          [0.1575, 0.2148, 0.1877, 0.2726, 0.1675],\n",
      "          [0.1942, 0.1682, 0.1955, 0.2821, 0.1599],\n",
      "          [0.1396, 0.1653, 0.1778, 0.3479, 0.1694],\n",
      "          [0.1309, 0.2010, 0.1694, 0.2964, 0.2024],\n",
      "          [0.1891, 0.1701, 0.1813, 0.2629, 0.1967],\n",
      "          [0.1544, 0.1795, 0.1664, 0.3426, 0.1571],\n",
      "          [0.1709, 0.1695, 0.1875, 0.2965, 0.1756],\n",
      "          [0.1745, 0.1872, 0.1698, 0.3056, 0.1629],\n",
      "          [0.1600, 0.1820, 0.1916, 0.3277, 0.1387],\n",
      "          [0.1696, 0.2479, 0.1369, 0.3023, 0.1432],\n",
      "          [0.1672, 0.2605, 0.1338, 0.2866, 0.1520]],\n",
      "\n",
      "         [[0.1763, 0.4124, 0.0821, 0.1895, 0.1397],\n",
      "          [0.1890, 0.3977, 0.0841, 0.1887, 0.1405],\n",
      "          [0.1727, 0.4454, 0.0775, 0.1778, 0.1265],\n",
      "          [0.2185, 0.4195, 0.0968, 0.1456, 0.1196],\n",
      "          [0.1661, 0.4115, 0.0944, 0.1747, 0.1533],\n",
      "          [0.1765, 0.4024, 0.1030, 0.1954, 0.1227],\n",
      "          [0.1770, 0.3472, 0.1297, 0.2127, 0.1334],\n",
      "          [0.1608, 0.4341, 0.0986, 0.1779, 0.1287],\n",
      "          [0.1607, 0.4001, 0.0808, 0.2114, 0.1470],\n",
      "          [0.1528, 0.3736, 0.0930, 0.2343, 0.1464],\n",
      "          [0.1747, 0.4655, 0.0779, 0.1614, 0.1205],\n",
      "          [0.1832, 0.4034, 0.0802, 0.2013, 0.1317],\n",
      "          [0.1661, 0.4149, 0.0956, 0.1784, 0.1450],\n",
      "          [0.1574, 0.4268, 0.1094, 0.1806, 0.1258],\n",
      "          [0.1635, 0.3755, 0.0941, 0.1846, 0.1823],\n",
      "          [0.1754, 0.3328, 0.0850, 0.2067, 0.2001]],\n",
      "\n",
      "         [[0.2755, 0.1469, 0.2095, 0.1657, 0.2025],\n",
      "          [0.2701, 0.1372, 0.1964, 0.2064, 0.1899],\n",
      "          [0.2728, 0.1422, 0.1953, 0.2000, 0.1896],\n",
      "          [0.2718, 0.1661, 0.1891, 0.1748, 0.1982],\n",
      "          [0.2669, 0.1241, 0.1988, 0.2011, 0.2091],\n",
      "          [0.2801, 0.1445, 0.1896, 0.1973, 0.1885],\n",
      "          [0.2531, 0.1260, 0.2075, 0.1865, 0.2269],\n",
      "          [0.2906, 0.1721, 0.1671, 0.1686, 0.2017],\n",
      "          [0.3122, 0.1627, 0.1578, 0.1859, 0.1815],\n",
      "          [0.2735, 0.1575, 0.1967, 0.1795, 0.1928],\n",
      "          [0.2731, 0.1583, 0.1901, 0.1606, 0.2179],\n",
      "          [0.2857, 0.1470, 0.1794, 0.1628, 0.2252],\n",
      "          [0.2578, 0.1683, 0.2387, 0.1618, 0.1735],\n",
      "          [0.2335, 0.1508, 0.2349, 0.1632, 0.2176],\n",
      "          [0.2733, 0.1490, 0.1949, 0.1872, 0.1957],\n",
      "          [0.2270, 0.1323, 0.2144, 0.2344, 0.1919]],\n",
      "\n",
      "         [[0.2096, 0.1909, 0.2047, 0.2053, 0.1896],\n",
      "          [0.2046, 0.1746, 0.1886, 0.2218, 0.2104],\n",
      "          [0.2099, 0.1544, 0.2056, 0.2197, 0.2104],\n",
      "          [0.1845, 0.1514, 0.1965, 0.2248, 0.2427],\n",
      "          [0.2213, 0.1824, 0.1712, 0.2077, 0.2174],\n",
      "          [0.2610, 0.1678, 0.1549, 0.1835, 0.2329],\n",
      "          [0.2543, 0.2053, 0.1561, 0.1758, 0.2085],\n",
      "          [0.2500, 0.1676, 0.1576, 0.2066, 0.2182],\n",
      "          [0.2240, 0.1540, 0.1956, 0.1855, 0.2408],\n",
      "          [0.1847, 0.1428, 0.2204, 0.2239, 0.2282],\n",
      "          [0.1983, 0.1880, 0.1900, 0.2121, 0.2116],\n",
      "          [0.1766, 0.1855, 0.2051, 0.2112, 0.2216],\n",
      "          [0.2138, 0.2250, 0.1613, 0.1920, 0.2080],\n",
      "          [0.1578, 0.1431, 0.2091, 0.2687, 0.2213],\n",
      "          [0.1721, 0.1931, 0.1923, 0.2208, 0.2217],\n",
      "          [0.1765, 0.1690, 0.1856, 0.2508, 0.2181]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "[34, 34, 34, 34, 34]\n",
      "predicted sentence: \n",
      " CCCCC\n"
     ]
    }
   ],
   "source": [
    "# Predicting next words\n",
    "sent = \"This is a simple sentence\"\n",
    "encoded_sent = encoding.encode(sent)\n",
    "enc_x = torch.tensor(encoded_sent).unsqueeze(0)\n",
    "dec_x = torch.tensor(encoding.encode(\"C\")).unsqueeze(0)\n",
    "\n",
    "transformer = Transformer(vocab_size=encoding.n_vocab, n=3, d=256, h=4)\n",
    "\n",
    "predicted_tokens = []\n",
    "for _ in range(5):\n",
    "    output = transformer(enc_x=enc_x, dec_x=dec_x)\n",
    "    softmaxed = F.softmax(output, dim=-1)\n",
    "    predicted = softmaxed.argmax(dim=-1)\n",
    "    predicted_tokens.append(predicted.tolist()[-1][-1]) \n",
    "    dec_x = torch.cat((dec_x, predicted), dim=-1)\n",
    "\n",
    "print(predicted_tokens)\n",
    "print(f\"predicted sentence: \\n {encoding.decode(predicted_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a4533-0646-49c1-a22f-04f055be1cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5588cc54-99dc-481d-8a78-d7d9e8adfd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hi.', 'START Salut!')\n",
      "('Stop!', 'START Arrte-toi !')\n",
      "('Hi.', 'START Salut!')\n",
      "('Run!', 'START Cours\\u202f!')\n",
      "('Run!', 'START Courez\\u202f!')\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "\n",
    "class Partition(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\"\n",
    "\n",
    "class Tokens(Enum):\n",
    "    START = \"START \"\n",
    "    END = \"<|endoftext|>\"\n",
    "    PAD = \" PAD\"\n",
    "    START_NUM = 23380\n",
    "    END_NUM = 100257\n",
    "    PAD_NUM = 62854\n",
    "    \n",
    "\n",
    "class EnFrDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file: Path | str, partition: Partition = Partition.TRAIN, val_ratio: float = 0.1):\n",
    "        # partition = TRAIN | VAL\n",
    "        self._partition = partition\n",
    "        self._val_ratio = val_ratio\n",
    "\n",
    "        self._data = []\n",
    "        self._train_map: dict[int, int] = {}\n",
    "        self._val_map: dict[int, int] = {}\n",
    "        train_id = 0\n",
    "        val_id = 0\n",
    "        with open(file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            # we want data indexes start from 0, but filter out the first header row\n",
    "            for i, row in enumerate(reader, start=-1):\n",
    "                if i == -1:\n",
    "                    continue\n",
    "                en = row[0]\n",
    "                fr = Tokens.START.value + row[1]\n",
    "                self._data.append(tuple([en, fr]))\n",
    "                if int(i * val_ratio) == int((i - 1) * val_ratio):\n",
    "                    self._train_map[train_id] = i\n",
    "                    train_id += 1\n",
    "                else:\n",
    "                    self._val_map[val_id] = i\n",
    "                    val_id += 1\n",
    "\n",
    "    class Iterator():\n",
    "\n",
    "        def __init__(self, outer):\n",
    "            self.cur = 0\n",
    "            self.outer = outer\n",
    "\n",
    "        def __next__(self):\n",
    "            if self.cur == len(self.outer._data):\n",
    "                raise StopIteration()\n",
    "            cur = self.outer._data[self.cur]\n",
    "            self.cur += 1\n",
    "            return cur\n",
    "\n",
    "    def __iter__(self):\n",
    "        return EnFrDataset.Iterator(self)\n",
    "    \n",
    "    @property\n",
    "    def partition(self):\n",
    "        return self._partition\n",
    "\n",
    "    @partition.setter\n",
    "    def partition(self, partition):\n",
    "        self._partition = partition\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._train_map) if self._partition == Partition.TRAIN else len(self._val_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._data[self._train_map[idx]] if self._partition == Partition.TRAIN else self._data[self._val_map[idx]]\n",
    "\n",
    "dataset = EnFrDataset(\"../data/eng_-french.csv\", val_ratio=0.1)\n",
    "train_sample = dataset[0]\n",
    "dataset.partition = Partition.VAL\n",
    "val_sample = dataset[0]\n",
    "assert train_sample != val_sample\n",
    "print(train_sample)\n",
    "print(val_sample)\n",
    "\n",
    "for i, d in enumerate(dataset):\n",
    "    if i > 2:\n",
    "        break\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d09eb729-53bb-420b-a608-73b1365e6dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([13347, 13], [23380], [8375])\n",
      "([6869, 0], [23380], [18733])\n",
      "([6869, 0], [23380], [18733])\n",
      "([36981, 0], [23380, 64105], [64105, 64])\n",
      "([12978, 0], [23380], [65381])\n"
     ]
    }
   ],
   "source": [
    "class TokEnFrDataset(Dataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def build_train_sample(en_str: str, dec_str: str):\n",
    "        en_encoded = encoding.encode(en_str)\n",
    "        dec_encoded = encoding.encode(dec_str)\n",
    "        dec_encoded.append(Tokens.END_NUM.value)\n",
    "        en_sents = []\n",
    "        dec_sents = []\n",
    "        target_sents = []\n",
    "        \n",
    "        for i in range(1, len(dec_encoded)):\n",
    "            dec_sents.append(dec_encoded[:i])\n",
    "            target_sents.append(dec_encoded[1: i + 1])\n",
    "        en_sents.extend([en_encoded] * len(dec_sents))\n",
    "        return list(zip(en_sents, dec_sents, target_sents))\n",
    "\n",
    "    def __init__(self, file: Path | str, partition: Partition = Partition.TRAIN, val_ratio: float = 0.1):\n",
    "        self._dataset = EnFrDataset(file, partition, val_ratio=0)\n",
    "        # partition = TRAIN | VAL\n",
    "        self._partition = partition\n",
    "        self._val_ratio = val_ratio\n",
    "\n",
    "        self._data = []\n",
    "        self._train_map: dict[int, int] = {}\n",
    "        self._val_map: dict[int, int] = {}\n",
    "        train_id = 0\n",
    "        val_id = 0\n",
    "        i = 0\n",
    "        for en, fr in self._dataset:\n",
    "            for sample in self.build_train_sample(en, fr):\n",
    "                self._data.append(sample)\n",
    "                if int(i * val_ratio) == int((i - 1) * val_ratio):\n",
    "                    self._train_map[train_id] = i\n",
    "                    train_id += 1\n",
    "                else:\n",
    "                    self._val_map[val_id] = i\n",
    "                    val_id += 1\n",
    "                i += 1\n",
    "\n",
    "    @property\n",
    "    def partition(self):\n",
    "        return self._partition\n",
    "\n",
    "    @partition.setter\n",
    "    def partition(self, partition):\n",
    "        self._partition = partition\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._train_map) if self._partition == Partition.TRAIN else len(self._val_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._data[self._train_map[idx]] if self._partition == Partition.TRAIN else self._data[self._val_map[idx]]\n",
    "\n",
    "dataset = TokEnFrDataset(\"../data/eng_-french.csv\", val_ratio=0.1)\n",
    "train_sample = dataset[0]\n",
    "dataset.partition = Partition.VAL\n",
    "val_sample = dataset[0]\n",
    "assert train_sample != val_sample\n",
    "print(train_sample)\n",
    "print(val_sample)\n",
    "\n",
    "for i, d in enumerate(dataset):\n",
    "    if i > 2:\n",
    "        break\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16252c2e-6c54-44c5-a4aa-4cfb4de90897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([6869, 0], [23380], [18733]), ([36981, 0], [23380, 64105], [64105, 64]), ([12978, 0], [23380], [65381]), ([35079, 13], [23380, 16233, 1088], [16233, 1088, 13]), ([10903, 0], [23380], [14549])]\n",
      "(tensor([[ 6869,     0],\n",
      "        [36981,     0],\n",
      "        [12978,     0],\n",
      "        [35079,    13],\n",
      "        [10903,     0]]), tensor([[23380, 62854, 62854],\n",
      "        [23380, 64105, 62854],\n",
      "        [23380, 62854, 62854],\n",
      "        [23380, 16233,  1088],\n",
      "        [23380, 62854, 62854]]), tensor([[18733, 62854, 62854],\n",
      "        [64105,    64, 62854],\n",
      "        [65381, 62854, 62854],\n",
      "        [16233,  1088,    13],\n",
      "        [14549, 62854, 62854]]), tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]]), tensor([[1, 0, 0],\n",
      "        [1, 1, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate(batch):\n",
    "    print(batch)\n",
    "    _x, _y, _label = list(zip(*batch))\n",
    "    x = pad_sequence([torch.tensor(t) for t in _x], batch_first=True, padding_value=Tokens.PAD_NUM.value)\n",
    "    y = pad_sequence([torch.tensor(t) for t in _y], batch_first=True, padding_value=Tokens.PAD_NUM.value)\n",
    "    label = pad_sequence([torch.tensor(t) for t in _label], batch_first=True, padding_value=Tokens.PAD_NUM.value)\n",
    "    enc_mask = build_padding_mask(x, pad_token=Tokens.PAD_NUM.value)\n",
    "    dec_mask = build_padding_mask(y, pad_token=Tokens.PAD_NUM.value)\n",
    "    return x, y, label, enc_mask, dec_mask\n",
    "\n",
    "training_generator = DataLoader(dataset, collate_fn=collate, batch_size=5, num_workers=0)\n",
    "for batch in training_generator:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98593c81-b0c3-4145-95bc-1965620ceb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# torch.set_default_device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "training_params = {\n",
    "    'collate_fn': collate,\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0}\n",
    "max_epochs = 5\n",
    "\n",
    "# Generators\n",
    "dataset = TokEnFrDataset(\"../data/eng_-french.csv\", val_ratio=0.05)\n",
    "dataloader = DataLoader(dataset, **training_params)\n",
    "\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    # Training\n",
    "    for local_batch, local_labels in training_generator:\n",
    "        # Transfer to GPU\n",
    "        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "        # Model computations\n",
    "        [...]\n",
    "\n",
    "    # Validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for local_batch, local_labels in validation_generator:\n",
    "            # Transfer to GPU\n",
    "            local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "            # Model computations\n",
    "            [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819338a-9df0-465b-b1cf-a0a6e8a59d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef7bbe-c8a8-493e-8677-49d9c02dbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def build_train_sample(en_str: str, dec_str: str):\n",
    "    en_encoded = encoding.encode(en_str)\n",
    "    dec_encoded = encoding.encode(dec_str)\n",
    "    dec_encoded.append(Tokens.END_NUM.value)\n",
    "    en_sents = []\n",
    "    dec_sents = []\n",
    "    target_sents = []\n",
    "    \n",
    "    for i in range(1, len(dec_encoded)):\n",
    "        dec_sents.append(dec_encoded[:i])\n",
    "        target_sents.append(dec_encoded[1: i + 1])\n",
    "    en_sents.extend([en_encoded] * len(dec_sents))\n",
    "    return list(zip(en_sents, dec_sents, target_sents))\n",
    "\n",
    "build_train_sample('Hi.', 'START Salut!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfee8d-38b9-4abb-b127-5e620ea387f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# def collate_fn\n",
    "\n",
    "dataset.partition = Partition.TRAIN\n",
    "training_generator = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "for i, s in enumerate(training_generator):\n",
    "    print(s)\n",
    "    if i > 2:\n",
    "        break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d5995-4736-4fec-9e51-e3672a9dc765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62b3c0-a20a-466d-b5fe-05b33071e963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0dbc9-7e82-48b4-9b90-0ddf28b10784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21175a-9751-4413-8cdb-579c52134778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207745b-3455-48f2-a6c1-d6546569344a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbfc3e-aca8-4edb-99e5-025c945d85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da787162-9955-4de5-a82d-60501d62ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Partition(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08f9da-be37-4a19-992e-11b2c6e1ce7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a2346-9e74-4eab-aab3-bd5bb0a0d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.3]]), dim=-1)\n",
    "torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.4]]).argmax(dim=-1)\n",
    "# torch.max(torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.4]]), dim=-1)\n",
    "\n",
    "t1 = torch.tensor([[0.1, 0.2]])\n",
    "t2 = torch.tensor([[0.3]])\n",
    "torch.cat((t1, t2), dim=1).tolist()[-1][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683599c0-fd00-40b0-8bb1-4e477a2114a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45e55c-6d60-409b-b26e-0b218224483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e70b0-a647-455b-bdfb-332d095aafc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082af878-9425-4445-b4b4-592cef79a2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dba170-623a-486b-8b67-58360bde104f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4d1a8-69aa-4c60-b3b4-ebb2e31f1c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda8a40-c41b-4eb3-90af-446f97e501f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f4736-acd3-4bd9-a9f5-b00240a17b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([1, 2, 3])\n",
    "mask = torch.ones([1, 2])\n",
    "mask[0, 1] = 0\n",
    "mask = mask.unsqueeze(1)\n",
    "print(mask == 0)\n",
    "x.masked_fill(mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4ff31-01d1-4144-b1ad-b2b600609d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bb090-365d-4c4d-986d-b048e7345f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
