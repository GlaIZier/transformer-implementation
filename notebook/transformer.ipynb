{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d7f736-b9af-48e3-adb5-18ab3536abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmasked attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d29dfa4-a1e1-4dd2-b2c5-e3ed8653fbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkhokhlush/github/transformer-implementation/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3, 3])\n",
      "torch.Size([2, 4, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def self_attention(q, k, v):\n",
    "    # if 3 dim: b t d\n",
    "    #prod = Q.bmm(K.permute(0, 2, 1))\n",
    "    # or\n",
    "    # prod = torch.einsum(\"btd, bsd -> bts\", q, k)\n",
    "    # if 4 dim: b t h dh\n",
    "    # q = q.permute(0, 2, 1, 3)\n",
    "    prod = torch.einsum(\"bthd, bshd -> bhts\", q, k)\n",
    "    scaled_prod = prod/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "    softmaxed_prod = F.softmax(scaled_prod, dim=-1)\n",
    "    print(softmaxed_prod.shape)\n",
    "    # print(softmaxed_prod)\n",
    "    return softmaxed_prod @ v.permute(0, 2, 1, 3)\n",
    "\n",
    "\n",
    "x = torch.rand([2, 3, 4, 5])\n",
    "self_attention(x, x, x)\n",
    "self_attention(x, x, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae60133-3d0c-4ada-8789-51107800432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        assert d % h == 0\n",
    "        self.d = d\n",
    "        self.dh = d // h\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(self.d, self.d)\n",
    "        self.wk = nn.Linear(self.d, self.d)\n",
    "        self.wv = nn.Linear(self.d, self.d)\n",
    "        self.wo = nn.Linear(self.d, self.d)\n",
    " \n",
    "    def forward(self, q, k, v):\n",
    "        # b, t, d\n",
    "        b, t, d = q.size()\n",
    "        wq = self.wq(q)\n",
    "        wk = self.wk(k)\n",
    "        wv = self.wv(v)\n",
    "        wq = wq.view(b, t, self.h, self.dh)\n",
    "        wk = wk.view(b, t, self.h, self.dh)\n",
    "        wv = wv.view(b, t, self.h, self.dh)\n",
    "        # b, t, h, dh\n",
    "        # if changing from 4 dim -> 3 dim: b*h, t, dh\n",
    "        # wq = wq.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wk = wk.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wv = wv.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # another option 4 dim -> 3 dim\n",
    "        # wq = wq.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wk = wk.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wv = wv.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # changing the number of dims is not necessary as @ supports 4 dims\n",
    "        attn = self_attention(wq, wk, wv)\n",
    "        # b * h, t, dh\n",
    "        # attn = attn.view(b, self.h, t, self.dh).permute(0, 2, 1, 3).reshape(b, t, d)\n",
    "        attn = attn.view(b, self.h, t, self.dh).transpose(1, 2).contiguous().view(b, t, d)\n",
    "        wo = self.wo(attn)\n",
    "        return wo\n",
    "        # # 1 2 3 4\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # return F.relu(self.conv2(x))\n",
    "\n",
    "mhsa = MHSA()\n",
    "x = torch.rand(2, 3, 512)\n",
    "mhsa(x, x, x).shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abcca093-9e66-4b46-8ec3-aded63ece6f8",
   "metadata": {},
   "source": [
    "class PE1():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # -> d vector\n",
    "    def __call__(self, pos):\n",
    "        pow = torch.pow(10000, torch.arange(0, self.d) / self.d)\n",
    "        return torch.sin(torch.arange(0, self.d) / pow)\n",
    "\n",
    "print(PE1()(1).size()) # torch.Size([512])\n",
    "\n",
    "class PEScalar():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # 1 -> d vector\n",
    "    def __call__(self, pos):\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2)\n",
    "        # b = torch.arange(1, 12, 2)\n",
    "        # torch.stack((a, b), dim=1).view(-1)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1)\n",
    "\n",
    "print(PEScalar()(1).size()) # torch.Size([1, 512])\n",
    "\n",
    "class PEVector():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # 1 -> 1 d\n",
    "    # t 1 -> t d\n",
    "    def __call__(self, pos):\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2).view(-1, 2)\n",
    "        # b = torch.arange(1, 12, 2).view(-1, 2)\n",
    "        # torch.stack((a, b), dim=-1).view(-1, 4)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1, self.d)\n",
    "\n",
    "print(PEVector()(1).size()) # torch.Size([1, 512])\n",
    "print(PEVector()(torch.arange(3).view(-1, 1)).size()) # torch.Size([3, 512])\n",
    "\n",
    "class PE():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # b t 1 -> b t d\n",
    "    def __call__(self, pos):\n",
    "        b, t, _ = pos.size()\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2).view(-1, 2)\n",
    "        # b = torch.arange(1, 12, 2).view(-1, 2)\n",
    "        # torch.stack((a, b), dim=-1).view(-1, 4)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1, t, self.d)\n",
    "\n",
    "print(PE()(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])\n",
    "\n",
    "class PEAnotherImpl():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # b t 1 -> b t d\n",
    "    def __call__(self, pos):\n",
    "        b, t, _ = pos.size()\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        max_len = 1024\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        sin_p = torch.sin(position / pow_)\n",
    "        cos_p = torch.cos(position / pow_)\n",
    "        pe = torch.zeros(max_len, self.d)\n",
    "        pe[:, 0::2] = sin_p\n",
    "        pe[:, 1::2] = cos_p\n",
    "        return pe[:t, :].unsqueeze(0).repeat(b, 1, 1)\n",
    "\n",
    "print(PEAnotherImpl()(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])\n",
    "\n",
    "class PEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        pos = torch.arange(max_len).unsqueeze(1)\n",
    "        print(pos.size())\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        print(sin_p.size())\n",
    "        print(cos_p.size())\n",
    "        pe = torch.stack((sin_p, cos_p), dim=-1).view(-1, self.d) # downside sin, cos don't alternate\n",
    "        print(pe.size())\n",
    "        pe = pe.unsqueeze(0)\n",
    "        print(pe.size())\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.size: b, t, d\n",
    "        x = x + self.pe[:, : t, :]\n",
    "        return self.dropout(x)\n",
    "print(PEModule(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])\n",
    "\n",
    "class PositionalEncodingAnnotatedTransformerModule(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncodingAnnotatedTransformer, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        print(position.size())\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        print(div_term.size())\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        print(pe.size())\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.pe[:, : x.size(1)].size())\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "print(PositionalEncodingAnnotatedTransformerModule(512, 0.1)(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56a9e6b-8461-4417-ab07-e5fbd79c60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4413f3-ef3e-4d04-baad-f49354915c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PE(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        sin_p = torch.sin(position / pow_)\n",
    "        cos_p = torch.cos(position / pow_)\n",
    "        pe = torch.zeros(max_len, self.d, requires_grad=False) # Explicit, register buffer insures requires grad = False\n",
    "        pe[:, 0::2] = sin_p\n",
    "        pe[:, 1::2] = cos_p\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe) \n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.pe[:, : t, :]\n",
    "        return self.dropout(x)\n",
    "print(PE(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd49c59-e4b6-4b7d-9719-79079f2f40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PEEmbed(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.pe = nn.Embedding(max_len, d)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        pos = self.pe(torch.arange(t))\n",
    "        x = x + pos\n",
    "        return self.dropout(x)\n",
    "print(PEEmbed(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c5bf9-3800-4b22-b7d8-8886d4f15b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d626059-fd88-4a03-8b20-ffbf0115fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderLayerWithoutMask(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSA(d, h)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.attn_dropout(self.mhsa(x, x, x))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "encoder_layer = EncoderLayerWithoutMask()\n",
    "x = torch.rand(2, 3, 512)\n",
    "encoder_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851eff3d-4816-4410-9184-f30c157e4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class EncoderWithoutMask(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [EncoderLayerWithoutMask(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t = x.size()\n",
    "        x = self.embed(x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "encoder = EncoderWithoutMask()\n",
    "x = torch.randint(0, 2**13, (2, 3))\n",
    "encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddfbf32-dd33-4246-adad-0baa8b6ba5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With masks\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def self_attention_masked(q, k, v, mask=None):\n",
    "    # if 3 dim: b t d\n",
    "    #prod = Q.bmm(K.permute(0, 2, 1))\n",
    "    # or\n",
    "    # prod = torch.einsum(\"btd, bsd -> bts\", q, k)\n",
    "    # if 4 dim: b t h dh:\n",
    "    prod = torch.einsum(\"bthd, bshd -> bhts\", q, k)\n",
    "    scaled_prod = prod/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "    print(f\"scaled_prod.shape: \\n {scaled_prod.shape}\")\n",
    "    # mask should be in shape to be broadcastable to bhts and lead to masked keys only (last s dim)\n",
    "    if mask is not None:\n",
    "        scaled_prod = scaled_prod.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    print(f\"scaled_prod: \\n {scaled_prod}\")\n",
    "    softmaxed_prod = F.softmax(scaled_prod, dim=-1)\n",
    "    # print(softmaxed_prod.shape)\n",
    "    print(f\"softmaxed_prod: \\n {softmaxed_prod}\")\n",
    "    # swap h and t in v\n",
    "    return softmaxed_prod @ v.permute(0, 2, 1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eac5e23-ea43-4295-ba24-a7edbe1a1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d78a45-be0c-4d97-9020-4b83e8c499f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5197, 0.5411, 0.6381, 0.3260],\n",
      "          [0.7154, 0.1061, 0.3673, 0.7780]],\n",
      "\n",
      "         [[0.2145, 0.1403, 0.0992, 0.6875],\n",
      "          [0.0835, 0.2168, 0.8869, 0.8104]],\n",
      "\n",
      "         [[0.6843, 0.3754, 0.7641, 0.3368],\n",
      "          [0.0599, 0.4743, 0.4382, 0.2703]]],\n",
      "\n",
      "\n",
      "        [[[0.5229, 0.5762, 0.5786, 0.8980],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496]],\n",
      "\n",
      "         [[0.8276, 0.2185, 0.5424, 0.0732],\n",
      "          [0.0893, 0.0777, 0.2497, 0.6546]],\n",
      "\n",
      "         [[0.8811, 0.8675, 0.5580, 0.9198],\n",
      "          [0.3234, 0.7859, 0.1576, 0.1278]]]])\n",
      "mask: \n",
      " tensor([[1., 1., 0.],\n",
      "        [1., 0., 0.]])\n",
      "wrong mask: \n",
      " tensor([[[1., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0.]]])\n",
      "wrong mask broadcast: \n",
      " tensor([[[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.5382, 0.2374,   -inf],\n",
      "          [0.2374, 0.2741,   -inf],\n",
      "          [0.5781, 0.2535,   -inf]],\n",
      "\n",
      "         [[0.6316,   -inf,   -inf],\n",
      "          [0.5194,   -inf,   -inf],\n",
      "          [0.2322,   -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8734, 0.4691,   -inf],\n",
      "          [0.4691, 0.5161,   -inf],\n",
      "          [1.0547, 0.6443,   -inf]],\n",
      "\n",
      "         [[0.3487,   -inf,   -inf],\n",
      "          [0.2130,   -inf,   -inf],\n",
      "          [0.1816,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5746, 0.4254, 0.0000],\n",
      "          [0.4908, 0.5092, 0.0000],\n",
      "          [0.5805, 0.4195, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5997, 0.4003, 0.0000],\n",
      "          [0.4883, 0.5117, 0.0000],\n",
      "          [0.6012, 0.3988, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "wrong a: \n",
      " tensor([[[[0.3899, 0.3706, 0.4089, 0.4798],\n",
      "          [0.3643, 0.3371, 0.3637, 0.5101],\n",
      "          [0.3916, 0.3730, 0.4120, 0.4777]],\n",
      "\n",
      "         [[0.7154, 0.1061, 0.3673, 0.7780],\n",
      "          [0.7154, 0.1061, 0.3673, 0.7780],\n",
      "          [0.7154, 0.1061, 0.3673, 0.7780]]],\n",
      "\n",
      "\n",
      "        [[[0.6449, 0.4330, 0.5641, 0.5678],\n",
      "          [0.6788, 0.3931, 0.5601, 0.4759],\n",
      "          [0.6444, 0.4335, 0.5642, 0.5691]],\n",
      "\n",
      "         [[0.6177, 0.1171, 0.0077, 0.5496],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496]]]])\n",
      "wrong a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n",
      "mask: \n",
      " tensor([[[[1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.]]]])\n",
      "mask broadcast: \n",
      " tensor([[[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.5382, 0.2374,   -inf],\n",
      "          [0.2374, 0.2741,   -inf],\n",
      "          [0.5781, 0.2535,   -inf]],\n",
      "\n",
      "         [[0.6316, 0.5194,   -inf],\n",
      "          [0.5194, 0.7486,   -inf],\n",
      "          [0.2322, 0.3578,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8734,   -inf,   -inf],\n",
      "          [0.4691,   -inf,   -inf],\n",
      "          [1.0547,   -inf,   -inf]],\n",
      "\n",
      "         [[0.3487,   -inf,   -inf],\n",
      "          [0.2130,   -inf,   -inf],\n",
      "          [0.1816,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5746, 0.4254, 0.0000],\n",
      "          [0.4908, 0.5092, 0.0000],\n",
      "          [0.5805, 0.4195, 0.0000]],\n",
      "\n",
      "         [[0.5280, 0.4720, 0.0000],\n",
      "          [0.4430, 0.5570, 0.0000],\n",
      "          [0.4687, 0.5313, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "a: \n",
      " tensor([[[[0.3899, 0.3706, 0.4089, 0.4798],\n",
      "          [0.3643, 0.3371, 0.3637, 0.5101],\n",
      "          [0.3916, 0.3730, 0.4120, 0.4777]],\n",
      "\n",
      "         [[0.4172, 0.1583, 0.6125, 0.7932],\n",
      "          [0.3634, 0.1677, 0.6567, 0.7960],\n",
      "          [0.3796, 0.1649, 0.6434, 0.7952]]],\n",
      "\n",
      "\n",
      "        [[[0.5229, 0.5762, 0.5786, 0.8980],\n",
      "          [0.5229, 0.5762, 0.5786, 0.8980],\n",
      "          [0.5229, 0.5762, 0.5786, 0.8980]],\n",
      "\n",
      "         [[0.6177, 0.1171, 0.0077, 0.5496],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496]]]])\n",
      "a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# play with mask\n",
    "\n",
    "x = torch.rand([2, 3, 2, 4])\n",
    "print(x)\n",
    "# mask 2 batches 3 timeseries\n",
    "mask = torch.ones([2, 3])\n",
    "mask[0, 2] = 0\n",
    "mask[1, 2] = 0\n",
    "mask[1, 1] = 0\n",
    "print(f\"mask: \\n {mask}\")\n",
    "# add head dim to make mask broatcastable to q x k.T prod. mask shape 2, 1, 3\n",
    "mask = mask.unsqueeze(1)\n",
    "\n",
    "\n",
    "# mask = mask.permute(0, 2, 1)\n",
    "# is the mask that I need? keys are ignored?\n",
    "print(f\"wrong mask: \\n {mask}\")\n",
    "#  mask = 2 1 3 -> b prepended before broadcasting (1!!!) h (remains since already 2) t (broadcasted from 1) d (remains since already 3) \n",
    "print(f\"wrong mask broadcast: \\n {mask.broadcast_to([2, 2, 3, 3])}\") \n",
    "a = self_attention_masked(x, x, x, mask=mask)\n",
    "print(f\"wrong a: \\n {a}\" )\n",
    "print(f\"wrong a.shape: \\n {a.shape}\")\n",
    "# leads to wrong attention since the shape of mask is wrong 2 1 3 \n",
    "\n",
    "# correct mask\n",
    "# mask 2 batches 3 timeseries\n",
    "mask = torch.ones([2, 3])\n",
    "mask[0, 2] = 0\n",
    "mask[1, 2] = 0\n",
    "mask[1, 1] = 0\n",
    "mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "print(f\"mask: \\n {mask}\")\n",
    "#  mask = 2 1 1 3 -> b (remains already 2) h (broadcasted from 1) t (broadcasted from 1) d (remains since already 3) \n",
    "print(f\"mask broadcast: \\n {mask.broadcast_to([2, 2, 3, 3])}\") \n",
    "a = self_attention_masked(x, x, x, mask=mask)\n",
    "print(f\"a: \\n {a}\" )\n",
    "print(f\"a.shape: \\n {a.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1c6a367-2547-4d72-be99-19bbc1023c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: \n",
      " tensor([[[[0.5197, 0.5411, 0.6381, 0.3260],\n",
      "          [0.7154, 0.1061, 0.3673, 0.7780]],\n",
      "\n",
      "         [[0.2145, 0.1403, 0.0992, 0.6875],\n",
      "          [0.0835, 0.2168, 0.8869, 0.8104]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.5229, 0.5762, 0.5786, 0.8980],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.5382, 0.2374,   -inf],\n",
      "          [0.2374, 0.2741,   -inf],\n",
      "          [0.5781, 0.2535,   -inf]],\n",
      "\n",
      "         [[0.6316, 0.5194,   -inf],\n",
      "          [0.5194, 0.7486,   -inf],\n",
      "          [0.2322, 0.3578,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8734,   -inf,   -inf],\n",
      "          [0.4691,   -inf,   -inf],\n",
      "          [1.0547,   -inf,   -inf]],\n",
      "\n",
      "         [[0.3487,   -inf,   -inf],\n",
      "          [0.2130,   -inf,   -inf],\n",
      "          [0.1816,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5746, 0.4254, 0.0000],\n",
      "          [0.4908, 0.5092, 0.0000],\n",
      "          [0.5805, 0.4195, 0.0000]],\n",
      "\n",
      "         [[0.5280, 0.4720, 0.0000],\n",
      "          [0.4430, 0.5570, 0.0000],\n",
      "          [0.4687, 0.5313, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "a: \n",
      " tensor([[[[0.3899, 0.3706, 0.4089, 0.4798],\n",
      "          [0.3643, 0.3371, 0.3637, 0.5101],\n",
      "          [0.3916, 0.3730, 0.4120, 0.4777]],\n",
      "\n",
      "         [[0.4172, 0.1583, 0.6125, 0.7932],\n",
      "          [0.3634, 0.1677, 0.6567, 0.7960],\n",
      "          [0.3796, 0.1649, 0.6434, 0.7952]]],\n",
      "\n",
      "\n",
      "        [[[0.5229, 0.5762, 0.5786, 0.8980],\n",
      "          [0.5229, 0.5762, 0.5786, 0.8980],\n",
      "          [0.5229, 0.5762, 0.5786, 0.8980]],\n",
      "\n",
      "         [[0.6177, 0.1171, 0.0077, 0.5496],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496],\n",
      "          [0.6177, 0.1171, 0.0077, 0.5496]]]])\n",
      "a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n",
      "test: \n",
      " tensor([[[0.6110, 0.9041, 0.3602, 0.0324],\n",
      "         [0.0498, 0.4516, 0.8150, 0.4237],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.2357, 0.4337, 0.9640, 0.9559],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "test_v: \n",
      " tensor([[[[0.6110, 0.9041],\n",
      "          [0.3602, 0.0324]],\n",
      "\n",
      "         [[0.0498, 0.4516],\n",
      "          [0.8150, 0.4237]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2357, 0.4337],\n",
      "          [0.9640, 0.9559]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]]])\n",
      "test_perm: \n",
      " tensor([[[[0.6110, 0.9041],\n",
      "          [0.0498, 0.4516],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3602, 0.0324],\n",
      "          [0.8150, 0.4237],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2357, 0.4337],\n",
      "          [0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.9640, 0.9559],\n",
      "          [0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]]])\n",
      "test_k: \n",
      " tensor([[[0.1525, 0.0966, 0.7438, 0.9373],\n",
      "         [0.4918, 0.3225, 0.9252, 0.6835],\n",
      "         [  -inf,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        [[0.4152, 0.8510, 0.4837, 0.4035],\n",
      "         [  -inf,   -inf,   -inf,   -inf],\n",
      "         [  -inf,   -inf,   -inf,   -inf]]])\n",
      "test_k_view: \n",
      " tensor([[[[0.1525, 0.0966],\n",
      "          [0.7438, 0.9373]],\n",
      "\n",
      "         [[0.4918, 0.3225],\n",
      "          [0.9252, 0.6835]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.4152, 0.8510],\n",
      "          [0.4837, 0.4035]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]]]])\n",
      "test_k_perm: \n",
      " tensor([[[[0.1525, 0.0966],\n",
      "          [0.4918, 0.3225],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[0.7438, 0.9373],\n",
      "          [0.9252, 0.6835],\n",
      "          [  -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.4152, 0.8510],\n",
      "          [  -inf,   -inf],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[0.4837, 0.4035],\n",
      "          [  -inf,   -inf],\n",
      "          [  -inf,   -inf]]]])\n",
      "q * k: \n",
      " tensor([[[[0.0326, 0.1062,   -inf],\n",
      "          [0.1062, 0.3459,   -inf],\n",
      "          [0.2140, 0.7009,   -inf]],\n",
      "\n",
      "         [[1.4316, 1.3288,   -inf],\n",
      "          [1.3288, 1.3231,   -inf],\n",
      "          [0.1784, 0.1649,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8967,   -inf,   -inf],\n",
      "          [0.6108,   -inf,   -inf],\n",
      "          [0.7695,   -inf,   -inf]],\n",
      "\n",
      "         [[0.3968,   -inf,   -inf],\n",
      "          [0.6278,   -inf,   -inf],\n",
      "          [0.3864,   -inf,   -inf]]]])\n"
     ]
    }
   ],
   "source": [
    "# mask is equal to making keys on masked places 0:\n",
    "# the result in terms of masked symbols is the same\n",
    "k = x.clone()\n",
    "k[0, 2, 0, :] = float(\"-inf\")\n",
    "k[0, 2, 1, :] = float(\"-inf\")\n",
    "k[1, 2, 0, :] = float(\"-inf\")\n",
    "k[1, 1, 0, :] = float(\"-inf\")\n",
    "k[1, 2, 1, :] = float(\"-inf\")\n",
    "k[1, 1, 1, :] = float(\"-inf\")\n",
    "print(f\"k: \\n {k}\")\n",
    "a = self_attention_masked(x, k, x)\n",
    "print(f\"a: \\n {a}\" )\n",
    "print(f\"a.shape: \\n {a.shape}\")\n",
    "# a is the same shape as if mask was applied in q * k:\n",
    "\n",
    "test = torch.rand([2, 3, 4])\n",
    "test[0, 2, :] = 0\n",
    "test[1, 1, :] = 0\n",
    "test[1, 2, :] = 0\n",
    "\n",
    "print(f\"test: \\n {test}\")\n",
    "test_v = test.view(2, 3, 2, 2)\n",
    "print(f\"test_v: \\n {test_v}\")\n",
    "test_perm = test_v.permute(0, 2, 1, 3)\n",
    "print(f\"test_perm: \\n {test_perm}\")\n",
    "\n",
    "# or like that:\n",
    "test_q = torch.rand([2, 3, 4])\n",
    "test_k = test_q.clone()\n",
    "test_k[0, 2, :] = float(\"-inf\")\n",
    "test_k[1, 1, :] = float(\"-inf\")\n",
    "test_k[1, 2, :] = float(\"-inf\")\n",
    "print(f\"test_k: \\n {test_k}\")\n",
    "\n",
    "test_q_view = test_q.view(2, 3, 2, 2)\n",
    "test_k_view = test_k.view(2, 3, 2, 2)\n",
    "print(f\"test_k_view: \\n {test_k_view}\")\n",
    "test_q_perm = test_q_view.permute(0, 2, 1, 3)\n",
    "test_k_perm = test_k_view.permute(0, 2, 1, 3)\n",
    "print(f\"test_k_perm: \\n {test_k_perm}\")\n",
    "print(f\"q * k: \\n {torch.einsum(\"bhtd, bhsd -> bhts\", test_q_perm, test_k_perm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90465ec8-787f-409e-977a-30c566450515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.6317e-01, 2.9040e-01, 4.2508e-01, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [7.7778e-01, 1.1218e-01, 1.0981e-01, 4.4139e-02, 1.0000e+02, 1.0000e+02],\n",
      "        [2.3179e-01, 2.6273e-01, 6.1778e-01, 3.1230e-01, 1.3051e-01, 1.0000e+02],\n",
      "        [1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [4.9919e-01, 8.8737e-01, 7.5314e-01, 8.6046e-01, 4.2014e-01, 7.3911e-01]])\n",
      "tensor([[1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_padding_mask(x, pad_token):\n",
    "    # x: b t shape\n",
    "    mask = torch.ones_like(x)\n",
    "    return mask.masked_fill(x == pad_token, 0)\n",
    "\n",
    "x = torch.rand(5, 6)\n",
    "x[0, -3:] = 100\n",
    "x[1, -2:] = 100\n",
    "x[2, -1] = 100\n",
    "x[3, :] = 100\n",
    "print(x)\n",
    "print(build_padding_mask(x, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647bfc41-5717-4c39-92d5-6d1ba132f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_causal_mask(x):\n",
    "    # x: b t shape\n",
    "    m = torch.ones_like(x)\n",
    "    return torch.tril(m)\n",
    "x = torch.rand(5, 6)\n",
    "\n",
    "print(build_causal_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6702b0c-11f5-4326-989e-d2b76a77dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8126e-01, 7.2617e-01, 9.9193e-01, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [9.7744e-01, 2.9643e-01, 6.3065e-02, 4.9401e-01, 2.6612e-01, 1.0000e+02],\n",
      "        [2.2052e-01, 1.2273e-01, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [9.4130e-01, 7.0709e-01, 9.1821e-02, 9.1652e-01, 2.5230e-01, 4.8051e-01]])\n",
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def merge_masks(m1, m2):\n",
    "    return m1 * m2\n",
    "\n",
    "x = torch.rand(5, 6)\n",
    "x[0, -3:] = 100\n",
    "x[1, -1] = 100\n",
    "x[2, -4:] = 100\n",
    "x[3, :] = 100\n",
    "print(x)\n",
    "m1 = build_padding_mask(x, 100)\n",
    "m2 = build_causal_mask(x)\n",
    "print(merge_masks(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c167748-72fb-40b3-9e6d-7755fa12bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def reshape_mask(mask):\n",
    "    # b t -> b 1 1 t (to be broadcastable to b h t t)\n",
    "    return mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "x = torch.rand(2, 3)\n",
    "print(reshape_mask(build_causal_mask(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "336c48b9-29d0-4f4e-9d67-a12ddc566634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([4, 2, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0373,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0716,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0067,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0635,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1106,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0179,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0067,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0570,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0437,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0307,    -inf,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0274,  0.0643,    -inf,    -inf,    -inf],\n",
      "          [ 0.0649,  0.1165,    -inf,    -inf,    -inf],\n",
      "          [ 0.1164,  0.1189,    -inf,    -inf,    -inf],\n",
      "          [ 0.1601,  0.1688,    -inf,    -inf,    -inf],\n",
      "          [ 0.1162,  0.1207,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0276,  0.0148,    -inf,    -inf,    -inf],\n",
      "          [-0.0461, -0.0547,    -inf,    -inf,    -inf],\n",
      "          [-0.1210, -0.1170,    -inf,    -inf,    -inf],\n",
      "          [-0.0246, -0.0230,    -inf,    -inf,    -inf],\n",
      "          [-0.0698, -0.0702,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0877,  0.0933,  0.1280,    -inf,    -inf],\n",
      "          [ 0.0387,  0.0688,  0.0813,    -inf,    -inf],\n",
      "          [ 0.1490,  0.1724,  0.1895,    -inf,    -inf],\n",
      "          [ 0.0716,  0.0533,  0.0968,    -inf,    -inf],\n",
      "          [ 0.1408,  0.1631,  0.1666,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0342, -0.0356,  0.0109,    -inf,    -inf],\n",
      "          [-0.0605, -0.0693, -0.0187,    -inf,    -inf],\n",
      "          [-0.0673, -0.0541, -0.0378,    -inf,    -inf],\n",
      "          [-0.0649, -0.0657, -0.0069,    -inf,    -inf],\n",
      "          [-0.0686, -0.0444, -0.0342,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2535,  0.0982,  0.2244,  0.0905,    -inf],\n",
      "          [ 0.2534,  0.1137,  0.2302,  0.1019,    -inf],\n",
      "          [ 0.2295,  0.0912,  0.2020,  0.0730,    -inf],\n",
      "          [ 0.1727,  0.0716,  0.1530,  0.0568,    -inf],\n",
      "          [ 0.1870,  0.0620,  0.1631,  0.0663,    -inf]],\n",
      "\n",
      "         [[-0.0331,  0.0244, -0.0118,  0.0082,    -inf],\n",
      "          [-0.0914, -0.0149, -0.0754, -0.0330,    -inf],\n",
      "          [ 0.0010,  0.0401, -0.0042,  0.0008,    -inf],\n",
      "          [-0.0279,  0.0400, -0.0079,  0.0119,    -inf],\n",
      "          [ 0.0612,  0.0778,  0.0789,  0.0610,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4908, 0.5092, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4871, 0.5129, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4994, 0.5006, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4978, 0.5022, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4989, 0.5011, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5032, 0.4968, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5022, 0.4978, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4990, 0.5010, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4996, 0.5004, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5001, 0.4999, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3282, 0.3301, 0.3417, 0.0000, 0.0000],\n",
      "          [0.3253, 0.3352, 0.3394, 0.0000, 0.0000],\n",
      "          [0.3263, 0.3340, 0.3398, 0.0000, 0.0000],\n",
      "          [0.3325, 0.3265, 0.3410, 0.0000, 0.0000],\n",
      "          [0.3280, 0.3354, 0.3366, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3284, 0.3280, 0.3436, 0.0000, 0.0000],\n",
      "          [0.3296, 0.3267, 0.3437, 0.0000, 0.0000],\n",
      "          [0.3286, 0.3330, 0.3384, 0.0000, 0.0000],\n",
      "          [0.3269, 0.3267, 0.3464, 0.0000, 0.0000],\n",
      "          [0.3268, 0.3349, 0.3383, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2720, 0.2328, 0.2642, 0.2310, 0.0000],\n",
      "          [0.2698, 0.2346, 0.2636, 0.2319, 0.0000],\n",
      "          [0.2704, 0.2354, 0.2630, 0.2312, 0.0000],\n",
      "          [0.2649, 0.2394, 0.2597, 0.2359, 0.0000],\n",
      "          [0.2670, 0.2356, 0.2607, 0.2366, 0.0000]],\n",
      "\n",
      "         [[0.2426, 0.2569, 0.2478, 0.2528, 0.0000],\n",
      "          [0.2406, 0.2598, 0.2445, 0.2551, 0.0000],\n",
      "          [0.2479, 0.2578, 0.2466, 0.2478, 0.0000],\n",
      "          [0.2421, 0.2591, 0.2470, 0.2519, 0.0000],\n",
      "          [0.2479, 0.2520, 0.2523, 0.2478, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[-0.4590, -0.0767, -0.3916, -0.2365, -0.6166, -0.5432],\n",
      "         [-0.4590, -0.0767, -0.3916, -0.2365, -0.6166, -0.5432],\n",
      "         [-0.4590, -0.0767, -0.3916, -0.2365, -0.6166, -0.5432],\n",
      "         [-0.4590, -0.0767, -0.3916, -0.2365, -0.6166, -0.5432],\n",
      "         [-0.4590, -0.0767, -0.3916, -0.2365, -0.6166, -0.5432]],\n",
      "\n",
      "        [[-0.4041, -0.1030, -0.4427, -0.1947, -0.6601, -0.5363],\n",
      "         [-0.4043, -0.1034, -0.4430, -0.1946, -0.6607, -0.5365],\n",
      "         [-0.4039, -0.1012, -0.4423, -0.1960, -0.6593, -0.5369],\n",
      "         [-0.4040, -0.1015, -0.4424, -0.1958, -0.6594, -0.5368],\n",
      "         [-0.4039, -0.1014, -0.4423, -0.1958, -0.6592, -0.5367]],\n",
      "\n",
      "        [[-0.4185, -0.1066, -0.4540, -0.2752, -0.7345, -0.5531],\n",
      "         [-0.4185, -0.1057, -0.4534, -0.2757, -0.7334, -0.5530],\n",
      "         [-0.4184, -0.1063, -0.4537, -0.2756, -0.7339, -0.5527],\n",
      "         [-0.4184, -0.1068, -0.4543, -0.2749, -0.7350, -0.5534],\n",
      "         [-0.4182, -0.1058, -0.4536, -0.2759, -0.7337, -0.5526]],\n",
      "\n",
      "        [[-0.5204, -0.0647, -0.3128, -0.2704, -0.4946, -0.4701],\n",
      "         [-0.5212, -0.0642, -0.3121, -0.2707, -0.4936, -0.4704],\n",
      "         [-0.5200, -0.0649, -0.3133, -0.2707, -0.4954, -0.4701],\n",
      "         [-0.5207, -0.0638, -0.3122, -0.2710, -0.4936, -0.4701],\n",
      "         [-0.5191, -0.0644, -0.3135, -0.2708, -0.4950, -0.4695]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([4, 2, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0373,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0716,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0067,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0635,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1106,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0179,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0067,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0570,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0437,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0307,    -inf,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0274,  0.0643,    -inf,    -inf,    -inf],\n",
      "          [ 0.0649,  0.1165,    -inf,    -inf,    -inf],\n",
      "          [ 0.1164,  0.1189,    -inf,    -inf,    -inf],\n",
      "          [ 0.1601,  0.1688,    -inf,    -inf,    -inf],\n",
      "          [ 0.1162,  0.1207,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0276,  0.0148,    -inf,    -inf,    -inf],\n",
      "          [-0.0461, -0.0547,    -inf,    -inf,    -inf],\n",
      "          [-0.1210, -0.1170,    -inf,    -inf,    -inf],\n",
      "          [-0.0246, -0.0230,    -inf,    -inf,    -inf],\n",
      "          [-0.0698, -0.0702,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0877,  0.0933,  0.1280,    -inf,    -inf],\n",
      "          [ 0.0387,  0.0688,  0.0813,    -inf,    -inf],\n",
      "          [ 0.1490,  0.1724,  0.1895,    -inf,    -inf],\n",
      "          [ 0.0716,  0.0533,  0.0968,    -inf,    -inf],\n",
      "          [ 0.1408,  0.1631,  0.1666,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0342, -0.0356,  0.0109,    -inf,    -inf],\n",
      "          [-0.0605, -0.0693, -0.0187,    -inf,    -inf],\n",
      "          [-0.0673, -0.0541, -0.0378,    -inf,    -inf],\n",
      "          [-0.0649, -0.0657, -0.0069,    -inf,    -inf],\n",
      "          [-0.0686, -0.0444, -0.0342,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2535,  0.0982,  0.2244,  0.0905,    -inf],\n",
      "          [ 0.2534,  0.1137,  0.2302,  0.1019,    -inf],\n",
      "          [ 0.2295,  0.0912,  0.2020,  0.0730,    -inf],\n",
      "          [ 0.1727,  0.0716,  0.1530,  0.0568,    -inf],\n",
      "          [ 0.1870,  0.0620,  0.1631,  0.0663,    -inf]],\n",
      "\n",
      "         [[-0.0331,  0.0244, -0.0118,  0.0082,    -inf],\n",
      "          [-0.0914, -0.0149, -0.0754, -0.0330,    -inf],\n",
      "          [ 0.0010,  0.0401, -0.0042,  0.0008,    -inf],\n",
      "          [-0.0279,  0.0400, -0.0079,  0.0119,    -inf],\n",
      "          [ 0.0612,  0.0778,  0.0789,  0.0610,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4908, 0.5092, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4871, 0.5129, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4994, 0.5006, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4978, 0.5022, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4989, 0.5011, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5032, 0.4968, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5022, 0.4978, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4990, 0.5010, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4996, 0.5004, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5001, 0.4999, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3282, 0.3301, 0.3417, 0.0000, 0.0000],\n",
      "          [0.3253, 0.3352, 0.3394, 0.0000, 0.0000],\n",
      "          [0.3263, 0.3340, 0.3398, 0.0000, 0.0000],\n",
      "          [0.3325, 0.3265, 0.3410, 0.0000, 0.0000],\n",
      "          [0.3280, 0.3354, 0.3366, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3284, 0.3280, 0.3436, 0.0000, 0.0000],\n",
      "          [0.3296, 0.3267, 0.3437, 0.0000, 0.0000],\n",
      "          [0.3286, 0.3330, 0.3384, 0.0000, 0.0000],\n",
      "          [0.3269, 0.3267, 0.3464, 0.0000, 0.0000],\n",
      "          [0.3268, 0.3349, 0.3383, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2720, 0.2328, 0.2642, 0.2310, 0.0000],\n",
      "          [0.2698, 0.2346, 0.2636, 0.2319, 0.0000],\n",
      "          [0.2704, 0.2354, 0.2630, 0.2312, 0.0000],\n",
      "          [0.2649, 0.2394, 0.2597, 0.2359, 0.0000],\n",
      "          [0.2670, 0.2356, 0.2607, 0.2366, 0.0000]],\n",
      "\n",
      "         [[0.2426, 0.2569, 0.2478, 0.2528, 0.0000],\n",
      "          [0.2406, 0.2598, 0.2445, 0.2551, 0.0000],\n",
      "          [0.2479, 0.2578, 0.2466, 0.2478, 0.0000],\n",
      "          [0.2421, 0.2591, 0.2470, 0.2519, 0.0000],\n",
      "          [0.2479, 0.2520, 0.2523, 0.2478, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MHSAMasked(nn.Module):\n",
    "    def __init__(self, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        assert d % h == 0\n",
    "        self.d = d\n",
    "        self.dh = d // h\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(self.d, self.d)\n",
    "        self.wk = nn.Linear(self.d, self.d)\n",
    "        self.wv = nn.Linear(self.d, self.d)\n",
    "        self.wo = nn.Linear(self.d, self.d)\n",
    " \n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        # q and k/v might be of different sizes if lengths of decoder and encoders inputs are different\n",
    "        bq, tq, dq = q.size()\n",
    "        bk, tk, dk = k.size()\n",
    "        wq = self.wq(q)\n",
    "        wk = self.wk(k)\n",
    "        wv = self.wv(v)\n",
    "        wq = wq.view(bq, tq, self.h, self.dh)\n",
    "        wk = wk.view(bk, tk, self.h, self.dh)\n",
    "        wv = wv.view(bk, tk, self.h, self.dh)\n",
    "        # b, t, h, dh\n",
    "        # if changing from 4 dim -> 3 dim: b*h, t, dh\n",
    "        # wq = wq.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wk = wk.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wv = wv.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # another option 4 dim -> 3 dim\n",
    "        # wq = wq.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wk = wk.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wv = wv.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # changing the number of dims is not necessary as @ supports 4 dims\n",
    "        attn = self_attention_masked(wq, wk, wv, mask=mask)\n",
    "        # b * h, t, dh\n",
    "        # attn = attn.view(b, self.h, t, self.dh).permute(0, 2, 1, 3).reshape(b, t, d)\n",
    "        attn = attn.view(bq, self.h, tq, self.dh).transpose(1, 2).contiguous().view(bq, tq, dq)\n",
    "        wo = self.wo(attn)\n",
    "        return wo\n",
    "        # # 1 2 3 4\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # return F.relu(self.conv2(x))\n",
    "\n",
    "mhsa_masked = MHSAMasked(h = 2, d = 6)\n",
    "x = torch.rand(4, 5)\n",
    "mask = reshape_mask(build_causal_mask(x))\n",
    "print(mask)\n",
    "x = torch.rand(4, 5, 6)\n",
    "print(mhsa_masked(x, x, x, mask=mask))\n",
    "print(mhsa_masked(x, x, x, mask=mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729ae6f8-a3f8-4386-837d-f1e67f022b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22d0cd6d-12f4-44f0-b8b9-62a18a6d2f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0823, -0.1225,    -inf],\n",
      "          [-0.0527, -0.0749,    -inf],\n",
      "          [-0.0348, -0.0261,    -inf]],\n",
      "\n",
      "         [[-0.0282, -0.1440,    -inf],\n",
      "          [ 0.0651, -0.1101,    -inf],\n",
      "          [ 0.0382, -0.1288,    -inf]],\n",
      "\n",
      "         [[-0.1386, -0.1153,    -inf],\n",
      "          [-0.0730, -0.0167,    -inf],\n",
      "          [-0.1262, -0.1576,    -inf]],\n",
      "\n",
      "         [[-0.0189, -0.0116,    -inf],\n",
      "          [ 0.0058,  0.0429,    -inf],\n",
      "          [ 0.0375, -0.0341,    -inf]],\n",
      "\n",
      "         [[ 0.0412,  0.0224,    -inf],\n",
      "          [-0.0168, -0.0034,    -inf],\n",
      "          [-0.0546, -0.0286,    -inf]],\n",
      "\n",
      "         [[-0.2706, -0.3284,    -inf],\n",
      "          [-0.0762, -0.0907,    -inf],\n",
      "          [-0.1119, -0.1862,    -inf]],\n",
      "\n",
      "         [[ 0.0689,  0.0890,    -inf],\n",
      "          [ 0.0651,  0.0416,    -inf],\n",
      "          [ 0.1561,  0.1816,    -inf]],\n",
      "\n",
      "         [[-0.1237, -0.1848,    -inf],\n",
      "          [ 0.0351, -0.0222,    -inf],\n",
      "          [-0.0299, -0.0595,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1217,    -inf,    -inf],\n",
      "          [-0.0276,    -inf,    -inf],\n",
      "          [-0.0388,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0935,    -inf,    -inf],\n",
      "          [-0.1723,    -inf,    -inf],\n",
      "          [-0.0651,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0004,    -inf,    -inf],\n",
      "          [ 0.0417,    -inf,    -inf],\n",
      "          [ 0.1328,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0255,    -inf,    -inf],\n",
      "          [ 0.0874,    -inf,    -inf],\n",
      "          [ 0.0717,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0698,    -inf,    -inf],\n",
      "          [-0.0719,    -inf,    -inf],\n",
      "          [ 0.0960,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3505,    -inf,    -inf],\n",
      "          [-0.1944,    -inf,    -inf],\n",
      "          [-0.2435,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2897,    -inf,    -inf],\n",
      "          [ 0.1017,    -inf,    -inf],\n",
      "          [ 0.2970,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0912,    -inf,    -inf],\n",
      "          [-0.2017,    -inf,    -inf],\n",
      "          [-0.1474,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5100, 0.4900, 0.0000],\n",
      "          [0.5056, 0.4944, 0.0000],\n",
      "          [0.4978, 0.5022, 0.0000]],\n",
      "\n",
      "         [[0.5289, 0.4711, 0.0000],\n",
      "          [0.5437, 0.4563, 0.0000],\n",
      "          [0.5416, 0.4584, 0.0000]],\n",
      "\n",
      "         [[0.4942, 0.5058, 0.0000],\n",
      "          [0.4859, 0.5141, 0.0000],\n",
      "          [0.5078, 0.4922, 0.0000]],\n",
      "\n",
      "         [[0.4982, 0.5018, 0.0000],\n",
      "          [0.4907, 0.5093, 0.0000],\n",
      "          [0.5179, 0.4821, 0.0000]],\n",
      "\n",
      "         [[0.5047, 0.4953, 0.0000],\n",
      "          [0.4966, 0.5034, 0.0000],\n",
      "          [0.4935, 0.5065, 0.0000]],\n",
      "\n",
      "         [[0.5145, 0.4855, 0.0000],\n",
      "          [0.5036, 0.4964, 0.0000],\n",
      "          [0.5186, 0.4814, 0.0000]],\n",
      "\n",
      "         [[0.4950, 0.5050, 0.0000],\n",
      "          [0.5059, 0.4941, 0.0000],\n",
      "          [0.4936, 0.5064, 0.0000]],\n",
      "\n",
      "         [[0.5153, 0.4847, 0.0000],\n",
      "          [0.5143, 0.4857, 0.0000],\n",
      "          [0.5074, 0.4926, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSAMasked(d, h)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, self_mask=None):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.attn_dropout(self.mhsa(x, x, x, mask=self_mask))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "encoder_layer = EncoderLayer()\n",
    "self_mask = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0]]), pad_token=0)\n",
    "self_mask = reshape_mask(self_mask)\n",
    "x = torch.rand(2, 3, 512)\n",
    "\n",
    "encoder_layer(x, self_mask=self_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e48412b-a00c-45e5-829f-441a7df2318e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-7.5255e-02,  1.5785e+00,        -inf],\n",
      "          [-5.1758e-01,  6.9589e-01,        -inf],\n",
      "          [-2.1072e-01,  6.3987e-02,        -inf]],\n",
      "\n",
      "         [[-3.6289e-01, -2.6427e-01,        -inf],\n",
      "          [ 4.2333e-01, -7.2971e-02,        -inf],\n",
      "          [-4.3477e-01,  2.8622e-01,        -inf]],\n",
      "\n",
      "         [[ 1.3705e-01, -4.3642e-02,        -inf],\n",
      "          [-4.6413e-02,  4.1261e-01,        -inf],\n",
      "          [-3.3340e-01,  8.8788e-01,        -inf]],\n",
      "\n",
      "         [[ 1.5946e-01, -7.2807e-01,        -inf],\n",
      "          [ 9.1806e-01,  8.0123e-02,        -inf],\n",
      "          [ 1.6280e-01, -4.1546e-01,        -inf]],\n",
      "\n",
      "         [[ 6.8802e-01,  4.9811e-03,        -inf],\n",
      "          [ 2.0877e-01, -3.8896e-01,        -inf],\n",
      "          [-1.4905e+00, -9.8413e-01,        -inf]],\n",
      "\n",
      "         [[ 3.0520e-01,  4.2186e-01,        -inf],\n",
      "          [ 1.0437e-03,  2.7047e-01,        -inf],\n",
      "          [ 5.9591e-01,  5.4857e-01,        -inf]],\n",
      "\n",
      "         [[-4.7272e-02, -1.6442e-01,        -inf],\n",
      "          [-8.6050e-02, -1.0976e-01,        -inf],\n",
      "          [-8.0828e-01, -7.0860e-01,        -inf]],\n",
      "\n",
      "         [[ 1.1185e-02,  8.6530e-01,        -inf],\n",
      "          [ 7.3089e-01,  6.4541e-01,        -inf],\n",
      "          [-3.5215e-01,  1.5449e-02,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9944e-01,        -inf,        -inf],\n",
      "          [-7.3046e-01,        -inf,        -inf],\n",
      "          [ 7.5997e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.8658e-01,        -inf,        -inf],\n",
      "          [-6.2885e-01,        -inf,        -inf],\n",
      "          [-1.2050e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.8806e-01,        -inf,        -inf],\n",
      "          [ 6.5300e-01,        -inf,        -inf],\n",
      "          [ 1.1508e-02,        -inf,        -inf]],\n",
      "\n",
      "         [[-7.2704e-01,        -inf,        -inf],\n",
      "          [ 2.4270e-01,        -inf,        -inf],\n",
      "          [ 6.8253e-02,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.3313e-01,        -inf,        -inf],\n",
      "          [-7.0263e-01,        -inf,        -inf],\n",
      "          [-2.0714e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.3845e-01,        -inf,        -inf],\n",
      "          [ 7.9700e-01,        -inf,        -inf],\n",
      "          [ 5.8116e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.2185e-01,        -inf,        -inf],\n",
      "          [ 1.9250e-01,        -inf,        -inf],\n",
      "          [-7.1957e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.3575e-01,        -inf,        -inf],\n",
      "          [ 8.5366e-01,        -inf,        -inf],\n",
      "          [ 1.2144e+00,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1606, 0.8394, 0.0000],\n",
      "          [0.2291, 0.7709, 0.0000],\n",
      "          [0.4318, 0.5682, 0.0000]],\n",
      "\n",
      "         [[0.4754, 0.5246, 0.0000],\n",
      "          [0.6216, 0.3784, 0.0000],\n",
      "          [0.3272, 0.6728, 0.0000]],\n",
      "\n",
      "         [[0.5451, 0.4549, 0.0000],\n",
      "          [0.3872, 0.6128, 0.0000],\n",
      "          [0.2277, 0.7723, 0.0000]],\n",
      "\n",
      "         [[0.7084, 0.2916, 0.0000],\n",
      "          [0.6980, 0.3020, 0.0000],\n",
      "          [0.6407, 0.3593, 0.0000]],\n",
      "\n",
      "         [[0.6644, 0.3356, 0.0000],\n",
      "          [0.6451, 0.3549, 0.0000],\n",
      "          [0.3760, 0.6240, 0.0000]],\n",
      "\n",
      "         [[0.4709, 0.5291, 0.0000],\n",
      "          [0.4330, 0.5670, 0.0000],\n",
      "          [0.5118, 0.4882, 0.0000]],\n",
      "\n",
      "         [[0.5293, 0.4707, 0.0000],\n",
      "          [0.5059, 0.4941, 0.0000],\n",
      "          [0.4751, 0.5249, 0.0000]],\n",
      "\n",
      "         [[0.2986, 0.7014, 0.0000],\n",
      "          [0.5214, 0.4786, 0.0000],\n",
      "          [0.4091, 0.5909, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1698,  0.8226,    -inf],\n",
      "          [-0.1222,  0.5286,    -inf],\n",
      "          [ 0.3180,  0.4401,    -inf]],\n",
      "\n",
      "         [[-0.0446, -0.2752,    -inf],\n",
      "          [-0.1143,  0.0325,    -inf],\n",
      "          [-0.4824, -0.3830,    -inf]],\n",
      "\n",
      "         [[ 0.1477,  0.2038,    -inf],\n",
      "          [-0.0609, -0.2657,    -inf],\n",
      "          [-0.4805, -0.1433,    -inf]],\n",
      "\n",
      "         [[-0.1329, -0.0594,    -inf],\n",
      "          [ 0.4536,  0.2775,    -inf],\n",
      "          [-0.3631, -0.4620,    -inf]],\n",
      "\n",
      "         [[-0.1329, -0.1415,    -inf],\n",
      "          [ 0.1512,  0.3245,    -inf],\n",
      "          [ 0.1171,  0.2869,    -inf]],\n",
      "\n",
      "         [[ 0.0534,  0.2131,    -inf],\n",
      "          [ 0.1022,  0.1081,    -inf],\n",
      "          [-0.1723, -0.4446,    -inf]],\n",
      "\n",
      "         [[ 0.1444, -0.1804,    -inf],\n",
      "          [ 0.7897,  0.6833,    -inf],\n",
      "          [ 0.0383, -0.4083,    -inf]],\n",
      "\n",
      "         [[ 0.3256, -0.1604,    -inf],\n",
      "          [ 0.5784,  0.0567,    -inf],\n",
      "          [ 0.2562, -0.1121,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0471,    -inf,    -inf],\n",
      "          [ 0.6976,    -inf,    -inf],\n",
      "          [ 0.5078,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4726,    -inf,    -inf],\n",
      "          [ 0.3578,    -inf,    -inf],\n",
      "          [-0.2879,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0378,    -inf,    -inf],\n",
      "          [ 0.0279,    -inf,    -inf],\n",
      "          [-0.1305,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2525,    -inf,    -inf],\n",
      "          [-0.0569,    -inf,    -inf],\n",
      "          [ 0.1675,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3132,    -inf,    -inf],\n",
      "          [-0.1150,    -inf,    -inf],\n",
      "          [ 0.4606,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0589,    -inf,    -inf],\n",
      "          [-0.6210,    -inf,    -inf],\n",
      "          [-0.1949,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1907,    -inf,    -inf],\n",
      "          [ 0.2015,    -inf,    -inf],\n",
      "          [-0.4208,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1643,    -inf,    -inf],\n",
      "          [-0.2798,    -inf,    -inf],\n",
      "          [-0.0217,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2704, 0.7296, 0.0000],\n",
      "          [0.3428, 0.6572, 0.0000],\n",
      "          [0.4695, 0.5305, 0.0000]],\n",
      "\n",
      "         [[0.5574, 0.4426, 0.0000],\n",
      "          [0.4634, 0.5366, 0.0000],\n",
      "          [0.4752, 0.5248, 0.0000]],\n",
      "\n",
      "         [[0.4860, 0.5140, 0.0000],\n",
      "          [0.5510, 0.4490, 0.0000],\n",
      "          [0.4165, 0.5835, 0.0000]],\n",
      "\n",
      "         [[0.4816, 0.5184, 0.0000],\n",
      "          [0.5439, 0.4561, 0.0000],\n",
      "          [0.5247, 0.4753, 0.0000]],\n",
      "\n",
      "         [[0.5022, 0.4978, 0.0000],\n",
      "          [0.4568, 0.5432, 0.0000],\n",
      "          [0.4576, 0.5424, 0.0000]],\n",
      "\n",
      "         [[0.4602, 0.5398, 0.0000],\n",
      "          [0.4985, 0.5015, 0.0000],\n",
      "          [0.5677, 0.4323, 0.0000]],\n",
      "\n",
      "         [[0.5805, 0.4195, 0.0000],\n",
      "          [0.5266, 0.4734, 0.0000],\n",
      "          [0.6098, 0.3902, 0.0000]],\n",
      "\n",
      "         [[0.6192, 0.3808, 0.0000],\n",
      "          [0.6275, 0.3725, 0.0000],\n",
      "          [0.5910, 0.4090, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0095,  0.3616,    -inf],\n",
      "          [ 0.0874,  0.5483,    -inf],\n",
      "          [-0.2459,  0.1732,    -inf]],\n",
      "\n",
      "         [[-0.5508, -0.5575,    -inf],\n",
      "          [-0.7044, -0.5990,    -inf],\n",
      "          [-0.3265,  0.0824,    -inf]],\n",
      "\n",
      "         [[ 0.3775,  0.2275,    -inf],\n",
      "          [ 0.3773, -0.0319,    -inf],\n",
      "          [-0.3540, -0.2277,    -inf]],\n",
      "\n",
      "         [[-0.1887, -0.2093,    -inf],\n",
      "          [-0.3689, -0.0398,    -inf],\n",
      "          [-0.1314, -0.5560,    -inf]],\n",
      "\n",
      "         [[-0.1980,  0.0081,    -inf],\n",
      "          [-0.2496,  0.0477,    -inf],\n",
      "          [-0.1378,  0.4607,    -inf]],\n",
      "\n",
      "         [[ 0.0434,  0.1733,    -inf],\n",
      "          [-0.3326, -0.2581,    -inf],\n",
      "          [-0.1106, -0.1982,    -inf]],\n",
      "\n",
      "         [[ 0.0196, -0.0357,    -inf],\n",
      "          [ 0.0757, -0.5266,    -inf],\n",
      "          [ 0.0992, -0.1767,    -inf]],\n",
      "\n",
      "         [[ 0.0737,  0.2241,    -inf],\n",
      "          [-0.2139,  0.1498,    -inf],\n",
      "          [ 0.2375,  0.2474,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2675,    -inf,    -inf],\n",
      "          [-0.0029,    -inf,    -inf],\n",
      "          [ 0.1727,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1928,    -inf,    -inf],\n",
      "          [-0.0572,    -inf,    -inf],\n",
      "          [-0.2282,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4654,    -inf,    -inf],\n",
      "          [ 0.2442,    -inf,    -inf],\n",
      "          [ 0.2962,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1308,    -inf,    -inf],\n",
      "          [ 0.6908,    -inf,    -inf],\n",
      "          [ 0.0539,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0146,    -inf,    -inf],\n",
      "          [-0.4673,    -inf,    -inf],\n",
      "          [-0.0358,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1614,    -inf,    -inf],\n",
      "          [-0.2418,    -inf,    -inf],\n",
      "          [-0.3628,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2157,    -inf,    -inf],\n",
      "          [ 0.0073,    -inf,    -inf],\n",
      "          [-0.2783,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2395,    -inf,    -inf],\n",
      "          [-0.5846,    -inf,    -inf],\n",
      "          [ 0.2592,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4129, 0.5871, 0.0000],\n",
      "          [0.3868, 0.6132, 0.0000],\n",
      "          [0.3967, 0.6033, 0.0000]],\n",
      "\n",
      "         [[0.5017, 0.4983, 0.0000],\n",
      "          [0.4737, 0.5263, 0.0000],\n",
      "          [0.3992, 0.6008, 0.0000]],\n",
      "\n",
      "         [[0.5374, 0.4626, 0.0000],\n",
      "          [0.6009, 0.3991, 0.0000],\n",
      "          [0.4685, 0.5315, 0.0000]],\n",
      "\n",
      "         [[0.5051, 0.4949, 0.0000],\n",
      "          [0.4185, 0.5815, 0.0000],\n",
      "          [0.6046, 0.3954, 0.0000]],\n",
      "\n",
      "         [[0.4487, 0.5513, 0.0000],\n",
      "          [0.4262, 0.5738, 0.0000],\n",
      "          [0.3547, 0.6453, 0.0000]],\n",
      "\n",
      "         [[0.4676, 0.5324, 0.0000],\n",
      "          [0.4814, 0.5186, 0.0000],\n",
      "          [0.5219, 0.4781, 0.0000]],\n",
      "\n",
      "         [[0.5138, 0.4862, 0.0000],\n",
      "          [0.6462, 0.3538, 0.0000],\n",
      "          [0.5685, 0.4315, 0.0000]],\n",
      "\n",
      "         [[0.4625, 0.5375, 0.0000],\n",
      "          [0.4101, 0.5899, 0.0000],\n",
      "          [0.4975, 0.5025, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0581,  0.2736,    -inf],\n",
      "          [ 0.2214,  0.3958,    -inf],\n",
      "          [ 0.5453,  0.5408,    -inf]],\n",
      "\n",
      "         [[ 0.1367, -0.2858,    -inf],\n",
      "          [ 0.3010,  0.2983,    -inf],\n",
      "          [-0.2252,  0.0366,    -inf]],\n",
      "\n",
      "         [[ 0.0547,  0.4815,    -inf],\n",
      "          [-0.3315, -0.0800,    -inf],\n",
      "          [-0.1571, -0.3030,    -inf]],\n",
      "\n",
      "         [[ 0.1309,  0.0328,    -inf],\n",
      "          [ 0.0226, -0.1627,    -inf],\n",
      "          [-0.2614, -0.5350,    -inf]],\n",
      "\n",
      "         [[-0.2294,  0.4212,    -inf],\n",
      "          [ 0.0969,  0.5512,    -inf],\n",
      "          [ 0.2815,  0.6876,    -inf]],\n",
      "\n",
      "         [[ 0.4862, -0.3175,    -inf],\n",
      "          [ 0.1758, -0.2434,    -inf],\n",
      "          [ 0.3759, -0.4825,    -inf]],\n",
      "\n",
      "         [[-0.2096, -0.2315,    -inf],\n",
      "          [-0.3526, -0.2009,    -inf],\n",
      "          [-0.2302, -0.1471,    -inf]],\n",
      "\n",
      "         [[-0.2015, -0.1190,    -inf],\n",
      "          [-0.1354, -0.1795,    -inf],\n",
      "          [-0.0704, -0.6923,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4874,    -inf,    -inf],\n",
      "          [-0.0964,    -inf,    -inf],\n",
      "          [-0.1246,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1808,    -inf,    -inf],\n",
      "          [-0.1446,    -inf,    -inf],\n",
      "          [-0.1887,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2839,    -inf,    -inf],\n",
      "          [-0.3189,    -inf,    -inf],\n",
      "          [-0.0590,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2434,    -inf,    -inf],\n",
      "          [ 0.1223,    -inf,    -inf],\n",
      "          [-0.0291,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3343,    -inf,    -inf],\n",
      "          [ 0.3361,    -inf,    -inf],\n",
      "          [ 0.8485,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0275,    -inf,    -inf],\n",
      "          [-0.6538,    -inf,    -inf],\n",
      "          [-0.1287,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0856,    -inf,    -inf],\n",
      "          [-0.0432,    -inf,    -inf],\n",
      "          [ 0.7209,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1907,    -inf,    -inf],\n",
      "          [ 0.2193,    -inf,    -inf],\n",
      "          [ 0.4009,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4178, 0.5822, 0.0000],\n",
      "          [0.4565, 0.5435, 0.0000],\n",
      "          [0.5011, 0.4989, 0.0000]],\n",
      "\n",
      "         [[0.6041, 0.3959, 0.0000],\n",
      "          [0.5007, 0.4993, 0.0000],\n",
      "          [0.4349, 0.5651, 0.0000]],\n",
      "\n",
      "         [[0.3949, 0.6051, 0.0000],\n",
      "          [0.4374, 0.5626, 0.0000],\n",
      "          [0.5364, 0.4636, 0.0000]],\n",
      "\n",
      "         [[0.5245, 0.4755, 0.0000],\n",
      "          [0.5462, 0.4538, 0.0000],\n",
      "          [0.5680, 0.4320, 0.0000]],\n",
      "\n",
      "         [[0.3429, 0.6571, 0.0000],\n",
      "          [0.3883, 0.6117, 0.0000],\n",
      "          [0.3999, 0.6001, 0.0000]],\n",
      "\n",
      "         [[0.6908, 0.3092, 0.0000],\n",
      "          [0.6033, 0.3967, 0.0000],\n",
      "          [0.7023, 0.2977, 0.0000]],\n",
      "\n",
      "         [[0.5055, 0.4945, 0.0000],\n",
      "          [0.4622, 0.5378, 0.0000],\n",
      "          [0.4792, 0.5208, 0.0000]],\n",
      "\n",
      "         [[0.4794, 0.5206, 0.0000],\n",
      "          [0.5110, 0.4890, 0.0000],\n",
      "          [0.6506, 0.3494, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0487,  0.8164,    -inf],\n",
      "          [-0.1906,  0.2724,    -inf],\n",
      "          [ 0.4333,  0.8474,    -inf]],\n",
      "\n",
      "         [[-0.3980, -0.4057,    -inf],\n",
      "          [-0.3990, -0.4179,    -inf],\n",
      "          [-0.0715,  0.1991,    -inf]],\n",
      "\n",
      "         [[-0.1129, -0.1414,    -inf],\n",
      "          [ 0.3158, -0.1408,    -inf],\n",
      "          [-0.3688, -0.1904,    -inf]],\n",
      "\n",
      "         [[-0.1607,  0.2550,    -inf],\n",
      "          [ 0.1419, -0.0466,    -inf],\n",
      "          [-0.2186, -0.1486,    -inf]],\n",
      "\n",
      "         [[-0.2561, -0.1459,    -inf],\n",
      "          [-0.9042, -0.9560,    -inf],\n",
      "          [-0.7315, -0.1094,    -inf]],\n",
      "\n",
      "         [[ 0.1108, -0.8483,    -inf],\n",
      "          [ 0.1160, -0.6722,    -inf],\n",
      "          [ 0.4798, -0.6590,    -inf]],\n",
      "\n",
      "         [[-0.1327,  0.3326,    -inf],\n",
      "          [ 0.4772,  0.3357,    -inf],\n",
      "          [-0.5999,  0.2840,    -inf]],\n",
      "\n",
      "         [[-0.1661, -0.1938,    -inf],\n",
      "          [-0.6587, -0.9597,    -inf],\n",
      "          [ 0.0468, -0.2076,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0383,    -inf,    -inf],\n",
      "          [-0.3432,    -inf,    -inf],\n",
      "          [-0.5979,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1270,    -inf,    -inf],\n",
      "          [-0.1119,    -inf,    -inf],\n",
      "          [-0.1795,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.9877,    -inf,    -inf],\n",
      "          [ 0.9919,    -inf,    -inf],\n",
      "          [ 0.5386,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0358,    -inf,    -inf],\n",
      "          [-0.5523,    -inf,    -inf],\n",
      "          [-0.6075,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5144,    -inf,    -inf],\n",
      "          [-0.2374,    -inf,    -inf],\n",
      "          [ 0.0882,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0679,    -inf,    -inf],\n",
      "          [-0.0336,    -inf,    -inf],\n",
      "          [ 0.0492,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0481,    -inf,    -inf],\n",
      "          [-0.2246,    -inf,    -inf],\n",
      "          [ 0.2006,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5698,    -inf,    -inf],\n",
      "          [-0.0639,    -inf,    -inf],\n",
      "          [ 0.3967,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2963, 0.7037, 0.0000],\n",
      "          [0.3863, 0.6137, 0.0000],\n",
      "          [0.3979, 0.6021, 0.0000]],\n",
      "\n",
      "         [[0.5019, 0.4981, 0.0000],\n",
      "          [0.5047, 0.4953, 0.0000],\n",
      "          [0.4328, 0.5672, 0.0000]],\n",
      "\n",
      "         [[0.5071, 0.4929, 0.0000],\n",
      "          [0.6122, 0.3878, 0.0000],\n",
      "          [0.4555, 0.5445, 0.0000]],\n",
      "\n",
      "         [[0.3975, 0.6025, 0.0000],\n",
      "          [0.5470, 0.4530, 0.0000],\n",
      "          [0.4825, 0.5175, 0.0000]],\n",
      "\n",
      "         [[0.4725, 0.5275, 0.0000],\n",
      "          [0.5129, 0.4871, 0.0000],\n",
      "          [0.3493, 0.6507, 0.0000]],\n",
      "\n",
      "         [[0.7229, 0.2771, 0.0000],\n",
      "          [0.6874, 0.3126, 0.0000],\n",
      "          [0.7575, 0.2425, 0.0000]],\n",
      "\n",
      "         [[0.3857, 0.6143, 0.0000],\n",
      "          [0.5353, 0.4647, 0.0000],\n",
      "          [0.2924, 0.7076, 0.0000]],\n",
      "\n",
      "         [[0.5069, 0.4931, 0.0000],\n",
      "          [0.5747, 0.4253, 0.0000],\n",
      "          [0.5633, 0.4367, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-5.4350e-01, -2.4035e-01,        -inf],\n",
      "          [-2.8710e-01,  1.0779e-03,        -inf],\n",
      "          [-6.9632e-02,  9.2135e-02,        -inf]],\n",
      "\n",
      "         [[ 1.5876e-01,  4.4279e-03,        -inf],\n",
      "          [-1.7672e-01, -3.1665e-01,        -inf],\n",
      "          [-3.0158e-01, -5.1385e-01,        -inf]],\n",
      "\n",
      "         [[ 7.0516e-03,  1.2214e-01,        -inf],\n",
      "          [ 1.9451e-01, -1.8271e-01,        -inf],\n",
      "          [-8.1892e-02,  4.0913e-01,        -inf]],\n",
      "\n",
      "         [[ 8.3194e-01,  1.1967e+00,        -inf],\n",
      "          [ 8.5240e-01,  9.4050e-01,        -inf],\n",
      "          [ 2.7681e-01,  1.2987e-01,        -inf]],\n",
      "\n",
      "         [[ 1.2457e-01,  5.5399e-01,        -inf],\n",
      "          [-2.6335e-01, -1.1442e-01,        -inf],\n",
      "          [-2.2472e-01,  2.8251e-01,        -inf]],\n",
      "\n",
      "         [[-4.2702e-02, -5.3383e-01,        -inf],\n",
      "          [-1.1946e-01, -2.7449e-01,        -inf],\n",
      "          [ 5.2510e-01, -1.2617e-01,        -inf]],\n",
      "\n",
      "         [[-3.4039e-01, -2.3989e-01,        -inf],\n",
      "          [-6.2800e-01,  4.5140e-03,        -inf],\n",
      "          [-5.9622e-01, -3.4450e-01,        -inf]],\n",
      "\n",
      "         [[ 2.7239e-01,  2.4228e-01,        -inf],\n",
      "          [ 7.4709e-01,  6.1974e-01,        -inf],\n",
      "          [ 4.1579e-01,  1.7834e-01,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[-5.5884e-02,        -inf,        -inf],\n",
      "          [ 3.3599e-01,        -inf,        -inf],\n",
      "          [-4.0576e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 8.4742e-02,        -inf,        -inf],\n",
      "          [-2.8972e-01,        -inf,        -inf],\n",
      "          [-1.4339e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-4.5567e-01,        -inf,        -inf],\n",
      "          [-6.4008e-01,        -inf,        -inf],\n",
      "          [-1.1147e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.1063e-01,        -inf,        -inf],\n",
      "          [-7.3326e-01,        -inf,        -inf],\n",
      "          [-2.7941e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.6874e-02,        -inf,        -inf],\n",
      "          [-6.8688e-02,        -inf,        -inf],\n",
      "          [ 1.6670e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.5293e-01,        -inf,        -inf],\n",
      "          [ 1.5736e-01,        -inf,        -inf],\n",
      "          [ 6.6309e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 4.3691e-01,        -inf,        -inf],\n",
      "          [-2.9846e-01,        -inf,        -inf],\n",
      "          [ 2.1734e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.3299e-01,        -inf,        -inf],\n",
      "          [-3.4656e-01,        -inf,        -inf],\n",
      "          [-5.7045e-01,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4248, 0.5752, 0.0000],\n",
      "          [0.4284, 0.5716, 0.0000],\n",
      "          [0.4596, 0.5404, 0.0000]],\n",
      "\n",
      "         [[0.5385, 0.4615, 0.0000],\n",
      "          [0.5349, 0.4651, 0.0000],\n",
      "          [0.5529, 0.4471, 0.0000]],\n",
      "\n",
      "         [[0.4713, 0.5287, 0.0000],\n",
      "          [0.5932, 0.4068, 0.0000],\n",
      "          [0.3797, 0.6203, 0.0000]],\n",
      "\n",
      "         [[0.4098, 0.5902, 0.0000],\n",
      "          [0.4780, 0.5220, 0.0000],\n",
      "          [0.5367, 0.4633, 0.0000]],\n",
      "\n",
      "         [[0.3943, 0.6057, 0.0000],\n",
      "          [0.4628, 0.5372, 0.0000],\n",
      "          [0.3758, 0.6242, 0.0000]],\n",
      "\n",
      "         [[0.6204, 0.3796, 0.0000],\n",
      "          [0.5387, 0.4613, 0.0000],\n",
      "          [0.6573, 0.3427, 0.0000]],\n",
      "\n",
      "         [[0.4749, 0.5251, 0.0000],\n",
      "          [0.3469, 0.6531, 0.0000],\n",
      "          [0.4374, 0.5626, 0.0000]],\n",
      "\n",
      "         [[0.5075, 0.4925, 0.0000],\n",
      "          [0.5318, 0.4682, 0.0000],\n",
      "          [0.5591, 0.4409, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Encoder(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [EncoderLayer(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, x, self_mask = None):\n",
    "        b, t = x.size()\n",
    "        x = self.embed(x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, self_mask=self_mask)\n",
    "        return x\n",
    "\n",
    "encoder = Encoder()\n",
    "x = torch.randint(0, 2**13, (2, 3))\n",
    "self_mask = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0]]), pad_token=0)\n",
    "self_mask = reshape_mask(self_mask)\n",
    "encoder(x, self_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7785e51c-c88e-4ad2-ad66-4117fbb1a52c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_mask: \n",
      " tensor([[1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0]])\n",
      "cross_mask: \n",
      " tensor([[[[1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0805,    -inf,    -inf],\n",
      "          [ 0.0826,    -inf,    -inf],\n",
      "          [-0.0313,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1963,    -inf,    -inf],\n",
      "          [ 0.1676,    -inf,    -inf],\n",
      "          [ 0.1429,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0006,    -inf,    -inf],\n",
      "          [ 0.0163,    -inf,    -inf],\n",
      "          [-0.0237,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1370,    -inf,    -inf],\n",
      "          [ 0.0370,    -inf,    -inf],\n",
      "          [ 0.0983,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0224,  0.0335,    -inf],\n",
      "          [ 0.0327,  0.0037,    -inf],\n",
      "          [ 0.0672,  0.0623,    -inf]],\n",
      "\n",
      "         [[ 0.0396,  0.1272,    -inf],\n",
      "          [-0.0054,  0.1835,    -inf],\n",
      "          [-0.0210,  0.1624,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4972, 0.5028, 0.0000],\n",
      "          [0.5072, 0.4928, 0.0000],\n",
      "          [0.5012, 0.4988, 0.0000]],\n",
      "\n",
      "         [[0.4781, 0.5219, 0.0000],\n",
      "          [0.4529, 0.5471, 0.0000],\n",
      "          [0.4543, 0.5457, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0463, -0.0103, -0.1234],\n",
      "          [-0.1253,  0.0771, -0.0554],\n",
      "          [-0.1659, -0.0703, -0.2111]],\n",
      "\n",
      "         [[-0.1412, -0.1986, -0.0836],\n",
      "          [-0.1473, -0.1180, -0.1140],\n",
      "          [ 0.0396, -0.1160,  0.1172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1428,    -inf,    -inf],\n",
      "          [ 0.1811,    -inf,    -inf],\n",
      "          [ 0.2181,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0864,    -inf,    -inf],\n",
      "          [-0.2378,    -inf,    -inf],\n",
      "          [ 0.0405,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1749, -0.4243,    -inf],\n",
      "          [-0.0393, -0.1825,    -inf],\n",
      "          [ 0.0728,  0.0310,    -inf]],\n",
      "\n",
      "         [[-0.1477, -0.0982,    -inf],\n",
      "          [ 0.0277,  0.1204,    -inf],\n",
      "          [-0.0084,  0.0744,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3376, 0.3499, 0.3125],\n",
      "          [0.3033, 0.3714, 0.3253],\n",
      "          [0.3272, 0.3600, 0.3127]],\n",
      "\n",
      "         [[0.3329, 0.3144, 0.3527],\n",
      "          [0.3264, 0.3361, 0.3375],\n",
      "          [0.3405, 0.2915, 0.3680]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5620, 0.4380, 0.0000],\n",
      "          [0.5358, 0.4642, 0.0000],\n",
      "          [0.5105, 0.4895, 0.0000]],\n",
      "\n",
      "         [[0.4876, 0.5124, 0.0000],\n",
      "          [0.4768, 0.5232, 0.0000],\n",
      "          [0.4793, 0.5207, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoderLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSAMasked(d=d, h=h)\n",
    "        self.attn_norm = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.mhca = MHSAMasked(d=d, h=h)\n",
    "        self.cross_attn_norm = nn.LayerNorm(d)\n",
    "        self.cross_attn_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(d)\n",
    "        \n",
    "\n",
    "    def forward(self, dec_x, enc_x, self_mask=None, cross_mask=None):\n",
    "        # self_mask is merged decoders padding and causal masks\n",
    "        # cross_mask is equal to endcoders padding mask because we don't want to attend to encoded padded tokens\n",
    "        b, t, d = dec_x.size()\n",
    "        x = dec_x + self.attn_dropout(self.mhsa(dec_x, dec_x, dec_x, mask=self_mask))\n",
    "        x = self.attn_norm(x)\n",
    "\n",
    "        x = x + self.cross_attn_dropout(self.mhca(x, enc_x, enc_x, mask=cross_mask))\n",
    "        x = self.cross_attn_norm(x)\n",
    "        \n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "decoder_layer = DecoderLayer(h=2, d=16)\n",
    "x = torch.rand(3, 3, 16)\n",
    "y = torch.rand(3, 3, 16)\n",
    "self_mask1 = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "self_mask2 = build_causal_mask(torch.tensor([[2, 2, 0], [2, 0, 0], [2, 2, 0]]))\n",
    "self_mask = merge_masks(self_mask1, self_mask2)\n",
    "print(f\"self_mask: \\n {self_mask}\")\n",
    "self_mask = reshape_mask(self_mask)\n",
    "\n",
    "cross_mask = build_padding_mask(torch.tensor([[2, 2, 2], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "cross_mask = reshape_mask(cross_mask)\n",
    "print(f\"cross_mask: \\n {cross_mask}\")\n",
    "decoder_layer(x, y, self_mask=self_mask, cross_mask=cross_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826a55e4-da2a-42e0-847d-14d0c7774cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_mask: \n",
      " tensor([[1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0]])\n",
      "cross_mask: \n",
      " tensor([[[[1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3712,    -inf,    -inf],\n",
      "          [-0.3560,    -inf,    -inf],\n",
      "          [-0.3503,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3399,    -inf,    -inf],\n",
      "          [ 0.0327,    -inf,    -inf],\n",
      "          [ 0.1566,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.3375,    -inf,    -inf],\n",
      "          [ 0.3308,    -inf,    -inf],\n",
      "          [ 0.0699,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3200,    -inf,    -inf],\n",
      "          [ 0.2670,    -inf,    -inf],\n",
      "          [ 0.0720,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1735,  0.0916,    -inf],\n",
      "          [ 0.0646,  0.2738,    -inf],\n",
      "          [-0.3096, -0.6128,    -inf]],\n",
      "\n",
      "         [[ 0.1896, -0.1227,    -inf],\n",
      "          [ 0.2528,  0.3859,    -inf],\n",
      "          [-0.4951, -0.2353,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4341, 0.5659, 0.0000],\n",
      "          [0.4479, 0.5521, 0.0000],\n",
      "          [0.5752, 0.4248, 0.0000]],\n",
      "\n",
      "         [[0.5774, 0.4226, 0.0000],\n",
      "          [0.4668, 0.5332, 0.0000],\n",
      "          [0.4354, 0.5646, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0745,  0.0273, -0.1167],\n",
      "          [ 0.4388,  0.2724,  0.3526],\n",
      "          [-0.0537, -0.0539, -0.1188]],\n",
      "\n",
      "         [[ 0.3849,  0.0347,  0.0793],\n",
      "          [ 0.3265, -0.0239, -0.0647],\n",
      "          [-0.0117,  0.0859,  0.0755]]],\n",
      "\n",
      "\n",
      "        [[[-0.2504,    -inf,    -inf],\n",
      "          [-0.3176,    -inf,    -inf],\n",
      "          [-0.3988,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0445,    -inf,    -inf],\n",
      "          [ 0.0613,    -inf,    -inf],\n",
      "          [ 0.0607,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2403,  0.3290,    -inf],\n",
      "          [-0.0018, -0.0789,    -inf],\n",
      "          [-0.0392, -0.0557,    -inf]],\n",
      "\n",
      "         [[ 0.0467,  0.0349,    -inf],\n",
      "          [-0.2846, -0.1223,    -inf],\n",
      "          [ 0.0898,  0.0588,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3597, 0.3431, 0.2971],\n",
      "          [0.3618, 0.3063, 0.3319],\n",
      "          [0.3405, 0.3404, 0.3191]],\n",
      "\n",
      "         [[0.4096, 0.2886, 0.3018],\n",
      "          [0.4201, 0.2959, 0.2841],\n",
      "          [0.3131, 0.3452, 0.3417]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4778, 0.5222, 0.0000],\n",
      "          [0.5193, 0.4807, 0.0000],\n",
      "          [0.5041, 0.4959, 0.0000]],\n",
      "\n",
      "         [[0.5030, 0.4970, 0.0000],\n",
      "          [0.4595, 0.5405, 0.0000],\n",
      "          [0.5077, 0.4923, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2842,    -inf,    -inf],\n",
      "          [-0.3932,    -inf,    -inf],\n",
      "          [ 0.2324,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0397,    -inf,    -inf],\n",
      "          [-0.8734,    -inf,    -inf],\n",
      "          [-0.0393,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2341,    -inf,    -inf],\n",
      "          [ 0.5818,    -inf,    -inf],\n",
      "          [ 0.4913,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3847,    -inf,    -inf],\n",
      "          [-0.7374,    -inf,    -inf],\n",
      "          [-0.6605,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0534, -0.0460,    -inf],\n",
      "          [ 0.3616, -0.1151,    -inf],\n",
      "          [ 0.2272,  0.0475,    -inf]],\n",
      "\n",
      "         [[-0.8640, -0.7847,    -inf],\n",
      "          [-0.0127, -0.0749,    -inf],\n",
      "          [-0.1232,  0.0878,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4982, 0.5018, 0.0000],\n",
      "          [0.6170, 0.3830, 0.0000],\n",
      "          [0.5448, 0.4552, 0.0000]],\n",
      "\n",
      "         [[0.4802, 0.5198, 0.0000],\n",
      "          [0.5155, 0.4845, 0.0000],\n",
      "          [0.4475, 0.5525, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0068, -0.0449, -0.0363],\n",
      "          [ 0.4536,  0.1560,  0.2445],\n",
      "          [ 0.2278, -0.0021, -0.0072]],\n",
      "\n",
      "         [[-0.1735, -0.1381, -0.1432],\n",
      "          [-0.4173, -0.3939, -0.3590],\n",
      "          [-0.4395, -0.3154, -0.4474]]],\n",
      "\n",
      "\n",
      "        [[[-0.4286,    -inf,    -inf],\n",
      "          [-0.1233,    -inf,    -inf],\n",
      "          [-0.1156,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1147,    -inf,    -inf],\n",
      "          [-0.0747,    -inf,    -inf],\n",
      "          [-0.0620,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2595,  0.4809,    -inf],\n",
      "          [-0.0297,  0.4710,    -inf],\n",
      "          [-0.0811,  0.2488,    -inf]],\n",
      "\n",
      "         [[-0.1489, -0.2307,    -inf],\n",
      "          [-0.1805, -0.2119,    -inf],\n",
      "          [ 0.0071, -0.0458,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3439, 0.3266, 0.3294],\n",
      "          [0.3915, 0.2908, 0.3177],\n",
      "          [0.3868, 0.3074, 0.3058]],\n",
      "\n",
      "         [[0.3261, 0.3378, 0.3361],\n",
      "          [0.3243, 0.3320, 0.3437],\n",
      "          [0.3201, 0.3624, 0.3176]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4449, 0.5551, 0.0000],\n",
      "          [0.3774, 0.6226, 0.0000],\n",
      "          [0.4183, 0.5817, 0.0000]],\n",
      "\n",
      "         [[0.5204, 0.4796, 0.0000],\n",
      "          [0.5078, 0.4922, 0.0000],\n",
      "          [0.5132, 0.4868, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Decoder(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [DecoderLayer(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, dec_x, enc_x, self_mask=None, cross_mask=None):\n",
    "        b, t = dec_x.size()\n",
    "        x = self.embed(dec_x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_x, self_mask=self_mask, cross_mask=cross_mask)\n",
    "        return x\n",
    "\n",
    "    def get_embed_weights(self):\n",
    "        return self.embed.weight\n",
    "\n",
    "decoder = Decoder(vocab_size=32, n=2, d=16, h=2)\n",
    "# x = torch.randint(0, 32, (2, 3))\n",
    "x = torch.tensor([[15, 7, 0], [10, 0, 0], [1, 3, 0]])\n",
    "y = torch.rand(3, 3, 16)\n",
    "\n",
    "self_mask1 = build_padding_mask(x, pad_token=0)\n",
    "self_mask2 = build_causal_mask(x)\n",
    "self_mask = merge_masks(self_mask1, self_mask2)\n",
    "print(f\"self_mask: \\n {self_mask}\")\n",
    "self_mask = reshape_mask(self_mask)\n",
    "\n",
    "cross_mask = build_padding_mask(torch.tensor([[2, 2, 2], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "cross_mask = reshape_mask(cross_mask)\n",
    "print(f\"cross_mask: \\n {cross_mask}\")\n",
    "print(decoder(x, y, self_mask=self_mask, cross_mask=cross_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b5aba42-4209-4fbb-8cc9-a9e8a0236e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Output(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, d: int = 512, ff_weight = None):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Linear(d, vocab_size)\n",
    "        # weight tying with the decoder embedding\n",
    "        if ff_weight is not None:\n",
    "            self.ff.weight = ff_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2477aec-7287-498b-bf31-cbb0bdfe154d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_mask: \n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 0, 0]])\n",
      "dec_mask: \n",
      " tensor([[1, 0, 0, 0],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 1, 1, 0]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.6742e+00, -9.9728e-04,  1.0976e+00],\n",
      "          [ 1.5374e+00,  8.7139e-01,  1.7909e-01],\n",
      "          [ 2.0514e+00,  1.0262e+00,  5.0747e-01]],\n",
      "\n",
      "         [[ 2.6828e-01,  5.7621e-01,  3.8235e-02],\n",
      "          [ 1.3697e+00,  1.6423e+00,  2.0728e+00],\n",
      "          [ 8.7461e-01,  1.0193e-01,  6.4389e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5975e-01,  3.5872e-01,        -inf],\n",
      "          [ 7.1827e-01,  5.7135e-01,        -inf],\n",
      "          [ 4.1149e-01,  4.6960e-01,        -inf]],\n",
      "\n",
      "         [[ 2.8763e-01,  3.9224e-01,        -inf],\n",
      "          [ 1.1159e+00,  9.6830e-01,        -inf],\n",
      "          [-1.2512e-01, -1.8677e-01,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8417e+00,        -inf,        -inf],\n",
      "          [ 2.9988e-01,        -inf,        -inf],\n",
      "          [ 4.3545e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.5599e-01,        -inf,        -inf],\n",
      "          [ 2.6504e-01,        -inf,        -inf],\n",
      "          [ 1.9174e-01,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5717, 0.1071, 0.3212],\n",
      "          [0.5647, 0.2901, 0.1452],\n",
      "          [0.6360, 0.2282, 0.1358]],\n",
      "\n",
      "         [[0.3169, 0.4312, 0.2518],\n",
      "          [0.2308, 0.3031, 0.4662],\n",
      "          [0.4433, 0.2047, 0.3520]]],\n",
      "\n",
      "\n",
      "        [[[0.5252, 0.4748, 0.0000],\n",
      "          [0.5367, 0.4633, 0.0000],\n",
      "          [0.4855, 0.5145, 0.0000]],\n",
      "\n",
      "         [[0.4739, 0.5261, 0.0000],\n",
      "          [0.5368, 0.4632, 0.0000],\n",
      "          [0.5154, 0.4846, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0621, -0.4145,  0.2601],\n",
      "          [-0.3124, -0.4106,  0.2989],\n",
      "          [ 0.3274,  0.5782,  0.0452]],\n",
      "\n",
      "         [[-0.4145, -0.5936,  0.0540],\n",
      "          [ 0.1012, -0.3447, -0.5711],\n",
      "          [-0.1144, -0.1344,  0.2496]]],\n",
      "\n",
      "\n",
      "        [[[-0.2702, -0.3231,    -inf],\n",
      "          [-0.1316, -0.1018,    -inf],\n",
      "          [ 0.5468,  0.4901,    -inf]],\n",
      "\n",
      "         [[-0.0108,  0.0930,    -inf],\n",
      "          [-0.0189,  0.0078,    -inf],\n",
      "          [-0.0964, -0.2768,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0138,    -inf,    -inf],\n",
      "          [-0.1803,    -inf,    -inf],\n",
      "          [-0.1328,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4318,    -inf,    -inf],\n",
      "          [-0.2389,    -inf,    -inf],\n",
      "          [-0.2667,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3244, 0.2280, 0.4476],\n",
      "          [0.2667, 0.2418, 0.4915],\n",
      "          [0.3290, 0.4228, 0.2481]],\n",
      "\n",
      "         [[0.2912, 0.2435, 0.4653],\n",
      "          [0.4650, 0.2977, 0.2374],\n",
      "          [0.2925, 0.2867, 0.4209]]],\n",
      "\n",
      "\n",
      "        [[[0.5132, 0.4868, 0.0000],\n",
      "          [0.4926, 0.5074, 0.0000],\n",
      "          [0.5142, 0.4858, 0.0000]],\n",
      "\n",
      "         [[0.4741, 0.5259, 0.0000],\n",
      "          [0.4933, 0.5067, 0.0000],\n",
      "          [0.5450, 0.4550, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2707,    -inf,    -inf,    -inf],\n",
      "          [ 0.5839,    -inf,    -inf,    -inf],\n",
      "          [-0.6773,    -inf,    -inf,    -inf],\n",
      "          [-0.7891,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3312,    -inf,    -inf,    -inf],\n",
      "          [ 0.0691,    -inf,    -inf,    -inf],\n",
      "          [-0.0317,    -inf,    -inf,    -inf],\n",
      "          [-0.2533,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.6729,    -inf,    -inf,    -inf],\n",
      "          [ 0.2557,    -inf,    -inf,    -inf],\n",
      "          [ 0.7786,    -inf,    -inf,    -inf],\n",
      "          [ 0.3962,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4403,    -inf,    -inf,    -inf],\n",
      "          [ 0.1230,    -inf,    -inf,    -inf],\n",
      "          [ 0.2332,    -inf,    -inf,    -inf],\n",
      "          [ 0.3443,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4081,  0.7563,  0.1238,    -inf],\n",
      "          [ 0.3630,  0.3455, -0.2731,    -inf],\n",
      "          [ 0.4244,  0.2092,  0.1023,    -inf],\n",
      "          [-0.0035,  0.2375, -0.1896,    -inf]],\n",
      "\n",
      "         [[ 0.8779,  0.0744,  0.5101,    -inf],\n",
      "          [ 1.2181,  0.9488,  0.4964,    -inf],\n",
      "          [ 0.3510,  1.1523, -0.1793,    -inf],\n",
      "          [ 0.5671, -0.0044,  0.5157,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3156, 0.4470, 0.2375, 0.0000],\n",
      "          [0.3981, 0.3912, 0.2107, 0.0000],\n",
      "          [0.3951, 0.3186, 0.2863, 0.0000],\n",
      "          [0.3223, 0.4101, 0.2676, 0.0000]],\n",
      "\n",
      "         [[0.4673, 0.2092, 0.3235, 0.0000],\n",
      "          [0.4445, 0.3396, 0.2160, 0.0000],\n",
      "          [0.2620, 0.5838, 0.1542, 0.0000],\n",
      "          [0.3977, 0.2246, 0.3778, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1469,  0.2274, -0.0947],\n",
      "          [-0.0079,  0.2704, -0.4168],\n",
      "          [ 0.3325,  0.5220,  0.2130],\n",
      "          [ 0.3472,  0.6304,  0.0918]],\n",
      "\n",
      "         [[ 0.2759, -0.4151,  0.1278],\n",
      "          [ 0.4261,  0.2127,  0.0599],\n",
      "          [-0.2828, -0.0496, -0.2182],\n",
      "          [-0.1795, -0.0438, -0.2698]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1627,  0.3154,    -inf],\n",
      "          [ 0.2871, -0.0056,    -inf],\n",
      "          [ 0.3962,  0.0286,    -inf],\n",
      "          [ 0.4646,  0.0530,    -inf]],\n",
      "\n",
      "         [[-0.6426, -0.8183,    -inf],\n",
      "          [-0.4713, -0.4437,    -inf],\n",
      "          [-0.2956, -0.2798,    -inf],\n",
      "          [-0.1989, -0.2433,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0404,    -inf,    -inf],\n",
      "          [ 0.3497,    -inf,    -inf],\n",
      "          [ 1.3530,    -inf,    -inf],\n",
      "          [ 0.5128,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3438,    -inf,    -inf],\n",
      "          [-0.4040,    -inf,    -inf],\n",
      "          [-0.4130,    -inf,    -inf],\n",
      "          [-0.6766,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3485, 0.3778, 0.2737],\n",
      "          [0.3350, 0.4425, 0.2226],\n",
      "          [0.3230, 0.3904, 0.2866],\n",
      "          [0.3224, 0.4279, 0.2497]],\n",
      "\n",
      "         [[0.4231, 0.2120, 0.3649],\n",
      "          [0.3998, 0.3230, 0.2772],\n",
      "          [0.3004, 0.3793, 0.3204],\n",
      "          [0.3269, 0.3744, 0.2987]]],\n",
      "\n",
      "\n",
      "        [[[0.4619, 0.5381, 0.0000],\n",
      "          [0.5727, 0.4273, 0.0000],\n",
      "          [0.5909, 0.4091, 0.0000],\n",
      "          [0.6015, 0.3985, 0.0000]],\n",
      "\n",
      "         [[0.5438, 0.4562, 0.0000],\n",
      "          [0.4931, 0.5069, 0.0000],\n",
      "          [0.4961, 0.5039, 0.0000],\n",
      "          [0.5111, 0.4889, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1922,    -inf,    -inf,    -inf],\n",
      "          [-0.1509,    -inf,    -inf,    -inf],\n",
      "          [-0.1075,    -inf,    -inf,    -inf],\n",
      "          [ 0.0741,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1411,    -inf,    -inf,    -inf],\n",
      "          [-0.5958,    -inf,    -inf,    -inf],\n",
      "          [-0.2650,    -inf,    -inf,    -inf],\n",
      "          [-0.2927,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6401,    -inf,    -inf,    -inf],\n",
      "          [-0.3998,    -inf,    -inf,    -inf],\n",
      "          [-0.6147,    -inf,    -inf,    -inf],\n",
      "          [-0.8979,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3467,    -inf,    -inf,    -inf],\n",
      "          [-0.0569,    -inf,    -inf,    -inf],\n",
      "          [-0.1969,    -inf,    -inf,    -inf],\n",
      "          [-0.3491,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1135,  0.0654,  0.6043,    -inf],\n",
      "          [ 0.3293,  0.2701,  0.6349,    -inf],\n",
      "          [ 0.9835,  0.3100,  0.3432,    -inf],\n",
      "          [-0.0065,  0.1859,  0.6284,    -inf]],\n",
      "\n",
      "         [[ 0.5491,  0.0680,  0.3600,    -inf],\n",
      "          [-0.1284, -0.1165, -0.1273,    -inf],\n",
      "          [ 0.4319, -0.2039,  0.3494,    -inf],\n",
      "          [ 0.2578, -0.1206, -0.1019,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2788, 0.2657, 0.4555, 0.0000],\n",
      "          [0.3030, 0.2856, 0.4114, 0.0000],\n",
      "          [0.4909, 0.2503, 0.2588, 0.0000],\n",
      "          [0.2440, 0.2957, 0.4603, 0.0000]],\n",
      "\n",
      "         [[0.4089, 0.2527, 0.3384, 0.0000],\n",
      "          [0.3319, 0.3359, 0.3322, 0.0000],\n",
      "          [0.4081, 0.2161, 0.3758, 0.0000],\n",
      "          [0.4197, 0.2875, 0.2929, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1533,  0.2892,  0.1710],\n",
      "          [ 0.3300, -0.1281,  0.5902],\n",
      "          [ 0.1318, -0.1542, -0.1154],\n",
      "          [-0.1156, -0.1982, -0.0867]],\n",
      "\n",
      "         [[ 0.0047,  0.1876,  0.5459],\n",
      "          [-0.4288,  0.0953,  0.3138],\n",
      "          [ 0.1110,  0.1381,  0.0530],\n",
      "          [ 0.1993,  0.2115,  0.0628]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2713,  0.1598,    -inf],\n",
      "          [ 0.3533,  0.0655,    -inf],\n",
      "          [ 0.4381,  0.1562,    -inf],\n",
      "          [ 0.5559,  0.1719,    -inf]],\n",
      "\n",
      "         [[-0.5178, -0.4556,    -inf],\n",
      "          [ 0.1900,  0.1160,    -inf],\n",
      "          [ 0.1529,  0.0690,    -inf],\n",
      "          [ 0.0369,  0.0358,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.3375,    -inf,    -inf],\n",
      "          [ 0.1585,    -inf,    -inf],\n",
      "          [-0.1956,    -inf,    -inf],\n",
      "          [-0.3505,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0856,    -inf,    -inf],\n",
      "          [ 0.5509,    -inf,    -inf],\n",
      "          [ 0.2377,    -inf,    -inf],\n",
      "          [ 0.0967,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2538, 0.3951, 0.3511],\n",
      "          [0.3413, 0.2159, 0.4428],\n",
      "          [0.3949, 0.2967, 0.3084],\n",
      "          [0.3390, 0.3121, 0.3489]],\n",
      "\n",
      "         [[0.2552, 0.3064, 0.4384],\n",
      "          [0.2088, 0.3526, 0.4387],\n",
      "          [0.3366, 0.3458, 0.3176],\n",
      "          [0.3466, 0.3509, 0.3024]]],\n",
      "\n",
      "\n",
      "        [[[0.5279, 0.4721, 0.0000],\n",
      "          [0.5715, 0.4285, 0.0000],\n",
      "          [0.5700, 0.4300, 0.0000],\n",
      "          [0.5948, 0.4052, 0.0000]],\n",
      "\n",
      "         [[0.4844, 0.5156, 0.0000],\n",
      "          [0.5185, 0.4815, 0.0000],\n",
      "          [0.5210, 0.4790, 0.0000],\n",
      "          [0.5003, 0.4997, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8, embed_tying=True):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size=vocab_size, n=n, d=d, h=h)\n",
    "        self.decoder = Decoder(vocab_size=vocab_size, n=n, d=d, h=h)\n",
    "        if embed_tying:\n",
    "            self.output = Output(vocab_size=vocab_size, d=d, ff_weight = self.decoder.get_embed_weights())\n",
    "        else:\n",
    "            self.output = Output(vocab_size=vocab_size, d=d)\n",
    "\n",
    "    def forward(self, enc_x, dec_x, enc_mask=None, dec_mask=None):\n",
    "        encoded = self.encoder(enc_x, enc_mask)\n",
    "        decoded = self.decoder(dec_x=dec_x, enc_x=encoded, self_mask=dec_mask, cross_mask=enc_mask)\n",
    "        return self.output(decoded)\n",
    "\n",
    "transformer = Transformer(vocab_size=32, n=2, d=16, h=2, embed_tying=False)\n",
    "enc_x = torch.tensor([[15, 7, 3], [10, 10, 0], [1, 0, 0]])\n",
    "dec_x = torch.tensor([[21, 8, 0, 0], [25, 0, 0, 0], [8, 1, 2, 3]])\n",
    "# dec_x = torch.tensor([[21, 8], [25, 0], [8, 1]])\n",
    "\n",
    "enc_mask = build_padding_mask(enc_x, pad_token=0)\n",
    "print(f\"enc_mask: \\n {enc_mask}\")\n",
    "enc_mask = reshape_mask(enc_mask)\n",
    "\n",
    "dec_mask1 = build_padding_mask(dec_x, pad_token=0)\n",
    "dec_mask2 = build_causal_mask(dec_x)\n",
    "dec_mask = merge_masks(dec_mask1, dec_mask2)\n",
    "print(f\"dec_mask: \\n {dec_mask}\")\n",
    "dec_mask = reshape_mask(dec_mask)\n",
    "\n",
    "print(transformer(enc_x, dec_x, enc_mask=enc_mask, dec_mask=dec_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f69bab-e9a5-44a7-af1d-f294f62d3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a06c43eb-c348-4905-9384-1b28378435b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  9906,   4435, 100257, 100257, 100257],\n",
      "        [  2028,    374,    264,   4382,  11914],\n",
      "        [  7979, 100257, 100257, 100257, 100257]])\n",
      "tensor([[ 82681, 100257, 100257, 100257],\n",
      "        [    34,  17771,   6316,  17571],\n",
      "        [ 23380, 100257, 100257, 100257]])\n",
      "enc_mask: \n",
      " tensor([[1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 0, 0, 0, 0]])\n",
      "dec_mask: \n",
      " tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 0, 0, 0]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-3.2755e-01,  1.3563e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.5796e-01,  2.8945e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.2562e-01, -9.1705e-02,        -inf,        -inf,        -inf],\n",
      "          [ 2.8101e-02, -1.2289e-02,        -inf,        -inf,        -inf],\n",
      "          [ 2.7247e-01,  2.5949e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.9820e-01,  9.5041e-01,        -inf,        -inf,        -inf],\n",
      "          [-2.7562e-02,  2.0617e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.4911e-01, -3.6637e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.2380e-01,  6.6838e-02,        -inf,        -inf,        -inf],\n",
      "          [ 1.0370e-01,  3.5827e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.1999e-01,  5.0602e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.5907e-02,  1.1100e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.5205e-01,  1.2907e-03,        -inf,        -inf,        -inf],\n",
      "          [ 1.9414e-01, -5.2381e-02,        -inf,        -inf,        -inf],\n",
      "          [ 5.2611e-01,  1.1316e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.5495e-01, -8.8558e-03,        -inf,        -inf,        -inf],\n",
      "          [ 5.3387e-02, -1.6699e-01,        -inf,        -inf,        -inf],\n",
      "          [-2.1419e-01, -2.1839e-01,        -inf,        -inf,        -inf],\n",
      "          [-3.6639e-01, -5.0227e-01,        -inf,        -inf,        -inf],\n",
      "          [-5.4786e-01, -3.7949e-01,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[-6.4650e-01, -6.6908e-01,  7.3874e-02, -1.9992e-01, -1.1315e+00],\n",
      "          [ 8.5238e-01,  3.4063e-01,  4.3001e-01, -1.2563e+00, -3.3523e-01],\n",
      "          [-4.7787e-01, -5.1204e-02,  6.7292e-01,  5.4181e-01, -8.2861e-01],\n",
      "          [ 2.3637e-01, -1.4053e-01,  8.0900e-01, -8.2381e-01, -2.6934e-01],\n",
      "          [-1.7691e-01, -4.3682e-01,  7.5595e-02, -6.2310e-01, -9.5307e-01]],\n",
      "\n",
      "         [[ 1.1248e-01, -3.1476e-01,  6.8219e-02, -4.1226e-01, -2.4390e-01],\n",
      "          [ 4.6078e-01,  7.8793e-01,  2.7996e-01, -4.8244e-01,  8.0512e-01],\n",
      "          [ 1.2919e+00, -5.5189e-01,  3.3143e-01,  4.1482e-03,  8.2094e-01],\n",
      "          [ 7.5577e-01,  8.7634e-02,  3.9738e-01, -2.7539e-02,  1.2153e-01],\n",
      "          [-2.9072e-01,  4.4008e-01,  1.2617e-01, -1.1403e-01, -2.1146e-01]],\n",
      "\n",
      "         [[-2.8440e-02,  2.8197e-02,  4.3336e-01,  4.6470e-01,  7.7113e-01],\n",
      "          [-4.2594e-02,  1.0432e+00,  4.7006e-03,  4.8532e-01,  4.6752e-01],\n",
      "          [-3.9841e-01,  5.9403e-01, -5.8312e-02, -6.9334e-01, -4.5165e-01],\n",
      "          [-1.9391e-01,  1.5559e-01, -2.6827e-01, -2.3449e-01, -1.2334e-01],\n",
      "          [-2.1123e-02,  6.9726e-01,  9.9392e-01, -3.9328e-01,  7.0183e-01]],\n",
      "\n",
      "         [[-4.1727e-01, -5.4096e-01, -1.1290e+00, -8.2698e-01, -7.9940e-01],\n",
      "          [ 7.1550e-01,  4.2887e-01, -5.5760e-01, -3.8820e-01,  4.4806e-01],\n",
      "          [ 1.2190e+00, -5.7741e-02, -4.4789e-01, -2.2281e-01, -5.0663e-01],\n",
      "          [ 7.4425e-01,  3.0863e-01,  1.6586e-01, -2.3595e-02,  2.5597e-01],\n",
      "          [-6.7395e-01,  7.8049e-01,  4.7584e-01,  1.1667e-01, -2.6907e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7475e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.2021e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.8066e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-6.1623e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.6972e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.8545e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-8.0113e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.1434e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-6.6632e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-9.9695e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.5564e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.0696e-03,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 8.4742e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.3464e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.6593e-02,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.7007e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.4615e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 9.0848e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.3610e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.2780e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3862, 0.6138, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5171, 0.4829, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5787, 0.4213, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5101, 0.4899, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5032, 0.4968, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3654, 0.6346, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4418, 0.5582, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6261, 0.3739, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5142, 0.4858, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5170, 0.4830, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4290, 0.5710, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4837, 0.5163, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5868, 0.4132, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5613, 0.4387, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6259, 0.3741, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5409, 0.4591, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5549, 0.4451, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5011, 0.4989, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5339, 0.4661, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4580, 0.5420, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1610, 0.1574, 0.3309, 0.2516, 0.0991],\n",
      "          [0.3730, 0.2236, 0.2445, 0.0453, 0.1137],\n",
      "          [0.1091, 0.1671, 0.3447, 0.3023, 0.0768],\n",
      "          [0.2268, 0.1556, 0.4022, 0.0786, 0.1368],\n",
      "          [0.2405, 0.1854, 0.3095, 0.1539, 0.1107]],\n",
      "\n",
      "         [[0.2564, 0.1672, 0.2453, 0.1517, 0.1795],\n",
      "          [0.1991, 0.2762, 0.1662, 0.0775, 0.2810],\n",
      "          [0.4096, 0.0648, 0.1568, 0.1130, 0.2558],\n",
      "          [0.3126, 0.1603, 0.2185, 0.1428, 0.1658],\n",
      "          [0.1456, 0.3023, 0.2209, 0.1737, 0.1576]],\n",
      "\n",
      "         [[0.1332, 0.1410, 0.2114, 0.2181, 0.2963],\n",
      "          [0.1195, 0.3538, 0.1252, 0.2025, 0.1990],\n",
      "          [0.1472, 0.3970, 0.2068, 0.1096, 0.1395],\n",
      "          [0.1859, 0.2636, 0.1726, 0.1785, 0.1995],\n",
      "          [0.1168, 0.2396, 0.3224, 0.0805, 0.2407]],\n",
      "\n",
      "         [[0.2688, 0.2375, 0.1319, 0.1784, 0.1834],\n",
      "          [0.3197, 0.2400, 0.0895, 0.1060, 0.2447],\n",
      "          [0.5313, 0.1482, 0.1003, 0.1256, 0.0946],\n",
      "          [0.3044, 0.1969, 0.1707, 0.1412, 0.1868],\n",
      "          [0.0823, 0.3526, 0.2600, 0.1816, 0.1235]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3586, -0.0661,    -inf,    -inf,    -inf],\n",
      "          [-0.2083, -0.0260,    -inf,    -inf,    -inf],\n",
      "          [-0.0756, -0.1310,    -inf,    -inf,    -inf],\n",
      "          [ 0.2104, -0.0268,    -inf,    -inf,    -inf],\n",
      "          [-0.0163, -0.1493,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4015, -0.0238,    -inf,    -inf,    -inf],\n",
      "          [ 0.0303, -0.1969,    -inf,    -inf,    -inf],\n",
      "          [-0.0483,  0.3268,    -inf,    -inf,    -inf],\n",
      "          [ 0.0532,  0.3951,    -inf,    -inf,    -inf],\n",
      "          [-0.1496,  0.0749,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3993, -0.1490,    -inf,    -inf,    -inf],\n",
      "          [ 0.3450, -0.0852,    -inf,    -inf,    -inf],\n",
      "          [ 0.0555, -0.0491,    -inf,    -inf,    -inf],\n",
      "          [ 0.0850, -0.1372,    -inf,    -inf,    -inf],\n",
      "          [-0.0426, -0.3058,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3737, -0.5775,    -inf,    -inf,    -inf],\n",
      "          [ 0.2317, -0.1065,    -inf,    -inf,    -inf],\n",
      "          [-0.0515, -0.0386,    -inf,    -inf,    -inf],\n",
      "          [-0.0864, -0.1267,    -inf,    -inf,    -inf],\n",
      "          [-0.0373, -0.1037,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3842,  0.3051, -0.3780, -0.1255,  0.2332],\n",
      "          [-0.1042, -0.2352, -0.0981, -0.0156, -0.8922],\n",
      "          [ 0.3942,  0.2409,  0.2274, -0.5993,  0.2128],\n",
      "          [ 0.5636,  0.5599, -0.2813, -0.1168,  0.2512],\n",
      "          [ 0.1946, -0.1625, -0.3854,  0.1902,  0.0317]],\n",
      "\n",
      "         [[-0.0780,  0.3563,  0.2334,  0.6001,  0.3212],\n",
      "          [ 0.0846,  0.0042, -0.2039,  0.2103, -0.0478],\n",
      "          [ 0.2650,  0.4664,  0.5722,  0.4394,  0.1275],\n",
      "          [ 0.3435,  0.5947,  0.4400,  0.3574,  0.5033],\n",
      "          [-0.3362, -0.4025, -0.0928, -0.4485, -0.3597]],\n",
      "\n",
      "         [[ 0.2030, -0.1096, -0.1673, -0.2899,  0.0371],\n",
      "          [ 0.1980,  0.0748, -0.0694,  0.4452,  0.1123],\n",
      "          [-0.0208,  0.0241, -0.2515, -0.1069,  0.3316],\n",
      "          [ 0.4922, -0.0440, -0.0061,  0.0796, -0.0141],\n",
      "          [ 0.3737, -0.1223, -0.2204,  0.6501, -0.1204]],\n",
      "\n",
      "         [[ 0.3809, -0.0932, -0.1861, -0.7476, -0.1798],\n",
      "          [-0.9736, -0.8212, -1.3092, -0.5701, -0.6869],\n",
      "          [ 0.1624,  0.1649,  0.2276, -0.5642, -0.5698],\n",
      "          [ 0.1354,  0.2082,  0.3066, -0.1924, -0.1974],\n",
      "          [ 0.0770,  0.1550, -0.1275, -0.4739, -0.6972]]],\n",
      "\n",
      "\n",
      "        [[[-0.1928,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2110,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2695,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.3401,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0174,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5912,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0463,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0122,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1217,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1890,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1263,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4889,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.5074,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6713,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.7640,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0552,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1762,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1932,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1299,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0626,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4274, 0.5726, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4546, 0.5454, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5139, 0.4861, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5590, 0.4410, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5332, 0.4668, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6047, 0.3953, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5565, 0.4435, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4073, 0.5927, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4153, 0.5847, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4441, 0.5559, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6337, 0.3663, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6059, 0.3941, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5261, 0.4739, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5553, 0.4447, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5654, 0.4346, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7214, 0.2786, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5837, 0.4163, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4968, 0.5032, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5101, 0.4899, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5166, 0.4834, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2597, 0.2399, 0.1212, 0.1560, 0.2233],\n",
      "          [0.2257, 0.1980, 0.2271, 0.2466, 0.1026],\n",
      "          [0.2558, 0.2195, 0.2165, 0.0947, 0.2134],\n",
      "          [0.2729, 0.2719, 0.1172, 0.1382, 0.1997],\n",
      "          [0.2436, 0.1705, 0.1364, 0.2425, 0.2070]],\n",
      "\n",
      "         [[0.1357, 0.2095, 0.1853, 0.2673, 0.2023],\n",
      "          [0.2136, 0.1971, 0.1601, 0.2422, 0.1871],\n",
      "          [0.1772, 0.2167, 0.2409, 0.2109, 0.1544],\n",
      "          [0.1794, 0.2306, 0.1976, 0.1819, 0.2105],\n",
      "          [0.1968, 0.1842, 0.2510, 0.1759, 0.1922]],\n",
      "\n",
      "         [[0.2577, 0.1885, 0.1780, 0.1574, 0.2183],\n",
      "          [0.2063, 0.1824, 0.1579, 0.2641, 0.1893],\n",
      "          [0.1930, 0.2019, 0.1533, 0.1771, 0.2746],\n",
      "          [0.2893, 0.1692, 0.1757, 0.1915, 0.1743],\n",
      "          [0.2445, 0.1489, 0.1350, 0.3224, 0.1492]],\n",
      "\n",
      "         [[0.3243, 0.2018, 0.1839, 0.1049, 0.1851],\n",
      "          [0.1752, 0.2040, 0.1252, 0.2622, 0.2333],\n",
      "          [0.2479, 0.2485, 0.2646, 0.1199, 0.1192],\n",
      "          [0.2128, 0.2289, 0.2525, 0.1533, 0.1525],\n",
      "          [0.2542, 0.2748, 0.2072, 0.1465, 0.1172]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4198,  0.0026,    -inf,    -inf,    -inf],\n",
      "          [-0.0515,  0.1670,    -inf,    -inf,    -inf],\n",
      "          [-0.2021, -0.0012,    -inf,    -inf,    -inf],\n",
      "          [-0.1514, -0.0864,    -inf,    -inf,    -inf],\n",
      "          [-0.3519, -0.0455,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6373,  0.6255,    -inf,    -inf,    -inf],\n",
      "          [-0.1874,  0.1893,    -inf,    -inf,    -inf],\n",
      "          [-0.2379,  0.0459,    -inf,    -inf,    -inf],\n",
      "          [-0.2403,  0.3974,    -inf,    -inf,    -inf],\n",
      "          [-0.4282,  0.1761,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1322,  0.1439,    -inf,    -inf,    -inf],\n",
      "          [ 0.0887, -0.2781,    -inf,    -inf,    -inf],\n",
      "          [ 0.3646,  0.0421,    -inf,    -inf,    -inf],\n",
      "          [ 0.4670,  0.3333,    -inf,    -inf,    -inf],\n",
      "          [ 0.5097,  0.3659,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0072, -0.1244,    -inf,    -inf,    -inf],\n",
      "          [ 0.1423, -0.3158,    -inf,    -inf,    -inf],\n",
      "          [ 0.0953,  0.5281,    -inf,    -inf,    -inf],\n",
      "          [ 0.0552,  0.7836,    -inf,    -inf,    -inf],\n",
      "          [ 0.0681,  0.7358,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.4707,  0.0761, -0.4145,  0.1492,  0.0513],\n",
      "          [ 0.1257,  0.1000,  0.2062,  0.3678,  0.1429],\n",
      "          [-0.2801, -0.1632, -0.4984, -0.3335,  0.2614],\n",
      "          [-0.6250, -0.1132, -0.1804, -0.0133,  0.6534],\n",
      "          [-0.0623, -0.0870,  0.0852,  0.0257, -0.1797]],\n",
      "\n",
      "         [[ 0.2786,  0.2116,  0.1136,  0.3441, -0.1507],\n",
      "          [-0.2164, -0.1676, -0.0847,  0.1689,  0.6428],\n",
      "          [ 0.0951, -0.3331,  0.1997,  0.2967,  0.1836],\n",
      "          [-0.1794,  0.0642, -0.0287,  0.6367, -0.1785],\n",
      "          [ 0.1492,  0.1601,  0.2527,  0.5189,  0.3082]],\n",
      "\n",
      "         [[ 0.1763, -0.0927, -0.1535, -0.0589, -0.2042],\n",
      "          [ 0.0942,  0.7976, -0.2685,  0.3011,  0.4212],\n",
      "          [-0.1494,  0.1139, -0.1813, -0.0791, -0.0127],\n",
      "          [-0.3223, -0.2016, -0.2505, -0.3161, -0.2840],\n",
      "          [ 0.2262,  0.3152, -0.2717, -0.0181, -0.3093]],\n",
      "\n",
      "         [[-0.1095,  0.2950,  0.3100, -0.0644,  0.1960],\n",
      "          [-0.1361,  0.6012,  0.1282, -0.2334, -0.3066],\n",
      "          [ 0.2510,  0.2782,  0.2713, -0.3184, -0.0971],\n",
      "          [-0.7046, -0.3339, -0.3131, -0.7628, -0.5668],\n",
      "          [-0.1991,  0.0834, -0.1466, -0.3086, -0.1026]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0456,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1833,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1172,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0439,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0736,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2872,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.6103,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.5731,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.5843,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.6917,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1615,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.7616,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6038,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6212,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.7502,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4693,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0095,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1981,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2775,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0393,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6028, 0.3972, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4456, 0.5544, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4499, 0.5501, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4837, 0.5163, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4240, 0.5760, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5030, 0.4970, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4069, 0.5931, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4295, 0.5705, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3458, 0.6542, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3534, 0.6466, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4314, 0.5686, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5907, 0.4093, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5799, 0.4201, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5334, 0.4666, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5359, 0.4641, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5328, 0.4672, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6126, 0.3874, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3934, 0.6066, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3255, 0.6745, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3390, 0.6610, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1364, 0.2357, 0.1443, 0.2536, 0.2299],\n",
      "          [0.1869, 0.1822, 0.2026, 0.2381, 0.1902],\n",
      "          [0.1787, 0.2009, 0.1437, 0.1695, 0.3072],\n",
      "          [0.1035, 0.1727, 0.1614, 0.1908, 0.3716],\n",
      "          [0.1955, 0.1907, 0.2265, 0.2134, 0.1738]],\n",
      "\n",
      "         [[0.2221, 0.2077, 0.1883, 0.2372, 0.1446],\n",
      "          [0.1424, 0.1495, 0.1625, 0.2093, 0.3363],\n",
      "          [0.1969, 0.1283, 0.2187, 0.2409, 0.2152],\n",
      "          [0.1492, 0.1904, 0.1735, 0.3375, 0.1494],\n",
      "          [0.1742, 0.1761, 0.1932, 0.2522, 0.2043]],\n",
      "\n",
      "         [[0.2527, 0.1931, 0.1817, 0.1997, 0.1727],\n",
      "          [0.1579, 0.3190, 0.1099, 0.1942, 0.2190],\n",
      "          [0.1822, 0.2371, 0.1765, 0.1955, 0.2089],\n",
      "          [0.1905, 0.2150, 0.2047, 0.1917, 0.1980],\n",
      "          [0.2457, 0.2686, 0.1494, 0.1925, 0.1438]],\n",
      "\n",
      "         [[0.1557, 0.2333, 0.2368, 0.1629, 0.2113],\n",
      "          [0.1628, 0.3403, 0.2120, 0.1477, 0.1373],\n",
      "          [0.2315, 0.2379, 0.2362, 0.1310, 0.1634],\n",
      "          [0.1661, 0.2407, 0.2458, 0.1567, 0.1907],\n",
      "          [0.1859, 0.2466, 0.1960, 0.1667, 0.2048]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5259,    -inf,    -inf,    -inf],\n",
      "          [-0.2472,    -inf,    -inf,    -inf],\n",
      "          [-0.2628,    -inf,    -inf,    -inf],\n",
      "          [-0.6071,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1108,    -inf,    -inf,    -inf],\n",
      "          [ 0.8899,    -inf,    -inf,    -inf],\n",
      "          [ 0.9102,    -inf,    -inf,    -inf],\n",
      "          [ 0.4087,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1626,    -inf,    -inf,    -inf],\n",
      "          [-0.2416,    -inf,    -inf,    -inf],\n",
      "          [-0.7687,    -inf,    -inf,    -inf],\n",
      "          [-0.5884,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.8480,    -inf,    -inf,    -inf],\n",
      "          [-0.9313,    -inf,    -inf,    -inf],\n",
      "          [-0.3266,    -inf,    -inf,    -inf],\n",
      "          [-0.4715,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1797, -0.4744,    -inf,    -inf],\n",
      "          [-0.6205, -1.0506,    -inf,    -inf],\n",
      "          [-0.3402,  0.1344,    -inf,    -inf],\n",
      "          [-0.3932, -0.7208,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.6104, -0.5497,    -inf,    -inf],\n",
      "          [ 0.4589,  0.6942,    -inf,    -inf],\n",
      "          [-0.0320, -0.1918,    -inf,    -inf],\n",
      "          [-0.1475, -0.0028,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4967,  0.5625,    -inf,    -inf],\n",
      "          [ 0.1588,  0.5092,    -inf,    -inf],\n",
      "          [ 0.3707,  0.8522,    -inf,    -inf],\n",
      "          [-0.4111, -0.3018,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3185, -0.6660,    -inf,    -inf],\n",
      "          [-0.0317, -0.0417,    -inf,    -inf],\n",
      "          [-0.0159,  0.5100,    -inf,    -inf],\n",
      "          [-0.2637,  0.6014,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4810,    -inf,    -inf,    -inf],\n",
      "          [-0.3750,    -inf,    -inf,    -inf],\n",
      "          [ 0.1712,    -inf,    -inf,    -inf],\n",
      "          [-0.3339,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0133,    -inf,    -inf,    -inf],\n",
      "          [-0.2968,    -inf,    -inf,    -inf],\n",
      "          [-0.0446,    -inf,    -inf,    -inf],\n",
      "          [-0.0765,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5205,    -inf,    -inf,    -inf],\n",
      "          [ 0.2396,    -inf,    -inf,    -inf],\n",
      "          [ 0.1027,    -inf,    -inf,    -inf],\n",
      "          [ 0.2206,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1980,    -inf,    -inf,    -inf],\n",
      "          [-1.1525,    -inf,    -inf,    -inf],\n",
      "          [-0.7876,    -inf,    -inf,    -inf],\n",
      "          [-1.1955,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5731, 0.4269, 0.0000, 0.0000],\n",
      "          [0.6059, 0.3941, 0.0000, 0.0000],\n",
      "          [0.3835, 0.6165, 0.0000, 0.0000],\n",
      "          [0.5812, 0.4188, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4848, 0.5152, 0.0000, 0.0000],\n",
      "          [0.4414, 0.5586, 0.0000, 0.0000],\n",
      "          [0.5399, 0.4601, 0.0000, 0.0000],\n",
      "          [0.4639, 0.5361, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4836, 0.5164, 0.0000, 0.0000],\n",
      "          [0.4133, 0.5867, 0.0000, 0.0000],\n",
      "          [0.3819, 0.6181, 0.0000, 0.0000],\n",
      "          [0.4727, 0.5273, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7280, 0.2720, 0.0000, 0.0000],\n",
      "          [0.5025, 0.4975, 0.0000, 0.0000],\n",
      "          [0.3715, 0.6285, 0.0000, 0.0000],\n",
      "          [0.2963, 0.7037, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3746,  0.3630,    -inf,    -inf,    -inf],\n",
      "          [-0.2994,  0.2753,    -inf,    -inf,    -inf],\n",
      "          [-0.1144,  0.4685,    -inf,    -inf,    -inf],\n",
      "          [-0.0967,  0.2573,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0427, -0.1591,    -inf,    -inf,    -inf],\n",
      "          [ 0.3013, -0.0767,    -inf,    -inf,    -inf],\n",
      "          [ 0.3575,  0.0172,    -inf,    -inf,    -inf],\n",
      "          [ 0.1058, -0.4832,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4915,  0.7970,    -inf,    -inf,    -inf],\n",
      "          [-0.1466,  0.4010,    -inf,    -inf,    -inf],\n",
      "          [ 0.0189,  0.4363,    -inf,    -inf,    -inf],\n",
      "          [ 0.0504,  0.3875,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4006, -0.2124,    -inf,    -inf,    -inf],\n",
      "          [-0.9996, -0.4274,    -inf,    -inf,    -inf],\n",
      "          [-0.6228, -0.3669,    -inf,    -inf,    -inf],\n",
      "          [-0.5614, -0.4124,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.4824, -0.3437,  0.5909,  0.1592, -0.4245],\n",
      "          [-0.5767, -0.1613,  0.1820, -0.3260, -0.3987],\n",
      "          [-0.1018, -0.6677, -0.0775,  0.0511, -0.3480],\n",
      "          [-0.6479, -0.0077, -0.0243,  0.0717, -0.0062]],\n",
      "\n",
      "         [[ 0.1151, -0.0691, -0.3737,  0.1638, -0.0651],\n",
      "          [ 0.4909,  0.0180,  0.0469, -0.0055, -0.1688],\n",
      "          [-0.1559, -0.2195, -0.0078, -0.1217,  0.0733],\n",
      "          [-0.0227,  0.2885, -0.2340, -0.6062, -0.2166]],\n",
      "\n",
      "         [[ 0.1572,  0.0122,  0.4948,  0.1934,  0.2921],\n",
      "          [ 0.1821,  0.0440,  0.2656,  0.6616,  0.6979],\n",
      "          [ 0.7253,  0.2569,  0.2225,  0.7110,  0.2036],\n",
      "          [ 0.6234,  0.2205,  0.4697,  0.4861,  0.6281]],\n",
      "\n",
      "         [[ 0.1332,  0.0301,  1.0001,  0.0494,  0.3490],\n",
      "          [-0.2734,  0.5481,  0.4837,  0.2099,  0.1111],\n",
      "          [ 0.3955,  0.3086,  0.1503,  0.1622,  0.4757],\n",
      "          [ 0.3185,  0.4709,  0.5353,  0.2941,  0.3581]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3466,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2809,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1988,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0565,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1230,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.4980,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.4208,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1983,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2133,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6099,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4396,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4399,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1502,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.7160,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6383,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.6096,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5029, 0.4971, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3602, 0.6398, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3583, 0.6417, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4124, 0.5876, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5503, 0.4497, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5934, 0.4066, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5843, 0.4157, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6431, 0.3569, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4242, 0.5758, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3664, 0.6336, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3971, 0.6029, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4165, 0.5835, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4531, 0.5469, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3607, 0.6393, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4364, 0.5636, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4628, 0.5372, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1245, 0.1430, 0.3641, 0.2365, 0.1319],\n",
      "          [0.1403, 0.2125, 0.2995, 0.1802, 0.1676],\n",
      "          [0.2203, 0.1251, 0.2257, 0.2567, 0.1722],\n",
      "          [0.1147, 0.2176, 0.2141, 0.2356, 0.2180]],\n",
      "\n",
      "         [[0.2309, 0.1921, 0.1416, 0.2425, 0.1929],\n",
      "          [0.2950, 0.1838, 0.1892, 0.1795, 0.1525],\n",
      "          [0.1855, 0.1741, 0.2151, 0.1920, 0.2333],\n",
      "          [0.2195, 0.2996, 0.1777, 0.1225, 0.1808]],\n",
      "\n",
      "         [[0.1836, 0.1588, 0.2573, 0.1903, 0.2101],\n",
      "          [0.1600, 0.1394, 0.1740, 0.2585, 0.2681],\n",
      "          [0.2624, 0.1643, 0.1587, 0.2587, 0.1558],\n",
      "          [0.2272, 0.1518, 0.1948, 0.1980, 0.2282]],\n",
      "\n",
      "         [[0.1552, 0.1400, 0.3694, 0.1427, 0.1926],\n",
      "          [0.1177, 0.2676, 0.2510, 0.1908, 0.1729],\n",
      "          [0.2186, 0.2004, 0.1711, 0.1731, 0.2368],\n",
      "          [0.1844, 0.2148, 0.2290, 0.1800, 0.1918]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 6.2137e-02,        -inf,        -inf,        -inf],\n",
      "          [ 4.4431e-04,        -inf,        -inf,        -inf],\n",
      "          [ 2.4939e-03,        -inf,        -inf,        -inf],\n",
      "          [-5.6921e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 4.1748e-01,        -inf,        -inf,        -inf],\n",
      "          [-3.6902e-02,        -inf,        -inf,        -inf],\n",
      "          [-4.7406e-02,        -inf,        -inf,        -inf],\n",
      "          [ 1.3162e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.8651e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.9637e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.8971e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.1904e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.9361e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.3526e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.9318e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.0730e-01,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7881e-01, -2.5127e-02,        -inf,        -inf],\n",
      "          [-1.7717e-01, -7.4935e-02,        -inf,        -inf],\n",
      "          [-3.9718e-01, -9.7968e-01,        -inf,        -inf],\n",
      "          [-2.7739e-02, -8.4888e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 7.3041e-01, -2.1904e-01,        -inf,        -inf],\n",
      "          [-1.5308e-01,  3.4548e-02,        -inf,        -inf],\n",
      "          [-1.7650e-01, -1.7193e-01,        -inf,        -inf],\n",
      "          [ 1.2858e-01, -1.7785e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.7052e-03, -2.6510e-01,        -inf,        -inf],\n",
      "          [-2.9204e-01, -1.5532e-01,        -inf,        -inf],\n",
      "          [-3.4260e-01, -3.4502e-01,        -inf,        -inf],\n",
      "          [-2.5071e-01, -3.3857e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.7022e-02, -3.6861e-01,        -inf,        -inf],\n",
      "          [ 1.8183e-01, -7.6768e-01,        -inf,        -inf],\n",
      "          [-2.5114e-01, -4.9097e-02,        -inf,        -inf],\n",
      "          [-1.1163e-02, -3.8479e-01,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 8.8269e-02,        -inf,        -inf,        -inf],\n",
      "          [ 3.1080e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.5472e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.0463e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-2.2167e-01,        -inf,        -inf,        -inf],\n",
      "          [ 5.1128e-02,        -inf,        -inf,        -inf],\n",
      "          [-5.3510e-02,        -inf,        -inf,        -inf],\n",
      "          [ 2.3764e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.0967e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.3249e-01,        -inf,        -inf,        -inf],\n",
      "          [ 6.5621e-02,        -inf,        -inf,        -inf],\n",
      "          [ 9.3752e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.0411e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.5604e-02,        -inf,        -inf,        -inf],\n",
      "          [ 2.2473e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.3357e-01,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5508, 0.4492, 0.0000, 0.0000],\n",
      "          [0.4745, 0.5255, 0.0000, 0.0000],\n",
      "          [0.6416, 0.3584, 0.0000, 0.0000],\n",
      "          [0.6945, 0.3055, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7210, 0.2790, 0.0000, 0.0000],\n",
      "          [0.4532, 0.5468, 0.0000, 0.0000],\n",
      "          [0.4989, 0.5011, 0.0000, 0.0000],\n",
      "          [0.5760, 0.4240, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5663, 0.4337, 0.0000, 0.0000],\n",
      "          [0.4659, 0.5341, 0.0000, 0.0000],\n",
      "          [0.5006, 0.4994, 0.0000, 0.0000],\n",
      "          [0.5220, 0.4780, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5976, 0.4024, 0.0000, 0.0000],\n",
      "          [0.7210, 0.2790, 0.0000, 0.0000],\n",
      "          [0.4497, 0.5503, 0.0000, 0.0000],\n",
      "          [0.5923, 0.4077, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1431, -0.2237,    -inf,    -inf,    -inf],\n",
      "          [-0.3004,  0.2529,    -inf,    -inf,    -inf],\n",
      "          [-0.3028,  0.2443,    -inf,    -inf,    -inf],\n",
      "          [-0.3517,  0.0329,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6530,  0.4125,    -inf,    -inf,    -inf],\n",
      "          [ 0.3309,  0.3708,    -inf,    -inf,    -inf],\n",
      "          [ 0.3349,  0.1811,    -inf,    -inf,    -inf],\n",
      "          [ 0.1950, -0.0097,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0288,  0.2852,    -inf,    -inf,    -inf],\n",
      "          [-0.1161,  0.1032,    -inf,    -inf,    -inf],\n",
      "          [-0.1972,  0.0850,    -inf,    -inf,    -inf],\n",
      "          [-0.0255,  0.2707,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0508, -0.1941,    -inf,    -inf,    -inf],\n",
      "          [-0.0563, -0.4226,    -inf,    -inf,    -inf],\n",
      "          [ 0.0614, -0.2535,    -inf,    -inf,    -inf],\n",
      "          [ 0.0881, -0.1768,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1759, -0.0640, -0.3543, -0.4201, -0.3486],\n",
      "          [-0.0470, -0.4207, -0.1523, -0.3141, -0.2387],\n",
      "          [-0.1834, -0.2861, -0.6136, -0.1094, -0.2879],\n",
      "          [ 0.2731,  0.0968, -0.2092,  0.0878, -0.0304]],\n",
      "\n",
      "         [[-0.5325, -0.3395,  0.1041,  0.3683,  0.0296],\n",
      "          [-0.1754, -0.3117,  0.2278, -0.4968,  0.2771],\n",
      "          [-0.3610, -0.5449, -0.2136, -0.4834,  0.5778],\n",
      "          [ 0.1660,  0.2230,  0.0561,  0.0067,  0.6567]],\n",
      "\n",
      "         [[ 0.0957,  0.3600,  0.1547, -0.2927, -0.2316],\n",
      "          [-0.0155,  0.2971,  0.2869, -0.0614, -0.2847],\n",
      "          [ 0.0175,  0.2945, -0.1517, -0.1999, -0.3468],\n",
      "          [-0.1879,  0.3508, -0.1199,  0.2754, -0.0116]],\n",
      "\n",
      "         [[-0.6337, -0.1264, -0.7395, -0.1114, -0.6307],\n",
      "          [ 0.1240,  0.2733, -0.4030, -0.1260,  0.2165],\n",
      "          [ 0.0572, -0.1465,  0.0050,  0.1906,  0.2905],\n",
      "          [ 0.0224,  0.2423, -0.6089, -0.2935, -0.0169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5868,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1282,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1749,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.4778,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6229,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3622,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3200,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2868,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2172,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4714,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.5563,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4345,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5605,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4365,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4066,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1119,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5907, 0.4093, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3651, 0.6349, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3666, 0.6334, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4050, 0.5950, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5598, 0.4402, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4900, 0.5100, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5384, 0.4616, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5510, 0.4490, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4362, 0.5638, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4454, 0.5546, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4299, 0.5701, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4265, 0.5735, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5358, 0.4642, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5906, 0.4094, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5781, 0.4219, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5658, 0.4342, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2842, 0.2236, 0.1673, 0.1566, 0.1682],\n",
      "          [0.2393, 0.1647, 0.2154, 0.1832, 0.1975],\n",
      "          [0.2207, 0.1992, 0.1436, 0.2377, 0.1988],\n",
      "          [0.2485, 0.2083, 0.1534, 0.2064, 0.1834]],\n",
      "\n",
      "         [[0.1202, 0.1458, 0.2272, 0.2959, 0.2109],\n",
      "          [0.1765, 0.1540, 0.2641, 0.1280, 0.2775],\n",
      "          [0.1555, 0.1293, 0.1802, 0.1375, 0.3975],\n",
      "          [0.1838, 0.1946, 0.1647, 0.1567, 0.3002]],\n",
      "\n",
      "         [[0.2100, 0.2735, 0.2227, 0.1424, 0.1514],\n",
      "          [0.1839, 0.2513, 0.2488, 0.1756, 0.1405],\n",
      "          [0.2145, 0.2829, 0.1811, 0.1726, 0.1490],\n",
      "          [0.1523, 0.2610, 0.1630, 0.2420, 0.1817]],\n",
      "\n",
      "         [[0.1600, 0.2658, 0.1439, 0.2698, 0.1605],\n",
      "          [0.2161, 0.2509, 0.1276, 0.1683, 0.2371],\n",
      "          [0.1934, 0.1578, 0.1836, 0.2210, 0.2442],\n",
      "          [0.2238, 0.2788, 0.1190, 0.1632, 0.2152]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1431,    -inf,    -inf,    -inf],\n",
      "          [ 0.2352,    -inf,    -inf,    -inf],\n",
      "          [ 0.1292,    -inf,    -inf,    -inf],\n",
      "          [-0.0475,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3238,    -inf,    -inf,    -inf],\n",
      "          [-0.4013,    -inf,    -inf,    -inf],\n",
      "          [-0.1500,    -inf,    -inf,    -inf],\n",
      "          [-0.6508,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1344,    -inf,    -inf,    -inf],\n",
      "          [ 0.1217,    -inf,    -inf,    -inf],\n",
      "          [ 0.3512,    -inf,    -inf,    -inf],\n",
      "          [ 0.3316,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1645,    -inf,    -inf,    -inf],\n",
      "          [-0.1295,    -inf,    -inf,    -inf],\n",
      "          [ 0.0759,    -inf,    -inf,    -inf],\n",
      "          [ 0.0084,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2120,  0.2941,    -inf,    -inf],\n",
      "          [ 0.0339, -0.0936,    -inf,    -inf],\n",
      "          [ 0.5144,  0.2952,    -inf,    -inf],\n",
      "          [ 0.2311, -0.1764,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5702, -0.6167,    -inf,    -inf],\n",
      "          [-0.3276, -0.2277,    -inf,    -inf],\n",
      "          [-0.8313, -0.4806,    -inf,    -inf],\n",
      "          [-0.3712, -0.5079,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1988,  0.2348,    -inf,    -inf],\n",
      "          [ 0.1219, -0.3371,    -inf,    -inf],\n",
      "          [-0.2228,  0.0913,    -inf,    -inf],\n",
      "          [-0.2764, -0.0282,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4969, -0.2424,    -inf,    -inf],\n",
      "          [ 0.4274, -0.0213,    -inf,    -inf],\n",
      "          [ 0.2902, -0.3126,    -inf,    -inf],\n",
      "          [-0.3140, -0.5247,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0238,    -inf,    -inf,    -inf],\n",
      "          [-0.6261,    -inf,    -inf,    -inf],\n",
      "          [-0.7876,    -inf,    -inf,    -inf],\n",
      "          [-0.6892,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.7023,    -inf,    -inf,    -inf],\n",
      "          [ 0.1315,    -inf,    -inf,    -inf],\n",
      "          [ 0.2096,    -inf,    -inf,    -inf],\n",
      "          [ 0.0459,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2158,    -inf,    -inf,    -inf],\n",
      "          [ 0.0853,    -inf,    -inf,    -inf],\n",
      "          [ 0.1654,    -inf,    -inf,    -inf],\n",
      "          [ 0.0940,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4217,    -inf,    -inf,    -inf],\n",
      "          [-0.1141,    -inf,    -inf,    -inf],\n",
      "          [ 0.0631,    -inf,    -inf,    -inf],\n",
      "          [-0.1540,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4795, 0.5205, 0.0000, 0.0000],\n",
      "          [0.5318, 0.4682, 0.0000, 0.0000],\n",
      "          [0.5546, 0.4454, 0.0000, 0.0000],\n",
      "          [0.6005, 0.3995, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5116, 0.4884, 0.0000, 0.0000],\n",
      "          [0.4750, 0.5250, 0.0000, 0.0000],\n",
      "          [0.4132, 0.5868, 0.0000, 0.0000],\n",
      "          [0.5341, 0.4659, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4910, 0.5090, 0.0000, 0.0000],\n",
      "          [0.6128, 0.3872, 0.0000, 0.0000],\n",
      "          [0.4221, 0.5779, 0.0000, 0.0000],\n",
      "          [0.4383, 0.5617, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4367, 0.5633, 0.0000, 0.0000],\n",
      "          [0.6103, 0.3897, 0.0000, 0.0000],\n",
      "          [0.6463, 0.3537, 0.0000, 0.0000],\n",
      "          [0.5525, 0.4475, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 7.5244e-01,  5.0196e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.2611e-01,  2.4028e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.4967e-01,  3.0015e-01,        -inf,        -inf,        -inf],\n",
      "          [ 9.6554e-02,  2.9837e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 8.2384e-02,  4.1182e-01,        -inf,        -inf,        -inf],\n",
      "          [ 5.8148e-01,  1.8408e-01,        -inf,        -inf,        -inf],\n",
      "          [ 6.4764e-01,  2.5457e-01,        -inf,        -inf,        -inf],\n",
      "          [ 7.5098e-01,  1.1798e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.1282e-01, -3.2642e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.8961e-01, -4.7038e-01,        -inf,        -inf,        -inf],\n",
      "          [-8.5823e-02, -4.7264e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.8431e-01, -5.6180e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-6.2899e-01,  1.0487e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.3100e-01,  3.2176e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.0045e-01,  4.3294e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.0836e-01,  4.7107e-01,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4205e-01,  6.2434e-02,  6.2552e-02, -2.6713e-01, -5.7642e-01],\n",
      "          [ 4.8206e-02, -6.8099e-02,  2.7993e-01,  2.4189e-01,  1.7754e-02],\n",
      "          [ 2.6099e-01,  1.4270e-01, -5.5076e-01, -2.2286e-02, -6.8213e-02],\n",
      "          [ 2.6352e-03,  3.3201e-01, -1.0645e-01, -2.2016e-01,  2.2052e-01]],\n",
      "\n",
      "         [[-2.9934e-01, -2.6090e-01, -3.3012e-01, -3.4163e-01, -2.5748e-01],\n",
      "          [-4.8653e-01, -1.2167e-01, -1.3767e-01,  1.7372e-01, -3.8076e-01],\n",
      "          [-1.6587e-01, -2.9872e-01, -1.4368e-01, -2.6355e-01,  1.5023e-02],\n",
      "          [ 2.7399e-02,  2.0208e-01,  5.7204e-02,  1.5500e-01,  2.0705e-01]],\n",
      "\n",
      "         [[-3.0014e-01,  1.4149e-01,  3.3794e-02, -1.5292e-01, -2.7355e-01],\n",
      "          [ 5.7822e-02,  3.0116e-01, -1.3369e-01,  3.0944e-01,  9.4244e-02],\n",
      "          [-2.1887e-04,  3.3598e-01, -9.8560e-02,  3.6078e-01, -3.0773e-01],\n",
      "          [ 3.9712e-01,  2.0483e-01,  1.0442e-02,  2.9567e-01, -8.2833e-03]],\n",
      "\n",
      "         [[-2.8256e-01, -3.1136e-01, -5.9820e-02, -1.3806e-01, -4.1428e-01],\n",
      "          [-2.0564e-01,  1.1417e-01,  2.7634e-01,  2.3710e-03,  1.5922e-01],\n",
      "          [-2.9172e-01,  5.8849e-01,  1.0854e-01,  7.0918e-02,  3.3973e-02],\n",
      "          [-4.9525e-02, -3.3998e-02,  5.6098e-01, -9.8203e-02,  1.4709e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4796e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.1140e-03,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 6.6628e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.1974e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.2158e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.9102e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-8.5287e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.4436e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.1300e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.6156e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.1661e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.8644e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.4120e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.4798e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 9.5140e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.9195e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5623, 0.4377, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4715, 0.5285, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5124, 0.4876, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4497, 0.5503, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4184, 0.5816, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5981, 0.4019, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5970, 0.4030, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6532, 0.3468, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6316, 0.3684, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5697, 0.4303, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5955, 0.4045, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5933, 0.4067, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3243, 0.6757, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5023, 0.4977, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4919, 0.5081, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4594, 0.5406, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2894, 0.2188, 0.2189, 0.1574, 0.1155],\n",
      "          [0.1875, 0.1669, 0.2363, 0.2275, 0.1818],\n",
      "          [0.2628, 0.2335, 0.1167, 0.1980, 0.1891],\n",
      "          [0.1876, 0.2608, 0.1682, 0.1501, 0.2333]],\n",
      "\n",
      "         [[0.1996, 0.2074, 0.1935, 0.1913, 0.2081],\n",
      "          [0.1448, 0.2086, 0.2053, 0.2803, 0.1610],\n",
      "          [0.1999, 0.1750, 0.2044, 0.1813, 0.2395],\n",
      "          [0.1800, 0.2144, 0.1855, 0.2046, 0.2155]],\n",
      "\n",
      "         [[0.1629, 0.2534, 0.2275, 0.1888, 0.1673],\n",
      "          [0.1844, 0.2351, 0.1522, 0.2371, 0.1912],\n",
      "          [0.1826, 0.2556, 0.1655, 0.2620, 0.1343],\n",
      "          [0.2454, 0.2025, 0.1667, 0.2217, 0.1636]],\n",
      "\n",
      "         [[0.1904, 0.1850, 0.2379, 0.2200, 0.1669],\n",
      "          [0.1500, 0.2065, 0.2429, 0.1847, 0.2160],\n",
      "          [0.1294, 0.3121, 0.1931, 0.1860, 0.1793],\n",
      "          [0.1659, 0.1685, 0.3055, 0.1580, 0.2020]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "output shape: torch.Size([3, 4, 100277])\n",
      "softmaxed[0, 0, :10]: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)\n",
      "predicted: \n",
      " tensor([[ 82681, 100257, 100257, 100257],\n",
      "        [    34,  17771,   6316,  17571],\n",
      "        [ 23380, 100257, 100257, 100257]])\n",
      "predicted decoded: \n",
      " ['Bonjour<|endoftext|><|endoftext|><|endoftext|>', \"C'est une phrase\", 'START<|endoftext|><|endoftext|><|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "sents = [\"Hello World\", \"This is a simple sentence\", \"Me\"]\n",
    "encoded_sents = [encoding.encode(s) for s in sents]\n",
    "enc_x = pad_sequence([torch.tensor(es) for es in encoded_sents], batch_first=True, padding_value=encoding.eot_token)\n",
    "print(enc_x)\n",
    "dec_sents = [\"Bonjour\", \"C'est une phrase\", \"START\"]\n",
    "dec_encoded_sents = [encoding.encode(s) for s in dec_sents]\n",
    "dec_x = pad_sequence([torch.tensor(es) for es in dec_encoded_sents], batch_first=True, padding_value=encoding.eot_token)\n",
    "print(dec_x)\n",
    "\n",
    "transformer = Transformer(vocab_size=encoding.n_vocab, n=3, d=256, h=4)\n",
    "\n",
    "enc_mask = build_padding_mask(enc_x, pad_token=100257)\n",
    "print(f\"enc_mask: \\n {enc_mask}\")\n",
    "enc_mask = reshape_mask(enc_mask)\n",
    "\n",
    "dec_mask1 = build_padding_mask(dec_x, pad_token=100257)\n",
    "dec_mask2 = build_causal_mask(dec_x)\n",
    "dec_mask = merge_masks(dec_mask1, dec_mask2)\n",
    "print(f\"dec_mask: \\n {dec_mask}\")\n",
    "dec_mask = reshape_mask(dec_mask)\n",
    "\n",
    "output = transformer(enc_x, dec_x, enc_mask=enc_mask, dec_mask=dec_mask)\n",
    "print(f\"output shape: {output.shape}\")\n",
    "softmaxed = F.softmax(output, dim=-1)\n",
    "print(f\"softmaxed[0, 0, :10]: {softmaxed[0, 0, :10]}\")\n",
    "predicted = softmaxed.argmax(dim=-1)\n",
    "print(f\"predicted: \\n {predicted}\")\n",
    "\n",
    "predicted_list = predicted.tolist()\n",
    "predicted_decoded = [encoding.decode(l) for l in predicted_list]\n",
    "print(f\"predicted decoded: \\n {predicted_decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf3a2346-9e74-4eab-aab3-bd5bb0a0d78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000001192092896"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.3]]), dim=-1)\n",
    "torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.4]]).argmax(dim=-1)\n",
    "# torch.max(torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.4]]), dim=-1)\n",
    "\n",
    "t1 = torch.tensor([[0.1, 0.2]])\n",
    "t2 = torch.tensor([[0.3]])\n",
    "torch.cat((t1, t2), dim=1).tolist()[-1][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "693b16e4-6684-4dbb-b21b-8c3650a10bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 7.9512e-01,  9.0694e-01,  4.5273e-01, -3.0508e-01, -3.6818e-01],\n",
      "          [ 4.1684e-01,  4.8840e-01,  4.2983e-01, -8.7179e-02, -5.3285e-02],\n",
      "          [ 9.3448e-01,  3.5573e-04, -1.9414e-02,  6.3703e-01, -4.1700e-01],\n",
      "          [ 2.8722e-02,  7.6172e-01, -9.0842e-02, -1.7895e-01,  5.8761e-01],\n",
      "          [-5.0746e-01,  1.9543e-01, -2.0671e-01, -1.4951e-01, -5.1422e-01]],\n",
      "\n",
      "         [[ 2.5287e-01,  8.4620e-03, -2.4208e-01, -1.3033e-01,  7.7651e-01],\n",
      "          [-8.5219e-01,  1.9928e-02, -6.2521e-01,  8.4488e-02, -7.2770e-01],\n",
      "          [ 5.0926e-01,  5.2909e-01,  5.9945e-01,  3.4674e-01,  1.4391e+00],\n",
      "          [ 6.4368e-01,  4.1816e-01,  4.9041e-01, -2.7250e-01,  4.0249e-01],\n",
      "          [-2.5678e-01,  2.8006e-01,  5.6157e-01,  9.0215e-01,  3.0465e-01]],\n",
      "\n",
      "         [[-1.2031e+00, -1.2954e+00, -8.8688e-01,  7.7508e-03, -7.1005e-01],\n",
      "          [-8.4900e-01, -1.1717e+00, -7.0141e-01, -1.9813e-01, -5.9729e-01],\n",
      "          [-1.1592e+00, -1.1231e+00, -9.7892e-01,  1.1179e-02,  8.2838e-01],\n",
      "          [-8.7891e-01, -1.7830e+00, -7.9189e-01, -1.7119e-01,  1.3152e-01],\n",
      "          [-8.5351e-01, -1.2949e+00, -7.0102e-01, -1.6148e-01,  1.9335e-01]],\n",
      "\n",
      "         [[ 3.6025e-01, -9.4185e-01,  5.7655e-01,  3.7265e-01,  2.2513e-01],\n",
      "          [ 1.0987e+00, -9.2501e-01, -4.7087e-01,  7.9312e-01,  4.6434e-01],\n",
      "          [-5.0897e-02, -1.1926e+00, -5.0411e-01,  5.4087e-01,  2.4363e-01],\n",
      "          [ 7.7305e-02,  1.1124e-01, -1.7816e-01,  8.7421e-02,  1.6034e-01],\n",
      "          [-2.2152e-01, -8.4076e-01, -9.1814e-01,  2.0658e-01,  2.0893e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2879, 0.3219, 0.2044, 0.0958, 0.0900],\n",
      "          [0.2317, 0.2489, 0.2347, 0.1400, 0.1448],\n",
      "          [0.3597, 0.1414, 0.1386, 0.2672, 0.0931],\n",
      "          [0.1531, 0.3187, 0.1359, 0.1244, 0.2678],\n",
      "          [0.1472, 0.2973, 0.1988, 0.2105, 0.1462]],\n",
      "\n",
      "         [[0.2100, 0.1644, 0.1280, 0.1431, 0.3545],\n",
      "          [0.1200, 0.2871, 0.1506, 0.3063, 0.1359],\n",
      "          [0.1539, 0.1570, 0.1684, 0.1308, 0.3899],\n",
      "          [0.2603, 0.2077, 0.2233, 0.1041, 0.2045],\n",
      "          [0.1008, 0.1725, 0.2286, 0.3213, 0.1768]],\n",
      "\n",
      "         [[0.1208, 0.1102, 0.1657, 0.4055, 0.1978],\n",
      "          [0.1643, 0.1190, 0.1904, 0.3150, 0.2113],\n",
      "          [0.0727, 0.0754, 0.0871, 0.2343, 0.5305],\n",
      "          [0.1375, 0.0557, 0.1500, 0.2791, 0.3777],\n",
      "          [0.1306, 0.0840, 0.1522, 0.2610, 0.3722]],\n",
      "\n",
      "         [[0.2273, 0.0618, 0.2822, 0.2301, 0.1986],\n",
      "          [0.3836, 0.0507, 0.0798, 0.2825, 0.2034],\n",
      "          [0.1959, 0.0625, 0.1245, 0.3540, 0.2630],\n",
      "          [0.2038, 0.2109, 0.1579, 0.2059, 0.2215],\n",
      "          [0.1957, 0.1054, 0.0975, 0.3003, 0.3010]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2597, -0.4691, -0.0352,  0.1627, -0.1964],\n",
      "          [ 0.3285, -0.8873, -0.3934, -0.0452, -0.2496],\n",
      "          [ 0.4946,  0.1020,  0.2553,  0.4328,  0.9139],\n",
      "          [ 0.4200, -0.2146, -0.3109,  0.1026,  0.0187],\n",
      "          [ 0.5746,  0.0612,  0.3608,  0.2572,  0.3841]],\n",
      "\n",
      "         [[ 0.2497,  0.4227,  0.4473,  0.1293,  1.1858],\n",
      "          [ 0.5127,  0.4775, -0.2422, -0.1188,  0.8689],\n",
      "          [ 0.4338,  0.4472,  0.1344,  0.7382,  0.3513],\n",
      "          [ 0.0810, -0.0951,  0.1082,  0.1983,  0.4797],\n",
      "          [ 0.5019,  0.5382,  0.5460, -0.3726,  0.0884]],\n",
      "\n",
      "         [[-0.7329, -0.4790, -0.0600,  0.2234,  0.2478],\n",
      "          [-0.7930,  0.2118,  0.1313, -0.2034, -0.2170],\n",
      "          [-0.6172, -0.0381,  0.1673,  0.1711,  0.1243],\n",
      "          [ 0.3632, -0.2899,  0.1818, -0.1321, -0.0343],\n",
      "          [-0.2634, -0.0323, -0.2297,  0.0687, -0.1390]],\n",
      "\n",
      "         [[-0.1863, -0.5908, -0.2180, -0.0474,  0.2113],\n",
      "          [-0.1560, -0.0091,  0.2167, -0.0561, -0.3259],\n",
      "          [-0.3304,  0.3813, -0.3948,  0.1691,  0.1599],\n",
      "          [ 0.0512, -0.4627, -0.1354, -0.1533, -0.0735],\n",
      "          [ 0.0472, -0.1794, -0.2544, -0.2164, -0.3654]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2654, 0.1280, 0.1976, 0.2408, 0.1682],\n",
      "          [0.3299, 0.0978, 0.1603, 0.2270, 0.1851],\n",
      "          [0.2031, 0.1372, 0.1599, 0.1909, 0.3089],\n",
      "          [0.2933, 0.1555, 0.1412, 0.2136, 0.1964],\n",
      "          [0.2525, 0.1511, 0.2039, 0.1838, 0.2087]],\n",
      "\n",
      "         [[0.1461, 0.1737, 0.1780, 0.1295, 0.3726],\n",
      "          [0.2275, 0.2196, 0.1070, 0.1210, 0.3249],\n",
      "          [0.1988, 0.2014, 0.1473, 0.2695, 0.1830],\n",
      "          [0.1825, 0.1530, 0.1875, 0.2052, 0.2718],\n",
      "          [0.2404, 0.2492, 0.2512, 0.1002, 0.1590]],\n",
      "\n",
      "         [[0.1051, 0.1354, 0.2059, 0.2734, 0.2802],\n",
      "          [0.1017, 0.2778, 0.2563, 0.1834, 0.1809],\n",
      "          [0.1078, 0.1924, 0.2363, 0.2372, 0.2263],\n",
      "          [0.2750, 0.1431, 0.2294, 0.1676, 0.1848],\n",
      "          [0.1718, 0.2165, 0.1777, 0.2395, 0.1946]],\n",
      "\n",
      "         [[0.1896, 0.1265, 0.1837, 0.2179, 0.2822],\n",
      "          [0.1799, 0.2084, 0.2611, 0.1988, 0.1518],\n",
      "          [0.1378, 0.2808, 0.1292, 0.2271, 0.2250],\n",
      "          [0.2424, 0.1450, 0.2011, 0.1975, 0.2140],\n",
      "          [0.2521, 0.2010, 0.1864, 0.1937, 0.1669]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0376, -0.0123, -0.3749, -0.4994,  0.0941],\n",
      "          [-0.1349, -0.0861, -0.5547,  0.2506,  0.1048],\n",
      "          [ 0.1409,  0.5151,  0.4076,  0.4346,  0.7367],\n",
      "          [ 0.6477,  0.2437,  0.0520, -0.6662, -0.0537],\n",
      "          [ 0.0242,  0.0437, -0.0494, -0.1176,  0.2126]],\n",
      "\n",
      "         [[-0.4766,  0.1543, -0.2105, -0.2830, -0.2162],\n",
      "          [-0.4654,  0.3510, -0.0980, -0.3699, -0.1792],\n",
      "          [ 0.1620,  0.3211,  0.4027,  0.1850, -0.1982],\n",
      "          [ 0.0164,  0.4298, -0.2703,  0.2060,  0.0838],\n",
      "          [-0.1285,  0.1538, -0.2051, -0.9050, -0.4289]],\n",
      "\n",
      "         [[-0.4807,  0.5632,  0.4060, -0.1970, -0.0084],\n",
      "          [-0.2732, -0.4707, -0.1491, -0.4274,  0.0601],\n",
      "          [-0.4601,  0.4349, -0.1675,  0.1612, -0.1633],\n",
      "          [-0.0492, -0.0087, -0.3633, -0.5347, -0.0789],\n",
      "          [ 0.0801,  0.1667, -0.1957, -0.3086, -0.3058]],\n",
      "\n",
      "         [[-0.1894, -0.3509,  0.2965,  0.2844, -0.2953],\n",
      "          [-0.2243,  0.2468,  0.0712,  0.4638,  0.3075],\n",
      "          [-0.2347, -0.3567, -0.0244,  0.2883, -0.5046],\n",
      "          [ 0.2798,  0.4850, -0.1369,  0.1138, -0.0932],\n",
      "          [ 0.5857,  0.5670, -0.0184,  0.2162, -0.1310]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2350, 0.2235, 0.1555, 0.1373, 0.2486],\n",
      "          [0.1835, 0.1927, 0.1206, 0.2699, 0.2333],\n",
      "          [0.1446, 0.2102, 0.1888, 0.1940, 0.2624],\n",
      "          [0.3352, 0.2238, 0.1847, 0.0901, 0.1662],\n",
      "          [0.1991, 0.2030, 0.1849, 0.1727, 0.2403]],\n",
      "\n",
      "         [[0.1494, 0.2807, 0.1949, 0.1813, 0.1938],\n",
      "          [0.1401, 0.3170, 0.2023, 0.1541, 0.1865],\n",
      "          [0.1936, 0.2270, 0.2463, 0.1981, 0.1350],\n",
      "          [0.1805, 0.2729, 0.1355, 0.2181, 0.1931],\n",
      "          [0.2246, 0.2978, 0.2080, 0.1033, 0.1663]],\n",
      "\n",
      "         [[0.1087, 0.3088, 0.2638, 0.1444, 0.1743],\n",
      "          [0.1921, 0.1577, 0.2175, 0.1647, 0.2681],\n",
      "          [0.1251, 0.3061, 0.1676, 0.2328, 0.1683],\n",
      "          [0.2295, 0.2390, 0.1676, 0.1412, 0.2228],\n",
      "          [0.2377, 0.2592, 0.1804, 0.1611, 0.1616]],\n",
      "\n",
      "         [[0.1672, 0.1422, 0.2717, 0.2685, 0.1504],\n",
      "          [0.1309, 0.2097, 0.1760, 0.2605, 0.2228],\n",
      "          [0.1795, 0.1589, 0.2216, 0.3029, 0.1371],\n",
      "          [0.2261, 0.2776, 0.1491, 0.1915, 0.1557],\n",
      "          [0.2697, 0.2647, 0.1474, 0.1864, 0.1317]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0556]],\n",
      "\n",
      "         [[-0.1362]],\n",
      "\n",
      "         [[ 0.1129]],\n",
      "\n",
      "         [[-0.1383]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.4062, -0.5080,  0.4073, -0.3529,  0.2527]],\n",
      "\n",
      "         [[-0.2544, -0.2286, -0.3848,  0.5021, -0.2595]],\n",
      "\n",
      "         [[ 0.5697, -0.4484, -0.4204,  0.3137, -0.0069]],\n",
      "\n",
      "         [[-0.0909, -0.0234,  0.5455,  0.0053,  0.0610]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1399, 0.1264, 0.3157, 0.1476, 0.2704]],\n",
      "\n",
      "         [[0.1658, 0.1702, 0.1456, 0.3534, 0.1650]],\n",
      "\n",
      "         [[0.3259, 0.1177, 0.1211, 0.2523, 0.1831]],\n",
      "\n",
      "         [[0.1607, 0.1719, 0.3036, 0.1769, 0.1870]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2450]],\n",
      "\n",
      "         [[ 0.0205]],\n",
      "\n",
      "         [[ 0.4695]],\n",
      "\n",
      "         [[ 0.4745]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3935, -0.0950, -0.2599, -0.4502, -0.0362]],\n",
      "\n",
      "         [[-0.0913,  0.0263,  0.1421,  0.1113,  0.2279]],\n",
      "\n",
      "         [[ 0.0787,  0.0836, -0.0275,  0.0275,  0.6552]],\n",
      "\n",
      "         [[ 0.2816, -0.2942,  0.0486,  0.5016,  0.0911]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3111, 0.1909, 0.1618, 0.1338, 0.2024]],\n",
      "\n",
      "         [[0.1670, 0.1878, 0.2109, 0.2045, 0.2298]],\n",
      "\n",
      "         [[0.1775, 0.1784, 0.1596, 0.1686, 0.3159]],\n",
      "\n",
      "         [[0.2259, 0.1270, 0.1789, 0.2815, 0.1867]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0883]],\n",
      "\n",
      "         [[-0.0138]],\n",
      "\n",
      "         [[ 0.7535]],\n",
      "\n",
      "         [[ 0.0058]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4593,  0.4696,  0.0568,  0.5535,  0.3169]],\n",
      "\n",
      "         [[-0.3739, -0.7598, -0.3804, -0.2403, -0.3416]],\n",
      "\n",
      "         [[ 0.0968,  0.0383, -0.4568, -0.0376, -0.0625]],\n",
      "\n",
      "         [[-0.0274, -0.1832,  0.0291,  0.2679, -0.1101]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2153, 0.2175, 0.1439, 0.2366, 0.1867]],\n",
      "\n",
      "         [[0.2062, 0.1402, 0.2049, 0.2357, 0.2130]],\n",
      "\n",
      "         [[0.2356, 0.2222, 0.1354, 0.2059, 0.2009]],\n",
      "\n",
      "         [[0.1931, 0.1653, 0.2043, 0.2595, 0.1778]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.3440,  0.3800,  0.2025,  0.0111, -0.7145],\n",
      "          [ 0.1684, -0.0591,  0.4435, -0.3482,  0.3666],\n",
      "          [ 0.5677, -0.4216, -0.2136,  0.2689, -0.4664],\n",
      "          [ 0.3344,  0.3763,  0.2038, -0.0766,  0.1241],\n",
      "          [-0.4346,  0.4757, -0.4686, -0.2402, -0.0447]],\n",
      "\n",
      "         [[ 0.2370, -0.0580, -0.2991,  0.2838,  0.5475],\n",
      "          [-0.6902,  0.2364, -0.6241, -0.3945, -0.8529],\n",
      "          [ 0.3911,  0.3980,  0.5597,  0.8346,  1.1486],\n",
      "          [ 0.1640,  0.2132,  0.3753, -0.1396,  0.1703],\n",
      "          [-0.1600,  0.5292,  1.1118,  0.0936,  0.1930]],\n",
      "\n",
      "         [[-1.2810, -1.2427, -0.4997, -0.1550, -0.6315],\n",
      "          [-0.9919, -1.2724, -0.2775, -0.4725, -0.3750],\n",
      "          [-1.4380, -0.9813, -0.9017, -0.2521,  0.6730],\n",
      "          [-0.9413, -1.6071, -0.4360, -0.3657,  0.2335],\n",
      "          [-0.5456, -1.3361,  0.0805,  0.1245,  0.2226]],\n",
      "\n",
      "         [[ 0.3716, -0.6567,  0.5639,  0.2695,  0.4257],\n",
      "          [ 1.2333, -0.5406, -0.8125,  0.5359,  0.5504],\n",
      "          [-0.1637, -1.1636, -0.2826,  0.0981,  0.3584],\n",
      "          [-0.3321, -0.2844, -0.6650, -0.4126,  0.4299],\n",
      "          [-0.0369, -1.1532, -1.0481,  0.3962,  0.2285]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4780, 0.1823, 0.1526, 0.1260, 0.0610],\n",
      "          [0.2029, 0.1616, 0.2671, 0.1210, 0.2474],\n",
      "          [0.3417, 0.1270, 0.1564, 0.2534, 0.1215],\n",
      "          [0.2276, 0.2373, 0.1997, 0.1509, 0.1844],\n",
      "          [0.1400, 0.3479, 0.1353, 0.1700, 0.2068]],\n",
      "\n",
      "         [[0.2109, 0.1570, 0.1234, 0.2210, 0.2877],\n",
      "          [0.1473, 0.3721, 0.1574, 0.1980, 0.1252],\n",
      "          [0.1453, 0.1463, 0.1720, 0.2264, 0.3099],\n",
      "          [0.1988, 0.2088, 0.2456, 0.1467, 0.2001],\n",
      "          [0.1079, 0.2149, 0.3848, 0.1390, 0.1535]],\n",
      "\n",
      "         [[0.1084, 0.1127, 0.2369, 0.3344, 0.2076],\n",
      "          [0.1364, 0.1030, 0.2786, 0.2292, 0.2527],\n",
      "          [0.0632, 0.0998, 0.1081, 0.2070, 0.5220],\n",
      "          [0.1221, 0.0628, 0.2025, 0.2172, 0.3954],\n",
      "          [0.1345, 0.0610, 0.2516, 0.2629, 0.2900]],\n",
      "\n",
      "         [[0.2208, 0.0790, 0.2677, 0.1994, 0.2331],\n",
      "          [0.4344, 0.0737, 0.0562, 0.2163, 0.2194],\n",
      "          [0.1908, 0.0702, 0.1694, 0.2479, 0.3216],\n",
      "          [0.1715, 0.1799, 0.1229, 0.1582, 0.3674],\n",
      "          [0.2204, 0.0722, 0.0802, 0.3399, 0.2874]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4549,  0.0975, -0.0999,  0.4081,  0.0210],\n",
      "          [ 0.4143, -0.3438, -0.5115,  0.1556, -0.2456],\n",
      "          [ 0.5593, -0.0194,  0.3772,  0.3897,  0.5360],\n",
      "          [ 0.2253, -0.5012, -0.3941, -0.0205,  0.0803],\n",
      "          [ 0.4990,  0.0520,  0.4340,  0.1428,  0.4468]],\n",
      "\n",
      "         [[ 0.1468,  0.7022,  0.3698,  0.1395,  1.0714],\n",
      "          [ 0.1498,  0.7288, -0.4742, -0.0588,  0.8663],\n",
      "          [ 0.3392,  0.6904, -0.0296,  0.6364,  0.6494],\n",
      "          [ 0.0174,  0.2816,  0.1273,  0.0925,  0.6881],\n",
      "          [ 0.0348,  0.6850,  0.2893, -0.2076,  0.1735]],\n",
      "\n",
      "         [[-0.5508, -0.5468, -0.1017, -0.0637,  0.4813],\n",
      "          [-0.6675,  0.2028,  0.4273, -0.6922, -0.1767],\n",
      "          [-0.7338, -0.0227,  0.1599, -0.1401,  0.5772],\n",
      "          [ 0.2313, -0.5867,  0.2696, -0.1451, -0.1565],\n",
      "          [-0.3988, -0.4678, -0.1374, -0.0955, -0.0904]],\n",
      "\n",
      "         [[-0.0251, -0.4812, -0.0252, -0.1405,  0.5455],\n",
      "          [ 0.0962,  0.0964,  0.1712, -0.0864, -0.1171],\n",
      "          [ 0.1814,  0.2499, -0.0512,  0.2938,  0.2942],\n",
      "          [-0.1018, -0.3274, -0.3225, -0.5040,  0.0292],\n",
      "          [-0.1514, -0.3255, -0.1700, -0.5049, -0.3573]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2580, 0.1805, 0.1481, 0.2462, 0.1672],\n",
      "          [0.3171, 0.1486, 0.1256, 0.2448, 0.1639],\n",
      "          [0.2372, 0.1330, 0.1977, 0.2002, 0.2318],\n",
      "          [0.2726, 0.1318, 0.1467, 0.2132, 0.2358],\n",
      "          [0.2366, 0.1513, 0.2217, 0.1657, 0.2246]],\n",
      "\n",
      "         [[0.1332, 0.2322, 0.1665, 0.1323, 0.3358],\n",
      "          [0.1618, 0.2888, 0.0867, 0.1314, 0.3313],\n",
      "          [0.1718, 0.2440, 0.1188, 0.2312, 0.2342],\n",
      "          [0.1550, 0.2018, 0.1730, 0.1671, 0.3031],\n",
      "          [0.1629, 0.3121, 0.2101, 0.1278, 0.1871]],\n",
      "\n",
      "         [[0.1249, 0.1254, 0.1957, 0.2033, 0.3506],\n",
      "          [0.1113, 0.2657, 0.3326, 0.1086, 0.1818],\n",
      "          [0.0909, 0.1851, 0.2222, 0.1646, 0.3372],\n",
      "          [0.2601, 0.1148, 0.2702, 0.1785, 0.1765],\n",
      "          [0.1681, 0.1569, 0.2184, 0.2277, 0.2289]],\n",
      "\n",
      "         [[0.1889, 0.1197, 0.1889, 0.1683, 0.3342],\n",
      "          [0.2119, 0.2119, 0.2284, 0.1765, 0.1712],\n",
      "          [0.1960, 0.2099, 0.1553, 0.2193, 0.2194],\n",
      "          [0.2268, 0.1810, 0.1819, 0.1517, 0.2586],\n",
      "          [0.2305, 0.1937, 0.2263, 0.1619, 0.1876]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2849,  0.2468, -0.0813, -0.3261,  0.3341],\n",
      "          [-0.1008, -0.1197, -0.4637,  0.2022,  0.1964],\n",
      "          [ 0.2049,  0.4761,  0.3694,  0.4713,  0.8096],\n",
      "          [ 0.2815, -0.1401,  0.2820, -0.7001,  0.0770],\n",
      "          [ 0.3119,  0.0600, -0.1023, -0.1836,  0.3554]],\n",
      "\n",
      "         [[-0.1148,  0.2262,  0.0670,  0.0289, -0.0612],\n",
      "          [-0.5514,  0.1556, -0.3985, -0.3227, -0.2744],\n",
      "          [ 0.2227,  0.2845,  0.4673,  0.0849, -0.2228],\n",
      "          [ 0.0208,  0.6458, -0.3922,  0.0145,  0.1546],\n",
      "          [ 0.3405,  0.3393, -0.1205, -0.4351,  0.1213]],\n",
      "\n",
      "         [[-0.0286,  0.2612,  0.1246, -0.1349, -0.1008],\n",
      "          [-0.0404, -0.4100, -0.2844, -0.4842, -0.2945],\n",
      "          [-0.3823,  0.0948, -0.2421, -0.0633, -0.3779],\n",
      "          [-0.0575,  0.0265, -0.2220, -0.7766, -0.0951],\n",
      "          [ 0.1452, -0.0315, -0.2081, -0.5204, -0.5824]],\n",
      "\n",
      "         [[-0.1058, -0.6592,  0.2167, -0.1752, -0.2424],\n",
      "          [-0.1210, -0.0323,  0.2946,  0.0807,  0.3437],\n",
      "          [ 0.0405, -0.6165, -0.1714,  0.2002, -0.1321],\n",
      "          [-0.1429,  0.0621, -0.1872,  0.0625,  0.0679],\n",
      "          [ 0.5307,  0.5654,  0.3586,  0.2372,  0.3233]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2353, 0.2265, 0.1632, 0.1277, 0.2472],\n",
      "          [0.1860, 0.1825, 0.1294, 0.2518, 0.2503],\n",
      "          [0.1509, 0.1979, 0.1779, 0.1970, 0.2763],\n",
      "          [0.2600, 0.1706, 0.2601, 0.0974, 0.2119],\n",
      "          [0.2444, 0.1900, 0.1615, 0.1489, 0.2552]],\n",
      "\n",
      "         [[0.1720, 0.2418, 0.2062, 0.1985, 0.1814],\n",
      "          [0.1477, 0.2996, 0.1721, 0.1857, 0.1949],\n",
      "          [0.2061, 0.2192, 0.2632, 0.1795, 0.1320],\n",
      "          [0.1765, 0.3297, 0.1168, 0.1754, 0.2017],\n",
      "          [0.2569, 0.2566, 0.1620, 0.1183, 0.2063]],\n",
      "\n",
      "         [[0.1876, 0.2506, 0.2186, 0.1687, 0.1745],\n",
      "          [0.2570, 0.1776, 0.2013, 0.1649, 0.1993],\n",
      "          [0.1628, 0.2624, 0.1873, 0.2240, 0.1635],\n",
      "          [0.2280, 0.2480, 0.1934, 0.1111, 0.2196],\n",
      "          [0.2827, 0.2369, 0.1986, 0.1453, 0.1366]],\n",
      "\n",
      "         [[0.2100, 0.1208, 0.2900, 0.1960, 0.1832],\n",
      "          [0.1557, 0.1701, 0.2359, 0.1905, 0.2478],\n",
      "          [0.2303, 0.1194, 0.1863, 0.2702, 0.1938],\n",
      "          [0.1771, 0.2174, 0.1694, 0.2175, 0.2186],\n",
      "          [0.2255, 0.2334, 0.1898, 0.1681, 0.1832]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2213, -0.0219],\n",
      "          [-0.4012, -0.2362]],\n",
      "\n",
      "         [[ 0.5845,  0.8986],\n",
      "          [ 0.4825,  0.7732]],\n",
      "\n",
      "         [[-0.3678,  0.1926],\n",
      "          [ 0.1156,  0.5057]],\n",
      "\n",
      "         [[-0.0062, -0.1699],\n",
      "          [ 0.2165, -0.0336]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4503, 0.5497],\n",
      "          [0.4588, 0.5412]],\n",
      "\n",
      "         [[0.4221, 0.5779],\n",
      "          [0.4278, 0.5722]],\n",
      "\n",
      "         [[0.3635, 0.6365],\n",
      "          [0.4037, 0.5963]],\n",
      "\n",
      "         [[0.5408, 0.4592],\n",
      "          [0.5622, 0.4378]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.7399, -0.2569,  0.6264, -0.4573, -0.1082],\n",
      "          [-0.8343, -0.1029,  0.6399, -0.4274, -0.1149]],\n",
      "\n",
      "         [[ 0.0380, -0.0015, -0.3530,  0.4459, -0.2801],\n",
      "          [ 0.1356, -0.1748, -0.1877,  0.8396, -0.0588]],\n",
      "\n",
      "         [[ 0.0750, -0.2117, -0.1630,  0.3115,  0.0594],\n",
      "          [ 0.1797, -0.1188, -0.4353,  0.1589, -0.0705]],\n",
      "\n",
      "         [[-0.0372,  0.1930,  0.3973,  0.0726,  0.4755],\n",
      "          [ 0.1924,  0.0581,  0.7072, -0.0820,  0.4373]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1026, 0.1663, 0.4022, 0.1361, 0.1929],\n",
      "          [0.0909, 0.1889, 0.3970, 0.1365, 0.1866]],\n",
      "\n",
      "         [[0.2054, 0.1974, 0.1389, 0.3088, 0.1494],\n",
      "          [0.1886, 0.1383, 0.1365, 0.3813, 0.1553]],\n",
      "\n",
      "         [[0.2088, 0.1567, 0.1645, 0.2645, 0.2055],\n",
      "          [0.2475, 0.1836, 0.1338, 0.2424, 0.1927]],\n",
      "\n",
      "         [[0.1518, 0.1911, 0.2344, 0.1694, 0.2534],\n",
      "          [0.1790, 0.1565, 0.2996, 0.1361, 0.2287]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3619,  0.4230],\n",
      "          [ 0.1245,  0.1860]],\n",
      "\n",
      "         [[-0.0814,  0.2469],\n",
      "          [-0.2308,  0.2826]],\n",
      "\n",
      "         [[ 0.5746,  0.5666],\n",
      "          [ 0.8118,  0.7302]],\n",
      "\n",
      "         [[-0.3283, -0.5365],\n",
      "          [-0.0032, -0.1392]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4847, 0.5153],\n",
      "          [0.4846, 0.5154]],\n",
      "\n",
      "         [[0.4187, 0.5813],\n",
      "          [0.3744, 0.6256]],\n",
      "\n",
      "         [[0.5020, 0.4980],\n",
      "          [0.5204, 0.4796]],\n",
      "\n",
      "         [[0.5519, 0.4481],\n",
      "          [0.5339, 0.4661]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4272, -0.0074,  0.2205, -0.5688,  0.4683],\n",
      "          [ 0.2397, -0.3488, -0.2762, -0.6806, -0.0800]],\n",
      "\n",
      "         [[ 0.0892,  0.1896,  0.3127,  0.1356,  0.0141],\n",
      "          [-0.1253,  0.1372,  0.2634,  0.0665,  0.1042]],\n",
      "\n",
      "         [[ 0.2978,  0.0461,  0.3781, -0.8360, -0.1091],\n",
      "          [ 0.3766, -0.1031,  0.3328, -0.4477,  0.0619]],\n",
      "\n",
      "         [[ 0.3465, -0.1865, -0.1574,  0.6263,  0.2690],\n",
      "          [ 0.3529, -0.2191,  0.0208,  0.4690,  0.3941]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2582, 0.1672, 0.2100, 0.0954, 0.2691],\n",
      "          [0.3052, 0.1694, 0.1822, 0.1216, 0.2217]],\n",
      "\n",
      "         [[0.1876, 0.2074, 0.2346, 0.1965, 0.1740],\n",
      "          [0.1601, 0.2082, 0.2362, 0.1940, 0.2014]],\n",
      "\n",
      "         [[0.2598, 0.2020, 0.2816, 0.0836, 0.1730],\n",
      "          [0.2671, 0.1653, 0.2556, 0.1171, 0.1949]],\n",
      "\n",
      "         [[0.2253, 0.1322, 0.1361, 0.2980, 0.2085],\n",
      "          [0.2249, 0.1269, 0.1613, 0.2526, 0.2343]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0947, -0.1955],\n",
      "          [-0.0614, -0.0768]],\n",
      "\n",
      "         [[ 0.4017,  0.2102],\n",
      "          [ 0.5977,  0.3830]],\n",
      "\n",
      "         [[ 0.6022,  0.3587],\n",
      "          [ 0.6399,  0.3723]],\n",
      "\n",
      "         [[ 0.1243,  0.0128],\n",
      "          [ 0.3850,  0.1997]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5252, 0.4748],\n",
      "          [0.5039, 0.4961]],\n",
      "\n",
      "         [[0.5477, 0.4523],\n",
      "          [0.5535, 0.4465]],\n",
      "\n",
      "         [[0.5606, 0.4394],\n",
      "          [0.5665, 0.4335]],\n",
      "\n",
      "         [[0.5278, 0.4722],\n",
      "          [0.5462, 0.4538]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3682,  0.1079, -0.2293,  0.4206,  0.2617],\n",
      "          [ 0.4350,  0.0308, -0.2903,  0.5274,  0.6168]],\n",
      "\n",
      "         [[-0.5323, -0.7889, -0.2900, -0.4529, -0.2618],\n",
      "          [-0.6300, -0.7904, -0.2658, -0.4043, -0.5274]],\n",
      "\n",
      "         [[-0.2203, -0.1600, -0.1822, -0.0099, -0.0610],\n",
      "          [-0.1631, -0.0939, -0.2866,  0.0140,  0.0033]],\n",
      "\n",
      "         [[-0.1269, -0.1473,  0.1528,  0.4668, -0.1328],\n",
      "          [-0.0829, -0.0348,  0.1901,  0.3579,  0.0821]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2340, 0.1804, 0.1287, 0.2466, 0.2103],\n",
      "          [0.2248, 0.1501, 0.1089, 0.2466, 0.2696]],\n",
      "\n",
      "         [[0.1838, 0.1422, 0.2342, 0.1990, 0.2409],\n",
      "          [0.1769, 0.1507, 0.2546, 0.2217, 0.1960]],\n",
      "\n",
      "         [[0.1816, 0.1928, 0.1886, 0.2241, 0.2129],\n",
      "          [0.1876, 0.2011, 0.1658, 0.2240, 0.2216]],\n",
      "\n",
      "         [[0.1637, 0.1604, 0.2166, 0.2965, 0.1628],\n",
      "          [0.1640, 0.1721, 0.2155, 0.2549, 0.1935]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.9089,  0.5534, -0.2199, -0.0487, -0.8198],\n",
      "          [-0.1848, -0.2089, -0.0304, -0.4517, -0.4832],\n",
      "          [ 0.6173, -0.3150,  0.1901,  0.8200,  0.3097],\n",
      "          [ 0.4027,  1.1126,  0.0391, -0.1029,  0.0033],\n",
      "          [-0.5568,  0.2535, -0.2541, -0.5591, -0.9289]],\n",
      "\n",
      "         [[ 0.2048, -0.2452,  0.0287,  0.3952,  0.2988],\n",
      "          [-0.8468, -0.0228, -0.5031, -0.0862, -0.8016],\n",
      "          [ 0.5210,  0.2613,  0.5350,  0.9890,  0.7088],\n",
      "          [ 0.4757,  0.4253,  0.4641,  0.3248,  0.4461],\n",
      "          [-0.5566,  0.2098,  0.6787,  0.3668,  0.4614]],\n",
      "\n",
      "         [[-1.1818, -1.2204, -1.1599, -0.4500, -0.5640],\n",
      "          [-0.8071, -0.9566, -0.3052, -0.4736, -0.4475],\n",
      "          [-0.8216, -0.8681, -1.0013, -0.4889,  0.0085],\n",
      "          [-1.0747, -1.6077, -0.7000, -0.7088,  0.0761],\n",
      "          [-0.6396, -1.6319, -0.2105,  0.0530,  0.5318]],\n",
      "\n",
      "         [[ 0.7103, -1.1319,  0.2754,  0.3395,  0.0176],\n",
      "          [ 1.0418, -0.7502,  0.0566,  1.0611,  0.4225],\n",
      "          [ 0.0130, -1.7106, -0.5702,  0.3626, -0.0717],\n",
      "          [ 0.0699, -0.0347, -0.8432, -0.1018,  0.3139],\n",
      "          [-0.3870, -1.1672, -0.6115,  0.3545,  0.2478]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3868, 0.2711, 0.1251, 0.1484, 0.0687],\n",
      "          [0.2150, 0.2099, 0.2509, 0.1647, 0.1595],\n",
      "          [0.2496, 0.0983, 0.1628, 0.3057, 0.1835],\n",
      "          [0.1999, 0.4065, 0.1390, 0.1206, 0.1341],\n",
      "          [0.1590, 0.3575, 0.2152, 0.1586, 0.1096]],\n",
      "\n",
      "         [[0.2090, 0.1333, 0.1753, 0.2528, 0.2296],\n",
      "          [0.1270, 0.2894, 0.1790, 0.2717, 0.1329],\n",
      "          [0.1789, 0.1380, 0.1815, 0.2857, 0.2159],\n",
      "          [0.2096, 0.1993, 0.2072, 0.1803, 0.2035],\n",
      "          [0.0842, 0.1812, 0.2896, 0.2120, 0.2330]],\n",
      "\n",
      "         [[0.1445, 0.1391, 0.1477, 0.3005, 0.2681],\n",
      "          [0.1577, 0.1358, 0.2605, 0.2201, 0.2259],\n",
      "          [0.1544, 0.1473, 0.1290, 0.2153, 0.3540],\n",
      "          [0.1308, 0.0768, 0.1903, 0.1886, 0.4135],\n",
      "          [0.1230, 0.0456, 0.1889, 0.2458, 0.3968]],\n",
      "\n",
      "         [[0.3337, 0.0529, 0.2161, 0.2304, 0.1669],\n",
      "          [0.3228, 0.0538, 0.1205, 0.3291, 0.1738],\n",
      "          [0.2455, 0.0438, 0.1370, 0.3482, 0.2255],\n",
      "          [0.2262, 0.2038, 0.0908, 0.1905, 0.2887],\n",
      "          [0.1602, 0.0734, 0.1280, 0.3362, 0.3022]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.5500, -0.2841, -0.1823,  0.4537, -0.2457],\n",
      "          [ 0.1781, -0.5639, -0.0536, -0.0315, -0.4565],\n",
      "          [ 0.9249, -0.0967,  0.3007,  0.8133,  0.4448],\n",
      "          [ 0.4237, -0.3303, -0.1264,  0.2531,  0.1549],\n",
      "          [ 0.3840,  0.3602,  0.3673,  0.0870,  0.7074]],\n",
      "\n",
      "         [[ 0.4928,  0.4964,  0.2010,  0.0604,  0.9057],\n",
      "          [ 0.1536,  0.1721, -0.1403,  0.0317,  0.5610],\n",
      "          [ 0.3311,  0.5507, -0.0999,  1.1678,  0.7299],\n",
      "          [-0.1046, -0.2450,  0.0134, -0.0924,  0.3652],\n",
      "          [ 0.0764,  0.4740,  0.3851, -0.3592, -0.2239]],\n",
      "\n",
      "         [[-0.8221, -0.5816, -0.5328,  0.0309,  0.1872],\n",
      "          [-0.7008,  0.2109,  0.0828, -0.4931, -0.2164],\n",
      "          [-0.7096,  0.0318, -0.1376, -0.2938,  0.1236],\n",
      "          [ 0.2047, -0.3464, -0.1332, -0.3008,  0.0307],\n",
      "          [ 0.1051, -0.1250, -0.1973, -0.0241,  0.0751]],\n",
      "\n",
      "         [[ 0.0362, -0.5421,  0.1310,  0.0159,  0.3066],\n",
      "          [-0.2600,  0.1707,  0.2091, -0.3049, -0.2817],\n",
      "          [-0.1463,  0.3764, -0.2797,  0.2029,  0.3686],\n",
      "          [ 0.1429, -0.0629,  0.0965, -0.0692,  0.1179],\n",
      "          [-0.0533, -0.1812,  0.1387, -0.2531, -0.4686]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3054, 0.1326, 0.1468, 0.2774, 0.1378],\n",
      "          [0.2770, 0.1319, 0.2197, 0.2246, 0.1468],\n",
      "          [0.2934, 0.1056, 0.1571, 0.2624, 0.1815],\n",
      "          [0.2736, 0.1287, 0.1578, 0.2307, 0.2091],\n",
      "          [0.1967, 0.1920, 0.1934, 0.1461, 0.2718]],\n",
      "\n",
      "         [[0.2036, 0.2044, 0.1521, 0.1322, 0.3077],\n",
      "          [0.1941, 0.1977, 0.1447, 0.1718, 0.2917],\n",
      "          [0.1494, 0.1861, 0.0971, 0.3449, 0.2226],\n",
      "          [0.1784, 0.1550, 0.2007, 0.1806, 0.2853],\n",
      "          [0.1909, 0.2842, 0.2600, 0.1235, 0.1414]],\n",
      "\n",
      "         [[0.1150, 0.1462, 0.1535, 0.2698, 0.3154],\n",
      "          [0.1172, 0.2917, 0.2566, 0.1443, 0.1902],\n",
      "          [0.1151, 0.2416, 0.2040, 0.1745, 0.2649],\n",
      "          [0.2679, 0.1544, 0.1911, 0.1616, 0.2251],\n",
      "          [0.2282, 0.1813, 0.1686, 0.2005, 0.2214]],\n",
      "\n",
      "         [[0.2020, 0.1133, 0.2221, 0.1979, 0.2647],\n",
      "          [0.1647, 0.2534, 0.2633, 0.1575, 0.1612],\n",
      "          [0.1503, 0.2535, 0.1315, 0.2131, 0.2515],\n",
      "          [0.2196, 0.1788, 0.2097, 0.1777, 0.2142],\n",
      "          [0.2188, 0.1925, 0.2651, 0.1792, 0.1444]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2063,  0.0715,  0.0111, -0.3405,  0.1301],\n",
      "          [-0.1853,  0.0125, -0.5733, -0.1117,  0.0417],\n",
      "          [ 0.2237,  0.5720,  0.3893,  0.3447,  0.6684],\n",
      "          [ 0.3857, -0.3940,  0.0940, -0.7577, -0.0049],\n",
      "          [ 0.0508, -0.0105, -0.2411, -0.0260,  0.1928]],\n",
      "\n",
      "         [[-0.2378,  0.3108,  0.0756, -0.3285, -0.1696],\n",
      "          [-0.3605,  0.4151, -0.2936, -0.2798, -0.2967],\n",
      "          [ 0.2026,  0.1343,  0.1429, -0.0908,  0.0193],\n",
      "          [ 0.1322,  0.1800, -0.0581,  0.3535,  0.2553],\n",
      "          [ 0.4199,  0.1507, -0.0297, -0.6828, -0.1234]],\n",
      "\n",
      "         [[-0.2372,  0.0236, -0.0342, -0.0212, -0.2771],\n",
      "          [-0.2058, -0.3523, -0.3201, -0.8537, -0.2919],\n",
      "          [ 0.0184,  0.3180, -0.0676,  0.0487, -0.6020],\n",
      "          [ 0.0803, -0.0734, -0.2129, -0.5054, -0.3592],\n",
      "          [ 0.3606,  0.1632, -0.2621, -0.3410, -0.6651]],\n",
      "\n",
      "         [[-0.2043, -0.5914, -0.0066,  0.1979,  0.0956],\n",
      "          [ 0.1205,  0.2561,  0.1023,  0.5397,  0.5181],\n",
      "          [ 0.0444, -0.3366, -0.5118,  0.3553, -0.3500],\n",
      "          [-0.1883,  0.1711, -0.5088,  0.1538, -0.2206],\n",
      "          [ 0.4442,  0.5056,  0.1765,  0.3668,  0.0807]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2380, 0.2080, 0.1958, 0.1377, 0.2205],\n",
      "          [0.1913, 0.2331, 0.1298, 0.2059, 0.2400],\n",
      "          [0.1591, 0.2254, 0.1878, 0.1796, 0.2482],\n",
      "          [0.3124, 0.1433, 0.2334, 0.0996, 0.2114],\n",
      "          [0.2098, 0.1973, 0.1567, 0.1943, 0.2418]],\n",
      "\n",
      "         [[0.1644, 0.2846, 0.2249, 0.1501, 0.1760],\n",
      "          [0.1565, 0.3399, 0.1673, 0.1696, 0.1668],\n",
      "          [0.2245, 0.2097, 0.2115, 0.1674, 0.1869],\n",
      "          [0.1903, 0.1996, 0.1573, 0.2375, 0.2152],\n",
      "          [0.3017, 0.2305, 0.1924, 0.1002, 0.1752]],\n",
      "\n",
      "         [[0.1747, 0.2267, 0.2140, 0.2168, 0.1678],\n",
      "          [0.2383, 0.2058, 0.2126, 0.1247, 0.2186],\n",
      "          [0.2068, 0.2791, 0.1898, 0.2132, 0.1112],\n",
      "          [0.2628, 0.2254, 0.1960, 0.1463, 0.1694],\n",
      "          [0.3114, 0.2556, 0.1670, 0.1544, 0.1116]],\n",
      "\n",
      "         [[0.1741, 0.1183, 0.2122, 0.2604, 0.2350],\n",
      "          [0.1630, 0.1866, 0.1600, 0.2478, 0.2425],\n",
      "          [0.2328, 0.1591, 0.1335, 0.3177, 0.1569],\n",
      "          [0.1807, 0.2588, 0.1311, 0.2544, 0.1749],\n",
      "          [0.2248, 0.2390, 0.1720, 0.2080, 0.1563]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1931, -0.0352, -0.0198, -0.2326],\n",
      "          [-0.0260, -0.1857,  0.0721, -0.1214],\n",
      "          [ 0.0371, -0.1536,  0.0918, -0.1026],\n",
      "          [ 0.0785, -0.0268,  0.0795, -0.1313]],\n",
      "\n",
      "         [[ 0.4273,  0.2463,  0.2961,  0.0062],\n",
      "          [ 0.3311,  0.1888,  0.1212, -0.1349],\n",
      "          [ 0.6386,  0.7072,  0.5547,  0.2603],\n",
      "          [-0.0336, -0.0257,  0.0337, -0.2479]],\n",
      "\n",
      "         [[ 0.3773,  0.2804,  0.2269,  0.3565],\n",
      "          [ 0.5410,  0.4311,  0.3623,  0.4762],\n",
      "          [ 0.4659,  0.4552,  0.2633,  0.3254],\n",
      "          [ 0.3544,  0.1624,  0.1677,  0.2612]],\n",
      "\n",
      "         [[ 0.1488,  0.2280, -0.0575,  0.7031],\n",
      "          [-0.3143, -0.0601, -0.1719,  0.4554],\n",
      "          [-0.5295, -0.2695, -0.3637,  0.2194],\n",
      "          [-0.3290, -0.1709, -0.1560,  0.4448]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3070, 0.2443, 0.2481, 0.2006],\n",
      "          [0.2588, 0.2206, 0.2854, 0.2352],\n",
      "          [0.2665, 0.2202, 0.2815, 0.2318],\n",
      "          [0.2694, 0.2425, 0.2697, 0.2184]],\n",
      "\n",
      "         [[0.2969, 0.2478, 0.2604, 0.1949],\n",
      "          [0.3025, 0.2624, 0.2452, 0.1898],\n",
      "          [0.2721, 0.2914, 0.2502, 0.1864],\n",
      "          [0.2574, 0.2595, 0.2753, 0.2078]],\n",
      "\n",
      "         [[0.2668, 0.2422, 0.2296, 0.2614],\n",
      "          [0.2725, 0.2441, 0.2279, 0.2554],\n",
      "          [0.2721, 0.2692, 0.2222, 0.2365],\n",
      "          [0.2804, 0.2314, 0.2327, 0.2555]],\n",
      "\n",
      "         [[0.2157, 0.2335, 0.1755, 0.3754],\n",
      "          [0.1785, 0.2302, 0.2058, 0.3854],\n",
      "          [0.1788, 0.2319, 0.2111, 0.3782],\n",
      "          [0.1809, 0.2119, 0.2151, 0.3922]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5275, -0.4302,  0.3278, -0.3659,  0.5692],\n",
      "          [-0.5104, -0.4076,  0.3781, -0.3277,  0.5300],\n",
      "          [-0.6771, -0.3576,  0.0599, -0.5084,  0.4757],\n",
      "          [-0.4759, -0.2096,  0.3648, -0.4545,  0.3077]],\n",
      "\n",
      "         [[-0.3354,  0.0065, -0.1115,  0.4657, -0.4172],\n",
      "          [-0.1710,  0.1067, -0.0869,  0.2279, -0.1628],\n",
      "          [-0.0091,  0.1110, -0.1043,  0.4241,  0.1030],\n",
      "          [-0.2611, -0.3139, -0.2146,  0.4308, -0.2545]],\n",
      "\n",
      "         [[ 0.2787, -0.5035, -0.2389,  0.5764,  0.0246],\n",
      "          [ 0.3284, -0.3196, -0.2607,  0.7120,  0.1776],\n",
      "          [ 0.0988, -0.5143, -0.1366,  0.5857,  0.0957],\n",
      "          [ 0.0322, -0.4789, -0.1903,  0.5908,  0.0124]],\n",
      "\n",
      "         [[-0.3964,  0.1098,  0.4203, -0.0484,  0.2344],\n",
      "          [-0.3406, -0.0838,  0.4189,  0.0718,  0.4242],\n",
      "          [-0.1942, -0.2728,  0.4660, -0.0745, -0.1553],\n",
      "          [-0.1689,  0.0208,  0.3293,  0.0584,  0.1821]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1160, 0.1278, 0.2727, 0.1363, 0.3472],\n",
      "          [0.1167, 0.1293, 0.2837, 0.1401, 0.3302],\n",
      "          [0.1134, 0.1561, 0.2370, 0.1343, 0.3592],\n",
      "          [0.1277, 0.1666, 0.2959, 0.1304, 0.2795]],\n",
      "\n",
      "         [[0.1469, 0.2068, 0.1837, 0.3272, 0.1353],\n",
      "          [0.1693, 0.2235, 0.1842, 0.2523, 0.1707],\n",
      "          [0.1755, 0.1979, 0.1596, 0.2707, 0.1963],\n",
      "          [0.1667, 0.1581, 0.1746, 0.3329, 0.1678]],\n",
      "\n",
      "         [[0.2395, 0.1095, 0.1427, 0.3225, 0.1857],\n",
      "          [0.2270, 0.1187, 0.1259, 0.3331, 0.1952],\n",
      "          [0.2018, 0.1093, 0.1595, 0.3284, 0.2011],\n",
      "          [0.1950, 0.1169, 0.1561, 0.3409, 0.1912]],\n",
      "\n",
      "         [[0.1217, 0.2019, 0.2754, 0.1723, 0.2287],\n",
      "          [0.1236, 0.1598, 0.2642, 0.1867, 0.2656],\n",
      "          [0.1659, 0.1534, 0.3211, 0.1870, 0.1725],\n",
      "          [0.1531, 0.1851, 0.2520, 0.1922, 0.2175]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1410,  0.1826,  0.2185,  0.0218],\n",
      "          [-0.0200,  0.0961,  0.0127, -0.1527],\n",
      "          [-0.0483,  0.1042,  0.0150, -0.1464],\n",
      "          [ 0.1445,  0.2268,  0.1806, -0.0243]],\n",
      "\n",
      "         [[-0.3606, -0.4335, -0.3658, -0.2357],\n",
      "          [-0.1818, -0.3387, -0.0680, -0.0508],\n",
      "          [-0.1500, -0.2188, -0.0279, -0.0532],\n",
      "          [-0.2580, -0.3893, -0.2880, -0.1744]],\n",
      "\n",
      "         [[ 0.5850,  0.6829,  0.7091,  0.8657],\n",
      "          [ 0.5045,  0.6255,  0.6228,  0.9226],\n",
      "          [ 0.4720,  0.4084,  0.4367,  0.7780],\n",
      "          [ 0.5543,  0.5041,  0.4615,  0.8430]],\n",
      "\n",
      "         [[-0.0036, -0.2162, -0.0876, -0.0546],\n",
      "          [-0.1721, -0.2952, -0.1914, -0.2171],\n",
      "          [-0.0051, -0.1135, -0.0222,  0.0457],\n",
      "          [ 0.1964,  0.1517,  0.2141,  0.0764]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2493, 0.2599, 0.2694, 0.2213],\n",
      "          [0.2480, 0.2785, 0.2563, 0.2172],\n",
      "          [0.2417, 0.2816, 0.2575, 0.2192],\n",
      "          [0.2521, 0.2737, 0.2613, 0.2129]],\n",
      "\n",
      "         [[0.2465, 0.2291, 0.2452, 0.2792],\n",
      "          [0.2430, 0.2077, 0.2723, 0.2770],\n",
      "          [0.2401, 0.2241, 0.2713, 0.2645],\n",
      "          [0.2542, 0.2229, 0.2466, 0.2763]],\n",
      "\n",
      "         [[0.2193, 0.2419, 0.2483, 0.2904],\n",
      "          [0.2095, 0.2364, 0.2358, 0.3182],\n",
      "          [0.2347, 0.2202, 0.2265, 0.3186],\n",
      "          [0.2383, 0.2266, 0.2172, 0.3180]],\n",
      "\n",
      "         [[0.2719, 0.2198, 0.2500, 0.2584],\n",
      "          [0.2617, 0.2314, 0.2567, 0.2502],\n",
      "          [0.2543, 0.2282, 0.2500, 0.2675],\n",
      "          [0.2590, 0.2477, 0.2636, 0.2297]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.5998,  0.0630,  0.1808, -0.1831,  0.3475],\n",
      "          [ 0.6862,  0.0661,  0.0370,  0.0483,  0.4065],\n",
      "          [ 0.4494,  0.1623,  0.1171, -0.1600,  0.4162],\n",
      "          [ 0.4641,  0.0744, -0.1548, -0.0071,  0.1263]],\n",
      "\n",
      "         [[-0.3920, -0.3074,  0.3724, -0.1088,  0.1118],\n",
      "          [-0.1570, -0.1522,  0.1813,  0.0792,  0.0402],\n",
      "          [-0.1501, -0.1091,  0.2342,  0.2631,  0.2374],\n",
      "          [-0.2649, -0.0760,  0.2539,  0.0181,  0.2026]],\n",
      "\n",
      "         [[-0.1050, -0.1971,  0.0814, -0.1661,  0.1395],\n",
      "          [ 0.2238, -0.3201,  0.1067, -0.4092, -0.0158],\n",
      "          [ 0.3273, -0.4751,  0.0581, -0.7580, -0.1140],\n",
      "          [ 0.1324, -0.5107,  0.0556, -0.6112,  0.1424]],\n",
      "\n",
      "         [[ 0.2232, -0.2174, -0.2089,  0.6329,  0.2268],\n",
      "          [ 0.1419, -0.1047, -0.0014,  0.4652,  0.3180],\n",
      "          [ 0.2315, -0.2542,  0.1336,  0.5373,  0.2838],\n",
      "          [ 0.1475, -0.2370,  0.0470,  0.5068,  0.2877]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2877, 0.1682, 0.1892, 0.1315, 0.2235],\n",
      "          [0.2990, 0.1608, 0.1562, 0.1580, 0.2260],\n",
      "          [0.2513, 0.1886, 0.1803, 0.1366, 0.2431],\n",
      "          [0.2814, 0.1906, 0.1515, 0.1757, 0.2007]],\n",
      "\n",
      "         [[0.1385, 0.1508, 0.2975, 0.1839, 0.2293],\n",
      "          [0.1697, 0.1705, 0.2381, 0.2149, 0.2067],\n",
      "          [0.1540, 0.1604, 0.2261, 0.2327, 0.2268],\n",
      "          [0.1468, 0.1774, 0.2466, 0.1948, 0.2343]],\n",
      "\n",
      "         [[0.1875, 0.1710, 0.2259, 0.1763, 0.2394],\n",
      "          [0.2640, 0.1532, 0.2348, 0.1402, 0.2078],\n",
      "          [0.3132, 0.1404, 0.2393, 0.1058, 0.2014],\n",
      "          [0.2540, 0.1335, 0.2352, 0.1207, 0.2565]],\n",
      "\n",
      "         [[0.2082, 0.1340, 0.1352, 0.3137, 0.2090],\n",
      "          [0.1915, 0.1496, 0.1659, 0.2646, 0.2284],\n",
      "          [0.2027, 0.1247, 0.1838, 0.2752, 0.2136],\n",
      "          [0.1935, 0.1317, 0.1750, 0.2772, 0.2226]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0307, -0.1216,  0.0950, -0.0039],\n",
      "          [ 0.1778, -0.0735,  0.1409,  0.2155],\n",
      "          [-0.1248, -0.3390, -0.0501, -0.0329],\n",
      "          [-0.0504, -0.3074, -0.0638, -0.1388]],\n",
      "\n",
      "         [[ 0.2693,  0.1102,  0.2523,  0.3010],\n",
      "          [ 0.2871,  0.1706,  0.2415,  0.3332],\n",
      "          [ 0.0820, -0.0090,  0.0612,  0.1701],\n",
      "          [ 0.5024,  0.4398,  0.4555,  0.4772]],\n",
      "\n",
      "         [[ 0.1189, -0.0451,  0.0855,  0.0719],\n",
      "          [ 0.4300,  0.4547,  0.4911,  0.4643],\n",
      "          [ 0.3690,  0.4287,  0.4269,  0.4470],\n",
      "          [ 0.2172,  0.1822,  0.2717,  0.2329]],\n",
      "\n",
      "         [[-0.0868, -0.3735, -0.3405, -0.1032],\n",
      "          [ 0.0642, -0.1629,  0.0167,  0.1499],\n",
      "          [ 0.1480, -0.3675, -0.2106,  0.2309],\n",
      "          [ 0.1102, -0.2293, -0.0699,  0.3068]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2454, 0.2241, 0.2783, 0.2521],\n",
      "          [0.2646, 0.2058, 0.2550, 0.2747],\n",
      "          [0.2512, 0.2028, 0.2707, 0.2754],\n",
      "          [0.2721, 0.2104, 0.2685, 0.2491]],\n",
      "\n",
      "         [[0.2585, 0.2205, 0.2542, 0.2668],\n",
      "          [0.2569, 0.2286, 0.2454, 0.2690],\n",
      "          [0.2510, 0.2291, 0.2458, 0.2741],\n",
      "          [0.2585, 0.2428, 0.2466, 0.2521]],\n",
      "\n",
      "         [[0.2652, 0.2251, 0.2565, 0.2531],\n",
      "          [0.2425, 0.2486, 0.2578, 0.2510],\n",
      "          [0.2380, 0.2526, 0.2521, 0.2573],\n",
      "          [0.2477, 0.2392, 0.2616, 0.2516]],\n",
      "\n",
      "         [[0.2849, 0.2139, 0.2210, 0.2802],\n",
      "          [0.2604, 0.2075, 0.2483, 0.2837],\n",
      "          [0.2957, 0.1766, 0.2066, 0.3212],\n",
      "          [0.2656, 0.1892, 0.2218, 0.3233]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 3.9340e-01,  9.3881e-02, -1.5630e-01,  3.2613e-01,  2.3761e-01],\n",
      "          [ 1.4785e-01,  9.0634e-02, -8.8072e-02,  3.7099e-01,  9.1820e-02],\n",
      "          [ 1.7773e-01, -1.7140e-02, -1.9492e-01,  6.8060e-01,  3.1629e-01],\n",
      "          [-6.5686e-02,  1.9507e-01, -4.6247e-02,  3.0632e-01,  3.5353e-01]],\n",
      "\n",
      "         [[-9.6531e-01, -6.5227e-01, -6.5265e-02, -1.9807e-04, -3.8561e-01],\n",
      "          [-6.5932e-01, -6.9612e-01, -1.5770e-01,  9.5413e-03, -4.0353e-01],\n",
      "          [-6.4817e-01, -7.5819e-01, -1.8947e-01, -1.8678e-01, -4.1226e-01],\n",
      "          [-7.8472e-01, -7.4118e-01,  2.2567e-02, -1.4077e-01, -1.5445e-01]],\n",
      "\n",
      "         [[-2.4722e-01, -1.2536e-01, -4.0657e-01, -5.3341e-02, -1.0385e-01],\n",
      "          [-1.7220e-01, -2.7410e-02, -3.9596e-01, -1.4733e-01, -1.2700e-01],\n",
      "          [-3.2345e-01, -2.0622e-01, -3.0610e-01,  3.2183e-03, -1.0309e-02],\n",
      "          [-3.4439e-01, -3.4355e-01, -4.4187e-01, -2.1982e-01, -1.6700e-01]],\n",
      "\n",
      "         [[-2.0810e-01, -2.2480e-01, -1.2658e-01,  4.1077e-01, -2.6314e-02],\n",
      "          [ 1.1131e-01, -3.8092e-01, -1.1981e-01,  4.2405e-01,  3.8418e-03],\n",
      "          [-9.1788e-02, -3.2828e-01, -1.4868e-01,  4.7799e-01, -8.4797e-03],\n",
      "          [-3.3754e-01, -4.1932e-01, -2.0850e-02,  8.0034e-01,  1.0160e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2434, 0.1804, 0.1405, 0.2275, 0.2083],\n",
      "          [0.2029, 0.1916, 0.1602, 0.2536, 0.1918],\n",
      "          [0.1882, 0.1549, 0.1296, 0.3112, 0.2162],\n",
      "          [0.1590, 0.2064, 0.1621, 0.2307, 0.2418]],\n",
      "\n",
      "         [[0.1083, 0.1480, 0.2663, 0.2842, 0.1933],\n",
      "          [0.1458, 0.1405, 0.2408, 0.2846, 0.1883],\n",
      "          [0.1580, 0.1415, 0.2499, 0.2506, 0.2000],\n",
      "          [0.1239, 0.1295, 0.2779, 0.2360, 0.2328]],\n",
      "\n",
      "         [[0.1869, 0.2111, 0.1594, 0.2269, 0.2157],\n",
      "          [0.1989, 0.2299, 0.1591, 0.2039, 0.2081],\n",
      "          [0.1696, 0.1907, 0.1726, 0.2351, 0.2320],\n",
      "          [0.1910, 0.1912, 0.1733, 0.2164, 0.2281]],\n",
      "\n",
      "         [[0.1633, 0.1606, 0.1771, 0.3032, 0.1958],\n",
      "          [0.2141, 0.1309, 0.1699, 0.2927, 0.1923],\n",
      "          [0.1789, 0.1412, 0.1690, 0.3163, 0.1945],\n",
      "          [0.1255, 0.1157, 0.1723, 0.3917, 0.1948]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.6326,  0.5934,  0.7025, -0.1554, -0.4424],\n",
      "          [ 0.5047,  0.1295,  0.4830, -0.1727,  0.1309],\n",
      "          [ 1.0406,  0.1674,  0.4801,  0.9780, -0.1715],\n",
      "          [ 0.4808,  0.4720,  0.0948, -0.0576,  0.1483],\n",
      "          [-0.3068,  0.2813, -0.3593, -0.2604, -0.1541]],\n",
      "\n",
      "         [[ 0.6257, -0.0241,  0.3235,  0.2852,  0.8285],\n",
      "          [-0.8715, -0.2696, -0.5740, -0.6693, -1.0423],\n",
      "          [ 0.2313,  0.1722,  0.4314,  0.8330,  1.2170],\n",
      "          [ 0.6825,  0.2924,  0.0457,  0.3940,  0.6633],\n",
      "          [-0.1687, -0.2671,  0.9700,  0.4352,  0.5432]],\n",
      "\n",
      "         [[-1.2117, -1.1307, -0.9182,  0.1005, -0.3950],\n",
      "          [-0.6603, -1.0280, -0.3960, -0.2849, -0.2909],\n",
      "          [-1.6124, -1.1130, -1.5950, -0.6077,  0.6100],\n",
      "          [-0.4725, -1.2974, -0.3902, -0.2814,  0.2802],\n",
      "          [-0.4323, -1.3957,  0.2612, -0.1340,  0.2592]],\n",
      "\n",
      "         [[ 0.7468, -0.5752,  0.4841,  0.2983, -0.0264],\n",
      "          [ 0.9015, -0.7683, -0.7390,  0.5966,  0.4132],\n",
      "          [ 0.3129, -1.1452, -0.2499, -0.0468,  0.1521],\n",
      "          [ 0.1031,  0.1562, -0.3203, -0.2039,  0.1358],\n",
      "          [ 0.2969, -1.1288, -1.1437,  0.2691,  0.1738]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2611, 0.2511, 0.2800, 0.1187, 0.0891],\n",
      "          [0.2590, 0.1779, 0.2534, 0.1315, 0.1782],\n",
      "          [0.3100, 0.1295, 0.1770, 0.2912, 0.0923],\n",
      "          [0.2518, 0.2496, 0.1712, 0.1470, 0.1806],\n",
      "          [0.1677, 0.3020, 0.1592, 0.1757, 0.1954]],\n",
      "\n",
      "         [[0.2382, 0.1244, 0.1761, 0.1695, 0.2918],\n",
      "          [0.1603, 0.2926, 0.2158, 0.1962, 0.1351],\n",
      "          [0.1304, 0.1229, 0.1593, 0.2380, 0.3494],\n",
      "          [0.2540, 0.1720, 0.1344, 0.1904, 0.2492],\n",
      "          [0.1124, 0.1019, 0.3510, 0.2056, 0.2291]],\n",
      "\n",
      "         [[0.1063, 0.1153, 0.1426, 0.3950, 0.2407],\n",
      "          [0.1696, 0.1174, 0.2209, 0.2468, 0.2453],\n",
      "          [0.0640, 0.1055, 0.0651, 0.1748, 0.5906],\n",
      "          [0.1707, 0.0748, 0.1854, 0.2067, 0.3624],\n",
      "          [0.1487, 0.0567, 0.2974, 0.2003, 0.2968]],\n",
      "\n",
      "         [[0.3189, 0.0850, 0.2452, 0.2036, 0.1472],\n",
      "          [0.3659, 0.0689, 0.0709, 0.2697, 0.2245],\n",
      "          [0.2984, 0.0694, 0.1699, 0.2082, 0.2541],\n",
      "          [0.2233, 0.2355, 0.1462, 0.1643, 0.2307],\n",
      "          [0.2999, 0.0721, 0.0710, 0.2917, 0.2652]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4633, -0.6806, -0.1296,  0.5756, -0.2834],\n",
      "          [ 0.5697, -0.4614, -0.4477,  0.0909, -0.0654],\n",
      "          [ 1.0365, -0.3048,  0.3000,  0.6800,  0.5351],\n",
      "          [ 0.2934, -0.3687, -0.2325,  0.2931,  0.0464],\n",
      "          [ 0.3873,  0.1165,  0.2242, -0.0150,  0.3200]],\n",
      "\n",
      "         [[ 0.3038,  0.0802,  0.3736, -0.1016,  0.9167],\n",
      "          [ 0.3477,  0.0414, -0.3067, -0.0083,  0.3828],\n",
      "          [ 0.2201,  0.4306,  0.1315,  0.6449,  0.5583],\n",
      "          [ 0.1426, -0.0160,  0.6955, -0.1044,  0.4898],\n",
      "          [ 0.2334,  0.4990,  0.5109, -0.4578,  0.0499]],\n",
      "\n",
      "         [[-0.6194, -0.8072, -0.3725,  0.1345,  0.0599],\n",
      "          [-0.7089,  0.0867,  0.2212, -0.4399, -0.2976],\n",
      "          [-0.6285,  0.0122,  0.0680, -0.0903, -0.1249],\n",
      "          [ 0.0460, -0.5005, -0.0774, -0.1685, -0.4524],\n",
      "          [-0.0643, -0.0224, -0.1119, -0.0528,  0.0679]],\n",
      "\n",
      "         [[ 0.2380, -0.0334, -0.0489,  0.1690,  0.6657],\n",
      "          [ 0.0622, -0.0645,  0.0278, -0.0773, -0.0387],\n",
      "          [-0.1670,  0.0131, -0.0971,  0.3521,  0.0833],\n",
      "          [ 0.2165, -0.1833, -0.1615,  0.0471,  0.0768],\n",
      "          [ 0.0017, -0.1559, -0.1891, -0.0833, -0.2092]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2887, 0.0920, 0.1596, 0.3230, 0.1368],\n",
      "          [0.3487, 0.1244, 0.1261, 0.2161, 0.1848],\n",
      "          [0.3283, 0.0858, 0.1572, 0.2298, 0.1988],\n",
      "          [0.2572, 0.1327, 0.1520, 0.2572, 0.2009],\n",
      "          [0.2372, 0.1809, 0.2015, 0.1586, 0.2218]],\n",
      "\n",
      "         [[0.1857, 0.1485, 0.1991, 0.1238, 0.3428],\n",
      "          [0.2505, 0.1844, 0.1302, 0.1755, 0.2594],\n",
      "          [0.1644, 0.2030, 0.1505, 0.2515, 0.2306],\n",
      "          [0.1728, 0.1474, 0.3003, 0.1350, 0.2445],\n",
      "          [0.2017, 0.2631, 0.2662, 0.1011, 0.1679]],\n",
      "\n",
      "         [[0.1388, 0.1150, 0.1776, 0.2949, 0.2737],\n",
      "          [0.1167, 0.2586, 0.2958, 0.1527, 0.1761],\n",
      "          [0.1209, 0.2294, 0.2426, 0.2071, 0.2000],\n",
      "          [0.2579, 0.1493, 0.2280, 0.2081, 0.1567],\n",
      "          [0.1942, 0.2025, 0.1852, 0.1965, 0.2216]],\n",
      "\n",
      "         [[0.2008, 0.1531, 0.1507, 0.1874, 0.3080],\n",
      "          [0.2164, 0.1907, 0.2091, 0.1882, 0.1956],\n",
      "          [0.1604, 0.1921, 0.1720, 0.2695, 0.2060],\n",
      "          [0.2457, 0.1648, 0.1684, 0.2074, 0.2137],\n",
      "          [0.2268, 0.1937, 0.1874, 0.2083, 0.1837]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2508,  0.1347,  0.0118, -0.4439,  0.2005],\n",
      "          [-0.2704, -0.2615, -0.4452, -0.1588, -0.1164],\n",
      "          [ 0.2246,  0.5688,  0.4782,  0.2324,  0.8224],\n",
      "          [ 0.5345, -0.3506, -0.0011, -0.4771,  0.0690],\n",
      "          [ 0.3316,  0.1664,  0.2025, -0.0727,  0.3963]],\n",
      "\n",
      "         [[ 0.1665,  0.4355,  0.2226, -0.0088, -0.0286],\n",
      "          [-0.0649, -0.2108,  0.0609, -0.2354, -0.3321],\n",
      "          [ 0.2088,  0.3344,  0.3887, -0.0211, -0.1400],\n",
      "          [-0.2982,  0.4733, -0.2945, -0.0498, -0.1816],\n",
      "          [ 0.1261,  0.2354, -0.0606, -0.5763, -0.0169]],\n",
      "\n",
      "         [[-0.2301,  0.2581,  0.1520, -0.1083, -0.1956],\n",
      "          [-0.2303, -0.8072, -0.4852, -0.2431, -0.4896],\n",
      "          [-0.3371, -0.0679, -0.1690, -0.0416, -0.1429],\n",
      "          [ 0.0363, -0.1667, -0.3515, -0.4627,  0.0518],\n",
      "          [ 0.2906, -0.1539, -0.3278, -0.1356, -0.3845]],\n",
      "\n",
      "         [[ 0.0337, -0.4822,  0.0943,  0.0231, -0.0679],\n",
      "          [ 0.3770,  0.1461, -0.0509,  0.5614,  0.2037],\n",
      "          [ 0.3160, -0.1312, -0.2163,  0.5093, -0.3055],\n",
      "          [-0.2199,  0.1700, -0.1582, -0.2227, -0.4514],\n",
      "          [ 0.2670,  0.4304,  0.1651,  0.2956,  0.0069]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2422, 0.2157, 0.1907, 0.1209, 0.2304],\n",
      "          [0.1948, 0.1966, 0.1636, 0.2178, 0.2273],\n",
      "          [0.1533, 0.2162, 0.1975, 0.1544, 0.2786],\n",
      "          [0.3345, 0.1380, 0.1958, 0.1216, 0.2100],\n",
      "          [0.2242, 0.1900, 0.1970, 0.1496, 0.2392]],\n",
      "\n",
      "         [[0.1989, 0.2603, 0.2103, 0.1669, 0.1636],\n",
      "          [0.2171, 0.1876, 0.2462, 0.1830, 0.1662],\n",
      "          [0.2070, 0.2347, 0.2478, 0.1645, 0.1460],\n",
      "          [0.1521, 0.3291, 0.1527, 0.1951, 0.1710],\n",
      "          [0.2322, 0.2590, 0.1926, 0.1150, 0.2012]],\n",
      "\n",
      "         [[0.1598, 0.2603, 0.2341, 0.1804, 0.1654],\n",
      "          [0.2442, 0.1371, 0.1892, 0.2411, 0.1884],\n",
      "          [0.1653, 0.2164, 0.1955, 0.2221, 0.2007],\n",
      "          [0.2429, 0.1982, 0.1648, 0.1475, 0.2466],\n",
      "          [0.2992, 0.1918, 0.1612, 0.1954, 0.1523]],\n",
      "\n",
      "         [[0.2197, 0.1311, 0.2334, 0.2174, 0.1984],\n",
      "          [0.2228, 0.1768, 0.1452, 0.2679, 0.1873],\n",
      "          [0.2515, 0.1608, 0.1477, 0.3051, 0.1351],\n",
      "          [0.1876, 0.2770, 0.1995, 0.1871, 0.1488],\n",
      "          [0.2049, 0.2413, 0.1850, 0.2108, 0.1580]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2508, -0.2352, -0.0485,  0.0676, -0.3919, -0.4043, -0.3590,\n",
      "           -0.3016],\n",
      "          [-0.5350, -0.3674, -0.0485, -0.1162, -0.4081, -0.4571, -0.3920,\n",
      "           -0.5632],\n",
      "          [-0.0456, -0.1507,  0.1205,  0.1876, -0.1735, -0.3498, -0.2477,\n",
      "           -0.2661],\n",
      "          [ 0.0120,  0.0015,  0.2836,  0.4406,  0.0296, -0.2459, -0.2072,\n",
      "           -0.1856],\n",
      "          [-0.2067, -0.1531,  0.0760,  0.1390, -0.2118, -0.2935, -0.3111,\n",
      "           -0.3145],\n",
      "          [-0.0137,  0.0531,  0.2168,  0.3907,  0.0663, -0.2476, -0.2073,\n",
      "           -0.1961],\n",
      "          [-0.3964, -0.2858, -0.0956,  0.0085, -0.1708, -0.6143, -0.6137,\n",
      "           -0.6342],\n",
      "          [-0.3309, -0.0884,  0.0798,  0.1400,  0.0380, -0.1683, -0.1802,\n",
      "           -0.2500]],\n",
      "\n",
      "         [[ 0.1172,  0.2306,  0.2347,  0.2755,  0.1848,  0.5512,  0.0155,\n",
      "            0.1696],\n",
      "          [ 0.3697,  0.6353,  0.5335,  0.3398,  0.2365,  0.5564,  0.1207,\n",
      "            0.4056],\n",
      "          [ 0.1112, -0.0147, -0.1462, -0.1907, -0.2132,  0.1302, -0.4079,\n",
      "            0.0521],\n",
      "          [ 0.0867,  0.0460, -0.0596, -0.0716, -0.1092,  0.2824, -0.2735,\n",
      "            0.0484],\n",
      "          [ 0.0930,  0.1335,  0.0721, -0.1455,  0.0135,  0.2089, -0.3759,\n",
      "           -0.1492],\n",
      "          [ 0.1275,  0.0404,  0.0615, -0.0770,  0.0057,  0.2574, -0.2804,\n",
      "           -0.1326],\n",
      "          [-0.0430, -0.1016, -0.0567, -0.2818, -0.1454,  0.0488, -0.3963,\n",
      "           -0.2227],\n",
      "          [-0.0825,  0.0329,  0.0649, -0.0768, -0.0562,  0.0972, -0.2081,\n",
      "           -0.1735]],\n",
      "\n",
      "         [[ 0.7268,  0.6555,  0.6473,  0.7940,  0.5192,  0.6642,  0.4461,\n",
      "            0.7956],\n",
      "          [ 0.4143,  0.3339,  0.2505,  0.2042,  0.0428,  0.1929, -0.0147,\n",
      "            0.1937],\n",
      "          [ 0.3288,  0.1547,  0.1232,  0.1567,  0.0116,  0.2293, -0.1653,\n",
      "            0.1574],\n",
      "          [ 0.6060,  0.2981,  0.3901,  0.4133,  0.0608,  0.4129,  0.0256,\n",
      "            0.3281],\n",
      "          [ 0.4967,  0.0486,  0.2381,  0.2946,  0.1209,  0.4380,  0.0534,\n",
      "            0.2355],\n",
      "          [ 0.5046,  0.0195,  0.2716,  0.2964,  0.0949,  0.5179,  0.1027,\n",
      "            0.3118],\n",
      "          [ 0.3723, -0.0358,  0.2049,  0.0909,  0.0021,  0.4483,  0.0696,\n",
      "            0.1731],\n",
      "          [ 0.3751, -0.0858,  0.0924,  0.0928, -0.1111,  0.1445, -0.2267,\n",
      "            0.1250]],\n",
      "\n",
      "         [[-0.5042, -0.3750,  0.1153,  0.1945,  0.3389,  0.4255,  0.1144,\n",
      "           -0.2482],\n",
      "          [-0.4399, -0.0961,  0.2061,  0.3123,  0.2206,  0.5798,  0.2239,\n",
      "           -0.1362],\n",
      "          [-0.4096, -0.3761,  0.1640,  0.0886,  0.1591,  0.5048,  0.0548,\n",
      "           -0.3535],\n",
      "          [-0.6794, -0.4329,  0.0695,  0.0697,  0.0613,  0.3449, -0.0206,\n",
      "           -0.3846],\n",
      "          [-0.3965, -0.2607,  0.1652,  0.2333,  0.3476,  0.7375,  0.2515,\n",
      "           -0.1264],\n",
      "          [-0.8318, -0.6871, -0.0888, -0.0727, -0.1434,  0.1582, -0.2930,\n",
      "           -0.4595],\n",
      "          [-0.3160, -0.1996,  0.3140,  0.2558,  0.3370,  0.7417,  0.2310,\n",
      "           -0.0298],\n",
      "          [-0.0887, -0.0609,  0.6460,  0.5922,  0.6156,  0.8764,  0.4270,\n",
      "            0.0941]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1221, 0.1240, 0.1495, 0.1679, 0.1060, 0.1047, 0.1096, 0.1161],\n",
      "          [0.1034, 0.1223, 0.1682, 0.1572, 0.1174, 0.1118, 0.1193, 0.1005],\n",
      "          [0.1319, 0.1188, 0.1558, 0.1666, 0.1161, 0.0973, 0.1078, 0.1058],\n",
      "          [0.1212, 0.1199, 0.1590, 0.1861, 0.1233, 0.0936, 0.0973, 0.0995],\n",
      "          [0.1176, 0.1241, 0.1560, 0.1661, 0.1170, 0.1078, 0.1059, 0.1056],\n",
      "          [0.1196, 0.1279, 0.1507, 0.1793, 0.1296, 0.0947, 0.0986, 0.0997],\n",
      "          [0.1160, 0.1296, 0.1568, 0.1740, 0.1454, 0.0933, 0.0934, 0.0915],\n",
      "          [0.0975, 0.1243, 0.1471, 0.1562, 0.1410, 0.1148, 0.1134, 0.1057]],\n",
      "\n",
      "         [[0.1113, 0.1246, 0.1251, 0.1304, 0.1191, 0.1717, 0.1005, 0.1173],\n",
      "          [0.1198, 0.1562, 0.1411, 0.1162, 0.1048, 0.1444, 0.0934, 0.1241],\n",
      "          [0.1498, 0.1321, 0.1158, 0.1108, 0.1083, 0.1527, 0.0892, 0.1412],\n",
      "          [0.1356, 0.1302, 0.1171, 0.1157, 0.1115, 0.1649, 0.0946, 0.1305],\n",
      "          [0.1376, 0.1433, 0.1348, 0.1084, 0.1271, 0.1546, 0.0861, 0.1080],\n",
      "          [0.1403, 0.1286, 0.1313, 0.1144, 0.1242, 0.1598, 0.0933, 0.1082],\n",
      "          [0.1379, 0.1300, 0.1360, 0.1086, 0.1244, 0.1511, 0.0968, 0.1152],\n",
      "          [0.1204, 0.1351, 0.1395, 0.1211, 0.1236, 0.1441, 0.1062, 0.1099]],\n",
      "\n",
      "         [[0.1333, 0.1241, 0.1231, 0.1426, 0.1083, 0.1252, 0.1007, 0.1428],\n",
      "          [0.1532, 0.1414, 0.1301, 0.1242, 0.1057, 0.1228, 0.0998, 0.1229],\n",
      "          [0.1519, 0.1276, 0.1237, 0.1279, 0.1106, 0.1375, 0.0927, 0.1280],\n",
      "          [0.1643, 0.1208, 0.1324, 0.1355, 0.0952, 0.1354, 0.0919, 0.1244],\n",
      "          [0.1595, 0.1019, 0.1231, 0.1303, 0.1095, 0.1504, 0.1024, 0.1228],\n",
      "          [0.1565, 0.0963, 0.1240, 0.1271, 0.1039, 0.1586, 0.1047, 0.1290],\n",
      "          [0.1517, 0.1008, 0.1283, 0.1145, 0.1047, 0.1636, 0.1121, 0.1243],\n",
      "          [0.1702, 0.1074, 0.1283, 0.1284, 0.1047, 0.1352, 0.0933, 0.1326]],\n",
      "\n",
      "         [[0.0714, 0.0812, 0.1326, 0.1435, 0.1658, 0.1808, 0.1325, 0.0922],\n",
      "          [0.0692, 0.0976, 0.1321, 0.1469, 0.1340, 0.1919, 0.1345, 0.0938],\n",
      "          [0.0809, 0.0836, 0.1435, 0.1331, 0.1428, 0.2018, 0.1287, 0.0855],\n",
      "          [0.0682, 0.0872, 0.1442, 0.1442, 0.1430, 0.1899, 0.1318, 0.0916],\n",
      "          [0.0704, 0.0806, 0.1234, 0.1321, 0.1481, 0.2187, 0.1345, 0.0922],\n",
      "          [0.0702, 0.0812, 0.1476, 0.1500, 0.1398, 0.1890, 0.1203, 0.1019],\n",
      "          [0.0734, 0.0824, 0.1377, 0.1299, 0.1409, 0.2112, 0.1268, 0.0977],\n",
      "          [0.0735, 0.0755, 0.1532, 0.1451, 0.1486, 0.1929, 0.1230, 0.0882]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-7.2488e-01, -2.2115e-01,  7.8104e-01, -6.4929e-01, -1.2541e-01],\n",
      "          [-6.1256e-01, -1.0853e-01,  2.4746e-01, -6.4874e-01, -1.2294e-01],\n",
      "          [-7.0209e-01, -2.1520e-01,  5.4944e-01, -6.4891e-01, -3.7577e-02],\n",
      "          [-7.8475e-01, -1.7236e-01,  7.7044e-01, -6.2812e-01,  2.7771e-03],\n",
      "          [-7.9082e-01, -8.0273e-02,  3.7382e-01, -6.8704e-01, -5.5068e-02],\n",
      "          [-6.7288e-01, -1.9668e-01,  3.9500e-01, -6.0844e-01, -1.6029e-01],\n",
      "          [-5.6576e-01, -1.7047e-01,  3.8605e-01, -5.1324e-01, -3.0998e-02],\n",
      "          [-5.8256e-01, -4.2313e-04,  5.3162e-01, -4.5080e-01,  1.9008e-01]],\n",
      "\n",
      "         [[ 7.9028e-02, -3.5015e-01, -1.8485e-02,  6.5550e-01, -5.5366e-02],\n",
      "          [ 6.5350e-02, -8.8917e-02, -1.7647e-01,  2.4308e-01, -2.2139e-01],\n",
      "          [ 2.0546e-01, -2.8204e-01, -3.1030e-01,  5.0624e-01, -2.7206e-01],\n",
      "          [ 3.2385e-01, -5.0601e-01,  1.9341e-02,  6.5191e-01, -2.4800e-01],\n",
      "          [ 3.0305e-01, -3.5434e-01, -2.1111e-01,  5.3471e-01, -3.8009e-03],\n",
      "          [ 1.8345e-01, -5.4113e-01, -7.2926e-03,  4.5638e-01, -3.5051e-01],\n",
      "          [ 2.6015e-01, -4.3811e-01, -2.3248e-01,  4.3503e-01, -7.3824e-02],\n",
      "          [ 1.8445e-01, -5.6972e-01,  9.3575e-02,  4.8624e-01, -2.3504e-01]],\n",
      "\n",
      "         [[ 1.6057e-01, -2.3212e-01, -3.8239e-01,  2.8861e-01, -6.4053e-02],\n",
      "          [-5.0018e-02, -3.0393e-01, -3.9409e-01,  1.8401e-01, -1.4368e-01],\n",
      "          [ 1.4875e-01, -3.8407e-01, -4.6047e-01,  2.4044e-01, -3.8529e-02],\n",
      "          [ 6.7935e-02, -2.6355e-01, -4.4470e-01,  3.9117e-01, -7.1635e-02],\n",
      "          [ 9.1624e-02, -2.6491e-01, -4.4949e-01,  1.8827e-01, -1.7009e-01],\n",
      "          [ 1.6410e-01, -2.1147e-01, -1.4630e-01,  5.8019e-02,  2.2393e-02],\n",
      "          [ 1.7249e-01, -1.3921e-01, -3.0366e-01,  1.4486e-01, -1.3277e-01],\n",
      "          [ 4.7966e-02, -3.4795e-02, -1.0897e-01,  8.4167e-02, -2.7847e-01]],\n",
      "\n",
      "         [[-9.5123e-03,  1.3473e-01,  3.5024e-01, -2.0376e-01,  5.2636e-01],\n",
      "          [-1.7516e-01,  1.2263e-01,  5.1737e-01, -2.6741e-01,  3.6345e-01],\n",
      "          [-7.8434e-03,  5.2640e-02,  7.2846e-01, -2.2088e-01,  5.1135e-01],\n",
      "          [-1.8056e-02,  1.1724e-01,  6.5619e-01, -1.2442e-01,  3.9753e-01],\n",
      "          [-9.2839e-03, -2.2627e-02,  7.0249e-01, -6.9503e-02,  4.2136e-01],\n",
      "          [ 7.8602e-02,  2.3841e-01,  8.2858e-01, -3.9176e-02,  4.7192e-01],\n",
      "          [ 1.0314e-01,  1.9472e-01,  7.9178e-01, -1.7264e-01,  3.3009e-01],\n",
      "          [ 3.9216e-02, -4.2306e-02,  3.6577e-01, -9.3257e-02,  3.3896e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0994, 0.1645, 0.4480, 0.1072, 0.1810],\n",
      "          [0.1313, 0.2174, 0.3103, 0.1267, 0.2143],\n",
      "          [0.1096, 0.1784, 0.3833, 0.1156, 0.2131],\n",
      "          [0.0913, 0.1685, 0.4326, 0.1068, 0.2008],\n",
      "          [0.1060, 0.2157, 0.3396, 0.1176, 0.2212],\n",
      "          [0.1211, 0.1950, 0.3524, 0.1292, 0.2022],\n",
      "          [0.1276, 0.1895, 0.3306, 0.1345, 0.2178],\n",
      "          [0.1094, 0.1958, 0.3333, 0.1248, 0.2368]],\n",
      "\n",
      "         [[0.1919, 0.1249, 0.1740, 0.3415, 0.1677],\n",
      "          [0.2180, 0.1868, 0.1712, 0.2604, 0.1636],\n",
      "          [0.2391, 0.1468, 0.1428, 0.3230, 0.1483],\n",
      "          [0.2423, 0.1057, 0.1787, 0.3364, 0.1368],\n",
      "          [0.2432, 0.1260, 0.1454, 0.3065, 0.1789],\n",
      "          [0.2375, 0.1151, 0.1962, 0.3120, 0.1392],\n",
      "          [0.2490, 0.1239, 0.1522, 0.2966, 0.1783],\n",
      "          [0.2276, 0.1071, 0.2079, 0.3078, 0.1496]],\n",
      "\n",
      "         [[0.2386, 0.1611, 0.1386, 0.2712, 0.1906],\n",
      "          [0.2146, 0.1665, 0.1522, 0.2712, 0.1955],\n",
      "          [0.2466, 0.1447, 0.1341, 0.2702, 0.2044],\n",
      "          [0.2189, 0.1571, 0.1311, 0.3024, 0.1904],\n",
      "          [0.2408, 0.1686, 0.1401, 0.2652, 0.1853],\n",
      "          [0.2388, 0.1640, 0.1751, 0.2148, 0.2073],\n",
      "          [0.2461, 0.1802, 0.1529, 0.2394, 0.1814],\n",
      "          [0.2206, 0.2031, 0.1885, 0.2287, 0.1591]],\n",
      "\n",
      "         [[0.1634, 0.1887, 0.2341, 0.1345, 0.2792],\n",
      "          [0.1434, 0.1932, 0.2867, 0.1308, 0.2458],\n",
      "          [0.1506, 0.1600, 0.3145, 0.1217, 0.2531],\n",
      "          [0.1533, 0.1755, 0.3009, 0.1379, 0.2323],\n",
      "          [0.1537, 0.1517, 0.3133, 0.1448, 0.2365],\n",
      "          [0.1501, 0.1761, 0.3178, 0.1334, 0.2225],\n",
      "          [0.1639, 0.1796, 0.3264, 0.1244, 0.2057],\n",
      "          [0.1807, 0.1666, 0.2505, 0.1583, 0.2439]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[ 3.6967e-01,  3.3705e-01,  2.2888e-01,  8.1715e-02,  1.9903e-01,\n",
      "            2.4701e-01,  3.0020e-02,  2.1614e-01],\n",
      "          [ 1.6678e-01,  1.7034e-01, -1.6626e-02, -1.6423e-02,  5.2746e-02,\n",
      "            8.9430e-02, -7.7754e-02,  2.7644e-02],\n",
      "          [-3.6960e-02, -1.3913e-02, -3.6538e-02, -8.9798e-02, -1.1892e-02,\n",
      "            1.0901e-02, -7.5953e-02,  1.5777e-02],\n",
      "          [ 1.0598e-01,  1.3937e-01,  1.3184e-01,  1.1233e-01,  1.5632e-01,\n",
      "            1.1576e-01,  3.0535e-02,  7.6057e-02],\n",
      "          [ 3.6310e-02, -3.7020e-04, -7.0756e-02, -2.6260e-02,  4.9480e-02,\n",
      "           -7.1746e-02, -7.5529e-02, -2.2058e-02],\n",
      "          [ 1.0830e-01,  1.2236e-01,  1.2784e-01,  1.4029e-01,  1.6542e-01,\n",
      "            5.1111e-02,  4.4386e-02,  9.4845e-02],\n",
      "          [ 1.2564e-02, -1.6296e-02, -4.9962e-02, -2.1986e-02,  6.0989e-02,\n",
      "           -7.0980e-02, -5.3233e-02, -1.0177e-02],\n",
      "          [-1.8099e-01, -7.7930e-02, -6.7820e-02,  2.7918e-02,  1.2538e-01,\n",
      "            1.9165e-02,  8.5753e-02,  7.6514e-03]],\n",
      "\n",
      "         [[-1.0166e-01, -3.7953e-01,  9.7978e-02,  5.3172e-02, -1.6903e-01,\n",
      "            1.0520e-01,  1.1132e-01,  1.2006e-01],\n",
      "          [-3.8316e-01, -5.9255e-01, -1.4718e-01, -1.1555e-01, -3.2597e-01,\n",
      "           -5.4404e-02,  3.2472e-02, -1.0694e-01],\n",
      "          [-9.6332e-02, -3.4722e-01,  1.2696e-01,  6.7357e-02, -8.1257e-02,\n",
      "            2.6299e-01,  2.0476e-01,  1.5671e-01],\n",
      "          [ 2.9140e-02, -2.6646e-01,  2.4998e-01,  1.9482e-01,  5.9361e-02,\n",
      "            3.1068e-01,  3.4559e-01,  3.0141e-01],\n",
      "          [-2.5954e-01, -4.8553e-01,  3.7774e-03,  8.5332e-04, -2.0164e-01,\n",
      "            9.6450e-02,  1.3500e-01,  4.2416e-02],\n",
      "          [-1.0419e-01, -3.7915e-01,  1.6329e-01,  9.8384e-02, -8.8717e-02,\n",
      "            1.1537e-01,  1.3692e-01,  1.6925e-01],\n",
      "          [-2.4056e-01, -4.5450e-01,  1.1177e-01,  5.1622e-02, -1.5081e-01,\n",
      "            1.1475e-01,  1.9174e-01,  7.9003e-02],\n",
      "          [-2.4063e-01, -4.9163e-01,  1.4586e-01,  4.8555e-02, -1.8870e-01,\n",
      "            1.0731e-01,  9.2463e-02,  1.2638e-01]],\n",
      "\n",
      "         [[ 8.8621e-01,  7.4725e-01,  6.7384e-01,  9.5415e-01,  8.6535e-01,\n",
      "            8.5512e-01,  9.5850e-01,  6.0498e-01],\n",
      "          [ 7.2364e-01,  5.9320e-01,  4.8567e-01,  6.8877e-01,  5.8896e-01,\n",
      "            5.6163e-01,  6.2275e-01,  3.0227e-01],\n",
      "          [ 5.4043e-01,  5.1904e-01,  3.9524e-01,  5.9266e-01,  5.5939e-01,\n",
      "            6.0358e-01,  6.0405e-01,  2.9714e-01],\n",
      "          [ 7.7306e-01,  6.7546e-01,  5.1772e-01,  8.5639e-01,  7.8150e-01,\n",
      "            7.6983e-01,  7.2311e-01,  5.0881e-01],\n",
      "          [ 5.5944e-01,  4.3950e-01,  2.8435e-01,  5.8014e-01,  5.4614e-01,\n",
      "            4.8971e-01,  4.9481e-01,  2.7557e-01],\n",
      "          [ 5.9941e-01,  4.4438e-01,  2.9176e-01,  7.4489e-01,  6.4998e-01,\n",
      "            6.4856e-01,  6.7110e-01,  3.9058e-01],\n",
      "          [ 6.0975e-01,  4.9978e-01,  2.7968e-01,  6.4851e-01,  6.1478e-01,\n",
      "            6.0632e-01,  6.5998e-01,  3.6035e-01],\n",
      "          [ 6.4024e-01,  5.4320e-01,  2.9245e-01,  6.9586e-01,  7.2797e-01,\n",
      "            7.0830e-01,  7.5192e-01,  4.7674e-01]],\n",
      "\n",
      "         [[-8.3140e-02, -3.2902e-01, -2.7352e-01, -8.6076e-02, -3.3772e-01,\n",
      "           -1.1234e-01, -2.7233e-01, -2.7573e-01],\n",
      "          [ 1.7063e-01, -1.6951e-01,  9.3442e-03,  1.2459e-01, -8.5454e-02,\n",
      "            1.6832e-01,  5.4360e-02,  7.2270e-02],\n",
      "          [ 2.2130e-01, -1.5323e-01, -7.8852e-02,  1.5963e-02, -2.5041e-01,\n",
      "            8.6459e-02, -1.2556e-01, -4.0605e-02],\n",
      "          [ 2.0185e-01, -1.0512e-01, -3.0342e-02,  6.9556e-02, -1.1085e-01,\n",
      "            9.0010e-02,  9.2876e-03,  6.0572e-02],\n",
      "          [ 2.5523e-01, -1.1417e-01,  1.4879e-02,  5.5137e-02, -7.0419e-02,\n",
      "            1.6077e-01,  4.5359e-02,  9.8099e-02],\n",
      "          [ 2.3031e-01, -1.2897e-01, -1.6670e-02,  8.6198e-02, -1.0450e-01,\n",
      "            1.2838e-01,  2.5025e-02,  3.9554e-02],\n",
      "          [ 2.5883e-01, -3.8634e-02,  9.2753e-03,  5.0795e-02, -1.1577e-01,\n",
      "            1.4830e-01,  7.4211e-03,  6.8125e-02],\n",
      "          [ 5.0404e-01,  1.3096e-01,  3.1154e-01,  2.6152e-01,  8.2398e-02,\n",
      "            4.4239e-01,  2.8606e-01,  3.6960e-01]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1453, 0.1406, 0.1262, 0.1089, 0.1225, 0.1285, 0.1034, 0.1246],\n",
      "          [0.1401, 0.1406, 0.1166, 0.1166, 0.1250, 0.1296, 0.1097, 0.1219],\n",
      "          [0.1240, 0.1269, 0.1241, 0.1176, 0.1272, 0.1301, 0.1193, 0.1307],\n",
      "          [0.1246, 0.1288, 0.1279, 0.1254, 0.1310, 0.1258, 0.1155, 0.1209],\n",
      "          [0.1324, 0.1277, 0.1190, 0.1244, 0.1342, 0.1189, 0.1184, 0.1249],\n",
      "          [0.1251, 0.1269, 0.1276, 0.1292, 0.1324, 0.1181, 0.1173, 0.1234],\n",
      "          [0.1289, 0.1252, 0.1211, 0.1245, 0.1353, 0.1185, 0.1207, 0.1260],\n",
      "          [0.1047, 0.1160, 0.1172, 0.1290, 0.1422, 0.1279, 0.1367, 0.1264]],\n",
      "\n",
      "         [[0.1137, 0.0861, 0.1388, 0.1327, 0.1063, 0.1398, 0.1407, 0.1419],\n",
      "          [0.1035, 0.0839, 0.1310, 0.1352, 0.1095, 0.1437, 0.1568, 0.1364],\n",
      "          [0.1076, 0.0837, 0.1345, 0.1267, 0.1092, 0.1541, 0.1454, 0.1386],\n",
      "          [0.1085, 0.0808, 0.1354, 0.1281, 0.1119, 0.1438, 0.1490, 0.1425],\n",
      "          [0.1029, 0.0821, 0.1339, 0.1335, 0.1090, 0.1469, 0.1526, 0.1391],\n",
      "          [0.1094, 0.0831, 0.1430, 0.1340, 0.1111, 0.1363, 0.1393, 0.1438],\n",
      "          [0.0999, 0.0807, 0.1421, 0.1338, 0.1093, 0.1426, 0.1540, 0.1376],\n",
      "          [0.1011, 0.0786, 0.1488, 0.1350, 0.1065, 0.1431, 0.1410, 0.1459]],\n",
      "\n",
      "         [[0.1328, 0.1156, 0.1074, 0.1422, 0.1301, 0.1288, 0.1428, 0.1003],\n",
      "          [0.1446, 0.1269, 0.1140, 0.1396, 0.1264, 0.1230, 0.1307, 0.0949],\n",
      "          [0.1277, 0.1250, 0.1104, 0.1345, 0.1301, 0.1360, 0.1361, 0.1001],\n",
      "          [0.1335, 0.1210, 0.1034, 0.1451, 0.1346, 0.1330, 0.1270, 0.1025],\n",
      "          [0.1374, 0.1219, 0.1044, 0.1403, 0.1356, 0.1282, 0.1288, 0.1035],\n",
      "          [0.1293, 0.1107, 0.0950, 0.1495, 0.1360, 0.1358, 0.1389, 0.1049],\n",
      "          [0.1336, 0.1197, 0.0960, 0.1388, 0.1342, 0.1331, 0.1405, 0.1041],\n",
      "          [0.1282, 0.1163, 0.0905, 0.1355, 0.1400, 0.1372, 0.1433, 0.1089]],\n",
      "\n",
      "         [[0.1428, 0.1116, 0.1180, 0.1423, 0.1107, 0.1387, 0.1182, 0.1178],\n",
      "          [0.1411, 0.1004, 0.1201, 0.1348, 0.1092, 0.1408, 0.1256, 0.1279],\n",
      "          [0.1608, 0.1106, 0.1191, 0.1310, 0.1004, 0.1406, 0.1137, 0.1238],\n",
      "          [0.1487, 0.1094, 0.1179, 0.1303, 0.1088, 0.1330, 0.1227, 0.1291],\n",
      "          [0.1517, 0.1048, 0.1193, 0.1242, 0.1095, 0.1380, 0.1230, 0.1296],\n",
      "          [0.1514, 0.1057, 0.1183, 0.1311, 0.1083, 0.1367, 0.1233, 0.1251],\n",
      "          [0.1534, 0.1139, 0.1195, 0.1245, 0.1054, 0.1373, 0.1193, 0.1267],\n",
      "          [0.1521, 0.1048, 0.1255, 0.1194, 0.0998, 0.1430, 0.1223, 0.1330]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 4.7667e-01,  1.9081e-01, -5.4118e-02, -2.4597e-02,  2.3676e-01],\n",
      "          [ 2.9622e-01, -4.8447e-02, -1.0971e-01, -1.9018e-01, -1.8632e-02],\n",
      "          [ 5.7642e-01,  1.4857e-01,  1.6183e-01, -1.2582e-01,  1.7456e-01],\n",
      "          [ 5.8970e-01,  1.4406e-01,  1.5563e-01,  1.9210e-01,  3.3440e-01],\n",
      "          [ 6.0309e-01,  1.7136e-01, -8.9688e-03, -1.0619e-02,  1.0523e-01],\n",
      "          [ 2.8512e-01,  1.3985e-01,  2.7638e-02, -9.9317e-02, -6.8296e-02],\n",
      "          [ 2.6852e-01,  1.1631e-01, -1.3586e-01, -2.2612e-01, -3.6381e-02],\n",
      "          [ 3.3055e-01, -3.3044e-02, -1.5758e-01,  2.0994e-02,  1.3815e-01]],\n",
      "\n",
      "         [[-1.6476e-01,  1.0734e-01,  3.8840e-01,  1.3299e-02,  1.2800e-02],\n",
      "          [-2.1867e-01, -1.5102e-02,  4.6702e-01,  1.4254e-01, -2.2698e-02],\n",
      "          [-4.1006e-02,  3.5845e-02,  5.7628e-01,  1.4119e-01,  2.0623e-01],\n",
      "          [ 5.1639e-02,  2.9208e-02,  4.0560e-01,  1.9303e-01,  3.1950e-01],\n",
      "          [ 1.4171e-01,  3.4485e-01,  5.1421e-01,  1.4862e-01,  3.1014e-01],\n",
      "          [ 5.9898e-02,  9.8780e-03,  3.9199e-01,  2.2653e-01,  3.6056e-01],\n",
      "          [ 4.3874e-02,  2.2314e-01,  2.5453e-01,  1.8710e-01,  3.3361e-01],\n",
      "          [ 4.3469e-02,  1.8135e-01,  3.5800e-01,  2.5116e-01,  2.7824e-01]],\n",
      "\n",
      "         [[ 4.6269e-01, -5.1172e-02,  2.4960e-01, -1.9815e-02,  1.9543e-01],\n",
      "          [ 1.5936e-01, -2.5228e-01,  9.3044e-03, -4.9025e-01,  5.1370e-02],\n",
      "          [ 3.7592e-01,  5.2936e-04,  2.7355e-01, -2.7071e-01,  2.9726e-01],\n",
      "          [ 3.3065e-01, -1.1314e-01,  1.6258e-01, -3.0200e-01,  2.1093e-01],\n",
      "          [ 2.6670e-01, -2.1046e-01,  1.2450e-01, -6.1591e-01, -2.2465e-02],\n",
      "          [ 2.3065e-01, -2.5880e-01,  1.1022e-01, -4.6140e-01, -7.5475e-02],\n",
      "          [ 2.9922e-01, -2.2621e-01,  1.2467e-01, -3.5215e-01,  4.1930e-02],\n",
      "          [ 1.9822e-01, -1.1350e-01,  7.5341e-02, -2.6833e-01,  2.0998e-01]],\n",
      "\n",
      "         [[ 3.3805e-01, -2.7366e-01, -2.7474e-01,  6.0184e-02,  3.5338e-01],\n",
      "          [ 2.8245e-01, -2.6819e-01,  6.4712e-02,  4.2440e-01,  1.8329e-01],\n",
      "          [ 4.8782e-01, -1.8894e-01,  2.9886e-01,  3.1575e-01,  2.8600e-01],\n",
      "          [ 4.2447e-01, -1.6353e-01,  2.0623e-01,  2.7668e-01,  3.3779e-01],\n",
      "          [ 2.9454e-01, -1.4432e-01,  3.7656e-01,  3.4417e-01,  3.1297e-01],\n",
      "          [ 3.4900e-01, -2.9680e-01,  6.6078e-02,  2.3204e-01,  1.8534e-01],\n",
      "          [ 2.4889e-01, -2.9773e-01,  1.5561e-01,  1.0823e-01,  2.5199e-01],\n",
      "          [ 2.3442e-01, -3.4560e-01, -1.3255e-02, -1.2806e-01,  1.7034e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2680, 0.2013, 0.1576, 0.1623, 0.2108],\n",
      "          [0.2688, 0.1905, 0.1792, 0.1653, 0.1962],\n",
      "          [0.2876, 0.1875, 0.1900, 0.1425, 0.1924],\n",
      "          [0.2677, 0.1715, 0.1735, 0.1799, 0.2074],\n",
      "          [0.2993, 0.1944, 0.1623, 0.1620, 0.1819],\n",
      "          [0.2487, 0.2151, 0.1922, 0.1693, 0.1747],\n",
      "          [0.2582, 0.2217, 0.1723, 0.1574, 0.1903],\n",
      "          [0.2586, 0.1797, 0.1587, 0.1897, 0.2133]],\n",
      "\n",
      "         [[0.1553, 0.2038, 0.2700, 0.1855, 0.1854],\n",
      "          [0.1457, 0.1786, 0.2893, 0.2091, 0.1773],\n",
      "          [0.1559, 0.1684, 0.2890, 0.1871, 0.1996],\n",
      "          [0.1706, 0.1668, 0.2431, 0.1965, 0.2230],\n",
      "          [0.1704, 0.2088, 0.2474, 0.1716, 0.2017],\n",
      "          [0.1702, 0.1618, 0.2372, 0.2010, 0.2298],\n",
      "          [0.1689, 0.2021, 0.2085, 0.1949, 0.2257],\n",
      "          [0.1663, 0.1909, 0.2278, 0.2047, 0.2103]],\n",
      "\n",
      "         [[0.2639, 0.1579, 0.2133, 0.1629, 0.2020],\n",
      "          [0.2536, 0.1680, 0.2183, 0.1324, 0.2276],\n",
      "          [0.2477, 0.1701, 0.2236, 0.1297, 0.2289],\n",
      "          [0.2561, 0.1643, 0.2165, 0.1360, 0.2272],\n",
      "          [0.2739, 0.1700, 0.2376, 0.1133, 0.2051],\n",
      "          [0.2676, 0.1641, 0.2373, 0.1340, 0.1971],\n",
      "          [0.2684, 0.1587, 0.2254, 0.1399, 0.2075],\n",
      "          [0.2350, 0.1721, 0.2078, 0.1474, 0.2378]],\n",
      "\n",
      "         [[0.2593, 0.1406, 0.1405, 0.1964, 0.2633],\n",
      "          [0.2253, 0.1299, 0.1812, 0.2596, 0.2040],\n",
      "          [0.2503, 0.1272, 0.2072, 0.2107, 0.2046],\n",
      "          [0.2416, 0.1342, 0.1942, 0.2084, 0.2215],\n",
      "          [0.2083, 0.1343, 0.2262, 0.2189, 0.2122],\n",
      "          [0.2490, 0.1305, 0.1876, 0.2215, 0.2114],\n",
      "          [0.2293, 0.1327, 0.2088, 0.1992, 0.2300],\n",
      "          [0.2516, 0.1409, 0.1964, 0.1751, 0.2360]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0362,  0.0578, -0.1801, -0.2322, -0.2778, -0.3808, -0.1814,\n",
      "           -0.3504],\n",
      "          [ 0.0737,  0.0219, -0.1228, -0.1632, -0.3340, -0.3215, -0.1817,\n",
      "           -0.3596],\n",
      "          [ 0.1768,  0.1425, -0.0418, -0.0857, -0.2033, -0.2326, -0.0211,\n",
      "           -0.2105],\n",
      "          [ 0.0022, -0.1382, -0.2631, -0.3588, -0.3854, -0.4561, -0.3320,\n",
      "           -0.3473],\n",
      "          [-0.0940, -0.0802, -0.2553, -0.2689, -0.2757, -0.3858, -0.1991,\n",
      "           -0.3713],\n",
      "          [-0.1087, -0.1188, -0.1740, -0.2274, -0.2957, -0.3702, -0.2811,\n",
      "           -0.2707],\n",
      "          [ 0.0249,  0.0453, -0.0746, -0.1492, -0.1594, -0.2283, -0.0380,\n",
      "           -0.2572],\n",
      "          [-0.0961, -0.0690, -0.1897, -0.3493, -0.3057, -0.4176, -0.0806,\n",
      "           -0.2859]],\n",
      "\n",
      "         [[ 0.4039,  0.2938,  0.3463,  0.2923,  0.2150,  0.0851,  0.2623,\n",
      "            0.2390],\n",
      "          [ 0.2880,  0.2725,  0.2995,  0.2631,  0.2242,  0.1509,  0.2622,\n",
      "            0.2677],\n",
      "          [ 0.0060,  0.1555,  0.1316,  0.0166,  0.1262, -0.0380,  0.1690,\n",
      "            0.0521],\n",
      "          [ 0.2428,  0.3109,  0.3363,  0.2844,  0.1979,  0.1123,  0.2847,\n",
      "            0.1213],\n",
      "          [ 0.4619,  0.5815,  0.5571,  0.5272,  0.4868,  0.4275,  0.5693,\n",
      "            0.4063],\n",
      "          [ 0.1824,  0.3305,  0.3063,  0.3461,  0.2727,  0.1429,  0.2391,\n",
      "            0.2794],\n",
      "          [ 0.1255,  0.3944,  0.3901,  0.3497,  0.3216,  0.1753,  0.3720,\n",
      "            0.2480],\n",
      "          [ 0.1825,  0.2185,  0.2894,  0.2779,  0.1788,  0.0885,  0.2270,\n",
      "            0.1334]],\n",
      "\n",
      "         [[ 0.5297,  0.5439,  0.4917,  0.4615,  0.5144,  0.4080,  0.3861,\n",
      "            0.3573],\n",
      "          [ 0.5142,  0.5161,  0.5148,  0.4524,  0.5324,  0.3589,  0.3719,\n",
      "            0.2850],\n",
      "          [ 0.2932,  0.5034,  0.4640,  0.3816,  0.4728,  0.3116,  0.3384,\n",
      "            0.2719],\n",
      "          [ 0.4003,  0.3452,  0.3827,  0.3474,  0.3578,  0.2296,  0.2764,\n",
      "            0.2037],\n",
      "          [ 0.5285,  0.4026,  0.5235,  0.5166,  0.5637,  0.4950,  0.4224,\n",
      "            0.3243],\n",
      "          [ 0.4321,  0.3658,  0.4256,  0.3349,  0.3447,  0.1802,  0.2760,\n",
      "            0.1721],\n",
      "          [ 0.4161,  0.2728,  0.4838,  0.3435,  0.3023,  0.2457,  0.3441,\n",
      "            0.3324],\n",
      "          [ 0.4139,  0.3323,  0.4208,  0.4019,  0.5348,  0.4734,  0.4489,\n",
      "            0.4168]],\n",
      "\n",
      "         [[ 0.1108,  0.0268, -0.0898,  0.0210, -0.2436,  0.0922, -0.1492,\n",
      "            0.0287],\n",
      "          [ 0.2247,  0.0060,  0.1025,  0.1525, -0.0875,  0.2094, -0.0571,\n",
      "            0.0684],\n",
      "          [ 0.2733,  0.0487,  0.1083,  0.2597, -0.0693,  0.1698,  0.0450,\n",
      "            0.1664],\n",
      "          [ 0.2458,  0.0224,  0.0929,  0.2046, -0.0768,  0.1066, -0.0187,\n",
      "            0.1262],\n",
      "          [ 0.3277,  0.0789,  0.0548,  0.1997, -0.1009,  0.1160, -0.0635,\n",
      "            0.0543],\n",
      "          [ 0.2211, -0.1304, -0.1093,  0.0998, -0.1896,  0.0422, -0.1839,\n",
      "            0.0499],\n",
      "          [ 0.1348, -0.1791, -0.0885, -0.0341, -0.2261,  0.0446, -0.1680,\n",
      "            0.0175],\n",
      "          [ 0.2357,  0.0899,  0.0075,  0.0746, -0.1006,  0.0780, -0.1383,\n",
      "            0.0505]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1454, 0.1598, 0.1259, 0.1196, 0.1142, 0.1030, 0.1258, 0.1062],\n",
      "          [0.1582, 0.1502, 0.1300, 0.1248, 0.1052, 0.1065, 0.1225, 0.1026],\n",
      "          [0.1566, 0.1513, 0.1258, 0.1204, 0.1071, 0.1040, 0.1285, 0.1063],\n",
      "          [0.1649, 0.1433, 0.1265, 0.1149, 0.1119, 0.1043, 0.1180, 0.1162],\n",
      "          [0.1440, 0.1460, 0.1226, 0.1209, 0.1201, 0.1076, 0.1297, 0.1091],\n",
      "          [0.1407, 0.1393, 0.1318, 0.1250, 0.1167, 0.1083, 0.1184, 0.1197],\n",
      "          [0.1415, 0.1444, 0.1281, 0.1189, 0.1177, 0.1098, 0.1329, 0.1067],\n",
      "          [0.1410, 0.1449, 0.1284, 0.1094, 0.1143, 0.1022, 0.1432, 0.1166]],\n",
      "\n",
      "         [[0.1428, 0.1279, 0.1348, 0.1277, 0.1182, 0.1038, 0.1239, 0.1211],\n",
      "          [0.1293, 0.1273, 0.1308, 0.1261, 0.1213, 0.1127, 0.1260, 0.1267],\n",
      "          [0.1161, 0.1348, 0.1316, 0.1173, 0.1309, 0.1111, 0.1366, 0.1216],\n",
      "          [0.1254, 0.1343, 0.1377, 0.1307, 0.1199, 0.1101, 0.1308, 0.1111],\n",
      "          [0.1198, 0.1350, 0.1318, 0.1279, 0.1229, 0.1158, 0.1334, 0.1133],\n",
      "          [0.1151, 0.1335, 0.1303, 0.1356, 0.1260, 0.1107, 0.1219, 0.1269],\n",
      "          [0.1048, 0.1372, 0.1366, 0.1312, 0.1275, 0.1102, 0.1341, 0.1185],\n",
      "          [0.1226, 0.1271, 0.1365, 0.1349, 0.1222, 0.1116, 0.1282, 0.1168]],\n",
      "\n",
      "         [[0.1335, 0.1354, 0.1286, 0.1247, 0.1315, 0.1182, 0.1157, 0.1124],\n",
      "          [0.1337, 0.1340, 0.1338, 0.1257, 0.1362, 0.1145, 0.1160, 0.1063],\n",
      "          [0.1142, 0.1410, 0.1355, 0.1248, 0.1367, 0.1164, 0.1195, 0.1118],\n",
      "          [0.1354, 0.1282, 0.1331, 0.1285, 0.1298, 0.1142, 0.1196, 0.1113],\n",
      "          [0.1319, 0.1163, 0.1312, 0.1303, 0.1366, 0.1275, 0.1186, 0.1075],\n",
      "          [0.1397, 0.1308, 0.1388, 0.1268, 0.1280, 0.1086, 0.1195, 0.1077],\n",
      "          [0.1342, 0.1163, 0.1436, 0.1248, 0.1197, 0.1132, 0.1249, 0.1234],\n",
      "          [0.1228, 0.1132, 0.1236, 0.1213, 0.1386, 0.1303, 0.1271, 0.1231]],\n",
      "\n",
      "         [[0.1423, 0.1308, 0.1164, 0.1301, 0.0998, 0.1397, 0.1097, 0.1311],\n",
      "          [0.1440, 0.1157, 0.1274, 0.1340, 0.1054, 0.1418, 0.1086, 0.1231],\n",
      "          [0.1441, 0.1151, 0.1222, 0.1422, 0.1023, 0.1299, 0.1147, 0.1295],\n",
      "          [0.1456, 0.1165, 0.1250, 0.1397, 0.1055, 0.1267, 0.1118, 0.1292],\n",
      "          [0.1583, 0.1234, 0.1205, 0.1392, 0.1031, 0.1281, 0.1070, 0.1204],\n",
      "          [0.1583, 0.1114, 0.1138, 0.1402, 0.1050, 0.1324, 0.1056, 0.1334],\n",
      "          [0.1512, 0.1105, 0.1209, 0.1277, 0.1054, 0.1382, 0.1117, 0.1345],\n",
      "          [0.1515, 0.1310, 0.1206, 0.1290, 0.1083, 0.1294, 0.1043, 0.1259]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3387,  0.1782, -0.2699,  0.0596,  0.0606],\n",
      "          [ 0.4419,  0.5562, -0.0717,  0.4670,  0.1781],\n",
      "          [ 0.2337,  0.4189, -0.1866,  0.3621,  0.2585],\n",
      "          [ 0.2548,  0.4735, -0.2022,  0.2360,  0.3209],\n",
      "          [ 0.2252,  0.5391, -0.1264,  0.5041,  0.3911],\n",
      "          [ 0.3634,  0.5675,  0.0027,  0.2162,  0.4525],\n",
      "          [ 0.3993,  0.3887,  0.0017,  0.3514,  0.4452],\n",
      "          [ 0.2593,  0.3725, -0.1356,  0.0239,  0.3279]],\n",
      "\n",
      "         [[-0.4471, -0.5821, -0.2084, -0.1868, -0.4534],\n",
      "          [-0.3563, -0.5873, -0.1986, -0.3922, -0.4207],\n",
      "          [-0.4139, -0.5450, -0.2794, -0.2191, -0.4430],\n",
      "          [-0.4348, -0.6882, -0.3742, -0.2525, -0.3545],\n",
      "          [-0.2995, -0.6008, -0.3766, -0.3258, -0.2843],\n",
      "          [-0.4461, -0.4315, -0.2992, -0.1186, -0.1741],\n",
      "          [-0.3057, -0.5530, -0.3327, -0.1927, -0.0262],\n",
      "          [-0.3639, -0.6406, -0.3931, -0.1253, -0.4213]],\n",
      "\n",
      "         [[-0.0807,  0.0782, -0.3550, -0.3334, -0.5219],\n",
      "          [-0.3377, -0.1895, -0.5330, -0.3068, -0.3469],\n",
      "          [-0.2746,  0.0746, -0.3673, -0.1635, -0.3987],\n",
      "          [-0.1684, -0.0704, -0.2271, -0.1359, -0.4116],\n",
      "          [-0.1458, -0.1235, -0.3549, -0.3316, -0.4058],\n",
      "          [-0.0516, -0.2326, -0.2924, -0.2046, -0.4417],\n",
      "          [-0.2402, -0.3094, -0.4455, -0.2746, -0.6023],\n",
      "          [-0.1465, -0.0687, -0.3544, -0.0310, -0.2969]],\n",
      "\n",
      "         [[-0.1045,  0.0348,  0.2356,  0.4832,  0.1730],\n",
      "          [-0.3248, -0.0945, -0.0460,  0.3624, -0.0096],\n",
      "          [-0.2280,  0.2405,  0.1574,  0.5187,  0.0769],\n",
      "          [-0.0479,  0.2696,  0.1861,  0.8351,  0.5543],\n",
      "          [-0.2825, -0.0268,  0.1063,  0.6623,  0.2448],\n",
      "          [-0.2268,  0.3602,  0.3025,  0.5700,  0.4586],\n",
      "          [-0.2955,  0.3727,  0.2108,  0.6526,  0.2490],\n",
      "          [-0.2491,  0.3410,  0.3050,  0.6735,  0.3905]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1486, 0.2492, 0.1592, 0.2214, 0.2216],\n",
      "          [0.2216, 0.2484, 0.1326, 0.2272, 0.1702],\n",
      "          [0.1991, 0.2396, 0.1308, 0.2264, 0.2041],\n",
      "          [0.2030, 0.2526, 0.1285, 0.1992, 0.2168],\n",
      "          [0.1794, 0.2455, 0.1262, 0.2371, 0.2118],\n",
      "          [0.2049, 0.2513, 0.1429, 0.1769, 0.2240],\n",
      "          [0.2145, 0.2123, 0.1441, 0.2045, 0.2246],\n",
      "          [0.2148, 0.2406, 0.1447, 0.1698, 0.2301]],\n",
      "\n",
      "         [[0.1840, 0.1608, 0.2336, 0.2387, 0.1829],\n",
      "          [0.2055, 0.1631, 0.2406, 0.1982, 0.1927],\n",
      "          [0.1920, 0.1684, 0.2197, 0.2333, 0.1865],\n",
      "          [0.1952, 0.1515, 0.2074, 0.2343, 0.2115],\n",
      "          [0.2148, 0.1589, 0.1989, 0.2092, 0.2181],\n",
      "          [0.1703, 0.1728, 0.1972, 0.2362, 0.2235],\n",
      "          [0.1924, 0.1503, 0.1873, 0.2155, 0.2545],\n",
      "          [0.2023, 0.1534, 0.1965, 0.2568, 0.1910]],\n",
      "\n",
      "         [[0.2298, 0.2693, 0.1746, 0.1785, 0.1478],\n",
      "          [0.1998, 0.2317, 0.1644, 0.2061, 0.1980],\n",
      "          [0.1876, 0.2660, 0.1710, 0.2097, 0.1657],\n",
      "          [0.2056, 0.2268, 0.1939, 0.2124, 0.1612],\n",
      "          [0.2255, 0.2306, 0.1829, 0.1872, 0.1738],\n",
      "          [0.2406, 0.2008, 0.1891, 0.2065, 0.1629],\n",
      "          [0.2268, 0.2116, 0.1847, 0.2191, 0.1579],\n",
      "          [0.2051, 0.2217, 0.1666, 0.2302, 0.1764]],\n",
      "\n",
      "         [[0.1498, 0.1722, 0.2105, 0.2697, 0.1978],\n",
      "          [0.1441, 0.1814, 0.1905, 0.2865, 0.1975],\n",
      "          [0.1327, 0.2120, 0.1951, 0.2801, 0.1800],\n",
      "          [0.1269, 0.1743, 0.1603, 0.3068, 0.2317],\n",
      "          [0.1245, 0.1607, 0.1836, 0.3202, 0.2109],\n",
      "          [0.1150, 0.2068, 0.1951, 0.2550, 0.2281],\n",
      "          [0.1122, 0.2188, 0.1861, 0.2895, 0.1934],\n",
      "          [0.1117, 0.2014, 0.1943, 0.2809, 0.2117]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.3941e+00,  7.3573e-01,  4.8010e-01,  1.3993e-01, -4.2648e-01],\n",
      "          [ 7.7318e-01, -2.7346e-01,  5.9892e-01, -5.8355e-02,  2.1268e-01],\n",
      "          [ 1.0628e+00, -8.9228e-02,  4.5012e-02,  1.0023e+00, -2.0073e-01],\n",
      "          [ 4.4724e-01,  7.6745e-01, -1.2125e-01, -1.0611e-01,  1.0556e-01],\n",
      "          [-2.3822e-01,  1.9508e-01, -2.6983e-01, -1.5519e-01, -2.9096e-01]],\n",
      "\n",
      "         [[-1.4768e-01, -7.4394e-02, -1.3469e-01,  3.8195e-01,  4.1849e-01],\n",
      "          [-4.8190e-01,  2.9162e-01, -1.1596e-01, -7.3083e-03, -7.5992e-01],\n",
      "          [-3.6189e-04,  4.7503e-01,  5.1416e-01,  1.1818e+00,  1.0591e+00],\n",
      "          [ 3.9976e-01,  2.9305e-01,  1.4997e-01,  2.1205e-01,  3.0346e-01],\n",
      "          [-3.1032e-01,  4.3519e-01,  7.2324e-01,  2.5864e-01,  4.9361e-01]],\n",
      "\n",
      "         [[-1.5512e+00, -1.4662e+00, -8.7653e-01, -4.2643e-01, -2.1262e-01],\n",
      "          [-1.1454e+00, -9.5370e-01, -3.2723e-01, -3.2331e-01, -5.1466e-01],\n",
      "          [-1.0363e+00, -1.1988e+00, -9.5733e-01, -7.2113e-02,  5.9998e-01],\n",
      "          [-6.1110e-01, -1.8330e+00, -5.8626e-01, -1.3575e-01,  4.2618e-01],\n",
      "          [-5.3754e-01, -1.8248e+00,  5.1265e-03, -1.8744e-01,  2.2093e-01]],\n",
      "\n",
      "         [[ 3.7241e-01, -6.1853e-01,  6.4860e-01,  7.7730e-01,  5.4604e-01],\n",
      "          [ 2.8241e-01, -7.9006e-01, -6.2506e-01,  7.2306e-01,  3.4092e-01],\n",
      "          [-3.0054e-01, -9.8207e-01, -7.4913e-01,  2.1650e-01,  1.7700e-01],\n",
      "          [-1.9945e-01,  1.0880e-02, -6.7866e-01, -2.5537e-01, -8.6766e-02],\n",
      "          [ 1.4945e-01, -9.3450e-01, -9.5716e-01,  2.1542e-02,  4.0775e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4227, 0.2188, 0.1695, 0.1206, 0.0684],\n",
      "          [0.3127, 0.1098, 0.2627, 0.1362, 0.1786],\n",
      "          [0.3447, 0.1089, 0.1246, 0.3244, 0.0974],\n",
      "          [0.2364, 0.3257, 0.1339, 0.1360, 0.1680],\n",
      "          [0.1803, 0.2781, 0.1747, 0.1959, 0.1710]],\n",
      "\n",
      "         [[0.1527, 0.1643, 0.1547, 0.2593, 0.2690],\n",
      "          [0.1434, 0.3108, 0.2068, 0.2305, 0.1086],\n",
      "          [0.0959, 0.1543, 0.1604, 0.3128, 0.2766],\n",
      "          [0.2265, 0.2036, 0.1764, 0.1877, 0.2057],\n",
      "          [0.1008, 0.2125, 0.2834, 0.1781, 0.2252]],\n",
      "\n",
      "         [[0.0914, 0.0995, 0.1794, 0.2814, 0.3484],\n",
      "          [0.1159, 0.1403, 0.2626, 0.2636, 0.2177],\n",
      "          [0.0935, 0.0795, 0.1012, 0.2453, 0.4804],\n",
      "          [0.1481, 0.0437, 0.1519, 0.2383, 0.4180],\n",
      "          [0.1527, 0.0421, 0.2627, 0.2166, 0.3259]],\n",
      "\n",
      "         [[0.1859, 0.0690, 0.2451, 0.2787, 0.2212],\n",
      "          [0.2294, 0.0785, 0.0926, 0.3564, 0.2432],\n",
      "          [0.1840, 0.0931, 0.1175, 0.3086, 0.2967],\n",
      "          [0.2033, 0.2509, 0.1259, 0.1923, 0.2276],\n",
      "          [0.2602, 0.0880, 0.0860, 0.2289, 0.3369]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.8215, -0.0413,  0.2010,  0.3123, -0.1933],\n",
      "          [ 0.6723, -0.2735,  0.0407,  0.3576,  0.1400],\n",
      "          [ 0.9759,  0.1691,  0.3972,  0.5925,  0.7250],\n",
      "          [ 0.5183, -0.4947, -0.2209,  0.2713,  0.0919],\n",
      "          [ 0.4940,  0.1105,  0.2828,  0.1587,  0.4430]],\n",
      "\n",
      "         [[ 0.1804,  0.3957,  0.1472,  0.3126,  1.3169],\n",
      "          [ 0.4447,  0.3479, -0.0077, -0.4261,  0.8641],\n",
      "          [ 0.3807,  0.7777, -0.0812,  0.9432,  1.0516],\n",
      "          [ 0.0941, -0.0986,  0.1030,  0.0844,  0.6448],\n",
      "          [ 0.4346,  0.4536,  0.4681, -0.6334,  0.2972]],\n",
      "\n",
      "         [[-0.5863, -0.6476, -0.0732,  0.2235,  0.0736],\n",
      "          [-0.5130,  0.1967,  0.0672, -0.3995, -0.1043],\n",
      "          [-0.6066, -0.1698, -0.3610, -0.2915, -0.2386],\n",
      "          [ 0.3272, -0.3364,  0.0019, -0.1467, -0.1376],\n",
      "          [ 0.0223, -0.0724, -0.0429, -0.1924,  0.1435]],\n",
      "\n",
      "         [[-0.0122, -0.1703, -0.0096,  0.2087,  0.1919],\n",
      "          [-0.0064,  0.3199,  0.0935, -0.1969, -0.1673],\n",
      "          [-0.2546,  0.4582, -0.1828, -0.1055,  0.1660],\n",
      "          [ 0.1400, -0.3562,  0.1488, -0.2030, -0.0431],\n",
      "          [-0.0116, -0.0794, -0.1592, -0.4643, -0.4881]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3421, 0.1444, 0.1839, 0.2056, 0.1240],\n",
      "          [0.3089, 0.1200, 0.1643, 0.2255, 0.1814],\n",
      "          [0.2885, 0.1287, 0.1617, 0.1966, 0.2245],\n",
      "          [0.3054, 0.1109, 0.1458, 0.2385, 0.1994],\n",
      "          [0.2406, 0.1639, 0.1948, 0.1720, 0.2286]],\n",
      "\n",
      "         [[0.1340, 0.1661, 0.1296, 0.1529, 0.4174],\n",
      "          [0.2230, 0.2025, 0.1419, 0.0934, 0.3393],\n",
      "          [0.1464, 0.2178, 0.0923, 0.2570, 0.2865],\n",
      "          [0.1799, 0.1484, 0.1815, 0.1782, 0.3120],\n",
      "          [0.2343, 0.2388, 0.2423, 0.0805, 0.2042]],\n",
      "\n",
      "         [[0.1283, 0.1207, 0.2144, 0.2884, 0.2482],\n",
      "          [0.1343, 0.2731, 0.2399, 0.1505, 0.2021],\n",
      "          [0.1506, 0.2330, 0.1925, 0.2063, 0.2176],\n",
      "          [0.2867, 0.1476, 0.2071, 0.1785, 0.1801],\n",
      "          [0.2091, 0.1902, 0.1959, 0.1687, 0.2361]],\n",
      "\n",
      "         [[0.1876, 0.1602, 0.1881, 0.2340, 0.2301],\n",
      "          [0.1935, 0.2681, 0.2138, 0.1599, 0.1647],\n",
      "          [0.1471, 0.3001, 0.1581, 0.1708, 0.2240],\n",
      "          [0.2404, 0.1463, 0.2425, 0.1706, 0.2002],\n",
      "          [0.2467, 0.2305, 0.2128, 0.1569, 0.1532]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2209,  0.0357, -0.2587, -0.0200,  0.1016],\n",
      "          [-0.2957, -0.1614, -0.1249,  0.1195,  0.0820],\n",
      "          [ 0.2278,  0.8786,  0.3927,  0.2534,  0.7294],\n",
      "          [ 0.2019,  0.2578,  0.0407, -0.2841,  0.1267],\n",
      "          [ 0.0063,  0.3130, -0.1199, -0.0523,  0.2784]],\n",
      "\n",
      "         [[-0.0701,  0.1252,  0.0762, -0.5864, -0.1686],\n",
      "          [-0.2763,  0.0618, -0.0277, -0.4322, -0.6954],\n",
      "          [ 0.1719, -0.1172,  0.5546, -0.4527, -0.3029],\n",
      "          [-0.1523,  0.1846, -0.3388, -0.0138,  0.1466],\n",
      "          [ 0.0244,  0.0650, -0.1958, -0.7689, -0.1226]],\n",
      "\n",
      "         [[-0.0844,  0.2794,  0.0879, -0.3610, -0.2459],\n",
      "          [ 0.0300,  0.1664, -0.0989, -0.9574, -0.4647],\n",
      "          [-0.1841,  0.1868, -0.0644, -0.1193, -0.4174],\n",
      "          [-0.0351, -0.0239, -0.3269, -0.8551, -0.3741],\n",
      "          [ 0.2276,  0.1170, -0.0865, -0.5595, -0.7833]],\n",
      "\n",
      "         [[ 0.3717, -0.2652,  0.5033, -0.0016, -0.1047],\n",
      "          [ 0.3114,  0.2163, -0.2018,  0.3360,  0.1630],\n",
      "          [-0.0774, -0.4197, -0.2938,  0.1558, -0.4199],\n",
      "          [-0.1314,  0.5463,  0.0499, -0.0949, -0.1312],\n",
      "          [ 0.8343,  0.8158,  0.6203,  0.1314, -0.1311]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2425, 0.2015, 0.1501, 0.1906, 0.2152],\n",
      "          [0.1586, 0.1814, 0.1882, 0.2403, 0.2314],\n",
      "          [0.1476, 0.2830, 0.1741, 0.1515, 0.2438],\n",
      "          [0.2247, 0.2376, 0.1912, 0.1382, 0.2084],\n",
      "          [0.1820, 0.2472, 0.1604, 0.1716, 0.2388]],\n",
      "\n",
      "         [[0.2051, 0.2493, 0.2374, 0.1224, 0.1858],\n",
      "          [0.1924, 0.2698, 0.2467, 0.1646, 0.1265],\n",
      "          [0.2287, 0.1713, 0.3353, 0.1225, 0.1423],\n",
      "          [0.1746, 0.2445, 0.1449, 0.2005, 0.2354],\n",
      "          [0.2404, 0.2504, 0.1929, 0.1088, 0.2075]],\n",
      "\n",
      "         [[0.1910, 0.2748, 0.2269, 0.1448, 0.1625],\n",
      "          [0.2495, 0.2860, 0.2194, 0.0930, 0.1521],\n",
      "          [0.1840, 0.2666, 0.2074, 0.1963, 0.1457],\n",
      "          [0.2557, 0.2586, 0.1910, 0.1126, 0.1822],\n",
      "          [0.2903, 0.2599, 0.2120, 0.1321, 0.1056]],\n",
      "\n",
      "         [[0.2513, 0.1329, 0.2867, 0.1730, 0.1561],\n",
      "          [0.2275, 0.2069, 0.1362, 0.2332, 0.1962],\n",
      "          [0.2228, 0.1582, 0.1794, 0.2813, 0.1582],\n",
      "          [0.1611, 0.3174, 0.1932, 0.1671, 0.1612],\n",
      "          [0.2728, 0.2679, 0.2203, 0.1351, 0.1039]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5842, -0.4063, -0.2971,  ..., -0.7211, -0.6380, -0.4262],\n",
      "          [-0.4462, -0.3029, -0.0531,  ..., -0.6306, -0.7077, -0.5049],\n",
      "          [-0.1848, -0.1119,  0.0049,  ..., -0.5795, -0.5925, -0.3272],\n",
      "          ...,\n",
      "          [-0.1899, -0.1246, -0.0962,  ..., -0.4277, -0.7052, -0.3959],\n",
      "          [-0.4917, -0.5262, -0.3696,  ..., -0.7051, -0.9597, -0.6654],\n",
      "          [-0.4777, -0.5266, -0.5926,  ..., -0.7729, -0.9797, -0.6620]],\n",
      "\n",
      "         [[-0.0024,  0.1576, -0.3969,  ..., -0.4129, -0.5717, -0.2673],\n",
      "          [-0.0272,  0.3440, -0.1596,  ..., -0.1789, -0.3426,  0.1326],\n",
      "          [ 0.3307,  0.6349,  0.1572,  ...,  0.2213,  0.1212,  0.3339],\n",
      "          ...,\n",
      "          [-0.1732, -0.1491, -0.4289,  ..., -0.2622, -0.5352, -0.0664],\n",
      "          [ 0.0768,  0.1659, -0.2019,  ...,  0.0670, -0.0719,  0.1982],\n",
      "          [-0.0860,  0.0299, -0.2937,  ..., -0.3060, -0.5435, -0.1919]],\n",
      "\n",
      "         [[ 0.2064,  0.1352,  0.0581,  ...,  0.3994,  0.5592,  0.1838],\n",
      "          [ 0.6364,  0.6095,  0.3984,  ...,  0.6328,  0.7452,  0.3837],\n",
      "          [ 0.4936,  0.5755,  0.3130,  ...,  0.7268,  0.7899,  0.4575],\n",
      "          ...,\n",
      "          [ 0.4481,  0.4465,  0.3285,  ...,  0.6076,  0.5733,  0.5032],\n",
      "          [ 0.1195,  0.1973,  0.1408,  ...,  0.5183,  0.4437,  0.3548],\n",
      "          [-0.1031, -0.0197, -0.1208,  ...,  0.0519,  0.0785, -0.0157]],\n",
      "\n",
      "         [[-0.3281, -0.3174, -0.3599,  ..., -0.3842, -0.6687, -0.2638],\n",
      "          [-0.4033, -0.4404, -0.4987,  ..., -0.4542, -0.6712, -0.2974],\n",
      "          [-0.6358, -0.5513, -0.4541,  ..., -0.4978, -0.6472, -0.2610],\n",
      "          ...,\n",
      "          [-0.7592, -0.5904, -0.4757,  ..., -0.3233, -0.4597, -0.1840],\n",
      "          [-0.6041, -0.3084, -0.2789,  ..., -0.2103, -0.2140, -0.0739],\n",
      "          [-0.6463, -0.5021, -0.4219,  ..., -0.1912, -0.3776, -0.1370]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0562, 0.0671, 0.0748,  ..., 0.0490, 0.0532, 0.0658],\n",
      "          [0.0576, 0.0665, 0.0853,  ..., 0.0479, 0.0443, 0.0543],\n",
      "          [0.0685, 0.0737, 0.0828,  ..., 0.0462, 0.0456, 0.0594],\n",
      "          ...,\n",
      "          [0.0697, 0.0744, 0.0765,  ..., 0.0549, 0.0416, 0.0567],\n",
      "          [0.0684, 0.0661, 0.0773,  ..., 0.0553, 0.0429, 0.0575],\n",
      "          [0.0773, 0.0736, 0.0689,  ..., 0.0575, 0.0468, 0.0643]],\n",
      "\n",
      "         [[0.0740, 0.0868, 0.0499,  ..., 0.0491, 0.0419, 0.0568],\n",
      "          [0.0588, 0.0853, 0.0515,  ..., 0.0505, 0.0429, 0.0690],\n",
      "          [0.0609, 0.0826, 0.0512,  ..., 0.0546, 0.0494, 0.0611],\n",
      "          ...,\n",
      "          [0.0690, 0.0706, 0.0534,  ..., 0.0631, 0.0480, 0.0767],\n",
      "          [0.0633, 0.0692, 0.0479,  ..., 0.0627, 0.0546, 0.0715],\n",
      "          [0.0697, 0.0782, 0.0566,  ..., 0.0559, 0.0441, 0.0627]],\n",
      "\n",
      "         [[0.0667, 0.0621, 0.0575,  ..., 0.0809, 0.0949, 0.0652],\n",
      "          [0.0781, 0.0760, 0.0615,  ..., 0.0778, 0.0870, 0.0606],\n",
      "          [0.0669, 0.0726, 0.0558,  ..., 0.0845, 0.0900, 0.0645],\n",
      "          ...,\n",
      "          [0.0658, 0.0657, 0.0584,  ..., 0.0772, 0.0746, 0.0696],\n",
      "          [0.0575, 0.0622, 0.0587,  ..., 0.0857, 0.0795, 0.0728],\n",
      "          [0.0678, 0.0737, 0.0666,  ..., 0.0791, 0.0813, 0.0740]],\n",
      "\n",
      "         [[0.0552, 0.0558, 0.0535,  ..., 0.0522, 0.0393, 0.0589],\n",
      "          [0.0538, 0.0519, 0.0489,  ..., 0.0512, 0.0412, 0.0599],\n",
      "          [0.0442, 0.0481, 0.0531,  ..., 0.0508, 0.0437, 0.0643],\n",
      "          ...,\n",
      "          [0.0407, 0.0482, 0.0540,  ..., 0.0629, 0.0549, 0.0723],\n",
      "          [0.0406, 0.0546, 0.0562,  ..., 0.0602, 0.0600, 0.0690],\n",
      "          [0.0413, 0.0477, 0.0517,  ..., 0.0651, 0.0540, 0.0687]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3952, -0.2205,  0.5378, -0.2432, -0.3061],\n",
      "          [-0.3254, -0.2406,  0.3660, -0.2883, -0.2148],\n",
      "          [-0.4810,  0.0488,  0.5730, -0.1371, -0.3679],\n",
      "          [-0.3970,  0.0926,  0.6710, -0.0374, -0.0097],\n",
      "          [-0.4229, -0.0649,  0.6514, -0.1102, -0.1397],\n",
      "          [-0.4519, -0.0848,  0.5519, -0.0341, -0.1136],\n",
      "          [-0.5304, -0.0099,  0.3900, -0.0531, -0.1451],\n",
      "          [-0.3538, -0.0937,  0.3264,  0.1207, -0.0735],\n",
      "          [-0.2905, -0.3024,  0.4249, -0.2773, -0.2875],\n",
      "          [-0.3943,  0.0297,  0.3549, -0.0890, -0.2158],\n",
      "          [-0.1689, -0.0151,  0.4539, -0.1427, -0.1149],\n",
      "          [-0.5043, -0.0754,  0.1522, -0.3630, -0.2750],\n",
      "          [-0.4002, -0.1275,  0.2046, -0.3850, -0.2036],\n",
      "          [-0.5356, -0.1780,  0.1533, -0.2747, -0.1088],\n",
      "          [-0.3548, -0.3940,  0.3175, -0.4858, -0.2894],\n",
      "          [-0.4613, -0.0680,  0.3044, -0.4404, -0.1581]],\n",
      "\n",
      "         [[-0.0750, -0.0591, -0.7225,  0.3090, -0.4864],\n",
      "          [-0.1770,  0.0532, -0.2641,  0.2368, -0.2800],\n",
      "          [-0.2616, -0.0261, -0.2830,  0.2747, -0.3858],\n",
      "          [ 0.0907, -0.0833, -0.3040,  0.3460, -0.1690],\n",
      "          [ 0.0075, -0.0431, -0.3490,  0.4575, -0.3183],\n",
      "          [-0.1291, -0.2378, -0.2347,  0.4261, -0.3875],\n",
      "          [-0.1995, -0.2252, -0.2222,  0.3876, -0.1615],\n",
      "          [-0.0745, -0.2358, -0.2955,  0.2226, -0.2461],\n",
      "          [ 0.1310, -0.1557, -0.3077,  0.3931, -0.1505],\n",
      "          [ 0.0030, -0.1374, -0.3566,  0.4619, -0.1411],\n",
      "          [ 0.1944, -0.0868, -0.6292,  0.4438, -0.2632],\n",
      "          [-0.0060, -0.1606, -0.4070,  0.4131, -0.1911],\n",
      "          [-0.1280, -0.1336, -0.4760,  0.5465, -0.2448],\n",
      "          [-0.1539, -0.1938, -0.4646,  0.2537, -0.2884],\n",
      "          [-0.0448, -0.2357, -0.5495,  0.3472, -0.5295],\n",
      "          [ 0.0965, -0.2149, -0.6288,  0.3143, -0.5029]],\n",
      "\n",
      "         [[ 0.3072, -0.3166, -0.5855,  0.2944, -0.0910],\n",
      "          [ 0.3374, -0.2278, -0.2440,  0.4755,  0.2478],\n",
      "          [ 0.1970, -0.5132, -0.1205,  0.4009, -0.0172],\n",
      "          [ 0.3428, -0.2407, -0.1383,  0.3992,  0.1264],\n",
      "          [ 0.2739, -0.2541, -0.0709,  0.2553,  0.1050],\n",
      "          [ 0.2392, -0.3885, -0.1568,  0.2291,  0.1363],\n",
      "          [ 0.1350, -0.4633, -0.1305,  0.1492, -0.0500],\n",
      "          [-0.0308, -0.5779, -0.2043,  0.0913,  0.0232],\n",
      "          [ 0.0913, -0.3377, -0.1841,  0.0770, -0.2482],\n",
      "          [ 0.0833, -0.3404,  0.0023,  0.0225, -0.1353],\n",
      "          [ 0.2294, -0.1317, -0.0722,  0.0431, -0.0612],\n",
      "          [ 0.2121, -0.2175, -0.2003,  0.1404, -0.0365],\n",
      "          [ 0.2300, -0.0356, -0.1400, -0.0169, -0.0637],\n",
      "          [ 0.2098, -0.1954, -0.3551,  0.0347, -0.1164],\n",
      "          [ 0.2859, -0.4387, -0.4681,  0.1680, -0.0933],\n",
      "          [ 0.3304, -0.3402, -0.3318,  0.2573, -0.0381]],\n",
      "\n",
      "         [[ 0.1891,  0.4156,  0.3868,  0.0234,  0.7067],\n",
      "          [ 0.0548,  0.2336,  0.2909, -0.1513,  0.3601],\n",
      "          [ 0.0234,  0.1189,  0.3369, -0.1576,  0.4412],\n",
      "          [ 0.1208,  0.0508,  0.5295, -0.0557,  0.4861],\n",
      "          [ 0.1234,  0.2418,  0.6433, -0.1440,  0.2417],\n",
      "          [ 0.1874,  0.2327,  0.5683, -0.1269,  0.4050],\n",
      "          [ 0.2022, -0.0252,  0.5561, -0.0752,  0.3908],\n",
      "          [ 0.0613,  0.0992,  0.7084,  0.0978,  0.6821],\n",
      "          [ 0.0453,  0.1431,  0.4609,  0.0524,  0.6116],\n",
      "          [ 0.1342,  0.0495,  0.5110,  0.2470,  0.6215],\n",
      "          [ 0.0279,  0.4856,  0.6718, -0.0149,  0.5551],\n",
      "          [ 0.1246,  0.2113,  0.5420, -0.0459,  0.5713],\n",
      "          [ 0.2139,  0.2510,  0.7159,  0.0776,  0.5103],\n",
      "          [ 0.3565,  0.2873,  0.6431,  0.3024,  0.6109],\n",
      "          [ 0.4210,  0.3849,  0.6569,  0.3159,  0.4110],\n",
      "          [ 0.3191,  0.2914,  0.7010,  0.1691,  0.7994]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1431, 0.1704, 0.3637, 0.1665, 0.1564],\n",
      "          [0.1603, 0.1745, 0.3199, 0.1663, 0.1790],\n",
      "          [0.1235, 0.2098, 0.3543, 0.1742, 0.1383],\n",
      "          [0.1184, 0.1932, 0.3444, 0.1696, 0.1744],\n",
      "          [0.1242, 0.1776, 0.3636, 0.1698, 0.1648],\n",
      "          [0.1236, 0.1784, 0.3371, 0.1876, 0.1733],\n",
      "          [0.1208, 0.2034, 0.3034, 0.1948, 0.1776],\n",
      "          [0.1389, 0.1801, 0.2741, 0.2232, 0.1838],\n",
      "          [0.1653, 0.1633, 0.3381, 0.1675, 0.1658],\n",
      "          [0.1390, 0.2124, 0.2940, 0.1886, 0.1661],\n",
      "          [0.1636, 0.1908, 0.3050, 0.1679, 0.1727],\n",
      "          [0.1455, 0.2234, 0.2805, 0.1676, 0.1830],\n",
      "          [0.1568, 0.2060, 0.2871, 0.1592, 0.1909],\n",
      "          [0.1379, 0.1972, 0.2746, 0.1790, 0.2113],\n",
      "          [0.1705, 0.1640, 0.3340, 0.1496, 0.1820],\n",
      "          [0.1427, 0.2115, 0.3069, 0.1457, 0.1932]],\n",
      "\n",
      "         [[0.2141, 0.2176, 0.1121, 0.3144, 0.1419],\n",
      "          [0.1789, 0.2252, 0.1640, 0.2706, 0.1614],\n",
      "          [0.1713, 0.2168, 0.1677, 0.2929, 0.1513],\n",
      "          [0.2185, 0.1836, 0.1473, 0.2821, 0.1685],\n",
      "          [0.2024, 0.1924, 0.1417, 0.3174, 0.1461],\n",
      "          [0.1883, 0.1689, 0.1694, 0.3280, 0.1454],\n",
      "          [0.1727, 0.1683, 0.1688, 0.3107, 0.1794],\n",
      "          [0.2066, 0.1758, 0.1656, 0.2780, 0.1740],\n",
      "          [0.2247, 0.1687, 0.1449, 0.2921, 0.1696],\n",
      "          [0.1994, 0.1733, 0.1392, 0.3155, 0.1726],\n",
      "          [0.2433, 0.1837, 0.1068, 0.3122, 0.1540],\n",
      "          [0.2050, 0.1756, 0.1373, 0.3117, 0.1704],\n",
      "          [0.1801, 0.1791, 0.1272, 0.3535, 0.1602],\n",
      "          [0.1972, 0.1895, 0.1445, 0.2964, 0.1724],\n",
      "          [0.2210, 0.1826, 0.1334, 0.3270, 0.1361],\n",
      "          [0.2494, 0.1827, 0.1208, 0.3101, 0.1370]],\n",
      "\n",
      "         [[0.2774, 0.1487, 0.1136, 0.2739, 0.1863],\n",
      "          [0.2387, 0.1356, 0.1334, 0.2740, 0.2182],\n",
      "          [0.2351, 0.1156, 0.1712, 0.2883, 0.1898],\n",
      "          [0.2475, 0.1381, 0.1530, 0.2619, 0.1994],\n",
      "          [0.2425, 0.1430, 0.1717, 0.2380, 0.2048],\n",
      "          [0.2440, 0.1302, 0.1642, 0.2415, 0.2201],\n",
      "          [0.2403, 0.1321, 0.1842, 0.2437, 0.1997],\n",
      "          [0.2172, 0.1257, 0.1826, 0.2454, 0.2292],\n",
      "          [0.2434, 0.1585, 0.1848, 0.2399, 0.1733],\n",
      "          [0.2314, 0.1515, 0.2134, 0.2177, 0.1860],\n",
      "          [0.2491, 0.1736, 0.1842, 0.2068, 0.1863],\n",
      "          [0.2485, 0.1617, 0.1646, 0.2313, 0.1938],\n",
      "          [0.2510, 0.1924, 0.1734, 0.1961, 0.1871],\n",
      "          [0.2634, 0.1757, 0.1497, 0.2211, 0.1901],\n",
      "          [0.2834, 0.1373, 0.1334, 0.2519, 0.1940],\n",
      "          [0.2741, 0.1402, 0.1413, 0.2548, 0.1896]],\n",
      "\n",
      "         [[0.1667, 0.2091, 0.2032, 0.1413, 0.2798],\n",
      "          [0.1775, 0.2123, 0.2248, 0.1445, 0.2409],\n",
      "          [0.1718, 0.1890, 0.2350, 0.1433, 0.2609],\n",
      "          [0.1749, 0.1631, 0.2633, 0.1466, 0.2521],\n",
      "          [0.1755, 0.1975, 0.2952, 0.1343, 0.1975],\n",
      "          [0.1824, 0.1908, 0.2669, 0.1332, 0.2267],\n",
      "          [0.1928, 0.1536, 0.2747, 0.1461, 0.2328],\n",
      "          [0.1461, 0.1517, 0.2790, 0.1515, 0.2718],\n",
      "          [0.1566, 0.1727, 0.2372, 0.1577, 0.2758],\n",
      "          [0.1633, 0.1500, 0.2380, 0.1828, 0.2658],\n",
      "          [0.1401, 0.2215, 0.2668, 0.1342, 0.2374],\n",
      "          [0.1662, 0.1813, 0.2524, 0.1402, 0.2599],\n",
      "          [0.1693, 0.1757, 0.2797, 0.1477, 0.2277],\n",
      "          [0.1817, 0.1696, 0.2421, 0.1722, 0.2344],\n",
      "          [0.1953, 0.1884, 0.2472, 0.1758, 0.1933],\n",
      "          [0.1691, 0.1644, 0.2477, 0.1455, 0.2733]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0981,  0.3267,  0.1151,  ...,  0.1027, -0.1074,  0.0446],\n",
      "          [ 0.0721,  0.2700,  0.1428,  ..., -0.0544, -0.1727, -0.0766],\n",
      "          [-0.0513,  0.1637, -0.0051,  ..., -0.0989, -0.2208, -0.1194],\n",
      "          ...,\n",
      "          [-0.0331,  0.1561,  0.0868,  ...,  0.0654, -0.0600, -0.0524],\n",
      "          [-0.1619, -0.0337, -0.0473,  ...,  0.0495, -0.0797, -0.1449],\n",
      "          [-0.2477, -0.0625, -0.0712,  ..., -0.0623, -0.1704, -0.1479]],\n",
      "\n",
      "         [[ 0.0165,  0.3512,  0.1680,  ...,  0.4023,  0.5379,  0.1297],\n",
      "          [-0.0953,  0.3275,  0.0766,  ...,  0.3112,  0.3924,  0.0293],\n",
      "          [-0.2450,  0.1056, -0.0550,  ...,  0.2226,  0.2179, -0.1596],\n",
      "          ...,\n",
      "          [ 0.0175,  0.3713,  0.2792,  ...,  0.4303,  0.5144,  0.1608],\n",
      "          [-0.0562,  0.2985,  0.2809,  ...,  0.4349,  0.4112,  0.0589],\n",
      "          [-0.0223,  0.3357,  0.2136,  ...,  0.4522,  0.3659, -0.0051]],\n",
      "\n",
      "         [[ 0.5573,  0.7717,  0.6740,  ...,  0.7002,  0.4715,  0.7812],\n",
      "          [ 0.4625,  0.7093,  0.6303,  ...,  0.5367,  0.3967,  0.5508],\n",
      "          [ 0.3449,  0.5241,  0.3993,  ...,  0.3908,  0.3424,  0.5061],\n",
      "          ...,\n",
      "          [ 0.3136,  0.5304,  0.4531,  ...,  0.3389,  0.2146,  0.4440],\n",
      "          [ 0.2900,  0.5418,  0.4921,  ...,  0.4006,  0.3649,  0.5884],\n",
      "          [ 0.3353,  0.5426,  0.4407,  ...,  0.4417,  0.2705,  0.5172]],\n",
      "\n",
      "         [[ 0.0036, -0.1149, -0.0891,  ..., -0.0049,  0.0059, -0.1238],\n",
      "          [ 0.0765, -0.0190, -0.0653,  ...,  0.1239,  0.0966, -0.0379],\n",
      "          [-0.0815, -0.0818, -0.1346,  ...,  0.1756,  0.1299, -0.0403],\n",
      "          ...,\n",
      "          [ 0.0432, -0.1161, -0.1776,  ...,  0.0938,  0.0279, -0.0177],\n",
      "          [-0.1164, -0.1715, -0.1461,  ...,  0.1775,  0.0739, -0.1016],\n",
      "          [-0.0689, -0.1877, -0.1240,  ..., -0.0370,  0.0396, -0.1619]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0617, 0.0775, 0.0627,  ..., 0.0620, 0.0502, 0.0585],\n",
      "          [0.0675, 0.0823, 0.0725,  ..., 0.0595, 0.0529, 0.0582],\n",
      "          [0.0645, 0.0800, 0.0675,  ..., 0.0615, 0.0544, 0.0602],\n",
      "          ...,\n",
      "          [0.0575, 0.0695, 0.0649,  ..., 0.0635, 0.0560, 0.0564],\n",
      "          [0.0549, 0.0624, 0.0615,  ..., 0.0678, 0.0596, 0.0558],\n",
      "          [0.0521, 0.0627, 0.0622,  ..., 0.0628, 0.0563, 0.0576]],\n",
      "\n",
      "         [[0.0465, 0.0650, 0.0541,  ..., 0.0684, 0.0783, 0.0521],\n",
      "          [0.0460, 0.0702, 0.0546,  ..., 0.0691, 0.0749, 0.0521],\n",
      "          [0.0467, 0.0663, 0.0565,  ..., 0.0746, 0.0742, 0.0509],\n",
      "          ...,\n",
      "          [0.0451, 0.0642, 0.0586,  ..., 0.0681, 0.0741, 0.0520],\n",
      "          [0.0443, 0.0631, 0.0620,  ..., 0.0723, 0.0706, 0.0497],\n",
      "          [0.0474, 0.0678, 0.0600,  ..., 0.0762, 0.0699, 0.0482]],\n",
      "\n",
      "         [[0.0553, 0.0686, 0.0622,  ..., 0.0638, 0.0508, 0.0692],\n",
      "          [0.0552, 0.0706, 0.0653,  ..., 0.0594, 0.0517, 0.0603],\n",
      "          [0.0564, 0.0675, 0.0595,  ..., 0.0590, 0.0562, 0.0662],\n",
      "          ...,\n",
      "          [0.0574, 0.0713, 0.0660,  ..., 0.0589, 0.0520, 0.0654],\n",
      "          [0.0528, 0.0680, 0.0647,  ..., 0.0590, 0.0570, 0.0712],\n",
      "          [0.0559, 0.0688, 0.0621,  ..., 0.0622, 0.0524, 0.0671]],\n",
      "\n",
      "         [[0.0634, 0.0564, 0.0578,  ..., 0.0629, 0.0636, 0.0559],\n",
      "          [0.0596, 0.0541, 0.0517,  ..., 0.0625, 0.0608, 0.0531],\n",
      "          [0.0525, 0.0525, 0.0498,  ..., 0.0679, 0.0649, 0.0548],\n",
      "          ...,\n",
      "          [0.0602, 0.0514, 0.0483,  ..., 0.0633, 0.0593, 0.0567],\n",
      "          [0.0529, 0.0500, 0.0513,  ..., 0.0709, 0.0640, 0.0537],\n",
      "          [0.0578, 0.0513, 0.0547,  ..., 0.0597, 0.0644, 0.0527]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 5.8693e-01, -2.4000e-01,  8.3813e-02, -2.9402e-01,  3.0492e-01],\n",
      "          [ 6.5923e-01, -1.7435e-01,  5.3001e-02, -1.3829e-01,  2.1861e-01],\n",
      "          [ 5.8868e-01, -4.3597e-02, -7.8749e-03, -1.9301e-01,  2.5551e-01],\n",
      "          [ 7.0828e-01, -1.8320e-01, -1.3593e-01, -2.4029e-01,  1.0742e-01],\n",
      "          [ 6.0201e-01, -3.4719e-01,  9.0758e-02, -7.6229e-02,  2.0542e-01],\n",
      "          [ 5.3982e-01, -2.6700e-01, -9.4975e-02, -3.3193e-01,  1.4436e-01],\n",
      "          [ 5.2372e-01, -2.2055e-01, -3.6938e-01, -3.6577e-01, -1.6391e-02],\n",
      "          [ 5.5121e-01, -5.0048e-01, -2.2823e-01, -3.2538e-01,  3.0771e-01],\n",
      "          [ 6.6824e-01, -1.3764e-01, -6.2522e-03, -4.4564e-01,  4.2180e-01],\n",
      "          [ 5.2724e-01, -2.2007e-01, -1.4594e-01, -2.0869e-01,  3.9613e-01],\n",
      "          [ 5.8360e-01, -3.2892e-01,  9.6826e-03, -3.4034e-01,  1.1615e-01],\n",
      "          [ 5.8482e-01, -4.3990e-02, -1.0532e-01, -2.4145e-01,  2.6705e-01],\n",
      "          [ 6.7586e-01, -3.9375e-01, -1.8537e-01, -3.3911e-01,  8.4984e-02],\n",
      "          [ 8.6010e-01, -1.5966e-01,  6.0235e-02, -7.7190e-02,  4.7450e-01],\n",
      "          [ 6.6120e-01, -7.1578e-02,  1.7826e-01, -1.4549e-01,  2.9076e-01],\n",
      "          [ 8.6515e-01, -2.0735e-01,  9.5544e-02, -2.7672e-01,  1.9141e-01]],\n",
      "\n",
      "         [[-5.2021e-02, -5.7154e-02,  3.9252e-01,  2.8826e-01, -1.2811e-01],\n",
      "          [ 4.1974e-02, -3.9759e-02,  4.7131e-01,  3.6510e-01, -4.6247e-02],\n",
      "          [-1.0941e-01,  3.2954e-02,  5.6847e-01,  2.8397e-01, -3.2133e-02],\n",
      "          [ 8.3404e-02,  3.2355e-01,  4.6549e-01,  2.2194e-01, -8.6908e-02],\n",
      "          [ 4.0302e-03,  2.3104e-01,  4.4063e-01,  2.5408e-01,  8.1317e-02],\n",
      "          [-1.6025e-01,  8.0053e-02,  5.1975e-01,  1.0970e-01, -9.3879e-02],\n",
      "          [-8.0888e-03, -1.3085e-03,  3.3882e-01,  1.7585e-01,  5.2330e-02],\n",
      "          [-5.4107e-02,  2.3735e-02,  5.1272e-01,  2.1836e-01,  9.0545e-03],\n",
      "          [-1.4730e-01, -2.1850e-02,  7.1766e-01,  1.6884e-01, -1.4727e-01],\n",
      "          [-1.8448e-01, -1.0701e-01,  4.9181e-01,  2.1150e-01,  2.1982e-02],\n",
      "          [-3.5408e-01, -2.5318e-01,  4.4653e-01,  3.0405e-01, -3.5547e-04],\n",
      "          [-2.7275e-01, -7.1216e-02,  5.5182e-01,  2.7627e-01, -1.1230e-01],\n",
      "          [-3.1801e-01,  6.7444e-02,  4.9896e-01,  1.3305e-03, -2.0974e-01],\n",
      "          [-2.3257e-01,  1.2886e-01,  4.8722e-01,  2.3958e-01, -1.5238e-01],\n",
      "          [-2.3815e-01, -2.2415e-01,  3.4145e-01,  1.7352e-01, -1.2815e-01],\n",
      "          [-2.7498e-01, -2.2115e-01,  2.2706e-01,  4.2414e-02, -1.6181e-01]],\n",
      "\n",
      "         [[-9.2315e-02, -1.7759e-01, -1.6292e-01, -4.9966e-01,  1.3753e-01],\n",
      "          [ 6.5427e-03, -5.6233e-02, -1.0314e-01, -3.6573e-01,  2.3526e-01],\n",
      "          [ 2.7435e-01, -1.0752e-01,  9.1550e-02, -4.1056e-01,  2.1888e-01],\n",
      "          [ 1.6049e-01, -1.3185e-01, -4.3005e-02, -6.7453e-01,  4.0547e-01],\n",
      "          [ 1.6407e-01, -4.1496e-02,  9.5101e-02, -6.4450e-01,  1.2887e-01],\n",
      "          [ 3.2351e-02,  9.7116e-02,  3.0993e-02, -5.9121e-01,  2.0357e-01],\n",
      "          [ 6.3791e-02, -2.8007e-01, -5.8498e-02, -7.7243e-01,  2.5704e-02],\n",
      "          [ 1.4684e-01, -2.4829e-01,  1.5977e-01, -4.5433e-01,  9.5260e-02],\n",
      "          [ 1.7318e-02, -2.0695e-02, -5.3305e-02, -3.9097e-01,  2.5102e-01],\n",
      "          [ 1.2737e-01, -2.4917e-01,  1.0585e-01, -2.6520e-01,  3.5345e-01],\n",
      "          [-5.3125e-02, -1.6770e-01, -1.5619e-01, -2.7055e-01,  5.3831e-01],\n",
      "          [-1.9941e-01, -3.1987e-01, -6.5536e-02, -6.4042e-01,  1.9324e-01],\n",
      "          [-9.4846e-02, -1.1114e-01,  3.0233e-02, -4.2420e-01,  2.9140e-01],\n",
      "          [-1.5673e-01, -2.0114e-01, -1.0033e-01, -3.9204e-01,  3.6760e-01],\n",
      "          [-4.2209e-01, -2.7740e-01, -1.0138e-01, -4.9920e-01,  3.2042e-01],\n",
      "          [-4.0052e-01, -2.4122e-01, -2.1846e-01, -4.1925e-01,  3.5441e-01]],\n",
      "\n",
      "         [[ 4.4056e-01, -2.8597e-01, -1.9267e-01,  4.0239e-01,  2.1655e-01],\n",
      "          [ 4.0736e-01, -7.3018e-02, -1.3800e-01,  3.4495e-01,  2.3781e-01],\n",
      "          [ 6.5984e-01, -2.3384e-01, -1.2336e-02,  3.8611e-01,  2.7488e-01],\n",
      "          [ 3.8043e-01, -5.1832e-01,  1.6402e-01,  4.8130e-01, -3.7327e-02],\n",
      "          [ 4.2137e-01, -3.8012e-01, -5.5730e-03,  3.7822e-01,  1.9677e-01],\n",
      "          [ 1.7723e-01, -4.9377e-01, -1.3494e-01,  2.3975e-01,  1.1745e-01],\n",
      "          [ 1.7547e-01, -3.3658e-01, -2.1071e-01,  3.4424e-02,  8.9285e-02],\n",
      "          [ 2.9351e-01, -2.4147e-01, -9.9668e-02,  1.3815e-01,  2.8283e-02],\n",
      "          [ 2.8379e-01, -2.4501e-01, -1.9233e-01,  2.4377e-01,  2.3498e-02],\n",
      "          [ 1.3962e-01, -3.1043e-01, -2.4677e-01, -1.3635e-02, -6.5838e-02],\n",
      "          [ 3.6690e-01, -5.0177e-02, -7.0752e-02,  2.3186e-01,  9.0643e-02],\n",
      "          [ 4.4566e-01, -5.3909e-02, -2.8087e-01,  3.4441e-01,  1.6445e-01],\n",
      "          [ 3.5206e-01, -3.1256e-01, -8.3167e-02,  3.1606e-01, -3.5310e-02],\n",
      "          [ 4.0916e-01, -1.6684e-01, -2.1559e-01,  1.8485e-01,  2.2175e-01],\n",
      "          [ 3.9324e-01, -1.1054e-01, -1.9093e-01,  1.0810e-01,  2.3615e-01],\n",
      "          [ 5.7000e-01, -1.1522e-01, -1.1759e-01,  1.4581e-01,  1.7672e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3115, 0.1362, 0.1883, 0.1291, 0.2349],\n",
      "          [0.3253, 0.1413, 0.1774, 0.1465, 0.2094],\n",
      "          [0.3071, 0.1632, 0.1691, 0.1405, 0.2201],\n",
      "          [0.3603, 0.1477, 0.1549, 0.1395, 0.1976],\n",
      "          [0.3158, 0.1222, 0.1894, 0.1603, 0.2124],\n",
      "          [0.3260, 0.1455, 0.1728, 0.1363, 0.2195],\n",
      "          [0.3475, 0.1651, 0.1422, 0.1428, 0.2025],\n",
      "          [0.3324, 0.1161, 0.1525, 0.1384, 0.2606],\n",
      "          [0.3262, 0.1457, 0.1662, 0.1071, 0.2549],\n",
      "          [0.2994, 0.1418, 0.1527, 0.1434, 0.2626],\n",
      "          [0.3346, 0.1344, 0.1885, 0.1328, 0.2097],\n",
      "          [0.3125, 0.1666, 0.1567, 0.1368, 0.2274],\n",
      "          [0.3729, 0.1279, 0.1576, 0.1351, 0.2065],\n",
      "          [0.3470, 0.1252, 0.1559, 0.1359, 0.2360],\n",
      "          [0.3092, 0.1486, 0.1908, 0.1380, 0.2135],\n",
      "          [0.3796, 0.1299, 0.1758, 0.1212, 0.1935]],\n",
      "\n",
      "         [[0.1699, 0.1690, 0.2650, 0.2387, 0.1574],\n",
      "          [0.1738, 0.1601, 0.2670, 0.2401, 0.1591],\n",
      "          [0.1496, 0.1725, 0.2946, 0.2217, 0.1616],\n",
      "          [0.1746, 0.2219, 0.2558, 0.2005, 0.1472],\n",
      "          [0.1622, 0.2035, 0.2509, 0.2082, 0.1752],\n",
      "          [0.1510, 0.1920, 0.2980, 0.1977, 0.1613],\n",
      "          [0.1759, 0.1771, 0.2488, 0.2114, 0.1868],\n",
      "          [0.1607, 0.1737, 0.2833, 0.2111, 0.1712],\n",
      "          [0.1453, 0.1648, 0.3452, 0.1994, 0.1453],\n",
      "          [0.1479, 0.1598, 0.2908, 0.2197, 0.1818],\n",
      "          [0.1301, 0.1439, 0.2896, 0.2512, 0.1853],\n",
      "          [0.1350, 0.1651, 0.3078, 0.2337, 0.1584],\n",
      "          [0.1384, 0.2035, 0.3133, 0.1905, 0.1542],\n",
      "          [0.1393, 0.2000, 0.2862, 0.2234, 0.1510],\n",
      "          [0.1556, 0.1578, 0.2779, 0.2349, 0.1737],\n",
      "          [0.1613, 0.1702, 0.2664, 0.2215, 0.1806]],\n",
      "\n",
      "         [[0.2095, 0.1923, 0.1952, 0.1394, 0.2636],\n",
      "          [0.2091, 0.1964, 0.1874, 0.1441, 0.2629],\n",
      "          [0.2522, 0.1721, 0.2100, 0.1271, 0.2386],\n",
      "          [0.2340, 0.1747, 0.1909, 0.1015, 0.2989],\n",
      "          [0.2405, 0.1958, 0.2244, 0.1071, 0.2322],\n",
      "          [0.2088, 0.2228, 0.2086, 0.1119, 0.2478],\n",
      "          [0.2506, 0.1777, 0.2218, 0.1086, 0.2413],\n",
      "          [0.2390, 0.1610, 0.2421, 0.1310, 0.2270],\n",
      "          [0.2074, 0.1996, 0.1932, 0.1378, 0.2619],\n",
      "          [0.2177, 0.1494, 0.2130, 0.1470, 0.2729],\n",
      "          [0.1850, 0.1650, 0.1669, 0.1489, 0.3342],\n",
      "          [0.1940, 0.1720, 0.2218, 0.1248, 0.2873],\n",
      "          [0.1884, 0.1854, 0.2135, 0.1355, 0.2772],\n",
      "          [0.1820, 0.1741, 0.1926, 0.1438, 0.3075],\n",
      "          [0.1524, 0.1761, 0.2101, 0.1411, 0.3203],\n",
      "          [0.1543, 0.1809, 0.1851, 0.1514, 0.3282]],\n",
      "\n",
      "         [[0.2648, 0.1281, 0.1406, 0.2549, 0.2117],\n",
      "          [0.2511, 0.1553, 0.1456, 0.2360, 0.2120],\n",
      "          [0.2976, 0.1217, 0.1519, 0.2263, 0.2025],\n",
      "          [0.2514, 0.1024, 0.2025, 0.2781, 0.1656],\n",
      "          [0.2592, 0.1163, 0.1691, 0.2483, 0.2071],\n",
      "          [0.2353, 0.1203, 0.1722, 0.2505, 0.2217],\n",
      "          [0.2460, 0.1474, 0.1672, 0.2137, 0.2257],\n",
      "          [0.2575, 0.1508, 0.1738, 0.2204, 0.1975],\n",
      "          [0.2537, 0.1495, 0.1576, 0.2437, 0.1955],\n",
      "          [0.2507, 0.1598, 0.1703, 0.2151, 0.2041],\n",
      "          [0.2540, 0.1674, 0.1640, 0.2219, 0.1927],\n",
      "          [0.2667, 0.1619, 0.1290, 0.2411, 0.2014],\n",
      "          [0.2628, 0.1352, 0.1701, 0.2535, 0.1784],\n",
      "          [0.2684, 0.1509, 0.1437, 0.2145, 0.2225],\n",
      "          [0.2654, 0.1603, 0.1480, 0.1995, 0.2268],\n",
      "          [0.2998, 0.1511, 0.1507, 0.1961, 0.2023]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1231, -0.0144, -0.0029,  ..., -0.1671, -0.0743, -0.1176],\n",
      "          [-0.0543, -0.0776,  0.0399,  ..., -0.2301, -0.2950, -0.0888],\n",
      "          [-0.1289, -0.1038, -0.0472,  ..., -0.2433, -0.1806, -0.1287],\n",
      "          ...,\n",
      "          [-0.1456, -0.1334, -0.0075,  ..., -0.3098, -0.2687, -0.0910],\n",
      "          [-0.1556, -0.0798,  0.0192,  ..., -0.1542, -0.1549, -0.1397],\n",
      "          [-0.1774, -0.0972, -0.0446,  ..., -0.3014, -0.2826, -0.1592]],\n",
      "\n",
      "         [[ 0.3052,  0.2602,  0.1664,  ...,  0.3712, -0.0041,  0.1593],\n",
      "          [ 0.2041,  0.2059,  0.1179,  ...,  0.1403, -0.1520,  0.0598],\n",
      "          [ 0.3764,  0.4306,  0.3077,  ...,  0.3605, -0.0178,  0.1429],\n",
      "          ...,\n",
      "          [ 0.0851,  0.0123, -0.0538,  ...,  0.0243, -0.3227, -0.1358],\n",
      "          [ 0.3509,  0.2713,  0.1517,  ...,  0.3060, -0.0078,  0.2244],\n",
      "          [ 0.1208,  0.0796,  0.0209,  ..., -0.0135, -0.3412, -0.1017]],\n",
      "\n",
      "         [[ 0.8321,  0.7460,  0.7456,  ...,  0.8205,  0.4662,  0.6972],\n",
      "          [ 0.6582,  0.5458,  0.6045,  ...,  0.7296,  0.4224,  0.6009],\n",
      "          [ 0.6888,  0.5239,  0.6565,  ...,  0.6524,  0.2718,  0.5159],\n",
      "          ...,\n",
      "          [ 0.8856,  0.7828,  0.7402,  ...,  0.9091,  0.5819,  0.8436],\n",
      "          [ 0.8051,  0.6675,  0.7214,  ...,  0.7193,  0.3949,  0.7487],\n",
      "          [ 0.6639,  0.5450,  0.6714,  ...,  0.6659,  0.3957,  0.5938]],\n",
      "\n",
      "         [[ 0.1465, -0.0433,  0.0895,  ..., -0.2371, -0.1130,  0.1723],\n",
      "          [ 0.1610,  0.0057,  0.1257,  ..., -0.0902, -0.0595,  0.1390],\n",
      "          [ 0.2077, -0.0139,  0.0736,  ..., -0.1201, -0.0753,  0.1662],\n",
      "          ...,\n",
      "          [ 0.1495, -0.0134,  0.0401,  ..., -0.1609, -0.1182,  0.0875],\n",
      "          [-0.1060, -0.1780, -0.1434,  ..., -0.4090, -0.3186, -0.0839],\n",
      "          [-0.1263, -0.2192, -0.1703,  ..., -0.3411, -0.1742, -0.0817]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0623, 0.0694, 0.0702,  ..., 0.0596, 0.0654, 0.0626],\n",
      "          [0.0671, 0.0655, 0.0737,  ..., 0.0563, 0.0527, 0.0648],\n",
      "          [0.0641, 0.0657, 0.0695,  ..., 0.0571, 0.0608, 0.0641],\n",
      "          ...,\n",
      "          [0.0665, 0.0673, 0.0763,  ..., 0.0564, 0.0588, 0.0702],\n",
      "          [0.0620, 0.0668, 0.0738,  ..., 0.0620, 0.0620, 0.0629],\n",
      "          [0.0653, 0.0707, 0.0746,  ..., 0.0577, 0.0588, 0.0665]],\n",
      "\n",
      "         [[0.0673, 0.0643, 0.0586,  ..., 0.0719, 0.0494, 0.0582],\n",
      "          [0.0683, 0.0684, 0.0626,  ..., 0.0640, 0.0478, 0.0591],\n",
      "          [0.0708, 0.0748, 0.0661,  ..., 0.0697, 0.0478, 0.0561],\n",
      "          ...,\n",
      "          [0.0710, 0.0660, 0.0618,  ..., 0.0668, 0.0472, 0.0569],\n",
      "          [0.0709, 0.0654, 0.0581,  ..., 0.0678, 0.0495, 0.0625],\n",
      "          [0.0698, 0.0670, 0.0632,  ..., 0.0610, 0.0440, 0.0559]],\n",
      "\n",
      "         [[0.0769, 0.0705, 0.0705,  ..., 0.0760, 0.0533, 0.0672],\n",
      "          [0.0717, 0.0641, 0.0680,  ..., 0.0770, 0.0567, 0.0677],\n",
      "          [0.0761, 0.0645, 0.0737,  ..., 0.0734, 0.0502, 0.0640],\n",
      "          ...,\n",
      "          [0.0710, 0.0641, 0.0614,  ..., 0.0727, 0.0524, 0.0681],\n",
      "          [0.0733, 0.0639, 0.0674,  ..., 0.0673, 0.0486, 0.0693],\n",
      "          [0.0691, 0.0614, 0.0696,  ..., 0.0693, 0.0529, 0.0644]],\n",
      "\n",
      "         [[0.0717, 0.0593, 0.0678,  ..., 0.0489, 0.0553, 0.0736],\n",
      "          [0.0675, 0.0578, 0.0651,  ..., 0.0525, 0.0541, 0.0660],\n",
      "          [0.0708, 0.0567, 0.0619,  ..., 0.0510, 0.0533, 0.0679],\n",
      "          ...,\n",
      "          [0.0699, 0.0594, 0.0627,  ..., 0.0513, 0.0535, 0.0657],\n",
      "          [0.0660, 0.0614, 0.0636,  ..., 0.0488, 0.0534, 0.0675],\n",
      "          [0.0629, 0.0573, 0.0601,  ..., 0.0507, 0.0599, 0.0657]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1858,  0.0448, -0.0781,  0.4697,  0.3952],\n",
      "          [ 0.2081,  0.2273, -0.1533,  0.6076,  0.4837],\n",
      "          [ 0.0234,  0.3581,  0.1086,  0.4688,  0.4393],\n",
      "          [ 0.2247,  0.3557, -0.0240,  0.3880,  0.2724],\n",
      "          [ 0.0199,  0.2215, -0.1855,  0.4369,  0.3053],\n",
      "          [ 0.1163,  0.1954,  0.2079,  0.4381,  0.4582],\n",
      "          [ 0.2993,  0.2333,  0.2628,  0.4892,  0.5726],\n",
      "          [ 0.3144,  0.1534,  0.1308,  0.3627,  0.6001],\n",
      "          [ 0.2056,  0.1857,  0.0030,  0.4106,  0.6130],\n",
      "          [ 0.1284,  0.0636,  0.0090,  0.4198,  0.5797],\n",
      "          [-0.1049,  0.1729, -0.1230,  0.2280,  0.4261],\n",
      "          [ 0.0613,  0.2259, -0.0251,  0.4387,  0.4249],\n",
      "          [-0.0228,  0.0864,  0.0539,  0.3809,  0.1474],\n",
      "          [-0.1009, -0.0961, -0.2490,  0.2714,  0.4017],\n",
      "          [ 0.1267,  0.2420, -0.0836,  0.4770,  0.7075],\n",
      "          [ 0.1765,  0.1993, -0.1291,  0.5936,  0.6374]],\n",
      "\n",
      "         [[-0.5026, -0.4207, -0.3238, -0.1511, -0.1566],\n",
      "          [-0.8873, -0.4072, -0.2661, -0.1357, -0.5466],\n",
      "          [-0.5503, -0.2872, -0.3756, -0.0361, -0.2421],\n",
      "          [-0.8317, -0.3610, -0.4204, -0.1792, -0.0895],\n",
      "          [-0.6626, -0.4843, -0.5659, -0.2656, -0.3373],\n",
      "          [-0.6702, -0.3218, -0.3997, -0.2065, -0.3331],\n",
      "          [-0.7636, -0.6020, -0.4919, -0.2984, -0.5211],\n",
      "          [-0.6033, -0.2832, -0.2484, -0.1291, -0.0985],\n",
      "          [-0.6026, -0.3340, -0.3338, -0.2449, -0.3156],\n",
      "          [-0.6428, -0.2895, -0.3516, -0.1176, -0.2378],\n",
      "          [-0.2683, -0.2339, -0.3323, -0.0153,  0.1301],\n",
      "          [-0.5486, -0.2460, -0.3993, -0.1214, -0.2978],\n",
      "          [-0.5485, -0.5233, -0.5928, -0.2684, -0.1258],\n",
      "          [-0.6134, -0.2966, -0.3583, -0.0369, -0.0347],\n",
      "          [-0.5066, -0.1768, -0.3525, -0.0205, -0.1259],\n",
      "          [-0.7555, -0.3727, -0.4396, -0.1189, -0.2646]],\n",
      "\n",
      "         [[-0.3401, -0.0330, -0.5006, -0.1743, -0.1894],\n",
      "          [-0.2996, -0.1258, -0.4685, -0.0924, -0.1510],\n",
      "          [-0.2395,  0.0199, -0.4520, -0.1425, -0.2213],\n",
      "          [-0.4448, -0.3107, -0.5202, -0.3693, -0.2763],\n",
      "          [-0.4343, -0.3160, -0.3702, -0.1783, -0.3740],\n",
      "          [-0.5050, -0.2901, -0.5364, -0.2207, -0.3031],\n",
      "          [-0.4194, -0.4350, -0.4542, -0.3609, -0.2892],\n",
      "          [-0.2325, -0.2242, -0.3188, -0.1110, -0.2018],\n",
      "          [-0.4961, -0.1324, -0.2367, -0.2972, -0.0162],\n",
      "          [-0.2108, -0.2945, -0.4377, -0.0384, -0.0975],\n",
      "          [-0.2689, -0.0995, -0.2980, -0.0742, -0.0861],\n",
      "          [-0.4198, -0.2054, -0.3562, -0.1007, -0.1404],\n",
      "          [-0.3707, -0.4168, -0.6564, -0.2767, -0.5176],\n",
      "          [-0.2225, -0.2675, -0.5174, -0.1231, -0.4207],\n",
      "          [-0.1930, -0.2497, -0.3406, -0.1094, -0.3521],\n",
      "          [-0.3031, -0.1835, -0.5198, -0.2563, -0.2403]],\n",
      "\n",
      "         [[-0.1443, -0.0950,  0.2368,  0.2904,  0.2444],\n",
      "          [-0.1707,  0.1369,  0.1113,  0.1864,  0.1724],\n",
      "          [-0.3021, -0.0105,  0.1171,  0.3991,  0.3049],\n",
      "          [-0.0803,  0.2093,  0.3986,  0.4690,  0.3913],\n",
      "          [-0.0187,  0.0320,  0.3646,  0.7060,  0.8191],\n",
      "          [ 0.1107,  0.0015,  0.5367,  0.6143,  0.8369],\n",
      "          [-0.2331, -0.0209,  0.2487,  0.5015,  0.4870],\n",
      "          [-0.2011,  0.1923,  0.1326,  0.6606,  0.4790],\n",
      "          [-0.2486,  0.0428,  0.0934,  0.3543,  0.4058],\n",
      "          [ 0.0944,  0.2061,  0.3939,  0.5159,  0.4865],\n",
      "          [-0.0204,  0.2003,  0.2543,  0.4346,  0.4750],\n",
      "          [-0.0583,  0.0515,  0.2156,  0.4200,  0.5085],\n",
      "          [ 0.0051,  0.0583,  0.2524,  0.5779,  0.6492],\n",
      "          [-0.2664,  0.1294,  0.0933,  0.3757,  0.5694],\n",
      "          [-0.2525,  0.1402, -0.0373,  0.3640,  0.5293],\n",
      "          [-0.1530, -0.0127,  0.0494,  0.4461,  0.2864]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1924, 0.1671, 0.1478, 0.2555, 0.2372],\n",
      "          [0.1810, 0.1845, 0.1261, 0.2699, 0.2384],\n",
      "          [0.1524, 0.2129, 0.1659, 0.2379, 0.2309],\n",
      "          [0.1943, 0.2215, 0.1515, 0.2288, 0.2038],\n",
      "          [0.1699, 0.2079, 0.1384, 0.2578, 0.2260],\n",
      "          [0.1676, 0.1814, 0.1837, 0.2313, 0.2360],\n",
      "          [0.1844, 0.1726, 0.1778, 0.2229, 0.2423],\n",
      "          [0.1975, 0.1681, 0.1644, 0.2073, 0.2628],\n",
      "          [0.1809, 0.1774, 0.1477, 0.2221, 0.2719],\n",
      "          [0.1744, 0.1635, 0.1548, 0.2334, 0.2739],\n",
      "          [0.1563, 0.2063, 0.1535, 0.2180, 0.2658],\n",
      "          [0.1669, 0.1967, 0.1530, 0.2434, 0.2400],\n",
      "          [0.1701, 0.1898, 0.1837, 0.2547, 0.2017],\n",
      "          [0.1675, 0.1683, 0.1444, 0.2430, 0.2768],\n",
      "          [0.1629, 0.1828, 0.1320, 0.2312, 0.2911],\n",
      "          [0.1706, 0.1745, 0.1257, 0.2589, 0.2704]],\n",
      "\n",
      "         [[0.1635, 0.1775, 0.1955, 0.2324, 0.2311],\n",
      "          [0.1249, 0.2019, 0.2325, 0.2649, 0.1757],\n",
      "          [0.1533, 0.1994, 0.1825, 0.2563, 0.2086],\n",
      "          [0.1230, 0.1969, 0.1856, 0.2362, 0.2584],\n",
      "          [0.1621, 0.1938, 0.1786, 0.2411, 0.2244],\n",
      "          [0.1488, 0.2109, 0.1951, 0.2366, 0.2085],\n",
      "          [0.1574, 0.1850, 0.2065, 0.2506, 0.2006],\n",
      "          [0.1415, 0.1949, 0.2018, 0.2274, 0.2344],\n",
      "          [0.1568, 0.2051, 0.2051, 0.2242, 0.2089],\n",
      "          [0.1438, 0.2048, 0.1925, 0.2432, 0.2157],\n",
      "          [0.1739, 0.1800, 0.1631, 0.2240, 0.2590],\n",
      "          [0.1579, 0.2137, 0.1834, 0.2421, 0.2029],\n",
      "          [0.1715, 0.1759, 0.1640, 0.2269, 0.2617],\n",
      "          [0.1384, 0.1900, 0.1786, 0.2463, 0.2468],\n",
      "          [0.1505, 0.2092, 0.1755, 0.2446, 0.2202],\n",
      "          [0.1358, 0.1992, 0.1863, 0.2567, 0.2219]],\n",
      "\n",
      "         [[0.1800, 0.2448, 0.1533, 0.2125, 0.2093],\n",
      "          [0.1843, 0.2193, 0.1557, 0.2268, 0.2139],\n",
      "          [0.1914, 0.2481, 0.1548, 0.2109, 0.1949],\n",
      "          [0.1875, 0.2144, 0.1739, 0.2022, 0.2219],\n",
      "          [0.1803, 0.2030, 0.1923, 0.2329, 0.1915],\n",
      "          [0.1736, 0.2152, 0.1682, 0.2307, 0.2124],\n",
      "          [0.1942, 0.1912, 0.1876, 0.2059, 0.2212],\n",
      "          [0.1966, 0.1982, 0.1804, 0.2220, 0.2028],\n",
      "          [0.1522, 0.2189, 0.1973, 0.1857, 0.2459],\n",
      "          [0.1990, 0.1830, 0.1586, 0.2365, 0.2229],\n",
      "          [0.1795, 0.2126, 0.1743, 0.2181, 0.2155],\n",
      "          [0.1666, 0.2064, 0.1775, 0.2292, 0.2203],\n",
      "          [0.2142, 0.2046, 0.1610, 0.2353, 0.1849],\n",
      "          [0.2162, 0.2067, 0.1610, 0.2388, 0.1773],\n",
      "          [0.2106, 0.1990, 0.1817, 0.2290, 0.1796],\n",
      "          [0.1982, 0.2234, 0.1596, 0.2077, 0.2111]],\n",
      "\n",
      "         [[0.1531, 0.1608, 0.2240, 0.2364, 0.2257],\n",
      "          [0.1533, 0.2085, 0.2032, 0.2191, 0.2160],\n",
      "          [0.1297, 0.1736, 0.1972, 0.2615, 0.2380],\n",
      "          [0.1373, 0.1834, 0.2216, 0.2378, 0.2200],\n",
      "          [0.1267, 0.1333, 0.1858, 0.2615, 0.2928],\n",
      "          [0.1399, 0.1254, 0.2142, 0.2314, 0.2891],\n",
      "          [0.1251, 0.1547, 0.2025, 0.2608, 0.2570],\n",
      "          [0.1217, 0.1803, 0.1699, 0.2880, 0.2402],\n",
      "          [0.1334, 0.1785, 0.1878, 0.2437, 0.2566],\n",
      "          [0.1545, 0.1728, 0.2085, 0.2355, 0.2287],\n",
      "          [0.1475, 0.1839, 0.1941, 0.2325, 0.2420],\n",
      "          [0.1469, 0.1640, 0.1932, 0.2370, 0.2589],\n",
      "          [0.1426, 0.1504, 0.1826, 0.2529, 0.2715],\n",
      "          [0.1231, 0.1828, 0.1763, 0.2339, 0.2839],\n",
      "          [0.1289, 0.1909, 0.1598, 0.2387, 0.2817],\n",
      "          [0.1482, 0.1705, 0.1815, 0.2698, 0.2300]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "[34, 34, 34, 34, 34]\n",
      "predicted sentence: \n",
      " CCCCC\n"
     ]
    }
   ],
   "source": [
    "# Predicting next words\n",
    "sent = \"This is a simple sentence\"\n",
    "encoded_sent = encoding.encode(sent)\n",
    "enc_x = torch.tensor(encoded_sent).unsqueeze(0)\n",
    "dec_x = torch.tensor(encoding.encode(\"C\")).unsqueeze(0)\n",
    "\n",
    "transformer = Transformer(vocab_size=encoding.n_vocab, n=3, d=256, h=4)\n",
    "\n",
    "predicted_tokens = []\n",
    "for _ in range(5):\n",
    "    output = transformer(enc_x=enc_x, dec_x=dec_x)\n",
    "    softmaxed = F.softmax(output, dim=-1)\n",
    "    predicted = softmaxed.argmax(dim=-1)\n",
    "    predicted_tokens.append(predicted.tolist()[-1][-1]) \n",
    "    dec_x = torch.cat((dec_x, predicted), dim=-1)\n",
    "\n",
    "print(predicted_tokens)\n",
    "print(f\"predicted sentence: \\n {encoding.decode(predicted_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbfc3e-aca8-4edb-99e5-025c945d85ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683599c0-fd00-40b0-8bb1-4e477a2114a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e70b0-a647-455b-bdfb-332d095aafc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082af878-9425-4445-b4b4-592cef79a2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dba170-623a-486b-8b67-58360bde104f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4d1a8-69aa-4c60-b3b4-ebb2e31f1c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cda8a40-c41b-4eb3-90af-446f97e501f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f4736-acd3-4bd9-a9f5-b00240a17b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([1, 2, 3])\n",
    "mask = torch.ones([1, 2])\n",
    "mask[0, 1] = 0\n",
    "mask = mask.unsqueeze(1)\n",
    "print(mask == 0)\n",
    "x.masked_fill(mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4ff31-01d1-4144-b1ad-b2b600609d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bb090-365d-4c4d-986d-b048e7345f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
