{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d7f736-b9af-48e3-adb5-18ab3536abd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmasked attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d29dfa4-a1e1-4dd2-b2c5-e3ed8653fbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkhokhlush/github/transformer-implementation/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:275: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3, 3])\n",
      "torch.Size([2, 4, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def self_attention(q, k, v):\n",
    "    # if 3 dim: b t d\n",
    "    #prod = Q.bmm(K.permute(0, 2, 1))\n",
    "    # or\n",
    "    # prod = torch.einsum(\"btd, bsd -> bts\", q, k)\n",
    "    # if 4 dim: b t h dh\n",
    "    # q = q.permute(0, 2, 1, 3)\n",
    "    prod = torch.einsum(\"bthd, bshd -> bhts\", q, k)\n",
    "    scaled_prod = prod/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "    softmaxed_prod = F.softmax(scaled_prod, dim=-1)\n",
    "    print(softmaxed_prod.shape)\n",
    "    # print(softmaxed_prod)\n",
    "    return softmaxed_prod @ v.permute(0, 2, 1, 3)\n",
    "\n",
    "\n",
    "x = torch.rand([2, 3, 4, 5])\n",
    "self_attention(x, x, x)\n",
    "self_attention(x, x, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae60133-3d0c-4ada-8789-51107800432a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        assert d % h == 0\n",
    "        self.d = d\n",
    "        self.dh = d // h\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(self.d, self.d)\n",
    "        self.wk = nn.Linear(self.d, self.d)\n",
    "        self.wv = nn.Linear(self.d, self.d)\n",
    "        self.wo = nn.Linear(self.d, self.d)\n",
    " \n",
    "    def forward(self, q, k, v):\n",
    "        # b, t, d\n",
    "        b, t, d = q.size()\n",
    "        wq = self.wq(q)\n",
    "        wk = self.wk(k)\n",
    "        wv = self.wv(v)\n",
    "        wq = wq.view(b, t, self.h, self.dh)\n",
    "        wk = wk.view(b, t, self.h, self.dh)\n",
    "        wv = wv.view(b, t, self.h, self.dh)\n",
    "        # b, t, h, dh\n",
    "        # if changing from 4 dim -> 3 dim: b*h, t, dh\n",
    "        # wq = wq.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wk = wk.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wv = wv.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # another option 4 dim -> 3 dim\n",
    "        # wq = wq.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wk = wk.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wv = wv.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # changing the number of dims is not necessary as @ supports 4 dims\n",
    "        attn = self_attention(wq, wk, wv)\n",
    "        # b * h, t, dh\n",
    "        # attn = attn.view(b, self.h, t, self.dh).permute(0, 2, 1, 3).reshape(b, t, d)\n",
    "        attn = attn.view(b, self.h, t, self.dh).transpose(1, 2).contiguous().view(b, t, d)\n",
    "        wo = self.wo(attn)\n",
    "        return wo\n",
    "        # # 1 2 3 4\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # return F.relu(self.conv2(x))\n",
    "\n",
    "mhsa = MHSA()\n",
    "x = torch.rand(2, 3, 512)\n",
    "mhsa(x, x, x).shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abcca093-9e66-4b46-8ec3-aded63ece6f8",
   "metadata": {},
   "source": [
    "class PE1():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # -> d vector\n",
    "    def __call__(self, pos):\n",
    "        pow = torch.pow(10000, torch.arange(0, self.d) / self.d)\n",
    "        return torch.sin(torch.arange(0, self.d) / pow)\n",
    "\n",
    "print(PE1()(1).size()) # torch.Size([512])\n",
    "\n",
    "class PEScalar():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # 1 -> d vector\n",
    "    def __call__(self, pos):\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2)\n",
    "        # b = torch.arange(1, 12, 2)\n",
    "        # torch.stack((a, b), dim=1).view(-1)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1)\n",
    "\n",
    "print(PEScalar()(1).size()) # torch.Size([1, 512])\n",
    "\n",
    "class PEVector():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # 1 -> 1 d\n",
    "    # t 1 -> t d\n",
    "    def __call__(self, pos):\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2).view(-1, 2)\n",
    "        # b = torch.arange(1, 12, 2).view(-1, 2)\n",
    "        # torch.stack((a, b), dim=-1).view(-1, 4)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1, self.d)\n",
    "\n",
    "print(PEVector()(1).size()) # torch.Size([1, 512])\n",
    "print(PEVector()(torch.arange(3).view(-1, 1)).size()) # torch.Size([3, 512])\n",
    "\n",
    "class PE():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # b t 1 -> b t d\n",
    "    def __call__(self, pos):\n",
    "        b, t, _ = pos.size()\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        # a = torch.arange(0, 12, 2).view(-1, 2)\n",
    "        # b = torch.arange(1, 12, 2).view(-1, 2)\n",
    "        # torch.stack((a, b), dim=-1).view(-1, 4)\n",
    "        return torch.stack((sin_p, cos_p), dim=-1).view(-1, t, self.d)\n",
    "\n",
    "print(PE()(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])\n",
    "\n",
    "class PEAnotherImpl():\n",
    "    def __init__(self, d: int = 512):\n",
    "        self.d = d\n",
    "    # b t 1 -> b t d\n",
    "    def __call__(self, pos):\n",
    "        b, t, _ = pos.size()\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        max_len = 1024\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        sin_p = torch.sin(position / pow_)\n",
    "        cos_p = torch.cos(position / pow_)\n",
    "        pe = torch.zeros(max_len, self.d)\n",
    "        pe[:, 0::2] = sin_p\n",
    "        pe[:, 1::2] = cos_p\n",
    "        return pe[:t, :].unsqueeze(0).repeat(b, 1, 1)\n",
    "\n",
    "print(PEAnotherImpl()(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])\n",
    "\n",
    "class PEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        pos = torch.arange(max_len).unsqueeze(1)\n",
    "        print(pos.size())\n",
    "        sin_p = torch.sin(pos / pow_)\n",
    "        cos_p = torch.cos(pos / pow_)\n",
    "        print(sin_p.size())\n",
    "        print(cos_p.size())\n",
    "        pe = torch.stack((sin_p, cos_p), dim=-1).view(-1, self.d) # downside sin, cos don't alternate\n",
    "        print(pe.size())\n",
    "        pe = pe.unsqueeze(0)\n",
    "        print(pe.size())\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.size: b, t, d\n",
    "        x = x + self.pe[:, : t, :]\n",
    "        return self.dropout(x)\n",
    "print(PEModule(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])\n",
    "\n",
    "class PositionalEncodingAnnotatedTransformerModule(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncodingAnnotatedTransformer, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        print(position.size())\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "        )\n",
    "        print(div_term.size())\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        print(pe.size())\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.pe[:, : x.size(1)].size())\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "print(PositionalEncodingAnnotatedTransformerModule(512, 0.1)(torch.arange(6).view(-1, 3, 1)).size()) # torch.Size([2, 3, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f56a9e6b-8461-4417-ab07-e5fbd79c60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4413f3-ef3e-4d04-baad-f49354915c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PE(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        twoi = torch.arange(0, self.d, 2)\n",
    "        pow_ = torch.pow(10000, twoi / self.d)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        sin_p = torch.sin(position / pow_)\n",
    "        cos_p = torch.cos(position / pow_)\n",
    "        pe = torch.zeros(max_len, self.d, requires_grad=False) # Explicit, register buffer insures requires grad = False\n",
    "        pe[:, 0::2] = sin_p\n",
    "        pe[:, 1::2] = cos_p\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe) \n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.pe[:, : t, :]\n",
    "        return self.dropout(x)\n",
    "print(PE(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dd49c59-e4b6-4b7d-9719-79079f2f40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PEEmbed(nn.Module):\n",
    "\n",
    "    def __init__(self, d: int = 512, max_len: int = 1024, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.d = d\n",
    "        self.pe = nn.Embedding(max_len, d)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        pos = self.pe(torch.arange(t))\n",
    "        x = x + pos\n",
    "        return self.dropout(x)\n",
    "print(PEEmbed(d=4)(torch.arange(24).view(-1, 3, 4)).size()) # torch.Size([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9c5bf9-3800-4b22-b7d8-8886d4f15b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d626059-fd88-4a03-8b20-ffbf0115fe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderLayerWithoutMask(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSA(d, h)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.attn_dropout(self.mhsa(x, x, x))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "encoder_layer = EncoderLayerWithoutMask()\n",
    "x = torch.rand(2, 3, 512)\n",
    "encoder_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851eff3d-4816-4410-9184-f30c157e4eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n",
      "torch.Size([2, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class EncoderWithoutMask(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [EncoderLayerWithoutMask(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t = x.size()\n",
    "        x = self.embed(x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "encoder = EncoderWithoutMask()\n",
    "x = torch.randint(0, 2**13, (2, 3))\n",
    "encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cddfbf32-dd33-4246-adad-0baa8b6ba5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With masks\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def self_attention_masked(q, k, v, mask=None):\n",
    "    # if 3 dim: b t d\n",
    "    #prod = Q.bmm(K.permute(0, 2, 1))\n",
    "    # or\n",
    "    # prod = torch.einsum(\"btd, bsd -> bts\", q, k)\n",
    "    # if 4 dim: b t h dh:\n",
    "    prod = torch.einsum(\"bthd, bshd -> bhts\", q, k)\n",
    "    scaled_prod = prod/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "    print(f\"scaled_prod.shape: \\n {scaled_prod.shape}\")\n",
    "    # mask should be in shape to be broadcastable to bhts and lead to masked keys only (last s dim)\n",
    "    if mask is not None:\n",
    "        scaled_prod = scaled_prod.masked_fill(mask == 0, float(\"-inf\"))\n",
    "    print(f\"scaled_prod: \\n {scaled_prod}\")\n",
    "    softmaxed_prod = F.softmax(scaled_prod, dim=-1)\n",
    "    # print(softmaxed_prod.shape)\n",
    "    print(f\"softmaxed_prod: \\n {softmaxed_prod}\")\n",
    "    # swap h and t in v\n",
    "    return softmaxed_prod @ v.permute(0, 2, 1, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eac5e23-ea43-4295-ba24-a7edbe1a1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d78a45-be0c-4d97-9020-4b83e8c499f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6164, 0.1778, 0.9353, 0.4388],\n",
      "          [0.6152, 0.1659, 0.4717, 0.4772]],\n",
      "\n",
      "         [[0.3524, 0.0751, 0.3100, 0.9328],\n",
      "          [0.0744, 0.9578, 0.5731, 0.7566]],\n",
      "\n",
      "         [[0.1704, 0.1385, 0.5422, 0.5292],\n",
      "          [0.7538, 0.3801, 0.4732, 0.1390]]],\n",
      "\n",
      "\n",
      "        [[[0.6504, 0.3352, 0.7541, 0.7502],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186]],\n",
      "\n",
      "         [[0.5849, 0.3492, 0.8659, 0.2505],\n",
      "          [0.1802, 0.2976, 0.4366, 0.5256]],\n",
      "\n",
      "         [[0.1058, 0.1050, 0.5552, 0.5796],\n",
      "          [0.2178, 0.4177, 0.6545, 0.5954]]]])\n",
      "mask: \n",
      " tensor([[1., 1., 0.],\n",
      "        [1., 0., 0.]])\n",
      "wrong mask: \n",
      " tensor([[[1., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 0.]]])\n",
      "wrong mask broadcast: \n",
      " tensor([[[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.7395, 0.4649,   -inf],\n",
      "          [0.4649, 0.5480,   -inf],\n",
      "          [0.4345, 0.3661,   -inf]],\n",
      "\n",
      "         [[0.4281,   -inf,   -inf],\n",
      "          [0.4180,   -inf,   -inf],\n",
      "          [0.4082,   -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8334, 0.6692,   -inf],\n",
      "          [0.6692, 0.6383,   -inf],\n",
      "          [0.4787, 0.3622,   -inf]],\n",
      "\n",
      "         [[0.3909,   -inf,   -inf],\n",
      "          [0.2631,   -inf,   -inf],\n",
      "          [0.3543,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5682, 0.4318, 0.0000],\n",
      "          [0.4792, 0.5208, 0.0000],\n",
      "          [0.5171, 0.4829, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5410, 0.4590, 0.0000],\n",
      "          [0.5077, 0.4923, 0.0000],\n",
      "          [0.5291, 0.4709, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "wrong a: \n",
      " tensor([[[[0.5024, 0.1335, 0.6653, 0.6521],\n",
      "          [0.4789, 0.1243, 0.6097, 0.6960],\n",
      "          [0.4889, 0.1282, 0.6333, 0.6773]],\n",
      "\n",
      "         [[0.6152, 0.1659, 0.4717, 0.4772],\n",
      "          [0.6152, 0.1659, 0.4717, 0.4772],\n",
      "          [0.6152, 0.1659, 0.4717, 0.4772]]],\n",
      "\n",
      "\n",
      "        [[[0.6204, 0.3416, 0.8054, 0.5208],\n",
      "          [0.6182, 0.3421, 0.8091, 0.5042],\n",
      "          [0.6196, 0.3418, 0.8067, 0.5149]],\n",
      "\n",
      "         [[0.6255, 0.1920, 0.5531, 0.2186],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186]]]])\n",
      "wrong a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n",
      "mask: \n",
      " tensor([[[[1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.]]]])\n",
      "mask broadcast: \n",
      " tensor([[[[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]],\n",
      "\n",
      "         [[1., 1., 0.],\n",
      "          [1., 1., 0.],\n",
      "          [1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]],\n",
      "\n",
      "         [[1., 0., 0.],\n",
      "          [1., 0., 0.],\n",
      "          [1., 0., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.7395, 0.4649,   -inf],\n",
      "          [0.4649, 0.5480,   -inf],\n",
      "          [0.4345, 0.3661,   -inf]],\n",
      "\n",
      "         [[0.4281, 0.4180,   -inf],\n",
      "          [0.4180, 0.9119,   -inf],\n",
      "          [0.4082, 0.3983,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8334,   -inf,   -inf],\n",
      "          [0.6692,   -inf,   -inf],\n",
      "          [0.4787,   -inf,   -inf]],\n",
      "\n",
      "         [[0.3909,   -inf,   -inf],\n",
      "          [0.2631,   -inf,   -inf],\n",
      "          [0.3543,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5682, 0.4318, 0.0000],\n",
      "          [0.4792, 0.5208, 0.0000],\n",
      "          [0.5171, 0.4829, 0.0000]],\n",
      "\n",
      "         [[0.5025, 0.4975, 0.0000],\n",
      "          [0.3790, 0.6210, 0.0000],\n",
      "          [0.5025, 0.4975, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "a: \n",
      " tensor([[[[0.5024, 0.1335, 0.6653, 0.6521],\n",
      "          [0.4789, 0.1243, 0.6097, 0.6960],\n",
      "          [0.4889, 0.1282, 0.6333, 0.6773]],\n",
      "\n",
      "         [[0.3462, 0.5599, 0.5221, 0.6162],\n",
      "          [0.2793, 0.6577, 0.5347, 0.6507],\n",
      "          [0.3461, 0.5599, 0.5221, 0.6162]]],\n",
      "\n",
      "\n",
      "        [[[0.6504, 0.3352, 0.7541, 0.7502],\n",
      "          [0.6504, 0.3352, 0.7541, 0.7502],\n",
      "          [0.6504, 0.3352, 0.7541, 0.7502]],\n",
      "\n",
      "         [[0.6255, 0.1920, 0.5531, 0.2186],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186]]]])\n",
      "a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# play with mask\n",
    "\n",
    "x = torch.rand([2, 3, 2, 4])\n",
    "print(x)\n",
    "# mask 2 batches 3 timeseries\n",
    "mask = torch.ones([2, 3])\n",
    "mask[0, 2] = 0\n",
    "mask[1, 2] = 0\n",
    "mask[1, 1] = 0\n",
    "print(f\"mask: \\n {mask}\")\n",
    "# add head dim to make mask broatcastable to q x k.T prod. mask shape 2, 1, 3\n",
    "mask = mask.unsqueeze(1)\n",
    "\n",
    "\n",
    "# mask = mask.permute(0, 2, 1)\n",
    "# is the mask that I need? keys are ignored?\n",
    "print(f\"wrong mask: \\n {mask}\")\n",
    "#  mask = 2 1 3 -> b prepended before broadcasting (1!!!) h (remains since already 2) t (broadcasted from 1) d (remains since already 3) \n",
    "print(f\"wrong mask broadcast: \\n {mask.broadcast_to([2, 2, 3, 3])}\") \n",
    "a = self_attention_masked(x, x, x, mask=mask)\n",
    "print(f\"wrong a: \\n {a}\" )\n",
    "print(f\"wrong a.shape: \\n {a.shape}\")\n",
    "# leads to wrong attention since the shape of mask is wrong 2 1 3 \n",
    "\n",
    "# correct mask\n",
    "# mask 2 batches 3 timeseries\n",
    "mask = torch.ones([2, 3])\n",
    "mask[0, 2] = 0\n",
    "mask[1, 2] = 0\n",
    "mask[1, 1] = 0\n",
    "mask = mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "print(f\"mask: \\n {mask}\")\n",
    "#  mask = 2 1 1 3 -> b (remains already 2) h (broadcasted from 1) t (broadcasted from 1) d (remains since already 3) \n",
    "print(f\"mask broadcast: \\n {mask.broadcast_to([2, 2, 3, 3])}\") \n",
    "a = self_attention_masked(x, x, x, mask=mask)\n",
    "print(f\"a: \\n {a}\" )\n",
    "print(f\"a.shape: \\n {a.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1c6a367-2547-4d72-be99-19bbc1023c99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: \n",
      " tensor([[[[0.6164, 0.1778, 0.9353, 0.4388],\n",
      "          [0.6152, 0.1659, 0.4717, 0.4772]],\n",
      "\n",
      "         [[0.3524, 0.0751, 0.3100, 0.9328],\n",
      "          [0.0744, 0.9578, 0.5731, 0.7566]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.6504, 0.3352, 0.7541, 0.7502],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]],\n",
      "\n",
      "         [[  -inf,   -inf,   -inf,   -inf],\n",
      "          [  -inf,   -inf,   -inf,   -inf]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[0.7395, 0.4649,   -inf],\n",
      "          [0.4649, 0.5480,   -inf],\n",
      "          [0.4345, 0.3661,   -inf]],\n",
      "\n",
      "         [[0.4281, 0.4180,   -inf],\n",
      "          [0.4180, 0.9119,   -inf],\n",
      "          [0.4082, 0.3983,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8334,   -inf,   -inf],\n",
      "          [0.6692,   -inf,   -inf],\n",
      "          [0.4787,   -inf,   -inf]],\n",
      "\n",
      "         [[0.3909,   -inf,   -inf],\n",
      "          [0.2631,   -inf,   -inf],\n",
      "          [0.3543,   -inf,   -inf]]]])\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5682, 0.4318, 0.0000],\n",
      "          [0.4792, 0.5208, 0.0000],\n",
      "          [0.5171, 0.4829, 0.0000]],\n",
      "\n",
      "         [[0.5025, 0.4975, 0.0000],\n",
      "          [0.3790, 0.6210, 0.0000],\n",
      "          [0.5025, 0.4975, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]])\n",
      "a: \n",
      " tensor([[[[0.5024, 0.1335, 0.6653, 0.6521],\n",
      "          [0.4789, 0.1243, 0.6097, 0.6960],\n",
      "          [0.4889, 0.1282, 0.6333, 0.6773]],\n",
      "\n",
      "         [[0.3462, 0.5599, 0.5221, 0.6162],\n",
      "          [0.2793, 0.6577, 0.5347, 0.6507],\n",
      "          [0.3461, 0.5599, 0.5221, 0.6162]]],\n",
      "\n",
      "\n",
      "        [[[0.6504, 0.3352, 0.7541, 0.7502],\n",
      "          [0.6504, 0.3352, 0.7541, 0.7502],\n",
      "          [0.6504, 0.3352, 0.7541, 0.7502]],\n",
      "\n",
      "         [[0.6255, 0.1920, 0.5531, 0.2186],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186],\n",
      "          [0.6255, 0.1920, 0.5531, 0.2186]]]])\n",
      "a.shape: \n",
      " torch.Size([2, 2, 3, 4])\n",
      "test: \n",
      " tensor([[[0.3888, 0.5855, 0.2134, 0.2141],\n",
      "         [0.6145, 0.0208, 0.5906, 0.8689],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.8259, 0.2437, 0.9276, 0.9749],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000]]])\n",
      "test_v: \n",
      " tensor([[[[0.3888, 0.5855],\n",
      "          [0.2134, 0.2141]],\n",
      "\n",
      "         [[0.6145, 0.0208],\n",
      "          [0.5906, 0.8689]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.8259, 0.2437],\n",
      "          [0.9276, 0.9749]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]]])\n",
      "test_perm: \n",
      " tensor([[[[0.3888, 0.5855],\n",
      "          [0.6145, 0.0208],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.2134, 0.2141],\n",
      "          [0.5906, 0.8689],\n",
      "          [0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.8259, 0.2437],\n",
      "          [0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.9276, 0.9749],\n",
      "          [0.0000, 0.0000],\n",
      "          [0.0000, 0.0000]]]])\n",
      "test_k: \n",
      " tensor([[[0.2867, 0.2215, 0.8561, 0.3156],\n",
      "         [0.4750, 0.6043, 0.1089, 0.7268],\n",
      "         [  -inf,   -inf,   -inf,   -inf]],\n",
      "\n",
      "        [[0.8828, 0.1971, 0.5777, 0.7374],\n",
      "         [  -inf,   -inf,   -inf,   -inf],\n",
      "         [  -inf,   -inf,   -inf,   -inf]]])\n",
      "test_k_view: \n",
      " tensor([[[[0.2867, 0.2215],\n",
      "          [0.8561, 0.3156]],\n",
      "\n",
      "         [[0.4750, 0.6043],\n",
      "          [0.1089, 0.7268]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8828, 0.1971],\n",
      "          [0.5777, 0.7374]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[  -inf,   -inf],\n",
      "          [  -inf,   -inf]]]])\n",
      "test_k_perm: \n",
      " tensor([[[[0.2867, 0.2215],\n",
      "          [0.4750, 0.6043],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[0.8561, 0.3156],\n",
      "          [0.1089, 0.7268],\n",
      "          [  -inf,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8828, 0.1971],\n",
      "          [  -inf,   -inf],\n",
      "          [  -inf,   -inf]],\n",
      "\n",
      "         [[0.5777, 0.7374],\n",
      "          [  -inf,   -inf],\n",
      "          [  -inf,   -inf]]]])\n",
      "q * k: \n",
      " tensor([[[[0.1313, 0.2701,   -inf],\n",
      "          [0.2701, 0.5908,   -inf],\n",
      "          [0.2752, 0.6817,   -inf]],\n",
      "\n",
      "         [[0.8325, 0.3226,   -inf],\n",
      "          [0.3226, 0.5402,   -inf],\n",
      "          [0.9431, 0.3972,   -inf]]],\n",
      "\n",
      "\n",
      "        [[[0.8181,   -inf,   -inf],\n",
      "          [0.5046,   -inf,   -inf],\n",
      "          [0.5522,   -inf,   -inf]],\n",
      "\n",
      "         [[0.8775,   -inf,   -inf],\n",
      "          [0.7607,   -inf,   -inf],\n",
      "          [1.2424,   -inf,   -inf]]]])\n"
     ]
    }
   ],
   "source": [
    "# mask is equal to making keys on masked places 0:\n",
    "# the result in terms of masked symbols is the same\n",
    "k = x.clone()\n",
    "k[0, 2, 0, :] = float(\"-inf\")\n",
    "k[0, 2, 1, :] = float(\"-inf\")\n",
    "k[1, 2, 0, :] = float(\"-inf\")\n",
    "k[1, 1, 0, :] = float(\"-inf\")\n",
    "k[1, 2, 1, :] = float(\"-inf\")\n",
    "k[1, 1, 1, :] = float(\"-inf\")\n",
    "print(f\"k: \\n {k}\")\n",
    "a = self_attention_masked(x, k, x)\n",
    "print(f\"a: \\n {a}\" )\n",
    "print(f\"a.shape: \\n {a.shape}\")\n",
    "# a is the same shape as if mask was applied in q * k:\n",
    "\n",
    "test = torch.rand([2, 3, 4])\n",
    "test[0, 2, :] = 0\n",
    "test[1, 1, :] = 0\n",
    "test[1, 2, :] = 0\n",
    "\n",
    "print(f\"test: \\n {test}\")\n",
    "test_v = test.view(2, 3, 2, 2)\n",
    "print(f\"test_v: \\n {test_v}\")\n",
    "test_perm = test_v.permute(0, 2, 1, 3)\n",
    "print(f\"test_perm: \\n {test_perm}\")\n",
    "\n",
    "# or like that:\n",
    "test_q = torch.rand([2, 3, 4])\n",
    "test_k = test_q.clone()\n",
    "test_k[0, 2, :] = float(\"-inf\")\n",
    "test_k[1, 1, :] = float(\"-inf\")\n",
    "test_k[1, 2, :] = float(\"-inf\")\n",
    "print(f\"test_k: \\n {test_k}\")\n",
    "\n",
    "test_q_view = test_q.view(2, 3, 2, 2)\n",
    "test_k_view = test_k.view(2, 3, 2, 2)\n",
    "print(f\"test_k_view: \\n {test_k_view}\")\n",
    "test_q_perm = test_q_view.permute(0, 2, 1, 3)\n",
    "test_k_perm = test_k_view.permute(0, 2, 1, 3)\n",
    "print(f\"test_k_perm: \\n {test_k_perm}\")\n",
    "print(f\"q * k: \\n {torch.einsum(\"bhtd, bhsd -> bhts\", test_q_perm, test_k_perm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90465ec8-787f-409e-977a-30c566450515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.4148e-01, 2.2639e-02, 1.2796e-01, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [3.5107e-01, 3.3189e-02, 6.5396e-01, 6.8129e-01, 1.0000e+02, 1.0000e+02],\n",
      "        [7.0389e-01, 6.7112e-01, 2.1144e-01, 4.4746e-02, 1.7409e-01, 1.0000e+02],\n",
      "        [1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02, 1.0000e+02],\n",
      "        [6.0043e-01, 8.4909e-01, 9.0186e-02, 8.3443e-01, 5.7014e-01, 1.9058e-01]])\n",
      "tensor([[1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_padding_mask(x, pad_token):\n",
    "    # x: b t shape\n",
    "    mask = torch.ones_like(x)\n",
    "    return mask.masked_fill(x == pad_token, 0)\n",
    "\n",
    "x = torch.rand(5, 6)\n",
    "x[0, -3:] = 100\n",
    "x[1, -2:] = 100\n",
    "x[2, -1] = 100\n",
    "x[3, :] = 100\n",
    "print(x)\n",
    "print(build_padding_mask(x, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "647bfc41-5717-4c39-92d5-6d1ba132f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def build_causal_mask(x):\n",
    "    # x: b t shape\n",
    "    m = torch.ones_like(x)\n",
    "    return torch.tril(m)\n",
    "x = torch.rand(5, 6)\n",
    "\n",
    "print(build_causal_mask(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6702b0c-11f5-4326-989e-d2b76a77dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.1822,   0.9773,   0.3937, 100.0000, 100.0000, 100.0000],\n",
      "        [  0.6297,   0.4831,   0.5250,   0.1028,   0.3756, 100.0000],\n",
      "        [  0.3837,   0.6903, 100.0000, 100.0000, 100.0000, 100.0000],\n",
      "        [100.0000, 100.0000, 100.0000, 100.0000, 100.0000, 100.0000],\n",
      "        [  0.4342,   0.5863,   0.4891,   0.4150,   0.5842,   0.6702]])\n",
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def merge_masks(m1, m2):\n",
    "    return m1 * m2\n",
    "\n",
    "x = torch.rand(5, 6)\n",
    "x[0, -3:] = 100\n",
    "x[1, -1] = 100\n",
    "x[2, -4:] = 100\n",
    "x[3, :] = 100\n",
    "print(x)\n",
    "m1 = build_padding_mask(x, 100)\n",
    "m2 = build_causal_mask(x)\n",
    "print(merge_masks(m1, m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c167748-72fb-40b3-9e6d-7755fa12bc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def reshape_mask(mask):\n",
    "    # b t -> b 1 1 t (to be broadcastable to b h t t)\n",
    "    return mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "x = torch.rand(2, 3)\n",
    "print(reshape_mask(build_causal_mask(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "336c48b9-29d0-4f4e-9d67-a12ddc566634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1., 1., 1., 0.]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([4, 2, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0537,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1387,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1328,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0958,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2381,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0215,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0674,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2111,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1404,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2935,    -inf,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0078,  0.0492,    -inf,    -inf,    -inf],\n",
      "          [ 0.0057,  0.0968,    -inf,    -inf,    -inf],\n",
      "          [-0.0754,  0.0486,    -inf,    -inf,    -inf],\n",
      "          [-0.0710,  0.0382,    -inf,    -inf,    -inf],\n",
      "          [-0.0371,  0.0492,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3095, -0.0794,    -inf,    -inf,    -inf],\n",
      "          [-0.2406, -0.0460,    -inf,    -inf,    -inf],\n",
      "          [-0.2341, -0.0398,    -inf,    -inf,    -inf],\n",
      "          [-0.2356, -0.0588,    -inf,    -inf,    -inf],\n",
      "          [-0.3578, -0.0941,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0989,  0.1060,  0.1150,    -inf,    -inf],\n",
      "          [ 0.1393,  0.1759,  0.1717,    -inf,    -inf],\n",
      "          [ 0.0802,  0.0930,  0.0981,    -inf,    -inf],\n",
      "          [ 0.0763,  0.0669,  0.0845,    -inf,    -inf],\n",
      "          [ 0.0344,  0.0572,  0.0569,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0314, -0.1989, -0.1213,    -inf,    -inf],\n",
      "          [-0.1282, -0.3883, -0.2772,    -inf,    -inf],\n",
      "          [ 0.0180, -0.1279, -0.0969,    -inf,    -inf],\n",
      "          [ 0.0768, -0.0107, -0.0118,    -inf,    -inf],\n",
      "          [-0.0252, -0.1796, -0.1332,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0153, -0.0026, -0.0538, -0.0438,    -inf],\n",
      "          [ 0.0796,  0.0661,  0.0075,  0.0475,    -inf],\n",
      "          [ 0.0460,  0.0499, -0.0071,  0.0146,    -inf],\n",
      "          [-0.0041,  0.0059, -0.0846, -0.0543,    -inf],\n",
      "          [-0.0806, -0.0590, -0.1857, -0.1513,    -inf]],\n",
      "\n",
      "         [[-0.2114, -0.1745, -0.2312, -0.1713,    -inf],\n",
      "          [-0.1131, -0.0968, -0.1088, -0.1086,    -inf],\n",
      "          [-0.2466, -0.2231, -0.2642, -0.2238,    -inf],\n",
      "          [-0.1756, -0.1327, -0.1723, -0.1484,    -inf],\n",
      "          [-0.0325, -0.0063, -0.0135, -0.0266,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4896, 0.5104, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4772, 0.5228, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4690, 0.5310, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4727, 0.5273, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4784, 0.5216, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4427, 0.5573, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4515, 0.5485, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4516, 0.5484, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4559, 0.5441, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4345, 0.5655, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3308, 0.3331, 0.3361, 0.0000, 0.0000],\n",
      "          [0.3257, 0.3379, 0.3364, 0.0000, 0.0000],\n",
      "          [0.3299, 0.3342, 0.3359, 0.0000, 0.0000],\n",
      "          [0.3335, 0.3303, 0.3362, 0.0000, 0.0000],\n",
      "          [0.3283, 0.3359, 0.3358, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3770, 0.2994, 0.3236, 0.0000, 0.0000],\n",
      "          [0.3799, 0.2929, 0.3273, 0.0000, 0.0000],\n",
      "          [0.3629, 0.3136, 0.3235, 0.0000, 0.0000],\n",
      "          [0.3532, 0.3236, 0.3232, 0.0000, 0.0000],\n",
      "          [0.3630, 0.3111, 0.3259, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2534, 0.2566, 0.2438, 0.2462, 0.0000],\n",
      "          [0.2574, 0.2539, 0.2395, 0.2492, 0.0000],\n",
      "          [0.2550, 0.2560, 0.2418, 0.2471, 0.0000],\n",
      "          [0.2575, 0.2601, 0.2376, 0.2449, 0.0000],\n",
      "          [0.2595, 0.2652, 0.2336, 0.2418, 0.0000]],\n",
      "\n",
      "         [[0.2464, 0.2556, 0.2415, 0.2564, 0.0000],\n",
      "          [0.2484, 0.2525, 0.2495, 0.2496, 0.0000],\n",
      "          [0.2482, 0.2541, 0.2439, 0.2539, 0.0000],\n",
      "          [0.2454, 0.2562, 0.2462, 0.2522, 0.0000],\n",
      "          [0.2468, 0.2534, 0.2516, 0.2483, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[ 0.2491, -0.2676, -0.2450,  0.3543, -0.0804, -0.2210],\n",
      "         [ 0.2491, -0.2676, -0.2450,  0.3543, -0.0804, -0.2210],\n",
      "         [ 0.2491, -0.2676, -0.2450,  0.3543, -0.0804, -0.2210],\n",
      "         [ 0.2491, -0.2676, -0.2450,  0.3543, -0.0804, -0.2210],\n",
      "         [ 0.2491, -0.2676, -0.2450,  0.3543, -0.0804, -0.2210]],\n",
      "\n",
      "        [[-0.0037, -0.5739, -0.0051,  0.3550, -0.2566, -0.1458],\n",
      "         [-0.0049, -0.5718, -0.0059,  0.3539, -0.2578, -0.1449],\n",
      "         [-0.0051, -0.5703, -0.0066,  0.3534, -0.2587, -0.1445],\n",
      "         [-0.0055, -0.5710, -0.0061,  0.3535, -0.2582, -0.1446],\n",
      "         [-0.0031, -0.5717, -0.0064,  0.3545, -0.2580, -0.1453]],\n",
      "\n",
      "        [[ 0.0333, -0.4980, -0.0168,  0.3282, -0.2150, -0.0994],\n",
      "         [ 0.0347, -0.4975, -0.0181,  0.3290, -0.2154, -0.1001],\n",
      "         [ 0.0305, -0.4987, -0.0140,  0.3262, -0.2135, -0.0983],\n",
      "         [ 0.0285, -0.4992, -0.0121,  0.3249, -0.2125, -0.0975],\n",
      "         [ 0.0311, -0.4984, -0.0146,  0.3265, -0.2136, -0.0986]],\n",
      "\n",
      "        [[ 0.0196, -0.5993, -0.0305,  0.3939, -0.2417, -0.1815],\n",
      "         [ 0.0185, -0.5989, -0.0308,  0.3936, -0.2416, -0.1808],\n",
      "         [ 0.0193, -0.5989, -0.0308,  0.3937, -0.2416, -0.1813],\n",
      "         [ 0.0183, -0.5982, -0.0310,  0.3931, -0.2419, -0.1806],\n",
      "         [ 0.0174, -0.5974, -0.0313,  0.3925, -0.2422, -0.1802]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([4, 2, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0537,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1387,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1328,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0958,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2381,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0215,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0674,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2111,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1404,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2935,    -inf,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0078,  0.0492,    -inf,    -inf,    -inf],\n",
      "          [ 0.0057,  0.0968,    -inf,    -inf,    -inf],\n",
      "          [-0.0754,  0.0486,    -inf,    -inf,    -inf],\n",
      "          [-0.0710,  0.0382,    -inf,    -inf,    -inf],\n",
      "          [-0.0371,  0.0492,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3095, -0.0794,    -inf,    -inf,    -inf],\n",
      "          [-0.2406, -0.0460,    -inf,    -inf,    -inf],\n",
      "          [-0.2341, -0.0398,    -inf,    -inf,    -inf],\n",
      "          [-0.2356, -0.0588,    -inf,    -inf,    -inf],\n",
      "          [-0.3578, -0.0941,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0989,  0.1060,  0.1150,    -inf,    -inf],\n",
      "          [ 0.1393,  0.1759,  0.1717,    -inf,    -inf],\n",
      "          [ 0.0802,  0.0930,  0.0981,    -inf,    -inf],\n",
      "          [ 0.0763,  0.0669,  0.0845,    -inf,    -inf],\n",
      "          [ 0.0344,  0.0572,  0.0569,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0314, -0.1989, -0.1213,    -inf,    -inf],\n",
      "          [-0.1282, -0.3883, -0.2772,    -inf,    -inf],\n",
      "          [ 0.0180, -0.1279, -0.0969,    -inf,    -inf],\n",
      "          [ 0.0768, -0.0107, -0.0118,    -inf,    -inf],\n",
      "          [-0.0252, -0.1796, -0.1332,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0153, -0.0026, -0.0538, -0.0438,    -inf],\n",
      "          [ 0.0796,  0.0661,  0.0075,  0.0475,    -inf],\n",
      "          [ 0.0460,  0.0499, -0.0071,  0.0146,    -inf],\n",
      "          [-0.0041,  0.0059, -0.0846, -0.0543,    -inf],\n",
      "          [-0.0806, -0.0590, -0.1857, -0.1513,    -inf]],\n",
      "\n",
      "         [[-0.2114, -0.1745, -0.2312, -0.1713,    -inf],\n",
      "          [-0.1131, -0.0968, -0.1088, -0.1086,    -inf],\n",
      "          [-0.2466, -0.2231, -0.2642, -0.2238,    -inf],\n",
      "          [-0.1756, -0.1327, -0.1723, -0.1484,    -inf],\n",
      "          [-0.0325, -0.0063, -0.0135, -0.0266,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4896, 0.5104, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4772, 0.5228, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4690, 0.5310, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4727, 0.5273, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4784, 0.5216, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4427, 0.5573, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4515, 0.5485, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4516, 0.5484, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4559, 0.5441, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4345, 0.5655, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3308, 0.3331, 0.3361, 0.0000, 0.0000],\n",
      "          [0.3257, 0.3379, 0.3364, 0.0000, 0.0000],\n",
      "          [0.3299, 0.3342, 0.3359, 0.0000, 0.0000],\n",
      "          [0.3335, 0.3303, 0.3362, 0.0000, 0.0000],\n",
      "          [0.3283, 0.3359, 0.3358, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3770, 0.2994, 0.3236, 0.0000, 0.0000],\n",
      "          [0.3799, 0.2929, 0.3273, 0.0000, 0.0000],\n",
      "          [0.3629, 0.3136, 0.3235, 0.0000, 0.0000],\n",
      "          [0.3532, 0.3236, 0.3232, 0.0000, 0.0000],\n",
      "          [0.3630, 0.3111, 0.3259, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2534, 0.2566, 0.2438, 0.2462, 0.0000],\n",
      "          [0.2574, 0.2539, 0.2395, 0.2492, 0.0000],\n",
      "          [0.2550, 0.2560, 0.2418, 0.2471, 0.0000],\n",
      "          [0.2575, 0.2601, 0.2376, 0.2449, 0.0000],\n",
      "          [0.2595, 0.2652, 0.2336, 0.2418, 0.0000]],\n",
      "\n",
      "         [[0.2464, 0.2556, 0.2415, 0.2564, 0.0000],\n",
      "          [0.2484, 0.2525, 0.2495, 0.2496, 0.0000],\n",
      "          [0.2482, 0.2541, 0.2439, 0.2539, 0.0000],\n",
      "          [0.2454, 0.2562, 0.2462, 0.2522, 0.0000],\n",
      "          [0.2468, 0.2534, 0.2516, 0.2483, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MHSAMasked(nn.Module):\n",
    "    def __init__(self, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        assert d % h == 0\n",
    "        self.d = d\n",
    "        self.dh = d // h\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(self.d, self.d)\n",
    "        self.wk = nn.Linear(self.d, self.d)\n",
    "        self.wv = nn.Linear(self.d, self.d)\n",
    "        self.wo = nn.Linear(self.d, self.d)\n",
    " \n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        # q and k/v might be of different sizes if lengths of decoder and encoders inputs are different\n",
    "        bq, tq, dq = q.size()\n",
    "        bk, tk, dk = k.size()\n",
    "        wq = self.wq(q)\n",
    "        wk = self.wk(k)\n",
    "        wv = self.wv(v)\n",
    "        wq = wq.view(bq, tq, self.h, self.dh)\n",
    "        wk = wk.view(bk, tk, self.h, self.dh)\n",
    "        wv = wv.view(bk, tk, self.h, self.dh)\n",
    "        # b, t, h, dh\n",
    "        # if changing from 4 dim -> 3 dim: b*h, t, dh\n",
    "        # wq = wq.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wk = wk.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wv = wv.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # another option 4 dim -> 3 dim\n",
    "        # wq = wq.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wk = wk.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wv = wv.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # changing the number of dims is not necessary as @ supports 4 dims\n",
    "        attn = self_attention_masked(wq, wk, wv, mask=mask)\n",
    "        # b * h, t, dh\n",
    "        # attn = attn.view(b, self.h, t, self.dh).permute(0, 2, 1, 3).reshape(b, t, d)\n",
    "        attn = attn.view(bq, self.h, tq, self.dh).transpose(1, 2).contiguous().view(bq, tq, dq)\n",
    "        wo = self.wo(attn)\n",
    "        return wo\n",
    "        # # 1 2 3 4\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # return F.relu(self.conv2(x))\n",
    "\n",
    "mhsa_masked = MHSAMasked(h = 2, d = 6)\n",
    "x = torch.rand(4, 5)\n",
    "mask = reshape_mask(build_causal_mask(x))\n",
    "print(mask)\n",
    "x = torch.rand(4, 5, 6)\n",
    "print(mhsa_masked(x, x, x, mask=mask))\n",
    "print(mhsa_masked(x, x, x, mask=mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "729ae6f8-a3f8-4386-837d-f1e67f022b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22d0cd6d-12f4-44f0-b8b9-62a18a6d2f22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0754, -0.1314,    -inf],\n",
      "          [-0.0970, -0.1964,    -inf],\n",
      "          [ 0.0464, -0.0945,    -inf]],\n",
      "\n",
      "         [[ 0.0843,  0.0848,    -inf],\n",
      "          [-0.0227, -0.0228,    -inf],\n",
      "          [ 0.0956,  0.0830,    -inf]],\n",
      "\n",
      "         [[-0.0293, -0.0763,    -inf],\n",
      "          [-0.0226, -0.0955,    -inf],\n",
      "          [-0.0309, -0.0531,    -inf]],\n",
      "\n",
      "         [[-0.0876,  0.0441,    -inf],\n",
      "          [-0.0258,  0.0927,    -inf],\n",
      "          [-0.0357,  0.0175,    -inf]],\n",
      "\n",
      "         [[ 0.0636,  0.1356,    -inf],\n",
      "          [ 0.1351,  0.1470,    -inf],\n",
      "          [-0.0188,  0.0551,    -inf]],\n",
      "\n",
      "         [[-0.1990,  0.0022,    -inf],\n",
      "          [-0.1659,  0.0083,    -inf],\n",
      "          [-0.2187, -0.0992,    -inf]],\n",
      "\n",
      "         [[ 0.0008, -0.0380,    -inf],\n",
      "          [ 0.0258, -0.0592,    -inf],\n",
      "          [-0.0053, -0.0550,    -inf]],\n",
      "\n",
      "         [[ 0.0972,  0.2530,    -inf],\n",
      "          [ 0.1754,  0.2615,    -inf],\n",
      "          [ 0.0913,  0.2150,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1104,    -inf,    -inf],\n",
      "          [-0.0428,    -inf,    -inf],\n",
      "          [-0.0335,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0965,    -inf,    -inf],\n",
      "          [-0.0130,    -inf,    -inf],\n",
      "          [-0.0951,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0339,    -inf,    -inf],\n",
      "          [ 0.0036,    -inf,    -inf],\n",
      "          [-0.1166,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1465,    -inf,    -inf],\n",
      "          [ 0.1540,    -inf,    -inf],\n",
      "          [ 0.1674,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3147,    -inf,    -inf],\n",
      "          [ 0.2004,    -inf,    -inf],\n",
      "          [ 0.0449,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0624,    -inf,    -inf],\n",
      "          [-0.0698,    -inf,    -inf],\n",
      "          [-0.1030,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0110,    -inf,    -inf],\n",
      "          [ 0.0955,    -inf,    -inf],\n",
      "          [ 0.1287,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1339,    -inf,    -inf],\n",
      "          [ 0.0934,    -inf,    -inf],\n",
      "          [ 0.1833,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5140, 0.4860, 0.0000],\n",
      "          [0.5248, 0.4752, 0.0000],\n",
      "          [0.5352, 0.4648, 0.0000]],\n",
      "\n",
      "         [[0.4999, 0.5001, 0.0000],\n",
      "          [0.5000, 0.5000, 0.0000],\n",
      "          [0.5031, 0.4969, 0.0000]],\n",
      "\n",
      "         [[0.5118, 0.4882, 0.0000],\n",
      "          [0.5182, 0.4818, 0.0000],\n",
      "          [0.5055, 0.4945, 0.0000]],\n",
      "\n",
      "         [[0.4671, 0.5329, 0.0000],\n",
      "          [0.4704, 0.5296, 0.0000],\n",
      "          [0.4867, 0.5133, 0.0000]],\n",
      "\n",
      "         [[0.4820, 0.5180, 0.0000],\n",
      "          [0.4970, 0.5030, 0.0000],\n",
      "          [0.4815, 0.5185, 0.0000]],\n",
      "\n",
      "         [[0.4499, 0.5501, 0.0000],\n",
      "          [0.4565, 0.5435, 0.0000],\n",
      "          [0.4701, 0.5299, 0.0000]],\n",
      "\n",
      "         [[0.5097, 0.4903, 0.0000],\n",
      "          [0.5212, 0.4788, 0.0000],\n",
      "          [0.5124, 0.4876, 0.0000]],\n",
      "\n",
      "         [[0.4611, 0.5389, 0.0000],\n",
      "          [0.4785, 0.5215, 0.0000],\n",
      "          [0.4691, 0.5309, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSAMasked(d, h)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, self_mask=None):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.attn_dropout(self.mhsa(x, x, x, mask=self_mask))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "encoder_layer = EncoderLayer()\n",
    "self_mask = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0]]), pad_token=0)\n",
    "self_mask = reshape_mask(self_mask)\n",
    "x = torch.rand(2, 3, 512)\n",
    "\n",
    "encoder_layer(x, self_mask=self_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e48412b-a00c-45e5-829f-441a7df2318e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.9491, -0.3482,    -inf],\n",
      "          [-0.0322,  0.4981,    -inf],\n",
      "          [-0.5286, -0.2884,    -inf]],\n",
      "\n",
      "         [[-0.0396,  0.2085,    -inf],\n",
      "          [ 0.4922,  0.1172,    -inf],\n",
      "          [ 0.9767, -0.5614,    -inf]],\n",
      "\n",
      "         [[-0.7110,  0.8074,    -inf],\n",
      "          [ 0.8500,  0.3379,    -inf],\n",
      "          [-0.1594,  0.0954,    -inf]],\n",
      "\n",
      "         [[ 0.5741,  0.1972,    -inf],\n",
      "          [ 0.0464,  1.7148,    -inf],\n",
      "          [ 0.4335,  0.0948,    -inf]],\n",
      "\n",
      "         [[-0.0058,  0.3594,    -inf],\n",
      "          [ 0.7504,  0.3286,    -inf],\n",
      "          [ 0.9123,  0.7980,    -inf]],\n",
      "\n",
      "         [[-0.3001,  0.3517,    -inf],\n",
      "          [ 0.6769,  0.3782,    -inf],\n",
      "          [-0.0225, -0.4206,    -inf]],\n",
      "\n",
      "         [[-0.2361,  0.3447,    -inf],\n",
      "          [ 0.8986,  0.4357,    -inf],\n",
      "          [ 0.5661, -0.0671,    -inf]],\n",
      "\n",
      "         [[-0.1737, -0.1760,    -inf],\n",
      "          [ 0.3013,  0.0356,    -inf],\n",
      "          [ 0.1016, -0.2116,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2522,    -inf,    -inf],\n",
      "          [ 0.4988,    -inf,    -inf],\n",
      "          [ 0.6637,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0780,    -inf,    -inf],\n",
      "          [ 0.0438,    -inf,    -inf],\n",
      "          [-0.0707,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.7208,    -inf,    -inf],\n",
      "          [ 0.4922,    -inf,    -inf],\n",
      "          [ 0.7631,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2406,    -inf,    -inf],\n",
      "          [ 0.2937,    -inf,    -inf],\n",
      "          [ 0.0629,    -inf,    -inf]],\n",
      "\n",
      "         [[-1.0098,    -inf,    -inf],\n",
      "          [ 0.6279,    -inf,    -inf],\n",
      "          [ 0.4089,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4433,    -inf,    -inf],\n",
      "          [-0.7700,    -inf,    -inf],\n",
      "          [-0.4937,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5582,    -inf,    -inf],\n",
      "          [-0.1409,    -inf,    -inf],\n",
      "          [-0.1761,    -inf,    -inf]],\n",
      "\n",
      "         [[-1.0463,    -inf,    -inf],\n",
      "          [-0.0207,    -inf,    -inf],\n",
      "          [ 0.0627,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3541, 0.6459, 0.0000],\n",
      "          [0.3704, 0.6296, 0.0000],\n",
      "          [0.4402, 0.5598, 0.0000]],\n",
      "\n",
      "         [[0.4383, 0.5617, 0.0000],\n",
      "          [0.5927, 0.4073, 0.0000],\n",
      "          [0.8232, 0.1768, 0.0000]],\n",
      "\n",
      "         [[0.1797, 0.8203, 0.0000],\n",
      "          [0.6253, 0.3747, 0.0000],\n",
      "          [0.4366, 0.5634, 0.0000]],\n",
      "\n",
      "         [[0.5931, 0.4069, 0.0000],\n",
      "          [0.1586, 0.8414, 0.0000],\n",
      "          [0.5839, 0.4161, 0.0000]],\n",
      "\n",
      "         [[0.4097, 0.5903, 0.0000],\n",
      "          [0.6039, 0.3961, 0.0000],\n",
      "          [0.5285, 0.4715, 0.0000]],\n",
      "\n",
      "         [[0.3426, 0.6574, 0.0000],\n",
      "          [0.5741, 0.4259, 0.0000],\n",
      "          [0.5982, 0.4018, 0.0000]],\n",
      "\n",
      "         [[0.3588, 0.6412, 0.0000],\n",
      "          [0.6137, 0.3863, 0.0000],\n",
      "          [0.6532, 0.3468, 0.0000]],\n",
      "\n",
      "         [[0.5006, 0.4994, 0.0000],\n",
      "          [0.5660, 0.4340, 0.0000],\n",
      "          [0.5777, 0.4223, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0731, -0.3540,    -inf],\n",
      "          [ 0.3347,  0.3161,    -inf],\n",
      "          [-0.0423,  0.2555,    -inf]],\n",
      "\n",
      "         [[ 0.4507, -0.3166,    -inf],\n",
      "          [-0.0250, -0.0097,    -inf],\n",
      "          [ 0.0647,  0.4929,    -inf]],\n",
      "\n",
      "         [[-0.0088, -0.3590,    -inf],\n",
      "          [ 0.1095,  0.2305,    -inf],\n",
      "          [ 0.4438,  0.2266,    -inf]],\n",
      "\n",
      "         [[ 0.4828,  0.3632,    -inf],\n",
      "          [ 0.0388, -0.2033,    -inf],\n",
      "          [ 0.2478,  0.0817,    -inf]],\n",
      "\n",
      "         [[ 0.2581,  0.1696,    -inf],\n",
      "          [-0.0191, -0.2400,    -inf],\n",
      "          [-0.1729,  0.0101,    -inf]],\n",
      "\n",
      "         [[ 0.4605,  0.4909,    -inf],\n",
      "          [ 0.3837, -0.0370,    -inf],\n",
      "          [-0.1800,  0.6697,    -inf]],\n",
      "\n",
      "         [[-0.1274,  0.0379,    -inf],\n",
      "          [ 0.1484,  0.0635,    -inf],\n",
      "          [ 0.2139,  0.4399,    -inf]],\n",
      "\n",
      "         [[-0.0494, -0.1780,    -inf],\n",
      "          [-0.0209, -0.2593,    -inf],\n",
      "          [ 0.3784, -0.5382,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1553,    -inf,    -inf],\n",
      "          [ 0.1703,    -inf,    -inf],\n",
      "          [ 0.0575,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1397,    -inf,    -inf],\n",
      "          [ 0.0194,    -inf,    -inf],\n",
      "          [ 0.4549,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4188,    -inf,    -inf],\n",
      "          [ 0.3780,    -inf,    -inf],\n",
      "          [ 0.4450,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3804,    -inf,    -inf],\n",
      "          [ 0.1315,    -inf,    -inf],\n",
      "          [-0.2660,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5570,    -inf,    -inf],\n",
      "          [ 0.2316,    -inf,    -inf],\n",
      "          [-0.2436,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3109,    -inf,    -inf],\n",
      "          [ 0.3383,    -inf,    -inf],\n",
      "          [ 0.4515,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0645,    -inf,    -inf],\n",
      "          [-0.1432,    -inf,    -inf],\n",
      "          [ 0.1965,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6028,    -inf,    -inf],\n",
      "          [ 0.2750,    -inf,    -inf],\n",
      "          [ 0.6934,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6052, 0.3948, 0.0000],\n",
      "          [0.5047, 0.4953, 0.0000],\n",
      "          [0.4261, 0.5739, 0.0000]],\n",
      "\n",
      "         [[0.6829, 0.3171, 0.0000],\n",
      "          [0.4962, 0.5038, 0.0000],\n",
      "          [0.3946, 0.6054, 0.0000]],\n",
      "\n",
      "         [[0.5867, 0.4133, 0.0000],\n",
      "          [0.4698, 0.5302, 0.0000],\n",
      "          [0.5541, 0.4459, 0.0000]],\n",
      "\n",
      "         [[0.5299, 0.4701, 0.0000],\n",
      "          [0.5602, 0.4398, 0.0000],\n",
      "          [0.5414, 0.4586, 0.0000]],\n",
      "\n",
      "         [[0.5221, 0.4779, 0.0000],\n",
      "          [0.5550, 0.4450, 0.0000],\n",
      "          [0.4544, 0.5456, 0.0000]],\n",
      "\n",
      "         [[0.4924, 0.5076, 0.0000],\n",
      "          [0.6036, 0.3964, 0.0000],\n",
      "          [0.2995, 0.7005, 0.0000]],\n",
      "\n",
      "         [[0.4588, 0.5412, 0.0000],\n",
      "          [0.5212, 0.4788, 0.0000],\n",
      "          [0.4437, 0.5563, 0.0000]],\n",
      "\n",
      "         [[0.5321, 0.4679, 0.0000],\n",
      "          [0.5593, 0.4407, 0.0000],\n",
      "          [0.7143, 0.2857, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4143, -0.2920,    -inf],\n",
      "          [ 0.0741,  0.2630,    -inf],\n",
      "          [ 0.0228, -0.0831,    -inf]],\n",
      "\n",
      "         [[ 0.3094, -0.2369,    -inf],\n",
      "          [-0.2945, -0.1897,    -inf],\n",
      "          [-0.0976,  0.1980,    -inf]],\n",
      "\n",
      "         [[-0.2590,  0.0193,    -inf],\n",
      "          [ 0.2971,  0.2454,    -inf],\n",
      "          [-0.4566, -0.3308,    -inf]],\n",
      "\n",
      "         [[-0.0232, -0.0982,    -inf],\n",
      "          [-0.6888, -0.4489,    -inf],\n",
      "          [-0.1246,  0.1190,    -inf]],\n",
      "\n",
      "         [[ 0.1847,  0.2753,    -inf],\n",
      "          [ 0.3639,  0.1753,    -inf],\n",
      "          [ 0.4666, -0.1385,    -inf]],\n",
      "\n",
      "         [[ 0.0660,  0.0883,    -inf],\n",
      "          [-0.2742, -0.1638,    -inf],\n",
      "          [-0.5126,  0.1518,    -inf]],\n",
      "\n",
      "         [[-0.7485, -0.4523,    -inf],\n",
      "          [-0.2653, -0.0241,    -inf],\n",
      "          [ 0.1579,  0.2437,    -inf]],\n",
      "\n",
      "         [[ 0.1354,  0.5583,    -inf],\n",
      "          [ 0.2899, -0.1775,    -inf],\n",
      "          [ 0.7065, -0.1233,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0013,    -inf,    -inf],\n",
      "          [-0.2211,    -inf,    -inf],\n",
      "          [-0.3354,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.8769,    -inf,    -inf],\n",
      "          [-0.6725,    -inf,    -inf],\n",
      "          [-0.5032,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1902,    -inf,    -inf],\n",
      "          [ 0.3782,    -inf,    -inf],\n",
      "          [ 0.4134,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1284,    -inf,    -inf],\n",
      "          [-0.3424,    -inf,    -inf],\n",
      "          [ 0.3977,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3920,    -inf,    -inf],\n",
      "          [-0.2531,    -inf,    -inf],\n",
      "          [-0.6799,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0523,    -inf,    -inf],\n",
      "          [ 0.1356,    -inf,    -inf],\n",
      "          [ 0.0597,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3284,    -inf,    -inf],\n",
      "          [-0.0707,    -inf,    -inf],\n",
      "          [ 0.2909,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0417,    -inf,    -inf],\n",
      "          [ 0.2983,    -inf,    -inf],\n",
      "          [ 0.1756,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6696, 0.3304, 0.0000],\n",
      "          [0.4529, 0.5471, 0.0000],\n",
      "          [0.5265, 0.4735, 0.0000]],\n",
      "\n",
      "         [[0.6333, 0.3667, 0.0000],\n",
      "          [0.4738, 0.5262, 0.0000],\n",
      "          [0.4266, 0.5734, 0.0000]],\n",
      "\n",
      "         [[0.4309, 0.5691, 0.0000],\n",
      "          [0.5129, 0.4871, 0.0000],\n",
      "          [0.4686, 0.5314, 0.0000]],\n",
      "\n",
      "         [[0.5187, 0.4813, 0.0000],\n",
      "          [0.4403, 0.5597, 0.0000],\n",
      "          [0.4394, 0.5606, 0.0000]],\n",
      "\n",
      "         [[0.4774, 0.5226, 0.0000],\n",
      "          [0.5470, 0.4530, 0.0000],\n",
      "          [0.6468, 0.3532, 0.0000]],\n",
      "\n",
      "         [[0.4944, 0.5056, 0.0000],\n",
      "          [0.4724, 0.5276, 0.0000],\n",
      "          [0.3398, 0.6602, 0.0000]],\n",
      "\n",
      "         [[0.4265, 0.5735, 0.0000],\n",
      "          [0.4400, 0.5600, 0.0000],\n",
      "          [0.4786, 0.5214, 0.0000]],\n",
      "\n",
      "         [[0.3958, 0.6042, 0.0000],\n",
      "          [0.6148, 0.3852, 0.0000],\n",
      "          [0.6963, 0.3037, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.5168,  0.0201,    -inf],\n",
      "          [ 0.3667, -0.4539,    -inf],\n",
      "          [-0.3980,  0.0316,    -inf]],\n",
      "\n",
      "         [[-0.5149,  0.0328,    -inf],\n",
      "          [ 0.0511,  0.2256,    -inf],\n",
      "          [-0.1869,  0.1529,    -inf]],\n",
      "\n",
      "         [[-0.0718, -0.0890,    -inf],\n",
      "          [-0.4920,  0.0097,    -inf],\n",
      "          [-0.2874,  0.3684,    -inf]],\n",
      "\n",
      "         [[-0.0319, -0.0707,    -inf],\n",
      "          [-0.2151, -0.2648,    -inf],\n",
      "          [ 0.0790,  0.2965,    -inf]],\n",
      "\n",
      "         [[ 0.3138,  0.2106,    -inf],\n",
      "          [ 0.1114,  0.7765,    -inf],\n",
      "          [ 0.3391,  0.0424,    -inf]],\n",
      "\n",
      "         [[-0.1508,  0.2766,    -inf],\n",
      "          [ 0.1780,  1.0126,    -inf],\n",
      "          [ 0.2935,  0.3291,    -inf]],\n",
      "\n",
      "         [[-0.2019, -0.1140,    -inf],\n",
      "          [-0.3760, -0.1651,    -inf],\n",
      "          [-0.0097, -0.0025,    -inf]],\n",
      "\n",
      "         [[ 0.4514,  0.0718,    -inf],\n",
      "          [ 0.2354,  0.1762,    -inf],\n",
      "          [ 0.2112,  0.0463,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0257,    -inf,    -inf],\n",
      "          [-0.6602,    -inf,    -inf],\n",
      "          [-0.2915,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4481,    -inf,    -inf],\n",
      "          [ 0.2090,    -inf,    -inf],\n",
      "          [ 0.5085,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3267,    -inf,    -inf],\n",
      "          [-0.1913,    -inf,    -inf],\n",
      "          [-0.0680,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6537,    -inf,    -inf],\n",
      "          [ 0.1109,    -inf,    -inf],\n",
      "          [ 0.3904,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1145,    -inf,    -inf],\n",
      "          [-0.5111,    -inf,    -inf],\n",
      "          [-0.0813,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3480,    -inf,    -inf],\n",
      "          [-0.1531,    -inf,    -inf],\n",
      "          [-0.3687,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0219,    -inf,    -inf],\n",
      "          [ 0.4286,    -inf,    -inf],\n",
      "          [ 0.4206,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3847,    -inf,    -inf],\n",
      "          [ 0.2309,    -inf,    -inf],\n",
      "          [ 0.3905,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6217, 0.3783, 0.0000],\n",
      "          [0.6944, 0.3056, 0.0000],\n",
      "          [0.3942, 0.6058, 0.0000]],\n",
      "\n",
      "         [[0.3664, 0.6336, 0.0000],\n",
      "          [0.4565, 0.5435, 0.0000],\n",
      "          [0.4159, 0.5841, 0.0000]],\n",
      "\n",
      "         [[0.5043, 0.4957, 0.0000],\n",
      "          [0.3771, 0.6229, 0.0000],\n",
      "          [0.3417, 0.6583, 0.0000]],\n",
      "\n",
      "         [[0.5097, 0.4903, 0.0000],\n",
      "          [0.5124, 0.4876, 0.0000],\n",
      "          [0.4459, 0.5541, 0.0000]],\n",
      "\n",
      "         [[0.5258, 0.4742, 0.0000],\n",
      "          [0.3396, 0.6604, 0.0000],\n",
      "          [0.5736, 0.4264, 0.0000]],\n",
      "\n",
      "         [[0.3948, 0.6052, 0.0000],\n",
      "          [0.3027, 0.6973, 0.0000],\n",
      "          [0.4911, 0.5089, 0.0000]],\n",
      "\n",
      "         [[0.4780, 0.5220, 0.0000],\n",
      "          [0.4475, 0.5525, 0.0000],\n",
      "          [0.4982, 0.5018, 0.0000]],\n",
      "\n",
      "         [[0.5938, 0.4062, 0.0000],\n",
      "          [0.5148, 0.4852, 0.0000],\n",
      "          [0.5411, 0.4589, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1517,  0.3030,    -inf],\n",
      "          [-0.2104,  0.1575,    -inf],\n",
      "          [-0.7045, -0.5022,    -inf]],\n",
      "\n",
      "         [[-0.0040, -0.5649,    -inf],\n",
      "          [-0.1460, -0.2102,    -inf],\n",
      "          [ 0.3987, -0.2099,    -inf]],\n",
      "\n",
      "         [[-0.5387, -0.7201,    -inf],\n",
      "          [-0.4652, -0.9189,    -inf],\n",
      "          [-0.1703, -0.2840,    -inf]],\n",
      "\n",
      "         [[ 0.4512,  0.5140,    -inf],\n",
      "          [-0.2475,  0.1155,    -inf],\n",
      "          [ 0.4251,  0.4928,    -inf]],\n",
      "\n",
      "         [[-0.1963,  0.1661,    -inf],\n",
      "          [ 0.0251, -0.3718,    -inf],\n",
      "          [ 0.4012,  0.2569,    -inf]],\n",
      "\n",
      "         [[ 0.1931,  0.0470,    -inf],\n",
      "          [ 0.5513, -0.1794,    -inf],\n",
      "          [ 0.1159,  0.0689,    -inf]],\n",
      "\n",
      "         [[ 0.0335,  0.1906,    -inf],\n",
      "          [-0.0193,  0.2169,    -inf],\n",
      "          [ 0.0340,  0.0554,    -inf]],\n",
      "\n",
      "         [[ 0.1938, -0.1123,    -inf],\n",
      "          [ 0.1739,  0.1353,    -inf],\n",
      "          [-0.1257, -0.2892,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1676,    -inf,    -inf],\n",
      "          [-0.0097,    -inf,    -inf],\n",
      "          [ 0.2970,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2143,    -inf,    -inf],\n",
      "          [ 0.5817,    -inf,    -inf],\n",
      "          [ 0.3377,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3185,    -inf,    -inf],\n",
      "          [ 0.7141,    -inf,    -inf],\n",
      "          [ 0.6828,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6923,    -inf,    -inf],\n",
      "          [ 0.2682,    -inf,    -inf],\n",
      "          [ 0.3036,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0959,    -inf,    -inf],\n",
      "          [ 0.0158,    -inf,    -inf],\n",
      "          [ 0.1795,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4879,    -inf,    -inf],\n",
      "          [-0.3150,    -inf,    -inf],\n",
      "          [-0.5216,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0313,    -inf,    -inf],\n",
      "          [-0.1677,    -inf,    -inf],\n",
      "          [ 0.2281,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1814,    -inf,    -inf],\n",
      "          [-0.1361,    -inf,    -inf],\n",
      "          [-0.0551,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4623, 0.5377, 0.0000],\n",
      "          [0.4091, 0.5909, 0.0000],\n",
      "          [0.4496, 0.5504, 0.0000]],\n",
      "\n",
      "         [[0.6367, 0.3633, 0.0000],\n",
      "          [0.5161, 0.4839, 0.0000],\n",
      "          [0.6476, 0.3524, 0.0000]],\n",
      "\n",
      "         [[0.5452, 0.4548, 0.0000],\n",
      "          [0.6115, 0.3885, 0.0000],\n",
      "          [0.5284, 0.4716, 0.0000]],\n",
      "\n",
      "         [[0.4843, 0.5157, 0.0000],\n",
      "          [0.4102, 0.5898, 0.0000],\n",
      "          [0.4831, 0.5169, 0.0000]],\n",
      "\n",
      "         [[0.4104, 0.5896, 0.0000],\n",
      "          [0.5979, 0.4021, 0.0000],\n",
      "          [0.5360, 0.4640, 0.0000]],\n",
      "\n",
      "         [[0.5365, 0.4635, 0.0000],\n",
      "          [0.6749, 0.3251, 0.0000],\n",
      "          [0.5118, 0.4882, 0.0000]],\n",
      "\n",
      "         [[0.4608, 0.5392, 0.0000],\n",
      "          [0.4412, 0.5588, 0.0000],\n",
      "          [0.4946, 0.5054, 0.0000]],\n",
      "\n",
      "         [[0.5759, 0.4241, 0.0000],\n",
      "          [0.5096, 0.4904, 0.0000],\n",
      "          [0.5408, 0.4592, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([2, 8, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3912, -0.0743,    -inf],\n",
      "          [-0.1199, -0.1941,    -inf],\n",
      "          [-0.3649, -0.0973,    -inf]],\n",
      "\n",
      "         [[-0.0297,  0.1159,    -inf],\n",
      "          [ 0.0688, -0.5079,    -inf],\n",
      "          [-0.0769, -0.2823,    -inf]],\n",
      "\n",
      "         [[ 0.6671,  0.1166,    -inf],\n",
      "          [ 0.7895,  0.7915,    -inf],\n",
      "          [-0.1638, -0.0138,    -inf]],\n",
      "\n",
      "         [[ 0.0881,  0.1808,    -inf],\n",
      "          [-0.2333, -0.0504,    -inf],\n",
      "          [ 0.1781, -0.3739,    -inf]],\n",
      "\n",
      "         [[ 0.1158, -0.0803,    -inf],\n",
      "          [ 0.0086,  0.5342,    -inf],\n",
      "          [-0.4186, -0.3131,    -inf]],\n",
      "\n",
      "         [[ 0.1736,  0.4914,    -inf],\n",
      "          [ 0.3177,  0.0517,    -inf],\n",
      "          [ 0.0872,  0.0853,    -inf]],\n",
      "\n",
      "         [[ 0.3186,  0.5707,    -inf],\n",
      "          [ 0.2169,  0.5921,    -inf],\n",
      "          [ 0.3798,  0.1114,    -inf]],\n",
      "\n",
      "         [[-0.2620, -0.1408,    -inf],\n",
      "          [ 0.6007,  0.0592,    -inf],\n",
      "          [ 0.2395,  0.0176,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1858,    -inf,    -inf],\n",
      "          [ 0.2778,    -inf,    -inf],\n",
      "          [-0.0376,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4330,    -inf,    -inf],\n",
      "          [-0.0325,    -inf,    -inf],\n",
      "          [-0.0291,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2674,    -inf,    -inf],\n",
      "          [ 0.3069,    -inf,    -inf],\n",
      "          [ 0.0280,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0831,    -inf,    -inf],\n",
      "          [-0.0596,    -inf,    -inf],\n",
      "          [ 0.2423,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1811,    -inf,    -inf],\n",
      "          [ 0.3490,    -inf,    -inf],\n",
      "          [-0.2530,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1551,    -inf,    -inf],\n",
      "          [ 0.3615,    -inf,    -inf],\n",
      "          [ 0.3860,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0594,    -inf,    -inf],\n",
      "          [ 0.1228,    -inf,    -inf],\n",
      "          [-0.1940,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2716,    -inf,    -inf],\n",
      "          [ 0.3597,    -inf,    -inf],\n",
      "          [ 0.0099,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6143, 0.3857, 0.0000],\n",
      "          [0.5185, 0.4815, 0.0000],\n",
      "          [0.4335, 0.5665, 0.0000]],\n",
      "\n",
      "         [[0.4637, 0.5363, 0.0000],\n",
      "          [0.6403, 0.3597, 0.0000],\n",
      "          [0.5512, 0.4488, 0.0000]],\n",
      "\n",
      "         [[0.6343, 0.3657, 0.0000],\n",
      "          [0.4995, 0.5005, 0.0000],\n",
      "          [0.4626, 0.5374, 0.0000]],\n",
      "\n",
      "         [[0.4768, 0.5232, 0.0000],\n",
      "          [0.4544, 0.5456, 0.0000],\n",
      "          [0.6346, 0.3654, 0.0000]],\n",
      "\n",
      "         [[0.5489, 0.4511, 0.0000],\n",
      "          [0.3715, 0.6285, 0.0000],\n",
      "          [0.4736, 0.5264, 0.0000]],\n",
      "\n",
      "         [[0.4212, 0.5788, 0.0000],\n",
      "          [0.5661, 0.4339, 0.0000],\n",
      "          [0.5005, 0.4995, 0.0000]],\n",
      "\n",
      "         [[0.4373, 0.5627, 0.0000],\n",
      "          [0.4073, 0.5927, 0.0000],\n",
      "          [0.5667, 0.4333, 0.0000]],\n",
      "\n",
      "         [[0.4697, 0.5303, 0.0000],\n",
      "          [0.6321, 0.3679, 0.0000],\n",
      "          [0.5553, 0.4447, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Encoder(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [EncoderLayer(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, x, self_mask = None):\n",
    "        b, t = x.size()\n",
    "        x = self.embed(x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, self_mask=self_mask)\n",
    "        return x\n",
    "\n",
    "encoder = Encoder()\n",
    "x = torch.randint(0, 2**13, (2, 3))\n",
    "self_mask = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0]]), pad_token=0)\n",
    "self_mask = reshape_mask(self_mask)\n",
    "encoder(x, self_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7785e51c-c88e-4ad2-ad66-4117fbb1a52c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_mask: \n",
      " tensor([[1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0]])\n",
      "cross_mask: \n",
      " tensor([[[[1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0310,    -inf,    -inf],\n",
      "          [-0.1026,    -inf,    -inf],\n",
      "          [-0.0142,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1056,    -inf,    -inf],\n",
      "          [ 0.0850,    -inf,    -inf],\n",
      "          [ 0.0925,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0730,    -inf,    -inf],\n",
      "          [-0.0086,    -inf,    -inf],\n",
      "          [-0.0795,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0661,    -inf,    -inf],\n",
      "          [-0.0332,    -inf,    -inf],\n",
      "          [ 0.0974,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0357, -0.0447,    -inf],\n",
      "          [-0.0492, -0.0687,    -inf],\n",
      "          [ 0.0827,  0.0655,    -inf]],\n",
      "\n",
      "         [[ 0.0153,  0.0570,    -inf],\n",
      "          [-0.0090, -0.0014,    -inf],\n",
      "          [-0.1045,  0.0419,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5023, 0.4977, 0.0000],\n",
      "          [0.5049, 0.4951, 0.0000],\n",
      "          [0.5043, 0.4957, 0.0000]],\n",
      "\n",
      "         [[0.4896, 0.5104, 0.0000],\n",
      "          [0.4981, 0.5019, 0.0000],\n",
      "          [0.4635, 0.5365, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1584, -0.0202,  0.1233],\n",
      "          [ 0.0725, -0.2060,  0.0235],\n",
      "          [-0.0452, -0.1572, -0.0091]],\n",
      "\n",
      "         [[ 0.1582,  0.2640,  0.1146],\n",
      "          [-0.1306, -0.1780, -0.0444],\n",
      "          [-0.0506, -0.0090, -0.3192]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3265,    -inf,    -inf],\n",
      "          [ 0.0104,    -inf,    -inf],\n",
      "          [ 0.2489,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0416,    -inf,    -inf],\n",
      "          [ 0.2194,    -inf,    -inf],\n",
      "          [-0.1996,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0718, -0.0794,    -inf],\n",
      "          [ 0.0462, -0.1731,    -inf],\n",
      "          [-0.0141, -0.1302,    -inf]],\n",
      "\n",
      "         [[ 0.0412,  0.1230,    -inf],\n",
      "          [ 0.2315,  0.2680,    -inf],\n",
      "          [-0.2978, -0.4019,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3569, 0.2985, 0.3446],\n",
      "          [0.3691, 0.2794, 0.3515],\n",
      "          [0.3412, 0.3050, 0.3538]],\n",
      "\n",
      "         [[0.3258, 0.3622, 0.3119],\n",
      "          [0.3285, 0.3133, 0.3581],\n",
      "          [0.3563, 0.3714, 0.2723]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5377, 0.4623, 0.0000],\n",
      "          [0.5546, 0.4454, 0.0000],\n",
      "          [0.5290, 0.4710, 0.0000]],\n",
      "\n",
      "         [[0.4796, 0.5204, 0.0000],\n",
      "          [0.4909, 0.5091, 0.0000],\n",
      "          [0.5260, 0.4740, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoderLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSAMasked(d=d, h=h)\n",
    "        self.attn_norm = nn.LayerNorm(d)\n",
    "        self.attn_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.mhca = MHSAMasked(d=d, h=h)\n",
    "        self.cross_attn_norm = nn.LayerNorm(d)\n",
    "        self.cross_attn_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.resid_dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(d)\n",
    "        \n",
    "\n",
    "    def forward(self, dec_x, enc_x, self_mask=None, cross_mask=None):\n",
    "        # self_mask is merged decoders padding and causal masks\n",
    "        # cross_mask is equal to endcoders padding mask because we don't want to attend to encoded padded tokens\n",
    "        b, t, d = dec_x.size()\n",
    "        x = dec_x + self.attn_dropout(self.mhsa(dec_x, dec_x, dec_x, mask=self_mask))\n",
    "        x = self.attn_norm(x)\n",
    "\n",
    "        x = x + self.cross_attn_dropout(self.mhca(x, enc_x, enc_x, mask=cross_mask))\n",
    "        x = self.cross_attn_norm(x)\n",
    "        \n",
    "        x = x + self.resid_dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "decoder_layer = DecoderLayer(h=2, d=16)\n",
    "x = torch.rand(3, 3, 16)\n",
    "y = torch.rand(3, 3, 16)\n",
    "self_mask1 = build_padding_mask(torch.tensor([[2, 2, 0], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "self_mask2 = build_causal_mask(torch.tensor([[2, 2, 0], [2, 0, 0], [2, 2, 0]]))\n",
    "self_mask = merge_masks(self_mask1, self_mask2)\n",
    "print(f\"self_mask: \\n {self_mask}\")\n",
    "self_mask = reshape_mask(self_mask)\n",
    "\n",
    "cross_mask = build_padding_mask(torch.tensor([[2, 2, 2], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "cross_mask = reshape_mask(cross_mask)\n",
    "print(f\"cross_mask: \\n {cross_mask}\")\n",
    "decoder_layer(x, y, self_mask=self_mask, cross_mask=cross_mask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826a55e4-da2a-42e0-847d-14d0c7774cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_mask: \n",
      " tensor([[1, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 0]])\n",
      "cross_mask: \n",
      " tensor([[[[1, 1, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 0]]]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3470,    -inf,    -inf],\n",
      "          [ 0.2680,    -inf,    -inf],\n",
      "          [ 0.0472,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4876,    -inf,    -inf],\n",
      "          [-0.5241,    -inf,    -inf],\n",
      "          [-0.0243,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.3846,    -inf,    -inf],\n",
      "          [ 0.0702,    -inf,    -inf],\n",
      "          [ 0.0368,    -inf,    -inf]],\n",
      "\n",
      "         [[ 1.5445,    -inf,    -inf],\n",
      "          [ 0.2934,    -inf,    -inf],\n",
      "          [ 0.2163,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-1.3250, -0.1522,    -inf],\n",
      "          [-1.0179, -0.2387,    -inf],\n",
      "          [-0.2871,  0.0590,    -inf]],\n",
      "\n",
      "         [[-0.2381,  0.2220,    -inf],\n",
      "          [-0.9814,  0.1479,    -inf],\n",
      "          [ 0.0563,  0.3812,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2364, 0.7636, 0.0000],\n",
      "          [0.3145, 0.6855, 0.0000],\n",
      "          [0.4143, 0.5857, 0.0000]],\n",
      "\n",
      "         [[0.3870, 0.6130, 0.0000],\n",
      "          [0.2443, 0.7557, 0.0000],\n",
      "          [0.4195, 0.5805, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.4979, -0.4188, -0.4375],\n",
      "          [-0.1533, -0.1435,  0.3942],\n",
      "          [-0.3587, -0.2564, -0.2567]],\n",
      "\n",
      "         [[ 0.1661,  0.1296, -0.0755],\n",
      "          [ 0.1053,  0.2433,  0.1079],\n",
      "          [ 0.3705,  0.3376, -0.0269]]],\n",
      "\n",
      "\n",
      "        [[[-0.1390,    -inf,    -inf],\n",
      "          [-0.1350,    -inf,    -inf],\n",
      "          [-0.1059,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1038,    -inf,    -inf],\n",
      "          [ 0.1884,    -inf,    -inf],\n",
      "          [ 0.3228,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1970, -0.2358,    -inf],\n",
      "          [-0.3259, -0.2771,    -inf],\n",
      "          [-0.2302, -0.1224,    -inf]],\n",
      "\n",
      "         [[-0.0415, -0.0416,    -inf],\n",
      "          [-0.1128, -0.0773,    -inf],\n",
      "          [ 0.1329,  0.2104,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3180, 0.3442, 0.3378],\n",
      "          [0.2675, 0.2701, 0.4624],\n",
      "          [0.3110, 0.3445, 0.3444]],\n",
      "\n",
      "         [[0.3637, 0.3507, 0.2856],\n",
      "          [0.3174, 0.3644, 0.3182],\n",
      "          [0.3788, 0.3666, 0.2546]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5097, 0.4903, 0.0000],\n",
      "          [0.4878, 0.5122, 0.0000],\n",
      "          [0.4731, 0.5269, 0.0000]],\n",
      "\n",
      "         [[0.5000, 0.5000, 0.0000],\n",
      "          [0.4911, 0.5089, 0.0000],\n",
      "          [0.4806, 0.5194, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3254,    -inf,    -inf],\n",
      "          [-0.1663,    -inf,    -inf],\n",
      "          [-0.3924,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4792,    -inf,    -inf],\n",
      "          [-0.5836,    -inf,    -inf],\n",
      "          [-0.2500,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1449,    -inf,    -inf],\n",
      "          [-0.5457,    -inf,    -inf],\n",
      "          [-0.4668,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0408,    -inf,    -inf],\n",
      "          [ 0.2718,    -inf,    -inf],\n",
      "          [ 0.1832,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1216,  0.5129,    -inf],\n",
      "          [-0.5801, -0.7872,    -inf],\n",
      "          [-0.2387, -0.4640,    -inf]],\n",
      "\n",
      "         [[-0.0873, -0.0315,    -inf],\n",
      "          [-0.0245, -0.1484,    -inf],\n",
      "          [ 0.2082,  0.0980,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3465, 0.6535, 0.0000],\n",
      "          [0.5516, 0.4484, 0.0000],\n",
      "          [0.5561, 0.4439, 0.0000]],\n",
      "\n",
      "         [[0.4861, 0.5139, 0.0000],\n",
      "          [0.5309, 0.4691, 0.0000],\n",
      "          [0.5275, 0.4725, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1680,  0.1860,  0.2217],\n",
      "          [-0.1225, -0.0521, -0.1509],\n",
      "          [ 0.0045,  0.0789,  0.0650]],\n",
      "\n",
      "         [[-0.0917, -0.0981, -0.2453],\n",
      "          [ 0.0246,  0.0991, -0.0455],\n",
      "          [-0.1002, -0.0978, -0.1427]]],\n",
      "\n",
      "\n",
      "        [[[-0.0673,    -inf,    -inf],\n",
      "          [ 0.2043,    -inf,    -inf],\n",
      "          [ 0.0666,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0432,    -inf,    -inf],\n",
      "          [-0.0269,    -inf,    -inf],\n",
      "          [ 0.0338,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0191, -0.0454,    -inf],\n",
      "          [ 0.3511,  0.2520,    -inf],\n",
      "          [ 0.1422,  0.1885,    -inf]],\n",
      "\n",
      "         [[ 0.0756,  0.2067,    -inf],\n",
      "          [-0.0711,  0.1345,    -inf],\n",
      "          [-0.2286, -0.1984,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3254, 0.3313, 0.3433],\n",
      "          [0.3284, 0.3524, 0.3192],\n",
      "          [0.3185, 0.3431, 0.3384]],\n",
      "\n",
      "         [[0.3507, 0.3485, 0.3008],\n",
      "          [0.3323, 0.3580, 0.3098],\n",
      "          [0.3377, 0.3386, 0.3237]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5161, 0.4839, 0.0000],\n",
      "          [0.5247, 0.4753, 0.0000],\n",
      "          [0.4884, 0.5116, 0.0000]],\n",
      "\n",
      "         [[0.4673, 0.5327, 0.0000],\n",
      "          [0.4488, 0.5512, 0.0000],\n",
      "          [0.4925, 0.5075, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 3, 16])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Decoder(nn.Module): \n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, d)\n",
    "        self.pe = PE(d=d)\n",
    "        self.layers = [DecoderLayer(d, h) for _ in range(n)]\n",
    "\n",
    "    def forward(self, dec_x, enc_x, self_mask=None, cross_mask=None):\n",
    "        b, t = dec_x.size()\n",
    "        x = self.embed(dec_x)\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_x, self_mask=self_mask, cross_mask=cross_mask)\n",
    "        return x\n",
    "\n",
    "    def get_embed_weights(self):\n",
    "        return self.embed.weight\n",
    "\n",
    "decoder = Decoder(vocab_size=32, n=2, d=16, h=2)\n",
    "# x = torch.randint(0, 32, (2, 3))\n",
    "x = torch.tensor([[15, 7, 0], [10, 0, 0], [1, 3, 0]])\n",
    "y = torch.rand(3, 3, 16)\n",
    "\n",
    "self_mask1 = build_padding_mask(x, pad_token=0)\n",
    "self_mask2 = build_causal_mask(x)\n",
    "self_mask = merge_masks(self_mask1, self_mask2)\n",
    "print(f\"self_mask: \\n {self_mask}\")\n",
    "self_mask = reshape_mask(self_mask)\n",
    "\n",
    "cross_mask = build_padding_mask(torch.tensor([[2, 2, 2], [2, 0, 0], [2, 2, 0]]), pad_token=0)\n",
    "cross_mask = reshape_mask(cross_mask)\n",
    "print(f\"cross_mask: \\n {cross_mask}\")\n",
    "print(decoder(x, y, self_mask=self_mask, cross_mask=cross_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b5aba42-4209-4fbb-8cc9-a9e8a0236e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Output(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size: int = 2**13, d: int = 512, ff_weight = None):\n",
    "        super().__init__()\n",
    "        self.ff = nn.Linear(d, vocab_size)\n",
    "        # weight tying with the decoder embedding\n",
    "        if ff_weight is not None:\n",
    "            self.ff.weight = ff_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2477aec-7287-498b-bf31-cbb0bdfe154d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc_mask: \n",
      " tensor([[1, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 0, 0]])\n",
      "dec_mask: \n",
      " tensor([[1, 0, 0, 0],\n",
      "        [1, 0, 0, 0],\n",
      "        [1, 1, 1, 0]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[ 5.9970e-01, -1.1968e-01,  4.6869e-01],\n",
      "          [-9.8441e-01,  2.4761e-01, -2.0759e-01],\n",
      "          [-2.5555e-01,  3.8735e-01, -3.5294e-01]],\n",
      "\n",
      "         [[-3.0122e-02, -1.0659e-04,  1.3670e-01],\n",
      "          [-4.6867e-01,  8.3376e-02, -1.7783e-01],\n",
      "          [-5.8456e-01,  1.0852e+00, -1.1018e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5371e-01,  4.1200e-01,        -inf],\n",
      "          [ 6.5218e-01,  6.4440e-01,        -inf],\n",
      "          [ 2.1543e-01,  4.5420e-01,        -inf]],\n",
      "\n",
      "         [[ 4.3294e-01,  8.5197e-02,        -inf],\n",
      "          [ 3.1179e-01,  2.4474e-01,        -inf],\n",
      "          [ 1.6698e-01, -3.2434e-02,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3633e+00,        -inf,        -inf],\n",
      "          [-2.3976e-01,        -inf,        -inf],\n",
      "          [-9.8775e-02,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.0072e+00,        -inf,        -inf],\n",
      "          [-6.0625e-01,        -inf,        -inf],\n",
      "          [-4.3719e-01,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4230, 0.2060, 0.3710],\n",
      "          [0.1515, 0.5192, 0.3293],\n",
      "          [0.2625, 0.4993, 0.2382]],\n",
      "\n",
      "         [[0.3113, 0.3208, 0.3679],\n",
      "          [0.2454, 0.4263, 0.3283],\n",
      "          [0.1263, 0.6707, 0.2030]]],\n",
      "\n",
      "\n",
      "        [[[0.5104, 0.4896, 0.0000],\n",
      "          [0.5019, 0.4981, 0.0000],\n",
      "          [0.4406, 0.5594, 0.0000]],\n",
      "\n",
      "         [[0.5861, 0.4139, 0.0000],\n",
      "          [0.5168, 0.4832, 0.0000],\n",
      "          [0.5497, 0.4503, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 3, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1314, -0.0215,  0.2843],\n",
      "          [ 0.6271,  0.0181,  0.2209],\n",
      "          [ 0.0628, -0.1397, -0.0380]],\n",
      "\n",
      "         [[ 0.3804,  0.0779,  0.3287],\n",
      "          [ 0.0212, -0.0611,  0.2585],\n",
      "          [-0.0131, -0.1566, -0.0280]]],\n",
      "\n",
      "\n",
      "        [[[-0.0007,  0.0801,    -inf],\n",
      "          [-0.0068,  0.0259,    -inf],\n",
      "          [-0.2799, -0.2486,    -inf]],\n",
      "\n",
      "         [[ 0.4814,  0.4838,    -inf],\n",
      "          [ 0.2794,  0.2611,    -inf],\n",
      "          [ 0.4387,  0.3973,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.0361,    -inf,    -inf],\n",
      "          [-0.4284,    -inf,    -inf],\n",
      "          [-0.3607,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.3154,    -inf,    -inf],\n",
      "          [ 0.5384,    -inf,    -inf],\n",
      "          [ 0.6494,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2754, 0.3074, 0.4173],\n",
      "          [0.4525, 0.2461, 0.3014],\n",
      "          [0.3676, 0.3002, 0.3323]],\n",
      "\n",
      "         [[0.3719, 0.2749, 0.3532],\n",
      "          [0.3136, 0.2888, 0.3976],\n",
      "          [0.3507, 0.3038, 0.3455]]],\n",
      "\n",
      "\n",
      "        [[[0.4798, 0.5202, 0.0000],\n",
      "          [0.4918, 0.5082, 0.0000],\n",
      "          [0.4922, 0.5078, 0.0000]],\n",
      "\n",
      "         [[0.4994, 0.5006, 0.0000],\n",
      "          [0.5046, 0.4954, 0.0000],\n",
      "          [0.5103, 0.4897, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.5699,    -inf,    -inf,    -inf],\n",
      "          [ 0.3507,    -inf,    -inf,    -inf],\n",
      "          [-0.7514,    -inf,    -inf,    -inf],\n",
      "          [-0.1504,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0426,    -inf,    -inf,    -inf],\n",
      "          [ 0.4189,    -inf,    -inf,    -inf],\n",
      "          [-0.4909,    -inf,    -inf,    -inf],\n",
      "          [-0.4079,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.1555,    -inf,    -inf,    -inf],\n",
      "          [-0.0655,    -inf,    -inf,    -inf],\n",
      "          [-0.0860,    -inf,    -inf,    -inf],\n",
      "          [-0.1072,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5718,    -inf,    -inf,    -inf],\n",
      "          [ 0.4914,    -inf,    -inf,    -inf],\n",
      "          [ 0.4680,    -inf,    -inf,    -inf],\n",
      "          [ 0.4650,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0316,  0.4593,  1.0711,    -inf],\n",
      "          [-0.2030,  0.1209,  0.9030,    -inf],\n",
      "          [-0.1134, -0.2286,  0.3038,    -inf],\n",
      "          [-0.1485, -0.1786,  0.5259,    -inf]],\n",
      "\n",
      "         [[-0.2834, -0.3454, -0.1068,    -inf],\n",
      "          [-0.5220, -0.6158, -0.3884,    -inf],\n",
      "          [ 0.0958,  0.0053, -0.7640,    -inf],\n",
      "          [-0.0109,  0.2269,  0.1974,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1865, 0.2861, 0.5274, 0.0000],\n",
      "          [0.1850, 0.2558, 0.5592, 0.0000],\n",
      "          [0.2934, 0.2614, 0.4452, 0.0000],\n",
      "          [0.2542, 0.2467, 0.4990, 0.0000]],\n",
      "\n",
      "         [[0.3192, 0.3000, 0.3808, 0.0000],\n",
      "          [0.3275, 0.2982, 0.3743, 0.0000],\n",
      "          [0.4280, 0.3909, 0.1811, 0.0000],\n",
      "          [0.2857, 0.3624, 0.3519, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-1.0368e+00, -4.7357e-01, -5.1001e-01],\n",
      "          [-7.8109e-01, -4.7276e-01, -4.6949e-01],\n",
      "          [-9.6584e-01, -9.4436e-02, -4.2960e-01],\n",
      "          [-9.4986e-01, -7.7996e-02, -3.7800e-01]],\n",
      "\n",
      "         [[ 7.7820e-02, -8.1333e-03,  1.9708e-01],\n",
      "          [ 2.8095e-01,  2.1728e-01,  9.7984e-02],\n",
      "          [ 1.5778e-01, -9.9794e-04, -1.5422e-01],\n",
      "          [ 1.7940e-01, -1.4351e-03, -1.1438e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5118e-01, -5.6104e-04,        -inf],\n",
      "          [ 3.1835e-01,  1.9983e-01,        -inf],\n",
      "          [ 3.8389e-01,  2.4704e-01,        -inf],\n",
      "          [ 1.5100e-01,  7.4833e-02,        -inf]],\n",
      "\n",
      "         [[-3.4078e-01, -7.3590e-01,        -inf],\n",
      "          [-6.0599e-01, -3.2850e-01,        -inf],\n",
      "          [-5.5631e-01, -2.7656e-01,        -inf],\n",
      "          [-4.9566e-01, -2.5054e-01,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[-9.5390e-01,        -inf,        -inf],\n",
      "          [ 1.2926e-02,        -inf,        -inf],\n",
      "          [ 1.3393e-01,        -inf,        -inf],\n",
      "          [ 7.1397e-01,        -inf,        -inf]],\n",
      "\n",
      "         [[ 4.1613e-01,        -inf,        -inf],\n",
      "          [-1.1123e-01,        -inf,        -inf],\n",
      "          [-3.7511e-01,        -inf,        -inf],\n",
      "          [-4.3212e-01,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2247, 0.3947, 0.3806],\n",
      "          [0.2683, 0.3652, 0.3664],\n",
      "          [0.1961, 0.4687, 0.3352],\n",
      "          [0.1937, 0.4632, 0.3431]],\n",
      "\n",
      "         [[0.3285, 0.3014, 0.3701],\n",
      "          [0.3609, 0.3386, 0.3005],\n",
      "          [0.3868, 0.3300, 0.2831],\n",
      "          [0.3876, 0.3235, 0.2889]]],\n",
      "\n",
      "\n",
      "        [[[0.5870, 0.4130, 0.0000],\n",
      "          [0.5296, 0.4704, 0.0000],\n",
      "          [0.5342, 0.4658, 0.0000],\n",
      "          [0.5190, 0.4810, 0.0000]],\n",
      "\n",
      "         [[0.5975, 0.4025, 0.0000],\n",
      "          [0.4311, 0.5689, 0.0000],\n",
      "          [0.4305, 0.5695, 0.0000],\n",
      "          [0.4390, 0.5610, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.8465,    -inf,    -inf,    -inf],\n",
      "          [-0.3043,    -inf,    -inf,    -inf],\n",
      "          [ 0.0434,    -inf,    -inf,    -inf],\n",
      "          [ 0.0098,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1767,    -inf,    -inf,    -inf],\n",
      "          [ 0.0785,    -inf,    -inf,    -inf],\n",
      "          [ 0.1978,    -inf,    -inf,    -inf],\n",
      "          [ 0.3174,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2899,    -inf,    -inf,    -inf],\n",
      "          [ 0.3947,    -inf,    -inf,    -inf],\n",
      "          [ 0.4865,    -inf,    -inf,    -inf],\n",
      "          [ 0.5378,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2720,    -inf,    -inf,    -inf],\n",
      "          [-0.2444,    -inf,    -inf,    -inf],\n",
      "          [-0.2168,    -inf,    -inf,    -inf],\n",
      "          [-0.2015,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3503,  0.3182,  0.3223,    -inf],\n",
      "          [-0.2737, -0.0983, -0.0843,    -inf],\n",
      "          [-0.0183, -0.4542, -0.1946,    -inf],\n",
      "          [ 0.1905, -0.1365,  0.3174,    -inf]],\n",
      "\n",
      "         [[-0.3079, -0.5371, -0.2554,    -inf],\n",
      "          [ 0.3205, -0.0732, -0.3113,    -inf],\n",
      "          [ 0.4413,  0.0283, -0.1937,    -inf],\n",
      "          [ 0.0087, -0.2678,  0.3816,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3400, 0.3293, 0.3307, 0.0000],\n",
      "          [0.2941, 0.3505, 0.3554, 0.0000],\n",
      "          [0.4024, 0.2602, 0.3374, 0.0000],\n",
      "          [0.3501, 0.2524, 0.3975, 0.0000]],\n",
      "\n",
      "         [[0.3510, 0.2791, 0.3699, 0.0000],\n",
      "          [0.4533, 0.3058, 0.2410, 0.0000],\n",
      "          [0.4563, 0.3019, 0.2418, 0.0000],\n",
      "          [0.3115, 0.2363, 0.4523, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 2, 4, 3])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0927, -0.0531, -0.0733],\n",
      "          [ 0.2454,  0.5065,  0.1346],\n",
      "          [ 0.3971, -0.9991,  0.0207],\n",
      "          [ 0.2563, -0.8088, -0.0979]],\n",
      "\n",
      "         [[-0.1403, -0.0517, -0.1112],\n",
      "          [ 0.1232,  0.1284,  0.2629],\n",
      "          [ 0.2116, -0.3785,  0.4584],\n",
      "          [ 0.1836, -0.1796,  0.3790]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1801,  0.2727,    -inf],\n",
      "          [-0.3848,  0.0641,    -inf],\n",
      "          [-0.4047, -0.0202,    -inf],\n",
      "          [-0.4536, -0.0820,    -inf]],\n",
      "\n",
      "         [[ 0.3058,  0.3906,    -inf],\n",
      "          [-0.3508,  0.1310,    -inf],\n",
      "          [-0.3469,  0.1671,    -inf],\n",
      "          [-0.3106,  0.2274,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5054,    -inf,    -inf],\n",
      "          [ 0.5426,    -inf,    -inf],\n",
      "          [ 0.2597,    -inf,    -inf],\n",
      "          [ 0.0659,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1449,    -inf,    -inf],\n",
      "          [ 0.3754,    -inf,    -inf],\n",
      "          [ 0.5105,    -inf,    -inf],\n",
      "          [ 0.6105,    -inf,    -inf]]]], grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3268, 0.3400, 0.3332],\n",
      "          [0.3131, 0.4066, 0.2803],\n",
      "          [0.5171, 0.1280, 0.3549],\n",
      "          [0.4886, 0.1684, 0.3429]],\n",
      "\n",
      "         [[0.3203, 0.3500, 0.3297],\n",
      "          [0.3169, 0.3186, 0.3645],\n",
      "          [0.3528, 0.1956, 0.4516],\n",
      "          [0.3435, 0.2389, 0.4176]]],\n",
      "\n",
      "\n",
      "        [[[0.4769, 0.5231, 0.0000],\n",
      "          [0.3896, 0.6104, 0.0000],\n",
      "          [0.4050, 0.5950, 0.0000],\n",
      "          [0.4082, 0.5918, 0.0000]],\n",
      "\n",
      "         [[0.4788, 0.5212, 0.0000],\n",
      "          [0.3818, 0.6182, 0.0000],\n",
      "          [0.3743, 0.6257, 0.0000],\n",
      "          [0.3686, 0.6314, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "torch.Size([3, 4, 32])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int = 2**13, n: int = 6, d: int = 512, h: int = 8, embed_tying=True):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(vocab_size=vocab_size, n=n, d=d, h=h)\n",
    "        self.decoder = Decoder(vocab_size=vocab_size, n=n, d=d, h=h)\n",
    "        if embed_tying:\n",
    "            self.output = Output(vocab_size=vocab_size, d=d, ff_weight = self.decoder.get_embed_weights())\n",
    "        else:\n",
    "            self.output = Output(vocab_size=vocab_size, d=d)\n",
    "\n",
    "    def forward(self, enc_x, dec_x, enc_mask=None, dec_mask=None):\n",
    "        encoded = self.encoder(enc_x, enc_mask)\n",
    "        decoded = self.decoder(dec_x=dec_x, enc_x=encoded, self_mask=dec_mask, cross_mask=enc_mask)\n",
    "        return self.output(decoded)\n",
    "\n",
    "transformer = Transformer(vocab_size=32, n=2, d=16, h=2, embed_tying=False)\n",
    "enc_x = torch.tensor([[15, 7, 3], [10, 10, 0], [1, 0, 0]])\n",
    "dec_x = torch.tensor([[21, 8, 0, 0], [25, 0, 0, 0], [8, 1, 2, 3]])\n",
    "# dec_x = torch.tensor([[21, 8], [25, 0], [8, 1]])\n",
    "\n",
    "enc_mask = build_padding_mask(enc_x, pad_token=0)\n",
    "print(f\"enc_mask: \\n {enc_mask}\")\n",
    "enc_mask = reshape_mask(enc_mask)\n",
    "\n",
    "dec_mask1 = build_padding_mask(dec_x, pad_token=0)\n",
    "dec_mask2 = build_causal_mask(dec_x)\n",
    "dec_mask = merge_masks(dec_mask1, dec_mask2)\n",
    "print(f\"dec_mask: \\n {dec_mask}\")\n",
    "dec_mask = reshape_mask(dec_mask)\n",
    "\n",
    "print(transformer(enc_x, dec_x, enc_mask=enc_mask, dec_mask=dec_mask).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5f69bab-e9a5-44a7-af1d-f294f62d3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a06c43eb-c348-4905-9384-1b28378435b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  9906,   4435, 100257, 100257, 100257],\n",
      "        [  2028,    374,    264,   4382,  11914],\n",
      "        [  7979, 100257, 100257, 100257, 100257]])\n",
      "tensor([[ 82681, 100257, 100257, 100257],\n",
      "        [    34,  17771,   6316,  17571],\n",
      "        [ 23380, 100257, 100257, 100257]])\n",
      "enc_mask: \n",
      " tensor([[1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 0, 0, 0, 0]])\n",
      "dec_mask: \n",
      " tensor([[1, 0, 0, 0],\n",
      "        [1, 1, 0, 0],\n",
      "        [1, 0, 0, 0]])\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-3.7867e-02, -8.2838e-01,        -inf,        -inf,        -inf],\n",
      "          [-2.8830e-01,  8.3117e-02,        -inf,        -inf,        -inf],\n",
      "          [-1.2055e-01, -1.0235e+00,        -inf,        -inf,        -inf],\n",
      "          [-3.5413e-01, -9.0736e-01,        -inf,        -inf,        -inf],\n",
      "          [-4.2189e-01, -8.9929e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.6490e-02, -2.1649e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.2192e-01, -1.5539e+00,        -inf,        -inf,        -inf],\n",
      "          [-3.8949e-02,  1.0801e-01,        -inf,        -inf,        -inf],\n",
      "          [-3.4011e-01, -1.7243e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.5979e-01, -4.5053e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-5.3834e-01,  2.6720e-03,        -inf,        -inf,        -inf],\n",
      "          [-2.7033e-01, -6.1314e-01,        -inf,        -inf,        -inf],\n",
      "          [-3.3063e-01,  4.3086e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.6950e-01,  7.5352e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.4220e-01,  4.6004e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.3681e-01,  3.2085e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.0928e-01,  1.7614e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.1572e+00,  1.4952e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.1209e+00, -1.5772e-01,        -inf,        -inf,        -inf],\n",
      "          [-6.7178e-01, -6.4316e-02,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7962e-01, -3.3168e-02,  3.3599e-01, -3.2729e-01, -1.4829e-01],\n",
      "          [ 8.4083e-01,  5.8549e-01, -1.9173e-02,  8.2342e-02, -5.7556e-01],\n",
      "          [ 5.2932e-01,  4.2841e-01, -1.5879e-01, -2.0444e-01, -5.8260e-01],\n",
      "          [ 5.2974e-01, -4.9685e-01,  3.5539e-01,  9.7867e-01,  8.1210e-01],\n",
      "          [ 6.8928e-01, -6.5567e-01,  1.1418e+00,  5.3610e-01,  2.7614e-01]],\n",
      "\n",
      "         [[ 1.1300e+00,  4.6882e-01,  5.7679e-01, -1.2222e-01, -1.3505e-02],\n",
      "          [ 1.3143e+00, -2.0086e-01,  4.2931e-01, -3.8968e-01,  3.6062e-01],\n",
      "          [ 2.8176e-01, -4.0044e-01, -2.3824e-01,  9.8473e-03, -3.9554e-01],\n",
      "          [ 4.0268e-01,  4.2060e-01,  1.2713e+00,  1.5480e-01, -1.7302e-01],\n",
      "          [ 1.9049e-01, -2.3770e-01, -1.2529e-01, -6.5782e-01, -3.6037e-01]],\n",
      "\n",
      "         [[-1.5596e-02,  8.9968e-02, -6.2724e-01,  9.7498e-02,  4.5829e-01],\n",
      "          [ 4.8851e-01,  5.9018e-01, -3.5221e-01,  1.4193e+00, -1.0948e-01],\n",
      "          [ 9.1615e-01, -4.7908e-02, -3.7789e-01,  9.9157e-01, -3.6227e-01],\n",
      "          [-2.1414e-01,  4.6123e-01, -5.2658e-02,  3.6989e-01, -2.4755e-01],\n",
      "          [-3.4478e-01,  9.0818e-01, -1.0361e+00,  1.2475e-01,  6.6409e-01]],\n",
      "\n",
      "         [[ 4.5764e-01,  9.7328e-01,  6.5396e-01,  5.2685e-01,  1.7962e+00],\n",
      "          [ 1.8432e-01, -3.7355e-04,  7.0232e-01,  3.7410e-01,  1.1378e+00],\n",
      "          [ 1.0964e-01, -1.0241e+00,  7.2501e-02, -1.4921e-01, -7.2565e-03],\n",
      "          [ 2.1615e-01,  5.3890e-02, -4.9627e-01,  1.1774e-01,  9.4983e-01],\n",
      "          [ 9.0757e-01,  1.2921e+00,  8.1326e-01,  1.0263e+00,  2.2061e+00]]],\n",
      "\n",
      "\n",
      "        [[[-9.9201e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 7.4344e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 4.4055e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.6354e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 4.6508e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-4.6346e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.1134e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-6.8792e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.7475e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-8.9952e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-9.0463e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-7.5569e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-6.4839e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.3042e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-6.4328e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-9.0015e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-7.5713e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.9272e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-1.1439e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.5063e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6879, 0.3121, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4082, 0.5918, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7116, 0.2884, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6349, 0.3651, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6171, 0.3829, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5449, 0.4551, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8072, 0.1928, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4633, 0.5367, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4582, 0.5418, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5722, 0.4278, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3680, 0.6320, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5849, 0.4151, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3183, 0.6817, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4295, 0.5705, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4955, 0.5045, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4541, 0.5459, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5083, 0.4917, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2130, 0.7870, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2762, 0.7238, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3526, 0.6474, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2701, 0.1788, 0.2586, 0.1332, 0.1593],\n",
      "          [0.3438, 0.2663, 0.1455, 0.1610, 0.0834],\n",
      "          [0.3110, 0.2811, 0.1563, 0.1493, 0.1023],\n",
      "          [0.1964, 0.0704, 0.1650, 0.3077, 0.2605],\n",
      "          [0.2298, 0.0599, 0.3612, 0.1971, 0.1520]],\n",
      "\n",
      "         [[0.3709, 0.1915, 0.2133, 0.1060, 0.1182],\n",
      "          [0.4546, 0.0999, 0.1876, 0.0827, 0.1752],\n",
      "          [0.2967, 0.1500, 0.1764, 0.2261, 0.1507],\n",
      "          [0.1741, 0.1772, 0.4149, 0.1359, 0.0979],\n",
      "          [0.2954, 0.1925, 0.2154, 0.1265, 0.1703]],\n",
      "\n",
      "         [[0.1859, 0.2066, 0.1008, 0.2081, 0.2986],\n",
      "          [0.1778, 0.1968, 0.0767, 0.4509, 0.0978],\n",
      "          [0.3320, 0.1266, 0.0910, 0.3580, 0.0924],\n",
      "          [0.1449, 0.2847, 0.1703, 0.2599, 0.1402],\n",
      "          [0.1070, 0.3747, 0.0536, 0.1712, 0.2935]],\n",
      "\n",
      "         [[0.1139, 0.1908, 0.1387, 0.1221, 0.4345],\n",
      "          [0.1367, 0.1137, 0.2295, 0.1653, 0.3548],\n",
      "          [0.2534, 0.0815, 0.2441, 0.1956, 0.2254],\n",
      "          [0.1876, 0.1595, 0.0920, 0.1700, 0.3908],\n",
      "          [0.1224, 0.1798, 0.1114, 0.1378, 0.4485]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1119, -0.7430,    -inf,    -inf,    -inf],\n",
      "          [-0.1013, -0.1552,    -inf,    -inf,    -inf],\n",
      "          [-0.5240, -0.2026,    -inf,    -inf,    -inf],\n",
      "          [-0.4070,  0.0220,    -inf,    -inf,    -inf],\n",
      "          [-0.5688, -0.2151,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5045,  0.4848,    -inf,    -inf,    -inf],\n",
      "          [ 0.1132, -0.2879,    -inf,    -inf,    -inf],\n",
      "          [ 0.4757,  0.6188,    -inf,    -inf,    -inf],\n",
      "          [ 0.2542,  0.3742,    -inf,    -inf,    -inf],\n",
      "          [ 0.1839,  0.3776,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2693, -0.4583,    -inf,    -inf,    -inf],\n",
      "          [ 0.2588, -0.2387,    -inf,    -inf,    -inf],\n",
      "          [ 0.1245, -0.5975,    -inf,    -inf,    -inf],\n",
      "          [-0.2163, -0.6658,    -inf,    -inf,    -inf],\n",
      "          [-0.0239, -0.6787,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5233,  0.1234,    -inf,    -inf,    -inf],\n",
      "          [ 0.0240, -0.5332,    -inf,    -inf,    -inf],\n",
      "          [ 0.0985, -0.3955,    -inf,    -inf,    -inf],\n",
      "          [ 0.0671, -0.1317,    -inf,    -inf,    -inf],\n",
      "          [ 0.2518,  0.0546,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[-0.2236, -0.5764, -0.7477, -0.4065, -0.0394],\n",
      "          [ 0.1953, -0.3200,  0.2269, -0.0102,  0.2735],\n",
      "          [-0.1131, -0.2203, -0.2097,  0.2001,  0.1838],\n",
      "          [-0.4077, -0.1816, -0.7447, -0.1399,  0.0399],\n",
      "          [ 0.5047, -0.0531,  0.2532,  0.4005,  0.5391]],\n",
      "\n",
      "         [[-0.6475,  0.3258, -0.3447, -0.2181, -0.2250],\n",
      "          [ 0.3799,  0.8399,  0.1969,  0.1924,  0.2008],\n",
      "          [-0.1926,  0.0904,  0.3668,  0.2537,  0.0469],\n",
      "          [ 0.1287,  0.9746,  0.1434,  0.2078,  0.8983],\n",
      "          [-0.4761, -0.0276, -0.1531,  0.0208,  0.5553]],\n",
      "\n",
      "         [[-0.0393, -0.2933,  0.1158, -0.1840,  0.2553],\n",
      "          [-0.1844, -0.4467, -0.4863, -0.2733, -0.9022],\n",
      "          [ 0.4371, -0.0176, -0.1109, -0.4890, -0.3026],\n",
      "          [ 0.1412,  0.1452,  0.1623, -0.0565, -0.7402],\n",
      "          [ 0.3942,  0.2122, -0.0900, -0.3364, -0.0312]],\n",
      "\n",
      "         [[ 0.2083, -0.3813, -0.0291,  0.0422, -0.2872],\n",
      "          [ 0.1483, -0.4761,  0.2139,  0.5518, -0.3512],\n",
      "          [-0.1618, -0.3423, -0.1451,  0.0340, -0.2479],\n",
      "          [-0.1794, -0.5397, -0.0823, -0.3630, -0.5596],\n",
      "          [ 0.1296, -0.3951,  0.0831, -0.2593,  0.0386]]],\n",
      "\n",
      "\n",
      "        [[[-0.1555,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2025,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4265,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1377,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2070,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1409,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.4038,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2638,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2297,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1911,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4306,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2946,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1016,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.3350,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2474,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0949,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3965,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2324,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3620,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0982,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.6527, 0.3473, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5135, 0.4865, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4203, 0.5797, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3944, 0.6056, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4125, 0.5875, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5049, 0.4951, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5989, 0.4011, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4643, 0.5357, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4701, 0.5299, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4517, 0.5483, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6743, 0.3257, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6219, 0.3781, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6731, 0.3269, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6105, 0.3895, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6581, 0.3419, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5987, 0.4013, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6358, 0.3642, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6211, 0.3789, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5495, 0.4505, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5492, 0.4508, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2310, 0.1623, 0.1367, 0.1923, 0.2777],\n",
      "          [0.2210, 0.1320, 0.2281, 0.1799, 0.2390],\n",
      "          [0.1812, 0.1628, 0.1645, 0.2478, 0.2438],\n",
      "          [0.1713, 0.2147, 0.1223, 0.2238, 0.2679],\n",
      "          [0.2333, 0.1336, 0.1814, 0.2102, 0.2415]],\n",
      "\n",
      "         [[0.1240, 0.3283, 0.1679, 0.1906, 0.1892],\n",
      "          [0.1968, 0.3117, 0.1639, 0.1631, 0.1645],\n",
      "          [0.1447, 0.1921, 0.2532, 0.2261, 0.1839],\n",
      "          [0.1318, 0.3071, 0.1338, 0.1427, 0.2846],\n",
      "          [0.1191, 0.1865, 0.1645, 0.1958, 0.3341]],\n",
      "\n",
      "         [[0.1941, 0.1506, 0.2267, 0.1680, 0.2606],\n",
      "          [0.2557, 0.1967, 0.1890, 0.2339, 0.1247],\n",
      "          [0.3240, 0.2056, 0.1873, 0.1284, 0.1546],\n",
      "          [0.2347, 0.2357, 0.2397, 0.1926, 0.0972],\n",
      "          [0.2789, 0.2325, 0.1719, 0.1343, 0.1823]],\n",
      "\n",
      "         [[0.2632, 0.1460, 0.2076, 0.2229, 0.1604],\n",
      "          [0.2124, 0.1138, 0.2268, 0.3180, 0.1289],\n",
      "          [0.2006, 0.1675, 0.2040, 0.2440, 0.1840],\n",
      "          [0.2317, 0.1616, 0.2554, 0.1929, 0.1584],\n",
      "          [0.2417, 0.1430, 0.2307, 0.1638, 0.2207]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.2664e-01,  5.8225e-02,        -inf,        -inf,        -inf],\n",
      "          [-4.5630e-02,  1.1361e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.2970e-01,  2.7421e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.2701e-02,  2.9746e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.0967e-01,  2.0706e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.5010e-01,  4.2206e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.5023e-01,  3.2418e-02,        -inf,        -inf,        -inf],\n",
      "          [ 1.8165e-01, -1.4951e-04,        -inf,        -inf,        -inf],\n",
      "          [ 2.7784e-01, -2.2283e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.9074e-01, -2.2613e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 3.2756e-01,  6.2201e-01,        -inf,        -inf,        -inf],\n",
      "          [ 5.6002e-01,  3.8796e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.5331e-01,  1.1579e-01,        -inf,        -inf,        -inf],\n",
      "          [ 2.0696e-01,  5.4009e-03,        -inf,        -inf,        -inf],\n",
      "          [ 1.5524e-01, -6.9892e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.1523e-01, -1.0926e-01,        -inf,        -inf,        -inf],\n",
      "          [ 5.5735e-03,  3.0650e-01,        -inf,        -inf,        -inf],\n",
      "          [ 8.0947e-02,  3.0038e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.6113e-01,  5.5738e-01,        -inf,        -inf,        -inf],\n",
      "          [-4.5651e-02,  4.9518e-01,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6164e-01,  2.1844e-01,  8.1717e-02,  1.4291e-01,  4.2131e-01],\n",
      "          [-3.4736e-01,  2.5733e-01,  4.4215e-02, -1.0410e-02, -2.0067e-02],\n",
      "          [ 2.3200e-01,  3.4824e-01,  4.4807e-01,  2.8767e-01,  1.0736e-01],\n",
      "          [-1.0185e-01,  2.6616e-02,  4.6420e-02, -5.2926e-02, -1.5265e-01],\n",
      "          [-1.3229e-01, -3.4593e-01,  8.3691e-02,  1.0964e-01,  2.7173e-01]],\n",
      "\n",
      "         [[-4.6724e-01,  1.7725e-01,  1.3292e-01,  2.6410e-01,  2.6069e-01],\n",
      "          [ 5.0230e-01, -3.8583e-01,  2.0957e-01, -3.4630e-02, -2.6571e-01],\n",
      "          [ 6.6570e-02, -5.0997e-01,  1.2793e-01,  1.2205e-01,  5.8219e-01],\n",
      "          [-1.7089e-01, -5.1045e-01,  3.1034e-01, -3.8727e-01,  1.6368e-01],\n",
      "          [-4.5347e-02, -8.6376e-02,  2.4915e-01, -2.1998e-01,  2.0750e-01]],\n",
      "\n",
      "         [[ 5.8637e-02,  2.3685e-01,  1.1903e-01,  3.7863e-01, -6.6434e-02],\n",
      "          [ 8.7954e-01,  3.2698e-01,  4.0378e-01,  6.5507e-01,  1.2375e-01],\n",
      "          [ 1.9885e-01, -2.3369e-01, -2.3270e-01,  1.8868e-01, -1.3005e-01],\n",
      "          [ 1.3672e-01,  2.2996e-01,  3.1562e-01,  2.7437e-01,  4.0225e-01],\n",
      "          [ 2.6601e-01,  4.3235e-01,  4.6433e-01,  3.9705e-01,  1.7111e-01]],\n",
      "\n",
      "         [[-3.3491e-01,  7.0468e-01, -3.1588e-01,  2.9487e-01,  2.6918e-01],\n",
      "          [-3.5221e-01,  1.6076e-01, -5.3017e-01, -4.0709e-01, -3.6613e-01],\n",
      "          [ 2.8011e-02,  1.9643e-01,  3.0782e-01, -6.8879e-01, -3.4931e-01],\n",
      "          [ 2.3738e-01, -1.0894e-01,  1.2833e-01,  3.2866e-02, -4.3048e-02],\n",
      "          [-5.2599e-03,  2.5340e-01,  1.3669e-01, -5.3219e-01,  4.0837e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6583e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.8106e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-3.6016e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.3817e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.5578e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-3.2481e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 4.5545e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 2.1587e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.7131e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.1199e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.4868e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 7.0101e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 6.5585e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 6.7403e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 6.2241e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-4.3902e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.8567e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.7087e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-4.3262e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.7678e-01,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5171, 0.4829, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4603, 0.5397, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4639, 0.5361, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4231, 0.5769, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4215, 0.5785, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4571, 0.5429, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5294, 0.4706, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5453, 0.4547, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6226, 0.3774, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6027, 0.3973, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4269, 0.5731, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5429, 0.4571, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5591, 0.4409, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5502, 0.4498, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5560, 0.4440, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4487, 0.5513, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4253, 0.5747, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4454, 0.5546, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4022, 0.5978, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3680, 0.6320, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1901, 0.2012, 0.1755, 0.1866, 0.2465],\n",
      "          [0.1409, 0.2579, 0.2084, 0.1973, 0.1954],\n",
      "          [0.1885, 0.2118, 0.2340, 0.1993, 0.1664],\n",
      "          [0.1888, 0.2146, 0.2189, 0.1982, 0.1794],\n",
      "          [0.1718, 0.1388, 0.2132, 0.2188, 0.2573]],\n",
      "\n",
      "         [[0.1127, 0.2146, 0.2053, 0.2341, 0.2333],\n",
      "          [0.3119, 0.1283, 0.2327, 0.1823, 0.1447],\n",
      "          [0.1867, 0.1049, 0.1985, 0.1973, 0.3126],\n",
      "          [0.1807, 0.1287, 0.2924, 0.1456, 0.2525],\n",
      "          [0.1842, 0.1768, 0.2472, 0.1547, 0.2372]],\n",
      "\n",
      "         [[0.1813, 0.2166, 0.1925, 0.2496, 0.1600],\n",
      "          [0.2886, 0.1661, 0.1793, 0.2305, 0.1355],\n",
      "          [0.2495, 0.1619, 0.1621, 0.2470, 0.1796],\n",
      "          [0.1741, 0.1911, 0.2082, 0.1997, 0.2270],\n",
      "          [0.1835, 0.2167, 0.2237, 0.2092, 0.1669]],\n",
      "\n",
      "         [[0.1169, 0.3306, 0.1191, 0.2195, 0.2139],\n",
      "          [0.1838, 0.3070, 0.1539, 0.1740, 0.1813],\n",
      "          [0.2137, 0.2529, 0.2826, 0.1043, 0.1465],\n",
      "          [0.2396, 0.1694, 0.2148, 0.1952, 0.1810],\n",
      "          [0.1802, 0.2334, 0.2076, 0.1064, 0.2725]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0894,    -inf,    -inf,    -inf],\n",
      "          [ 0.3608,    -inf,    -inf,    -inf],\n",
      "          [-0.3323,    -inf,    -inf,    -inf],\n",
      "          [-0.0476,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1899,    -inf,    -inf,    -inf],\n",
      "          [-0.2034,    -inf,    -inf,    -inf],\n",
      "          [-0.3979,    -inf,    -inf,    -inf],\n",
      "          [-0.3629,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5892,    -inf,    -inf,    -inf],\n",
      "          [ 0.0632,    -inf,    -inf,    -inf],\n",
      "          [-0.1550,    -inf,    -inf,    -inf],\n",
      "          [-0.2013,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1566,    -inf,    -inf,    -inf],\n",
      "          [ 0.0918,    -inf,    -inf,    -inf],\n",
      "          [ 0.1157,    -inf,    -inf,    -inf],\n",
      "          [-0.1866,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8917,  0.6946,    -inf,    -inf],\n",
      "          [-0.3047,  0.2390,    -inf,    -inf],\n",
      "          [-0.2688, -0.1543,    -inf,    -inf],\n",
      "          [ 0.0969, -0.7152,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0696,  1.1599,    -inf,    -inf],\n",
      "          [-0.4069,  0.4126,    -inf,    -inf],\n",
      "          [ 0.0907,  0.5683,    -inf,    -inf],\n",
      "          [-0.2230,  1.0287,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.4222,  0.6580,    -inf,    -inf],\n",
      "          [-0.3458,  0.1365,    -inf,    -inf],\n",
      "          [ 0.8024,  0.2575,    -inf,    -inf],\n",
      "          [-0.6551,  0.1010,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.6622, -0.4276,    -inf,    -inf],\n",
      "          [-0.5381,  0.0294,    -inf,    -inf],\n",
      "          [-0.5520, -0.0339,    -inf,    -inf],\n",
      "          [ 0.1560, -0.1996,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0693,    -inf,    -inf,    -inf],\n",
      "          [-0.0560,    -inf,    -inf,    -inf],\n",
      "          [-0.1794,    -inf,    -inf,    -inf],\n",
      "          [-0.4049,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.6335,    -inf,    -inf,    -inf],\n",
      "          [ 0.3398,    -inf,    -inf,    -inf],\n",
      "          [ 0.0700,    -inf,    -inf,    -inf],\n",
      "          [ 0.3231,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1009,    -inf,    -inf,    -inf],\n",
      "          [-0.1265,    -inf,    -inf,    -inf],\n",
      "          [-0.5445,    -inf,    -inf,    -inf],\n",
      "          [-0.0787,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2624,    -inf,    -inf,    -inf],\n",
      "          [ 0.5687,    -inf,    -inf,    -inf],\n",
      "          [ 0.0802,    -inf,    -inf,    -inf],\n",
      "          [ 0.3119,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5491, 0.4509, 0.0000, 0.0000],\n",
      "          [0.3673, 0.6327, 0.0000, 0.0000],\n",
      "          [0.4714, 0.5286, 0.0000, 0.0000],\n",
      "          [0.6926, 0.3074, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.2263, 0.7737, 0.0000, 0.0000],\n",
      "          [0.3059, 0.6941, 0.0000, 0.0000],\n",
      "          [0.3828, 0.6172, 0.0000, 0.0000],\n",
      "          [0.2224, 0.7776, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4413, 0.5587, 0.0000, 0.0000],\n",
      "          [0.3817, 0.6183, 0.0000, 0.0000],\n",
      "          [0.6330, 0.3670, 0.0000, 0.0000],\n",
      "          [0.3195, 0.6805, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4416, 0.5584, 0.0000, 0.0000],\n",
      "          [0.3618, 0.6382, 0.0000, 0.0000],\n",
      "          [0.3733, 0.6267, 0.0000, 0.0000],\n",
      "          [0.5880, 0.4120, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2971,  0.3622,    -inf,    -inf,    -inf],\n",
      "          [ 0.1373,  0.0865,    -inf,    -inf,    -inf],\n",
      "          [-0.1087, -0.1187,    -inf,    -inf,    -inf],\n",
      "          [ 0.0305, -0.1932,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0883, -0.1424,    -inf,    -inf,    -inf],\n",
      "          [ 0.2089,  0.1218,    -inf,    -inf,    -inf],\n",
      "          [-0.1027,  0.0539,    -inf,    -inf,    -inf],\n",
      "          [-0.0575,  0.3142,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1727, -0.7935,    -inf,    -inf,    -inf],\n",
      "          [-0.3002, -0.1929,    -inf,    -inf,    -inf],\n",
      "          [-0.3418, -0.0718,    -inf,    -inf,    -inf],\n",
      "          [-0.2923, -0.3322,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1951, -0.3094,    -inf,    -inf,    -inf],\n",
      "          [-0.1400,  0.0376,    -inf,    -inf,    -inf],\n",
      "          [-0.1216,  0.1184,    -inf,    -inf,    -inf],\n",
      "          [-0.1382,  0.0539,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0139, -0.0221, -0.3307, -0.0848, -0.6697],\n",
      "          [-0.3038, -0.3985,  0.4626, -0.1075,  0.1867],\n",
      "          [-0.5511, -0.5846, -0.2710,  0.0962,  0.4477],\n",
      "          [-0.3640, -0.3125, -1.0905, -0.3696, -0.6260]],\n",
      "\n",
      "         [[-0.0616, -0.1952,  0.2532,  0.2157,  0.2010],\n",
      "          [ 0.0215, -0.7156, -0.7294, -1.0581, -0.1618],\n",
      "          [ 0.5812, -0.0454,  0.0644,  0.0164,  0.1987],\n",
      "          [ 0.0848, -0.5202,  0.6955,  0.0190, -0.0995]],\n",
      "\n",
      "         [[-0.0489, -0.1495,  0.2724, -0.0590,  0.0215],\n",
      "          [ 0.4339,  0.1016, -0.4042, -0.2059,  0.1348],\n",
      "          [-0.1252, -0.1855, -0.1545,  0.2211, -0.4149],\n",
      "          [-0.0043,  0.3274, -0.3227, -0.1523,  0.0073]],\n",
      "\n",
      "         [[ 0.0796,  0.0358, -0.1722, -0.4354,  0.0453],\n",
      "          [-0.4704,  0.1627, -0.0174, -0.5012,  0.4453],\n",
      "          [ 0.7502,  0.5958,  0.5238,  0.6730,  0.7111],\n",
      "          [ 0.1563,  0.2304, -0.4215, -0.2160,  0.4847]]],\n",
      "\n",
      "\n",
      "        [[[-0.3151,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.2455,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1454,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0601,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3156,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.1195,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0443,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0720,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0104,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4552,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4334,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.8354,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4820,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.3431,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2427,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4171,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.3409, 0.6591, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5127, 0.4873, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5025, 0.4975, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5557, 0.4443, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5135, 0.4865, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5218, 0.4782, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4609, 0.5391, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4081, 0.5919, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.7244, 0.2756, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4732, 0.5268, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4329, 0.5671, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5100, 0.4900, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.6235, 0.3765, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4557, 0.5443, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4403, 0.5597, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4521, 0.5479, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2449, 0.2362, 0.1735, 0.2219, 0.1236],\n",
      "          [0.1447, 0.1316, 0.3114, 0.1761, 0.2363],\n",
      "          [0.1263, 0.1222, 0.1672, 0.2413, 0.3430],\n",
      "          [0.2325, 0.2448, 0.1125, 0.2312, 0.1789]],\n",
      "\n",
      "         [[0.1705, 0.1492, 0.2336, 0.2250, 0.2217],\n",
      "          [0.3202, 0.1532, 0.1511, 0.1088, 0.2666],\n",
      "          [0.2957, 0.1580, 0.1764, 0.1681, 0.2017],\n",
      "          [0.1939, 0.1059, 0.3572, 0.1816, 0.1613]],\n",
      "\n",
      "         [[0.1871, 0.1692, 0.2579, 0.1852, 0.2007],\n",
      "          [0.2925, 0.2098, 0.1265, 0.1543, 0.2169],\n",
      "          [0.1970, 0.1855, 0.1914, 0.2786, 0.1475],\n",
      "          [0.2002, 0.2789, 0.1456, 0.1727, 0.2025]],\n",
      "\n",
      "         [[0.2327, 0.2227, 0.1809, 0.1390, 0.2248],\n",
      "          [0.1262, 0.2377, 0.1985, 0.1224, 0.3153],\n",
      "          [0.2202, 0.1887, 0.1756, 0.2038, 0.2117],\n",
      "          [0.2120, 0.2284, 0.1190, 0.1461, 0.2945]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0063,    -inf,    -inf,    -inf],\n",
      "          [-0.2298,    -inf,    -inf,    -inf],\n",
      "          [-0.1977,    -inf,    -inf,    -inf],\n",
      "          [ 0.1445,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1908,    -inf,    -inf,    -inf],\n",
      "          [ 0.4246,    -inf,    -inf,    -inf],\n",
      "          [ 0.3578,    -inf,    -inf,    -inf],\n",
      "          [ 0.2589,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.2101,    -inf,    -inf,    -inf],\n",
      "          [ 0.3298,    -inf,    -inf,    -inf],\n",
      "          [ 0.1778,    -inf,    -inf,    -inf],\n",
      "          [ 0.1678,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4186,    -inf,    -inf,    -inf],\n",
      "          [-0.7064,    -inf,    -inf,    -inf],\n",
      "          [-0.5783,    -inf,    -inf,    -inf],\n",
      "          [-0.6695,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1172, -0.0208,    -inf,    -inf],\n",
      "          [-0.3383, -0.7914,    -inf,    -inf],\n",
      "          [ 0.3515, -0.0234,    -inf,    -inf],\n",
      "          [-0.2746,  0.0067,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.2054,  0.2940,    -inf,    -inf],\n",
      "          [ 0.1170, -1.0023,    -inf,    -inf],\n",
      "          [ 0.3276, -0.0682,    -inf,    -inf],\n",
      "          [ 0.0957, -0.2787,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4521,  0.2624,    -inf,    -inf],\n",
      "          [-0.0770, -0.0555,    -inf,    -inf],\n",
      "          [-0.0233, -0.1863,    -inf,    -inf],\n",
      "          [-0.3997, -0.4517,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.1996,  0.2613,    -inf,    -inf],\n",
      "          [-0.5877, -0.6868,    -inf,    -inf],\n",
      "          [ 0.6721, -0.1551,    -inf,    -inf],\n",
      "          [-0.3667, -0.6049,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4629,    -inf,    -inf,    -inf],\n",
      "          [ 0.1630,    -inf,    -inf,    -inf],\n",
      "          [ 0.1404,    -inf,    -inf,    -inf],\n",
      "          [ 0.0752,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.5574,    -inf,    -inf,    -inf],\n",
      "          [-0.1987,    -inf,    -inf,    -inf],\n",
      "          [-0.3966,    -inf,    -inf,    -inf],\n",
      "          [-0.3918,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.4869,    -inf,    -inf,    -inf],\n",
      "          [ 0.1301,    -inf,    -inf,    -inf],\n",
      "          [ 0.2528,    -inf,    -inf,    -inf],\n",
      "          [ 0.2287,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.6067,    -inf,    -inf,    -inf],\n",
      "          [ 0.3203,    -inf,    -inf,    -inf],\n",
      "          [ 0.3896,    -inf,    -inf,    -inf],\n",
      "          [ 0.0572,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.5345, 0.4655, 0.0000, 0.0000],\n",
      "          [0.6114, 0.3886, 0.0000, 0.0000],\n",
      "          [0.5927, 0.4073, 0.0000, 0.0000],\n",
      "          [0.4301, 0.5699, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4779, 0.5221, 0.0000, 0.0000],\n",
      "          [0.7539, 0.2461, 0.0000, 0.0000],\n",
      "          [0.5977, 0.4023, 0.0000, 0.0000],\n",
      "          [0.5925, 0.4075, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3286, 0.6714, 0.0000, 0.0000],\n",
      "          [0.4946, 0.5054, 0.0000, 0.0000],\n",
      "          [0.5406, 0.4594, 0.0000, 0.0000],\n",
      "          [0.5130, 0.4870, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3868, 0.6132, 0.0000, 0.0000],\n",
      "          [0.5247, 0.4753, 0.0000, 0.0000],\n",
      "          [0.6958, 0.3042, 0.0000, 0.0000],\n",
      "          [0.5592, 0.4408, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-1.0942e-01, -8.0697e-02,        -inf,        -inf,        -inf],\n",
      "          [ 1.0965e-01,  3.9712e-01,        -inf,        -inf,        -inf],\n",
      "          [ 8.8920e-02,  1.5680e-01,        -inf,        -inf,        -inf],\n",
      "          [-2.0280e-02,  1.2778e-01,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-6.1319e-02, -1.3695e-01,        -inf,        -inf,        -inf],\n",
      "          [-8.7307e-01, -3.2170e-01,        -inf,        -inf,        -inf],\n",
      "          [-5.4102e-01, -2.6469e-01,        -inf,        -inf,        -inf],\n",
      "          [-4.7967e-01,  7.1908e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.4549e-02, -2.1140e-01,        -inf,        -inf,        -inf],\n",
      "          [ 3.8987e-01,  7.6993e-02,        -inf,        -inf,        -inf],\n",
      "          [ 3.8976e-01,  2.3283e-01,        -inf,        -inf,        -inf],\n",
      "          [ 1.2744e-01, -5.6325e-02,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.9407e-01, -1.1144e-01,        -inf,        -inf,        -inf],\n",
      "          [-1.6316e-01, -2.1577e-01,        -inf,        -inf,        -inf],\n",
      "          [ 4.8678e-02, -2.1358e-01,        -inf,        -inf,        -inf],\n",
      "          [-8.4278e-02, -3.2128e-02,        -inf,        -inf,        -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2817e-02, -1.9228e-01,  7.6857e-02, -4.9343e-01, -3.4222e-01],\n",
      "          [-7.3287e-02,  1.8726e-01,  2.6365e-01,  3.1458e-01,  5.6430e-02],\n",
      "          [ 1.0525e-01, -1.5773e-01, -6.0939e-02,  1.5417e-01, -2.1790e-01],\n",
      "          [-3.4976e-01, -9.8388e-04, -6.9732e-02,  1.3701e-01,  4.5345e-01]],\n",
      "\n",
      "         [[-1.9478e-01, -7.3613e-02, -3.6216e-01, -1.4088e-01,  1.1351e-01],\n",
      "          [ 2.2728e-01,  3.3069e-01, -2.0455e-01,  5.8292e-01,  4.1892e-01],\n",
      "          [ 1.2597e-01, -1.3893e-01, -7.2035e-01, -1.0660e-01,  2.2760e-01],\n",
      "          [-2.2525e-01,  5.7994e-02, -3.9220e-01,  1.9424e-01, -1.2430e-02]],\n",
      "\n",
      "         [[ 6.5602e-01,  1.0681e-01,  6.1811e-01,  3.4231e-01,  2.0331e-01],\n",
      "          [-2.9407e-01,  5.4794e-02,  2.6314e-01,  1.3228e-01,  6.9819e-01],\n",
      "          [ 1.3489e-01,  1.0706e-01,  4.0458e-01,  1.2228e-01, -1.8635e-01],\n",
      "          [ 6.3785e-01,  8.3632e-02,  5.2117e-02,  1.2833e-01,  4.9652e-02]],\n",
      "\n",
      "         [[-4.3470e-01,  1.1049e-01, -1.3702e-01, -1.6308e-01, -2.1920e-01],\n",
      "          [-2.6365e-01,  2.5574e-01, -3.2203e-01, -2.4090e-02,  1.4413e-01],\n",
      "          [-2.3339e-01,  1.3489e-01, -2.4465e-01,  1.2082e-01, -1.0041e-02],\n",
      "          [-1.6038e-01,  9.6236e-03,  7.9245e-02,  3.1774e-03, -6.8467e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7572e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.8393e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.1457e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.6344e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[-1.4798e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.5396e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.3041e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.2957e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 1.3689e+00,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 4.3027e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 3.8440e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.4828e-01,        -inf,        -inf,        -inf,        -inf]],\n",
      "\n",
      "         [[ 2.0777e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [ 1.0687e-01,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-5.1893e-02,        -inf,        -inf,        -inf,        -inf],\n",
      "          [-2.0405e-02,        -inf,        -inf,        -inf,        -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4928, 0.5072, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4286, 0.5714, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4830, 0.5170, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4631, 0.5369, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5189, 0.4811, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3655, 0.6345, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4314, 0.5686, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3655, 0.6345, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5587, 0.4413, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5776, 0.4224, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5392, 0.4608, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5458, 0.4542, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5758, 0.4242, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5131, 0.4869, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5652, 0.4348, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4870, 0.5130, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2501, 0.1918, 0.2511, 0.1419, 0.1651],\n",
      "          [0.1585, 0.2056, 0.2220, 0.2335, 0.1804],\n",
      "          [0.2278, 0.1751, 0.1929, 0.2392, 0.1649],\n",
      "          [0.1316, 0.1865, 0.1741, 0.2141, 0.2938]],\n",
      "\n",
      "         [[0.1855, 0.2094, 0.1569, 0.1958, 0.2525],\n",
      "          [0.1853, 0.2055, 0.1203, 0.2644, 0.2244],\n",
      "          [0.2442, 0.1873, 0.1047, 0.1935, 0.2703],\n",
      "          [0.1686, 0.2238, 0.1427, 0.2564, 0.2086]],\n",
      "\n",
      "         [[0.2560, 0.1478, 0.2464, 0.1870, 0.1628],\n",
      "          [0.1192, 0.1689, 0.2080, 0.1825, 0.3214],\n",
      "          [0.2002, 0.1947, 0.2622, 0.1977, 0.1452],\n",
      "          [0.3042, 0.1748, 0.1693, 0.1828, 0.1689]],\n",
      "\n",
      "         [[0.1510, 0.2604, 0.2033, 0.1981, 0.1873],\n",
      "          [0.1563, 0.2627, 0.1474, 0.1986, 0.2350],\n",
      "          [0.1637, 0.2366, 0.1619, 0.2333, 0.2046],\n",
      "          [0.1745, 0.2069, 0.2218, 0.2055, 0.1913]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3420,    -inf,    -inf,    -inf],\n",
      "          [-0.0776,    -inf,    -inf,    -inf],\n",
      "          [-0.0923,    -inf,    -inf,    -inf],\n",
      "          [ 0.0260,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0290,    -inf,    -inf,    -inf],\n",
      "          [ 0.4801,    -inf,    -inf,    -inf],\n",
      "          [ 0.3838,    -inf,    -inf,    -inf],\n",
      "          [ 0.2425,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5507,    -inf,    -inf,    -inf],\n",
      "          [-0.1598,    -inf,    -inf,    -inf],\n",
      "          [-0.1425,    -inf,    -inf,    -inf],\n",
      "          [ 0.0233,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0423,    -inf,    -inf,    -inf],\n",
      "          [ 0.0613,    -inf,    -inf,    -inf],\n",
      "          [ 0.3570,    -inf,    -inf,    -inf],\n",
      "          [ 0.2458,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0030,  0.0614,    -inf,    -inf],\n",
      "          [ 0.0882, -0.2921,    -inf,    -inf],\n",
      "          [ 0.0250, -0.1969,    -inf,    -inf],\n",
      "          [-0.0171,  0.1546,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0634,  0.2481,    -inf,    -inf],\n",
      "          [ 0.1266, -0.3878,    -inf,    -inf],\n",
      "          [-0.0359, -0.1902,    -inf,    -inf],\n",
      "          [ 0.2229, -0.6904,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.0816,  0.0522,    -inf,    -inf],\n",
      "          [ 0.1223, -0.0395,    -inf,    -inf],\n",
      "          [ 0.4803, -0.1261,    -inf,    -inf],\n",
      "          [-0.2365, -0.2282,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0449,  0.1601,    -inf,    -inf],\n",
      "          [-0.2300, -0.2528,    -inf,    -inf],\n",
      "          [-0.2831,  0.7914,    -inf,    -inf],\n",
      "          [ 0.0048,  0.5359,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4157,    -inf,    -inf,    -inf],\n",
      "          [ 0.4926,    -inf,    -inf,    -inf],\n",
      "          [ 0.2858,    -inf,    -inf,    -inf],\n",
      "          [ 0.3026,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0865,    -inf,    -inf,    -inf],\n",
      "          [ 0.2537,    -inf,    -inf,    -inf],\n",
      "          [ 0.4008,    -inf,    -inf,    -inf],\n",
      "          [ 0.7108,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0796,    -inf,    -inf,    -inf],\n",
      "          [ 0.1308,    -inf,    -inf,    -inf],\n",
      "          [ 0.4991,    -inf,    -inf,    -inf],\n",
      "          [ 0.2675,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3493,    -inf,    -inf,    -inf],\n",
      "          [-0.1521,    -inf,    -inf,    -inf],\n",
      "          [-0.3726,    -inf,    -inf,    -inf],\n",
      "          [-0.1607,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4854, 0.5146, 0.0000, 0.0000],\n",
      "          [0.5939, 0.4061, 0.0000, 0.0000],\n",
      "          [0.5552, 0.4448, 0.0000, 0.0000],\n",
      "          [0.4572, 0.5428, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4227, 0.5773, 0.0000, 0.0000],\n",
      "          [0.6258, 0.3742, 0.0000, 0.0000],\n",
      "          [0.5385, 0.4615, 0.0000, 0.0000],\n",
      "          [0.7137, 0.2863, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4666, 0.5334, 0.0000, 0.0000],\n",
      "          [0.5404, 0.4596, 0.0000, 0.0000],\n",
      "          [0.6471, 0.3529, 0.0000, 0.0000],\n",
      "          [0.4979, 0.5021, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4712, 0.5288, 0.0000, 0.0000],\n",
      "          [0.5057, 0.4943, 0.0000, 0.0000],\n",
      "          [0.2545, 0.7455, 0.0000, 0.0000],\n",
      "          [0.3703, 0.6297, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([3, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1553, -0.0519,    -inf,    -inf,    -inf],\n",
      "          [-0.1877,  0.2369,    -inf,    -inf,    -inf],\n",
      "          [-0.0278,  0.4188,    -inf,    -inf,    -inf],\n",
      "          [-0.0935,  0.2747,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1022, -0.0702,    -inf,    -inf,    -inf],\n",
      "          [-0.0788, -0.0044,    -inf,    -inf,    -inf],\n",
      "          [-0.1304, -0.1446,    -inf,    -inf,    -inf],\n",
      "          [-0.0795, -0.0602,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.1208,  0.1753,    -inf,    -inf,    -inf],\n",
      "          [ 0.1011, -0.0382,    -inf,    -inf,    -inf],\n",
      "          [-0.1870, -0.1386,    -inf,    -inf,    -inf],\n",
      "          [-0.2616, -0.3046,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.5896, -0.3197,    -inf,    -inf,    -inf],\n",
      "          [ 0.3706,  0.2737,    -inf,    -inf,    -inf],\n",
      "          [ 0.2946,  0.4055,    -inf,    -inf,    -inf],\n",
      "          [ 0.2063,  0.2550,    -inf,    -inf,    -inf]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7854, -0.1698, -0.0149,  0.1888, -0.0127],\n",
      "          [ 0.3362, -0.2983, -0.2333,  0.0790, -0.4181],\n",
      "          [ 0.7284,  0.1558,  0.1444, -0.0010, -0.1787],\n",
      "          [ 0.5670, -0.2084, -0.1118,  0.0740,  0.3456]],\n",
      "\n",
      "         [[-0.1824, -0.4267,  0.3462,  0.0189, -0.2275],\n",
      "          [-0.2512,  0.5286, -0.3130, -0.4353, -0.2894],\n",
      "          [-0.2156, -0.4884,  0.1039, -0.6918, -0.1946],\n",
      "          [-0.4377, -0.7297,  0.2867, -0.3955, -0.2665]],\n",
      "\n",
      "         [[ 0.1026,  0.6716,  0.3079,  0.6103,  0.5498],\n",
      "          [ 0.7463,  0.7279,  0.7679,  0.5780,  0.8358],\n",
      "          [ 0.1626,  0.4645,  0.2289,  0.6474,  0.5752],\n",
      "          [ 0.2812,  0.4948,  0.5260,  0.5054,  0.5134]],\n",
      "\n",
      "         [[ 0.8158,  0.4028,  0.6927,  0.6597,  0.3034],\n",
      "          [ 0.2515,  0.1560,  0.3991,  0.4483,  0.1130],\n",
      "          [ 0.3717, -0.1506,  0.1607,  0.1095,  0.0302],\n",
      "          [ 0.0730, -0.4490,  0.3238,  0.2713, -0.1321]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1789,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1123,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2354,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0880,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0872,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3121,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3019,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.3265,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[-0.3772,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.2946,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.4214,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.3496,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "         [[ 0.0736,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.1189,    -inf,    -inf,    -inf,    -inf],\n",
      "          [-0.0853,    -inf,    -inf,    -inf,    -inf],\n",
      "          [ 0.0770,    -inf,    -inf,    -inf,    -inf]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4742, 0.5258, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3954, 0.6046, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3902, 0.6098, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4090, 0.5910, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5430, 0.4570, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4814, 0.5186, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5036, 0.4964, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4952, 0.5048, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4864, 0.5136, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5348, 0.4652, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4879, 0.5121, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5108, 0.4892, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.4329, 0.5671, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5242, 0.4758, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4723, 0.5277, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4878, 0.5122, 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.3528, 0.1357, 0.1585, 0.1943, 0.1588],\n",
      "          [0.2994, 0.1588, 0.1694, 0.2315, 0.1408],\n",
      "          [0.3325, 0.1875, 0.1854, 0.1603, 0.1342],\n",
      "          [0.2959, 0.1363, 0.1501, 0.1807, 0.2371]],\n",
      "\n",
      "         [[0.1767, 0.1384, 0.2998, 0.2161, 0.1689],\n",
      "          [0.1691, 0.3687, 0.1589, 0.1406, 0.1627],\n",
      "          [0.2092, 0.1593, 0.2880, 0.1299, 0.2136],\n",
      "          [0.1656, 0.1236, 0.3416, 0.1727, 0.1965]],\n",
      "\n",
      "         [[0.1385, 0.2447, 0.1701, 0.2301, 0.2166],\n",
      "          [0.2023, 0.1986, 0.2067, 0.1710, 0.2213],\n",
      "          [0.1525, 0.2063, 0.1630, 0.2477, 0.2304],\n",
      "          [0.1659, 0.2054, 0.2119, 0.2076, 0.2092]],\n",
      "\n",
      "         [[0.2500, 0.1654, 0.2210, 0.2138, 0.1498],\n",
      "          [0.1939, 0.1763, 0.2248, 0.2361, 0.1689],\n",
      "          [0.2575, 0.1528, 0.2086, 0.1981, 0.1830],\n",
      "          [0.2036, 0.1208, 0.2616, 0.2482, 0.1658]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [1.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "output shape: torch.Size([3, 4, 100277])\n",
      "softmaxed[0, 0, :10]: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SliceBackward0>)\n",
      "predicted: \n",
      " tensor([[ 82681, 100257, 100257, 100257],\n",
      "        [    34,  17771,   6316,  17571],\n",
      "        [ 23380, 100257, 100257, 100257]])\n",
      "predicted decoded: \n",
      " ['Bonjour<|endoftext|><|endoftext|><|endoftext|>', \"C'est une phrase\", 'START<|endoftext|><|endoftext|><|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "sents = [\"Hello World\", \"This is a simple sentence\", \"Me\"]\n",
    "encoded_sents = [encoding.encode(s) for s in sents]\n",
    "enc_x = pad_sequence([torch.tensor(es) for es in encoded_sents], batch_first=True, padding_value=encoding.eot_token)\n",
    "print(enc_x)\n",
    "dec_sents = [\"Bonjour\", \"C'est une phrase\", \"START\"]\n",
    "dec_encoded_sents = [encoding.encode(s) for s in dec_sents]\n",
    "dec_x = pad_sequence([torch.tensor(es) for es in dec_encoded_sents], batch_first=True, padding_value=encoding.eot_token)\n",
    "print(dec_x)\n",
    "\n",
    "transformer = Transformer(vocab_size=encoding.n_vocab, n=3, d=256, h=4)\n",
    "\n",
    "enc_mask = build_padding_mask(enc_x, pad_token=100257)\n",
    "print(f\"enc_mask: \\n {enc_mask}\")\n",
    "enc_mask = reshape_mask(enc_mask)\n",
    "\n",
    "dec_mask1 = build_padding_mask(dec_x, pad_token=100257)\n",
    "dec_mask2 = build_causal_mask(dec_x)\n",
    "dec_mask = merge_masks(dec_mask1, dec_mask2)\n",
    "print(f\"dec_mask: \\n {dec_mask}\")\n",
    "dec_mask = reshape_mask(dec_mask)\n",
    "\n",
    "output = transformer(enc_x, dec_x, enc_mask=enc_mask, dec_mask=dec_mask)\n",
    "print(f\"output shape: {output.shape}\")\n",
    "softmaxed = F.softmax(output, dim=-1)\n",
    "print(f\"softmaxed[0, 0, :10]: {softmaxed[0, 0, :10]}\")\n",
    "predicted = softmaxed.argmax(dim=-1)\n",
    "print(f\"predicted: \\n {predicted}\")\n",
    "\n",
    "predicted_list = predicted.tolist()\n",
    "predicted_decoded = [encoding.decode(l) for l in predicted_list]\n",
    "print(f\"predicted decoded: \\n {predicted_decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "693b16e4-6684-4dbb-b21b-8c3650a10bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4056, -0.0592,  0.3210,  0.7641,  0.2315],\n",
      "          [ 0.1923,  0.2160,  0.6901, -0.3807,  0.4211],\n",
      "          [ 0.1536, -1.1140,  0.2217, -0.5141, -0.7577],\n",
      "          [-0.2799,  0.7452, -0.6044, -0.7963,  0.2692],\n",
      "          [ 0.4924, -0.5034, -0.1884, -0.9747,  0.0758]],\n",
      "\n",
      "         [[ 0.2996,  0.9493,  0.4883,  0.8463,  0.5434],\n",
      "          [ 0.9331,  1.1882, -0.0688, -1.1243, -0.4603],\n",
      "          [ 0.6546,  0.1881,  1.0822, -0.6032, -0.0829],\n",
      "          [ 0.0524,  0.4807, -0.3223, -0.4373,  0.4061],\n",
      "          [ 1.3109,  0.8021,  1.0551, -0.3777,  0.3677]],\n",
      "\n",
      "         [[-0.0879, -0.0493, -0.0073, -0.2372,  0.5121],\n",
      "          [-0.6886, -0.5000, -0.7529, -0.1972,  0.2821],\n",
      "          [-0.1928,  0.6222, -0.1332, -0.7815, -0.3502],\n",
      "          [ 0.4074,  0.9669,  0.2027,  0.9032,  1.0341],\n",
      "          [ 0.7860,  0.3283,  0.2983,  0.1211,  0.0942]],\n",
      "\n",
      "         [[ 0.5253,  0.6203,  0.1955,  0.1431,  0.6613],\n",
      "          [-0.6797,  0.1664, -0.0585, -1.4418,  0.2335],\n",
      "          [ 0.4301,  0.0510, -0.4387, -0.4784,  0.4537],\n",
      "          [ 0.0294,  0.4696,  0.3298, -0.7748, -0.1850],\n",
      "          [ 1.2403,  0.6410,  0.6524, -0.4449,  0.1409]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2075, 0.1304, 0.1907, 0.2970, 0.1744],\n",
      "          [0.1821, 0.1865, 0.2996, 0.1027, 0.2290],\n",
      "          [0.3061, 0.0862, 0.3277, 0.1570, 0.1231],\n",
      "          [0.1462, 0.4076, 0.1057, 0.0873, 0.2532],\n",
      "          [0.3616, 0.1336, 0.1831, 0.0834, 0.2384]],\n",
      "\n",
      "         [[0.1403, 0.2687, 0.1695, 0.2424, 0.1791],\n",
      "          [0.3296, 0.4254, 0.1210, 0.0421, 0.0818],\n",
      "          [0.2549, 0.1599, 0.3909, 0.0725, 0.1219],\n",
      "          [0.1901, 0.2918, 0.1307, 0.1165, 0.2708],\n",
      "          [0.3390, 0.2038, 0.2625, 0.0626, 0.1320]],\n",
      "\n",
      "         [[0.1722, 0.1790, 0.1867, 0.1483, 0.3138],\n",
      "          [0.1348, 0.1628, 0.1264, 0.2203, 0.3558],\n",
      "          [0.1745, 0.3943, 0.1852, 0.0969, 0.1491],\n",
      "          [0.1413, 0.2472, 0.1151, 0.2320, 0.2644],\n",
      "          [0.3066, 0.1940, 0.1883, 0.1577, 0.1535]],\n",
      "\n",
      "         [[0.2152, 0.2366, 0.1547, 0.1468, 0.2465],\n",
      "          [0.1227, 0.2859, 0.2283, 0.0573, 0.3058],\n",
      "          [0.2832, 0.1938, 0.1188, 0.1142, 0.2900],\n",
      "          [0.1939, 0.3011, 0.2618, 0.0867, 0.1565],\n",
      "          [0.3812, 0.2094, 0.2118, 0.0707, 0.1270]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.8522e-01,  1.6214e-01, -4.4270e-01,  4.6105e-01,  5.8130e-01],\n",
      "          [-2.3856e-01, -1.8255e-01, -1.3761e-01,  4.5941e-01,  2.8487e-02],\n",
      "          [ 8.0485e-02,  6.6883e-02, -1.1928e-01, -8.5323e-01, -3.4666e-01],\n",
      "          [ 3.9500e-01, -1.5859e-01,  3.0896e-01, -5.2684e-01, -4.0274e-01],\n",
      "          [-1.2830e-01,  2.3939e-02,  3.6257e-02, -2.3485e-02,  2.1325e-02]],\n",
      "\n",
      "         [[ 4.7732e-01,  4.3302e-01,  2.3400e-01,  1.4415e-01, -3.1618e-02],\n",
      "          [-3.1457e-01,  3.2287e-01,  1.9229e-01, -4.2430e-01, -1.7708e-01],\n",
      "          [-1.1358e-01,  5.2742e-01, -1.1980e-01, -3.2444e-01, -1.7476e-01],\n",
      "          [-1.5871e-01,  7.4107e-01,  1.4753e-01,  2.7466e-01,  2.2585e-01],\n",
      "          [-3.9691e-01,  2.0914e-01, -3.5647e-01,  7.0011e-01, -4.9648e-01]],\n",
      "\n",
      "         [[ 6.6339e-01, -4.3046e-01, -1.1265e-02, -5.7181e-01, -4.4205e-01],\n",
      "          [ 2.3222e-01,  3.6992e-01,  7.5958e-02,  2.1418e-02,  4.1413e-01],\n",
      "          [ 6.8991e-01,  1.1454e-01,  2.8027e-01, -3.2174e-01,  2.8641e-04],\n",
      "          [ 8.8710e-01,  5.3583e-01,  6.8308e-02, -2.9074e-01,  2.3174e-01],\n",
      "          [ 3.6985e-01,  2.6571e-01,  3.1571e-02, -1.8880e-01,  1.4116e-01]],\n",
      "\n",
      "         [[ 2.5348e-01, -1.0338e-01, -2.3386e-01, -5.8959e-01, -1.1472e-01],\n",
      "          [ 1.1525e-01, -1.9063e-01, -1.9630e-02, -1.6221e-01, -8.2484e-01],\n",
      "          [-7.3733e-01, -3.1195e-01, -4.8971e-01,  2.3052e-03, -2.6995e-02],\n",
      "          [-5.4526e-01, -4.0455e-01, -4.7739e-01,  4.3013e-01, -5.1758e-01],\n",
      "          [ 7.8420e-03,  8.3797e-02,  9.5093e-02, -2.0938e-01, -3.5874e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1882, 0.1839, 0.1004, 0.2479, 0.2796],\n",
      "          [0.1543, 0.1632, 0.1707, 0.3102, 0.2016],\n",
      "          [0.2597, 0.2562, 0.2127, 0.1021, 0.1694],\n",
      "          [0.2994, 0.1721, 0.2747, 0.1191, 0.1348],\n",
      "          [0.1781, 0.2074, 0.2099, 0.1978, 0.2068]],\n",
      "\n",
      "         [[0.2464, 0.2357, 0.1932, 0.1766, 0.1481],\n",
      "          [0.1516, 0.2868, 0.2517, 0.1359, 0.1740],\n",
      "          [0.1772, 0.3364, 0.1761, 0.1435, 0.1667],\n",
      "          [0.1277, 0.3141, 0.1735, 0.1970, 0.1876],\n",
      "          [0.1286, 0.2358, 0.1339, 0.3852, 0.1164]],\n",
      "\n",
      "         [[0.4055, 0.1358, 0.2065, 0.1179, 0.1342],\n",
      "          [0.1995, 0.2290, 0.1706, 0.1616, 0.2393],\n",
      "          [0.3234, 0.1819, 0.2147, 0.1176, 0.1623],\n",
      "          [0.3365, 0.2368, 0.1484, 0.1036, 0.1747],\n",
      "          [0.2512, 0.2263, 0.1791, 0.1437, 0.1998]],\n",
      "\n",
      "         [[0.2910, 0.2037, 0.1787, 0.1252, 0.2014],\n",
      "          [0.2661, 0.1959, 0.2325, 0.2016, 0.1039],\n",
      "          [0.1259, 0.1927, 0.1613, 0.2638, 0.2562],\n",
      "          [0.1449, 0.1668, 0.1551, 0.3843, 0.1490],\n",
      "          [0.2142, 0.2311, 0.2338, 0.1724, 0.1485]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 1.5370e-01, -7.3357e-02,  4.3444e-01, -3.2216e-01, -1.4918e-01],\n",
      "          [ 1.6849e-01,  3.4631e-01,  2.6713e-02, -2.3200e-01, -6.0489e-02],\n",
      "          [ 3.5321e-01,  4.9994e-01,  4.1333e-01,  3.2208e-01, -1.4962e-01],\n",
      "          [ 1.7875e-01,  2.0608e-01,  2.1615e-01,  1.6239e-01,  1.8748e-01],\n",
      "          [ 3.5338e-01, -3.6912e-01, -2.2428e-01,  7.0272e-02, -4.6726e-02]],\n",
      "\n",
      "         [[-6.0403e-01,  4.8111e-01, -5.3240e-01,  7.4322e-01,  3.0014e-04],\n",
      "          [-1.2244e-01,  5.1853e-01, -6.8333e-01,  3.4742e-01, -3.7055e-01],\n",
      "          [ 5.6771e-02,  2.3624e-01, -4.4600e-01,  2.0415e-01, -5.0795e-01],\n",
      "          [ 1.1106e-01,  9.3937e-02, -2.8712e-01,  7.0163e-01, -7.4403e-02],\n",
      "          [ 4.5636e-02,  7.2743e-01,  1.2593e-01,  1.5962e-01,  4.1651e-01]],\n",
      "\n",
      "         [[ 8.0715e-01,  7.2470e-01,  3.9068e-01, -2.5278e-01, -1.8933e-01],\n",
      "          [-2.9391e-02, -7.9719e-02,  1.8040e-01,  2.0174e-01, -3.5771e-01],\n",
      "          [ 3.3180e-01,  5.6982e-01,  5.5853e-02,  1.9173e-01,  1.5627e-01],\n",
      "          [-7.4476e-02, -4.2802e-02,  4.1520e-01,  3.6651e-01, -1.4144e-01],\n",
      "          [ 2.2500e-01,  2.0670e-01,  8.5708e-02,  1.2117e-01, -4.7328e-01]],\n",
      "\n",
      "         [[ 8.4372e-02,  2.0863e-01, -8.3225e-03,  2.0840e-01,  2.4458e-01],\n",
      "          [ 2.4003e-01, -3.2182e-01,  2.0714e-01,  2.6087e-01,  4.9018e-01],\n",
      "          [ 8.9205e-02,  3.7078e-01, -2.8665e-01,  4.5673e-01,  6.0440e-01],\n",
      "          [ 6.4471e-01, -1.1397e-01,  5.7609e-01, -3.6632e-02,  8.1177e-01],\n",
      "          [ 2.1666e-01, -2.7810e-02, -7.7740e-02,  1.3173e-01,  4.0693e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2232, 0.1778, 0.2955, 0.1387, 0.1648],\n",
      "          [0.2209, 0.2638, 0.1917, 0.1480, 0.1757],\n",
      "          [0.2086, 0.2416, 0.2215, 0.2022, 0.1262],\n",
      "          [0.1977, 0.2032, 0.2052, 0.1945, 0.1994],\n",
      "          [0.2881, 0.1399, 0.1617, 0.2171, 0.1931]],\n",
      "\n",
      "         [[0.0934, 0.2763, 0.1003, 0.3591, 0.1709],\n",
      "          [0.1710, 0.3246, 0.0976, 0.2735, 0.1334],\n",
      "          [0.2208, 0.2642, 0.1336, 0.2559, 0.1255],\n",
      "          [0.1890, 0.1858, 0.1269, 0.3412, 0.1570],\n",
      "          [0.1508, 0.2982, 0.1634, 0.1690, 0.2185]],\n",
      "\n",
      "         [[0.3034, 0.2794, 0.2001, 0.1051, 0.1120],\n",
      "          [0.1936, 0.1841, 0.2388, 0.2440, 0.1394],\n",
      "          [0.2112, 0.2679, 0.1602, 0.1836, 0.1772],\n",
      "          [0.1625, 0.1677, 0.2652, 0.2526, 0.1520],\n",
      "          [0.2353, 0.2310, 0.2047, 0.2121, 0.1170]],\n",
      "\n",
      "         [[0.1869, 0.2117, 0.1704, 0.2116, 0.2194],\n",
      "          [0.2065, 0.1177, 0.1998, 0.2108, 0.2652],\n",
      "          [0.1631, 0.2162, 0.1120, 0.2356, 0.2731],\n",
      "          [0.2445, 0.1145, 0.2283, 0.1237, 0.2890],\n",
      "          [0.2148, 0.1682, 0.1600, 0.1973, 0.2598]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4879]],\n",
      "\n",
      "         [[ 0.7329]],\n",
      "\n",
      "         [[-0.4894]],\n",
      "\n",
      "         [[ 1.7733]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0796, -0.1020,  0.2055,  0.3292, -0.0081]],\n",
      "\n",
      "         [[ 0.0208,  0.1456,  0.1808, -0.0509, -0.3771]],\n",
      "\n",
      "         [[-0.0716, -0.8439,  0.0157, -0.2715, -0.2828]],\n",
      "\n",
      "         [[-0.5141, -0.4069, -0.8277, -0.4170, -0.0668]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1935, 0.1614, 0.2195, 0.2484, 0.1773]],\n",
      "\n",
      "         [[0.2037, 0.2308, 0.2391, 0.1896, 0.1368]],\n",
      "\n",
      "         [[0.2392, 0.1105, 0.2610, 0.1958, 0.1936]],\n",
      "\n",
      "         [[0.1815, 0.2020, 0.1326, 0.2000, 0.2839]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.2806]],\n",
      "\n",
      "         [[-0.2174]],\n",
      "\n",
      "         [[ 0.2563]],\n",
      "\n",
      "         [[ 0.3001]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3182, -0.3613, -0.1885,  0.0492, -0.0977]],\n",
      "\n",
      "         [[-0.1828,  0.0825, -0.1397,  0.2653, -0.4198]],\n",
      "\n",
      "         [[-0.2041, -0.1683, -0.2605,  0.0168, -0.2516]],\n",
      "\n",
      "         [[-0.1228, -0.4002, -0.2912,  0.2894,  0.0177]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1728, 0.1655, 0.1967, 0.2495, 0.2154]],\n",
      "\n",
      "         [[0.1754, 0.2286, 0.1831, 0.2745, 0.1384]],\n",
      "\n",
      "         [[0.1930, 0.2000, 0.1824, 0.2407, 0.1840]],\n",
      "\n",
      "         [[0.1900, 0.1440, 0.1605, 0.2869, 0.2186]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 1])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.8417]],\n",
      "\n",
      "         [[-0.2089]],\n",
      "\n",
      "         [[ 0.0212]],\n",
      "\n",
      "         [[-0.3151]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]],\n",
      "\n",
      "         [[1.]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 1, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0907, -0.0501,  0.3138,  0.9290,  0.1796]],\n",
      "\n",
      "         [[ 0.2048, -0.1781,  0.2633,  0.1888,  0.2137]],\n",
      "\n",
      "         [[ 0.0685, -0.0891, -0.6050, -0.4233, -0.1256]],\n",
      "\n",
      "         [[ 0.2228,  0.1242,  0.5105,  0.5278,  0.3966]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1533, 0.1331, 0.1916, 0.3545, 0.1675]],\n",
      "\n",
      "         [[0.2112, 0.1440, 0.2239, 0.2078, 0.2131]],\n",
      "\n",
      "         [[0.2632, 0.2248, 0.1342, 0.1610, 0.2168]],\n",
      "\n",
      "         [[0.1728, 0.1566, 0.2305, 0.2345, 0.2056]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2251, -0.4471,  0.0798,  0.8584,  0.1245],\n",
      "          [-0.3400, -0.2066,  0.1318, -0.5529,  0.3980],\n",
      "          [-0.0875, -1.0396, -0.0727, -0.3204, -0.4093],\n",
      "          [-0.1793,  0.2111, -0.7759, -0.0816,  0.1699],\n",
      "          [ 0.2511, -0.3885, -0.1896, -0.2526, -0.0382]],\n",
      "\n",
      "         [[ 0.4658,  0.8318,  0.4820,  0.6179,  0.2775],\n",
      "          [ 1.1518,  1.1040,  0.3035, -0.7554, -0.5408],\n",
      "          [ 0.3251,  0.4562,  0.6283, -0.4409, -0.3184],\n",
      "          [ 0.1451,  0.6854, -0.1334, -0.2746,  0.2878],\n",
      "          [ 0.9774,  0.9163,  1.0323, -0.0576,  0.6731]],\n",
      "\n",
      "         [[ 0.0144,  0.2559,  0.3283, -0.4993,  0.4458],\n",
      "          [-0.9752, -0.9428, -0.8732, -0.2158, -0.2282],\n",
      "          [-0.1907,  0.4367,  0.2065, -0.1305, -0.3114],\n",
      "          [ 0.1253,  0.3964,  0.3284,  0.6572,  0.7216],\n",
      "          [ 0.5242,  0.2028,  0.4449,  0.0805, -0.0700]],\n",
      "\n",
      "         [[ 0.1528,  0.2893,  0.3129, -0.1544,  0.5039],\n",
      "          [-0.6833,  0.2105,  0.0727, -0.8987,  0.0269],\n",
      "          [-0.2550,  0.4565, -0.3829, -0.8069,  0.3185],\n",
      "          [ 0.0299,  0.6424,  0.1263, -0.7182, -0.7169],\n",
      "          [ 1.3809,  1.2256,  0.5401, -0.1262, -0.3211]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1937, 0.0989, 0.1675, 0.3648, 0.1751],\n",
      "          [0.1505, 0.1720, 0.2412, 0.1216, 0.3148],\n",
      "          [0.2552, 0.0985, 0.2590, 0.2022, 0.1850],\n",
      "          [0.1802, 0.2663, 0.0992, 0.1987, 0.2555],\n",
      "          [0.2837, 0.1497, 0.1826, 0.1715, 0.2125]],\n",
      "\n",
      "         [[0.1835, 0.2645, 0.1865, 0.2136, 0.1520],\n",
      "          [0.3685, 0.3513, 0.1578, 0.0547, 0.0678],\n",
      "          [0.2230, 0.2542, 0.3020, 0.1037, 0.1172],\n",
      "          [0.1892, 0.3249, 0.1432, 0.1244, 0.2183],\n",
      "          [0.2445, 0.2300, 0.2583, 0.0869, 0.1804]],\n",
      "\n",
      "         [[0.1730, 0.2203, 0.2368, 0.1035, 0.2663],\n",
      "          [0.1354, 0.1398, 0.1499, 0.2892, 0.2857],\n",
      "          [0.1585, 0.2968, 0.2358, 0.1683, 0.1405],\n",
      "          [0.1418, 0.1859, 0.1737, 0.2413, 0.2574],\n",
      "          [0.2602, 0.1887, 0.2404, 0.1670, 0.1437]],\n",
      "\n",
      "         [[0.1826, 0.2093, 0.2143, 0.1343, 0.2594],\n",
      "          [0.1188, 0.2905, 0.2531, 0.0958, 0.2418],\n",
      "          [0.1596, 0.3250, 0.1404, 0.0919, 0.2831],\n",
      "          [0.2044, 0.3770, 0.2250, 0.0967, 0.0968],\n",
      "          [0.3716, 0.3181, 0.1603, 0.0823, 0.0677]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3964,  0.1459, -0.1522,  0.0155,  0.4513],\n",
      "          [ 0.0778, -0.2646,  0.1105,  0.3709,  0.3846],\n",
      "          [ 0.1046, -0.0847, -0.0582, -0.5229, -0.4249],\n",
      "          [ 0.3778, -0.1486,  0.3583, -0.3224, -0.3120],\n",
      "          [ 0.2047, -0.1847, -0.1834, -0.0228,  0.1761]],\n",
      "\n",
      "         [[ 0.1417,  0.2667,  0.2431,  0.0853, -0.0188],\n",
      "          [-0.6302,  0.3858, -0.0370, -0.3642, -0.1422],\n",
      "          [-0.1214,  0.4537, -0.1295,  0.0085, -0.2797],\n",
      "          [-0.0454,  0.3679,  0.0469, -0.1155,  0.0742],\n",
      "          [-0.2000,  0.0009, -0.2359,  0.6151, -0.5349]],\n",
      "\n",
      "         [[ 0.6062, -0.5087,  0.0117, -0.3565, -0.1305],\n",
      "          [ 0.1138,  0.4921, -0.1094,  0.1059,  0.5179],\n",
      "          [ 0.4544, -0.2473,  0.1808, -0.4029, -0.1548],\n",
      "          [ 0.8180,  0.1928,  0.0197, -0.6031,  0.0614],\n",
      "          [ 0.6277,  0.1445,  0.2021, -0.5711, -0.0457]],\n",
      "\n",
      "         [[ 0.3535,  0.2450,  0.0942, -0.6987, -0.2365],\n",
      "          [ 0.3016, -0.2810,  0.2183, -0.0637, -0.4806],\n",
      "          [-0.3066, -0.0016, -0.5706, -0.1224,  0.2347],\n",
      "          [-0.4355, -0.1412, -0.5128,  0.3566, -0.5826],\n",
      "          [ 0.0803, -0.0706,  0.0363, -0.6806, -0.2293]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2441, 0.1900, 0.1411, 0.1668, 0.2579],\n",
      "          [0.1837, 0.1305, 0.1898, 0.2463, 0.2497],\n",
      "          [0.2632, 0.2178, 0.2236, 0.1405, 0.1550],\n",
      "          [0.2801, 0.1655, 0.2747, 0.1391, 0.1405],\n",
      "          [0.2425, 0.1643, 0.1645, 0.1931, 0.2356]],\n",
      "\n",
      "         [[0.1985, 0.2250, 0.2197, 0.1876, 0.1691],\n",
      "          [0.1176, 0.3247, 0.2128, 0.1534, 0.1915],\n",
      "          [0.1736, 0.3085, 0.1722, 0.1976, 0.1481],\n",
      "          [0.1764, 0.2667, 0.1935, 0.1645, 0.1989],\n",
      "          [0.1623, 0.1984, 0.1566, 0.3667, 0.1161]],\n",
      "\n",
      "         [[0.3649, 0.1197, 0.2014, 0.1393, 0.1747],\n",
      "          [0.1739, 0.2539, 0.1391, 0.1725, 0.2605],\n",
      "          [0.3101, 0.1537, 0.2359, 0.1316, 0.1686],\n",
      "          [0.3709, 0.1985, 0.1669, 0.0896, 0.1741],\n",
      "          [0.3245, 0.2002, 0.2120, 0.0979, 0.1655]],\n",
      "\n",
      "         [[0.2799, 0.2511, 0.2160, 0.0977, 0.1552],\n",
      "          [0.2755, 0.1539, 0.2535, 0.1912, 0.1260],\n",
      "          [0.1654, 0.2244, 0.1270, 0.1989, 0.2842],\n",
      "          [0.1578, 0.2117, 0.1460, 0.3483, 0.1362],\n",
      "          [0.2489, 0.2140, 0.2382, 0.1163, 0.1826]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0525, -0.0193,  0.5192, -0.0680, -0.2639],\n",
      "          [ 0.3911,  0.3576,  0.4955,  0.0319,  0.0194],\n",
      "          [-0.2032, -0.1734, -0.1083,  0.4140, -0.1825],\n",
      "          [ 0.4179,  0.2660,  0.6168,  0.1531,  0.0576],\n",
      "          [ 0.4222, -0.2168, -0.0402, -0.1309, -0.1771]],\n",
      "\n",
      "         [[-0.5513,  0.2903, -0.2657,  0.5423,  0.0486],\n",
      "          [-0.1873, -0.0053, -0.3307,  0.0878, -0.1399],\n",
      "          [ 0.1209, -0.0263, -0.3903,  0.3314, -0.4423],\n",
      "          [ 0.0066, -0.0685, -0.2297,  0.5110, -0.1658],\n",
      "          [ 0.0339,  0.3645,  0.0250,  0.0144,  0.3238]],\n",
      "\n",
      "         [[ 0.7099,  0.4479,  0.4415, -0.1148,  0.2712],\n",
      "          [ 0.3146,  0.0967,  0.2969,  0.2656, -0.0072],\n",
      "          [ 0.7869,  0.4510,  0.1668,  0.1035,  0.4039],\n",
      "          [-0.0295,  0.2042,  0.0142,  0.0920, -0.2280],\n",
      "          [ 0.4485, -0.0764,  0.1385, -0.2934, -0.1705]],\n",
      "\n",
      "         [[ 0.0740,  0.5318, -0.0817, -0.0543,  0.2654],\n",
      "          [ 0.2727, -0.1647, -0.1286,  0.0641,  0.2247],\n",
      "          [ 0.0447,  0.5895, -0.1570,  0.2534,  0.7306],\n",
      "          [ 0.3743, -0.0389,  0.4134, -0.2554,  0.7303],\n",
      "          [ 0.1761,  0.1961,  0.0133, -0.1106,  0.1578]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1786, 0.1846, 0.3164, 0.1759, 0.1446],\n",
      "          [0.2240, 0.2166, 0.2486, 0.1564, 0.1544],\n",
      "          [0.1665, 0.1716, 0.1831, 0.3087, 0.1700],\n",
      "          [0.2201, 0.1891, 0.2685, 0.1689, 0.1535],\n",
      "          [0.3047, 0.1608, 0.1919, 0.1753, 0.1673]],\n",
      "\n",
      "         [[0.1057, 0.2453, 0.1407, 0.3156, 0.1926],\n",
      "          [0.1841, 0.2209, 0.1595, 0.2424, 0.1930],\n",
      "          [0.2344, 0.2023, 0.1406, 0.2893, 0.1335],\n",
      "          [0.1918, 0.1779, 0.1514, 0.3176, 0.1614],\n",
      "          [0.1754, 0.2442, 0.1739, 0.1721, 0.2344]],\n",
      "\n",
      "         [[0.2765, 0.2127, 0.2114, 0.1212, 0.1783],\n",
      "          [0.2240, 0.1802, 0.2201, 0.2133, 0.1624],\n",
      "          [0.2908, 0.2078, 0.1564, 0.1468, 0.1982],\n",
      "          [0.1902, 0.2403, 0.1987, 0.2148, 0.1560],\n",
      "          [0.2994, 0.1771, 0.2196, 0.1426, 0.1612]],\n",
      "\n",
      "         [[0.1809, 0.2860, 0.1548, 0.1591, 0.2191],\n",
      "          [0.2451, 0.1583, 0.1641, 0.1989, 0.2336],\n",
      "          [0.1479, 0.2551, 0.1209, 0.1823, 0.2937],\n",
      "          [0.2145, 0.1419, 0.2231, 0.1143, 0.3062],\n",
      "          [0.2173, 0.2217, 0.1846, 0.1631, 0.2133]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4948,  0.5464],\n",
      "          [ 0.2470,  0.4924]],\n",
      "\n",
      "         [[ 0.6419,  0.5864],\n",
      "          [ 0.6082,  0.5819]],\n",
      "\n",
      "         [[ 0.2673,  0.1387],\n",
      "          [-0.2610, -0.2502]],\n",
      "\n",
      "         [[ 1.1346,  0.9384],\n",
      "          [ 1.2852,  1.4219]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.4871, 0.5129],\n",
      "          [0.4390, 0.5610]],\n",
      "\n",
      "         [[0.5139, 0.4861],\n",
      "          [0.5066, 0.4934]],\n",
      "\n",
      "         [[0.5321, 0.4679],\n",
      "          [0.4973, 0.5027]],\n",
      "\n",
      "         [[0.5489, 0.4511],\n",
      "          [0.4659, 0.5341]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1759,  0.1723,  0.1303,  0.0809,  0.2304],\n",
      "          [ 0.0345,  0.0677,  0.1721,  0.2410, -0.1933]],\n",
      "\n",
      "         [[ 0.2420,  0.0734,  0.1538,  0.0830, -0.1046],\n",
      "          [ 0.3221, -0.0232,  0.1932, -0.2805, -0.3603]],\n",
      "\n",
      "         [[-0.0306, -0.3450, -0.2380,  0.1342,  0.0169],\n",
      "          [ 0.0214, -0.6570,  0.0904, -0.1988,  0.0557]],\n",
      "\n",
      "         [[-0.2288, -0.0952, -0.7416, -0.4887,  0.0591],\n",
      "          [-0.3560, -0.1681, -0.6107, -0.4344, -0.0229]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2034, 0.2026, 0.1943, 0.1849, 0.2148],\n",
      "          [0.1921, 0.1985, 0.2204, 0.2361, 0.1529]],\n",
      "\n",
      "         [[0.2315, 0.1955, 0.2119, 0.1974, 0.1637],\n",
      "          [0.2747, 0.1945, 0.2415, 0.1504, 0.1388]],\n",
      "\n",
      "         [[0.2096, 0.1531, 0.1703, 0.2472, 0.2198],\n",
      "          [0.2264, 0.1149, 0.2426, 0.1817, 0.2343]],\n",
      "\n",
      "         [[0.2063, 0.2358, 0.1236, 0.1591, 0.2752],\n",
      "          [0.1886, 0.2276, 0.1462, 0.1744, 0.2632]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1140, -0.0420],\n",
      "          [ 0.0122, -0.2557]],\n",
      "\n",
      "         [[-0.3417, -0.5743],\n",
      "          [ 0.0079, -0.1361]],\n",
      "\n",
      "         [[ 0.3701,  0.4274],\n",
      "          [ 0.2960,  0.3571]],\n",
      "\n",
      "         [[-0.1880, -0.1633],\n",
      "          [-0.2913, -0.1568]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5389, 0.4611],\n",
      "          [0.5666, 0.4334]],\n",
      "\n",
      "         [[0.5579, 0.4421],\n",
      "          [0.5359, 0.4641]],\n",
      "\n",
      "         [[0.4857, 0.5143],\n",
      "          [0.4847, 0.5153]],\n",
      "\n",
      "         [[0.4938, 0.5062],\n",
      "          [0.4664, 0.5336]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.4595, -0.4622, -0.2001, -0.1488, -0.3137],\n",
      "          [-0.4656, -0.2966, -0.2996,  0.0510, -0.3097]],\n",
      "\n",
      "         [[-0.2051,  0.0021, -0.2755,  0.0383, -0.3713],\n",
      "          [-0.0101, -0.0053, -0.0987,  0.1424, -0.3427]],\n",
      "\n",
      "         [[-0.0911,  0.1765, -0.4300, -0.0383, -0.2081],\n",
      "          [-0.0011,  0.1606, -0.4399, -0.0431, -0.2374]],\n",
      "\n",
      "         [[-0.0333, -0.5471, -0.5348,  0.5091,  0.2070],\n",
      "          [-0.0622, -0.6419, -0.7137,  0.6726,  0.2495]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1720, 0.1715, 0.2229, 0.2346, 0.1990],\n",
      "          [0.1610, 0.1907, 0.1901, 0.2700, 0.1882]],\n",
      "\n",
      "         [[0.1892, 0.2328, 0.1764, 0.2414, 0.1602],\n",
      "          [0.2082, 0.2093, 0.1906, 0.2426, 0.1493]],\n",
      "\n",
      "         [[0.2015, 0.2633, 0.1436, 0.2124, 0.1792],\n",
      "          [0.2189, 0.2573, 0.1411, 0.2099, 0.1728]],\n",
      "\n",
      "         [[0.1925, 0.1151, 0.1166, 0.3311, 0.2447],\n",
      "          [0.1808, 0.1012, 0.0942, 0.3769, 0.2469]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 2])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5530, -0.6853],\n",
      "          [-0.4943, -0.7442]],\n",
      "\n",
      "         [[ 0.0185, -0.0748],\n",
      "          [-0.4516, -0.4639]],\n",
      "\n",
      "         [[ 0.2845,  0.0347],\n",
      "          [ 0.1774,  0.1217]],\n",
      "\n",
      "         [[ 0.1332, -0.0347],\n",
      "          [ 0.0802, -0.0010]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.5330, 0.4670],\n",
      "          [0.5621, 0.4379]],\n",
      "\n",
      "         [[0.5233, 0.4767],\n",
      "          [0.5031, 0.4969]],\n",
      "\n",
      "         [[0.5621, 0.4379],\n",
      "          [0.5139, 0.4861]],\n",
      "\n",
      "         [[0.5419, 0.4581],\n",
      "          [0.5203, 0.4797]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 2, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2934,  0.0768,  0.5512,  0.4343, -0.0392],\n",
      "          [ 0.1243, -0.0253,  0.3804,  0.5900, -0.3790]],\n",
      "\n",
      "         [[-0.1841, -0.2381, -0.1768,  0.0647,  0.2533],\n",
      "          [ 0.1488, -0.1072,  0.0728,  0.1596,  0.1995]],\n",
      "\n",
      "         [[ 0.0922, -0.1851, -0.4479, -0.1514, -0.1777],\n",
      "          [ 0.0824,  0.0174, -0.2785, -0.1076, -0.0464]],\n",
      "\n",
      "         [[-0.0045, -0.1128,  0.5757,  0.4363,  0.1703],\n",
      "          [ 0.1427,  0.1663,  0.6417,  0.4923,  0.0337]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2013, 0.1621, 0.2605, 0.2318, 0.1443],\n",
      "          [0.1869, 0.1609, 0.2415, 0.2977, 0.1130]],\n",
      "\n",
      "         [[0.1728, 0.1638, 0.1741, 0.2217, 0.2677],\n",
      "          [0.2099, 0.1625, 0.1946, 0.2122, 0.2208]],\n",
      "\n",
      "         [[0.2572, 0.1949, 0.1499, 0.2016, 0.1964],\n",
      "          [0.2304, 0.2159, 0.1606, 0.1905, 0.2026]],\n",
      "\n",
      "         [[0.1556, 0.1396, 0.2779, 0.2417, 0.1853],\n",
      "          [0.1671, 0.1710, 0.2751, 0.2370, 0.1498]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1792, -0.0472,  0.6782,  0.1694,  0.1810],\n",
      "          [-0.0776, -0.0841,  0.3655, -0.8058,  0.6179],\n",
      "          [ 0.2126, -1.3014,  0.8104, -0.4845, -0.5571],\n",
      "          [-0.4180,  0.3943, -1.0792, -0.8667, -0.0111],\n",
      "          [ 0.4683, -0.5565,  0.2203, -0.4768,  0.3896]],\n",
      "\n",
      "         [[ 0.1353,  0.4195,  0.3084,  0.5512, -0.1247],\n",
      "          [ 0.6392,  1.2504,  0.0714, -0.9604, -0.5226],\n",
      "          [ 0.5779,  0.5585,  1.2378, -0.1810,  0.0882],\n",
      "          [ 0.4297,  1.1381, -0.3183, -0.1794,  0.6033],\n",
      "          [ 0.9990,  0.7381,  0.9622, -0.2879,  0.5338]],\n",
      "\n",
      "         [[ 0.2841, -0.2469,  0.0302, -0.1599,  0.3024],\n",
      "          [-0.9162, -0.6247, -0.8816,  0.2427, -0.1704],\n",
      "          [-0.5330,  0.6006, -0.1872,  0.0103, -0.5827],\n",
      "          [ 0.1781,  1.0884,  0.7573,  0.8524,  0.6221],\n",
      "          [ 0.6642,  0.2187,  0.6892, -0.0115, -0.0502]],\n",
      "\n",
      "         [[ 0.4563,  0.1968, -0.0865, -0.3366,  0.7861],\n",
      "          [-0.0459,  0.3005,  0.0132, -1.3236, -0.1168],\n",
      "          [ 0.7823,  0.0106, -0.4279, -0.9999,  0.2344],\n",
      "          [ 0.3892, -0.0250,  0.3130, -0.9379, -0.6655],\n",
      "          [ 1.4221,  0.7013,  0.7214, -0.5054, -0.3892]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1839, 0.1467, 0.3030, 0.1821, 0.1843],\n",
      "          [0.1656, 0.1645, 0.2579, 0.0800, 0.3320],\n",
      "          [0.2500, 0.0550, 0.4546, 0.1245, 0.1158],\n",
      "          [0.1692, 0.3812, 0.0874, 0.1080, 0.2542],\n",
      "          [0.2897, 0.1039, 0.2260, 0.1126, 0.2678]],\n",
      "\n",
      "         [[0.1723, 0.2289, 0.2048, 0.2611, 0.1328],\n",
      "          [0.2548, 0.4696, 0.1444, 0.0515, 0.0797],\n",
      "          [0.2001, 0.1963, 0.3872, 0.0937, 0.1227],\n",
      "          [0.1909, 0.3877, 0.0904, 0.1038, 0.2271],\n",
      "          [0.2748, 0.2117, 0.2649, 0.0759, 0.1726]],\n",
      "\n",
      "         [[0.2485, 0.1461, 0.1928, 0.1594, 0.2531],\n",
      "          [0.1154, 0.1544, 0.1194, 0.3676, 0.2432],\n",
      "          [0.1221, 0.3792, 0.1725, 0.2101, 0.1161],\n",
      "          [0.1138, 0.2827, 0.2030, 0.2232, 0.1773],\n",
      "          [0.2729, 0.1748, 0.2798, 0.1389, 0.1336]],\n",
      "\n",
      "         [[0.2383, 0.1839, 0.1385, 0.1078, 0.3315],\n",
      "          [0.2134, 0.3018, 0.2264, 0.0595, 0.1988],\n",
      "          [0.3989, 0.1844, 0.1189, 0.0671, 0.2306],\n",
      "          [0.3124, 0.2064, 0.2895, 0.0829, 0.1088],\n",
      "          [0.4364, 0.2122, 0.2166, 0.0635, 0.0713]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2583,  0.2313, -0.5293, -0.0634,  0.3896],\n",
      "          [ 0.2386, -0.1359, -0.3510,  0.0341,  0.3231],\n",
      "          [-0.0729, -0.0683, -0.4205, -0.7477, -0.4398],\n",
      "          [ 0.5118, -0.3729,  0.2492, -0.1811, -0.3357],\n",
      "          [ 0.2578, -0.0520, -0.1069, -0.2264,  0.1857]],\n",
      "\n",
      "         [[ 0.4385,  0.1299,  0.1818, -0.0972, -0.0336],\n",
      "          [ 0.0216,  0.4732,  0.0982, -0.2134, -0.3538],\n",
      "          [-0.1963,  0.1867, -0.2683, -0.1418, -0.3585],\n",
      "          [-0.0426,  0.3200,  0.1011, -0.0937,  0.0782],\n",
      "          [-0.3055,  0.2034, -0.3973,  0.6927, -0.6065]],\n",
      "\n",
      "         [[ 0.4850, -0.7620, -0.2141, -0.5718, -0.3639],\n",
      "          [ 0.0811,  0.4589, -0.0035,  0.2216,  0.5031],\n",
      "          [ 0.9466,  0.0038,  0.1760, -0.3764,  0.0065],\n",
      "          [ 1.0802,  0.5183,  0.0074, -0.3770,  0.2748],\n",
      "          [ 0.1743, -0.0346,  0.0797, -0.3948,  0.1430]],\n",
      "\n",
      "         [[ 0.1433, -0.2369, -0.0193, -0.9192, -0.4363],\n",
      "          [ 0.1046, -0.4107, -0.0212, -0.5847, -0.6814],\n",
      "          [-0.7264, -0.4168, -0.6598, -0.2967, -0.3300],\n",
      "          [-0.2549, -0.5773, -0.5825,  0.2758, -0.5554],\n",
      "          [-0.0102,  0.1057,  0.2208, -0.4942, -0.4174]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2329, 0.2267, 0.1060, 0.1688, 0.2656],\n",
      "          [0.2412, 0.1659, 0.1338, 0.1966, 0.2625],\n",
      "          [0.2555, 0.2567, 0.1805, 0.1301, 0.1771],\n",
      "          [0.3215, 0.1327, 0.2472, 0.1608, 0.1378],\n",
      "          [0.2516, 0.1846, 0.1747, 0.1550, 0.2341]],\n",
      "\n",
      "         [[0.2690, 0.1976, 0.2081, 0.1575, 0.1678],\n",
      "          [0.1950, 0.3063, 0.2105, 0.1542, 0.1340],\n",
      "          [0.1886, 0.2765, 0.1755, 0.1991, 0.1603],\n",
      "          [0.1764, 0.2534, 0.2036, 0.1676, 0.1990],\n",
      "          [0.1423, 0.2367, 0.1298, 0.3860, 0.1053]],\n",
      "\n",
      "         [[0.3907, 0.1123, 0.1942, 0.1358, 0.1672],\n",
      "          [0.1652, 0.2410, 0.1518, 0.1901, 0.2519],\n",
      "          [0.3985, 0.1552, 0.1844, 0.1061, 0.1557],\n",
      "          [0.3858, 0.2199, 0.1320, 0.0899, 0.1724],\n",
      "          [0.2349, 0.1907, 0.2137, 0.1330, 0.2277]],\n",
      "\n",
      "         [[0.2908, 0.1988, 0.2471, 0.1005, 0.1629],\n",
      "          [0.2910, 0.1738, 0.2566, 0.1460, 0.1326],\n",
      "          [0.1549, 0.2111, 0.1656, 0.2381, 0.2303],\n",
      "          [0.2047, 0.1483, 0.1475, 0.3480, 0.1515],\n",
      "          [0.2144, 0.2407, 0.2701, 0.1321, 0.1427]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1252,  0.1056,  0.7120,  0.2084, -0.0757],\n",
      "          [ 0.0546,  0.6706,  0.2245,  0.2114, -0.2002],\n",
      "          [ 0.1086,  0.3631,  0.6661,  0.1005, -0.3832],\n",
      "          [ 0.6200,  0.3176,  0.5258,  0.4180,  0.5407],\n",
      "          [ 0.3475, -0.2503,  0.1908, -0.1145, -0.1336]],\n",
      "\n",
      "         [[-0.5043,  0.4358, -0.6276,  0.4465, -0.0327],\n",
      "          [-0.3628,  0.1844, -0.7072,  0.0420, -0.2563],\n",
      "          [ 0.1554, -0.1098, -0.3930,  0.1006, -0.4860],\n",
      "          [ 0.0675, -0.0730, -0.1559,  0.4676, -0.1102],\n",
      "          [-0.0213,  0.8168,  0.1165, -0.0399,  0.5227]],\n",
      "\n",
      "         [[ 0.7742,  0.3945,  0.5281, -0.5311, -0.2322],\n",
      "          [-0.1891, -0.1107,  0.4411,  0.0417, -0.1850],\n",
      "          [ 0.6137,  0.2705,  0.4170,  0.3395,  0.4089],\n",
      "          [ 0.0343, -0.2868,  0.6983,  0.1696, -0.1533],\n",
      "          [ 0.2214, -0.2781,  0.1561, -0.1392, -0.1090]],\n",
      "\n",
      "         [[ 0.0564,  0.3457, -0.2785, -0.0269,  0.3916],\n",
      "          [-0.0812, -0.0907,  0.1647,  0.4781,  0.4093],\n",
      "          [-0.0624,  0.1955, -0.1082,  0.2174,  0.7918],\n",
      "          [ 0.3933, -0.1703,  0.4213, -0.1330,  0.9530],\n",
      "          [ 0.1049,  0.2728,  0.0222,  0.3457,  0.3663]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1425, 0.1795, 0.3292, 0.1990, 0.1498],\n",
      "          [0.1672, 0.3095, 0.1981, 0.1956, 0.1296],\n",
      "          [0.1773, 0.2287, 0.3096, 0.1759, 0.1084],\n",
      "          [0.2278, 0.1684, 0.2073, 0.1861, 0.2104],\n",
      "          [0.2737, 0.1506, 0.2340, 0.1725, 0.1692]],\n",
      "\n",
      "         [[0.1158, 0.2965, 0.1024, 0.2997, 0.1856],\n",
      "          [0.1653, 0.2858, 0.1172, 0.2478, 0.1839],\n",
      "          [0.2619, 0.2009, 0.1513, 0.2479, 0.1379],\n",
      "          [0.2001, 0.1739, 0.1600, 0.2985, 0.1675],\n",
      "          [0.1396, 0.3227, 0.1602, 0.1370, 0.2405]],\n",
      "\n",
      "         [[0.3223, 0.2205, 0.2520, 0.0874, 0.1178],\n",
      "          [0.1607, 0.1738, 0.3018, 0.2024, 0.1613],\n",
      "          [0.2436, 0.1728, 0.2001, 0.1851, 0.1984],\n",
      "          [0.1773, 0.1286, 0.3443, 0.2029, 0.1469],\n",
      "          [0.2526, 0.1533, 0.2366, 0.1761, 0.1815]],\n",
      "\n",
      "         [[0.1862, 0.2487, 0.1332, 0.1714, 0.2604],\n",
      "          [0.1503, 0.1489, 0.1922, 0.2630, 0.2455],\n",
      "          [0.1445, 0.1870, 0.1380, 0.1911, 0.3394],\n",
      "          [0.2025, 0.1153, 0.2082, 0.1196, 0.3544],\n",
      "          [0.1762, 0.2084, 0.1622, 0.2242, 0.2289]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.5578,  0.5295,  0.4574,  0.6122],\n",
      "          [ 0.3906,  0.5554,  0.4492,  0.4800],\n",
      "          [ 0.6553,  0.7909,  0.6595,  0.7743],\n",
      "          [ 0.5662,  0.8263,  0.5983,  0.5879]],\n",
      "\n",
      "         [[ 0.4612,  0.3614,  0.4101,  0.2394],\n",
      "          [ 0.7913,  0.7506,  0.6004,  0.6961],\n",
      "          [ 0.6393,  0.5275,  0.5160,  0.5166],\n",
      "          [ 0.4389,  0.5413,  0.4658,  0.5695]],\n",
      "\n",
      "         [[-0.3903, -0.3024, -0.0543, -0.1345],\n",
      "          [-0.7397, -0.7414, -0.5065, -0.5750],\n",
      "          [-0.4604, -0.4887, -0.2121, -0.2404],\n",
      "          [-0.1548, -0.2100,  0.0166, -0.0528]],\n",
      "\n",
      "         [[ 0.8473,  1.2905,  0.7448,  0.6810],\n",
      "          [ 0.9582,  1.3905,  0.9611,  0.9782],\n",
      "          [ 0.6613,  1.0271,  0.7096,  0.5477],\n",
      "          [ 0.7452,  0.9453,  0.7345,  0.7235]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2543, 0.2472, 0.2300, 0.2685],\n",
      "          [0.2308, 0.2721, 0.2447, 0.2524],\n",
      "          [0.2339, 0.2678, 0.2349, 0.2634],\n",
      "          [0.2298, 0.2981, 0.2373, 0.2348]],\n",
      "\n",
      "         [[0.2735, 0.2475, 0.2599, 0.2191],\n",
      "          [0.2706, 0.2598, 0.2236, 0.2460],\n",
      "          [0.2730, 0.2441, 0.2413, 0.2415],\n",
      "          [0.2340, 0.2592, 0.2403, 0.2666]],\n",
      "\n",
      "         [[0.2091, 0.2283, 0.2926, 0.2700],\n",
      "          [0.2252, 0.2249, 0.2844, 0.2655],\n",
      "          [0.2222, 0.2160, 0.2849, 0.2769],\n",
      "          [0.2358, 0.2231, 0.2799, 0.2611]],\n",
      "\n",
      "         [[0.2322, 0.3616, 0.2096, 0.1966],\n",
      "          [0.2191, 0.3376, 0.2197, 0.2235],\n",
      "          [0.2281, 0.3289, 0.2394, 0.2036],\n",
      "          [0.2387, 0.2916, 0.2362, 0.2336]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0207,  0.0512,  0.2829,  0.2375,  0.2110],\n",
      "          [ 0.1446,  0.1200,  0.3106,  0.0770,  0.0762],\n",
      "          [ 0.0866,  0.2205,  0.2878,  0.1789,  0.1837],\n",
      "          [-0.1927, -0.0234,  0.2470,  0.0676, -0.1547]],\n",
      "\n",
      "         [[ 0.4056,  0.2373,  0.4115,  0.0510,  0.0952],\n",
      "          [ 0.2956,  0.1291,  0.0123,  0.0130, -0.1283],\n",
      "          [ 0.3978,  0.2773,  0.3482,  0.1322,  0.0568],\n",
      "          [ 0.3186,  0.1252,  0.2257,  0.1314, -0.2271]],\n",
      "\n",
      "         [[-0.0198, -0.7835, -0.1199,  0.0502,  0.0832],\n",
      "          [ 0.1122, -0.5608,  0.2942, -0.1122,  0.1188],\n",
      "          [ 0.3678, -0.2919,  0.2118, -0.0572,  0.3666],\n",
      "          [ 0.1036, -0.3799,  0.1919, -0.2133,  0.2741]],\n",
      "\n",
      "         [[-0.4610, -0.5590, -0.5366, -0.1535, -0.0822],\n",
      "          [-0.4527, -0.5460, -0.6950, -0.4377, -0.1799],\n",
      "          [-0.4570, -0.5971, -0.6738, -0.4282, -0.1867],\n",
      "          [-0.3114, -0.4704, -0.5146, -0.4729, -0.4378]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1729, 0.1783, 0.2248, 0.2148, 0.2092],\n",
      "          [0.1990, 0.1942, 0.2349, 0.1860, 0.1859],\n",
      "          [0.1797, 0.2054, 0.2198, 0.1971, 0.1980],\n",
      "          [0.1647, 0.1950, 0.2556, 0.2136, 0.1710]],\n",
      "\n",
      "         [[0.2333, 0.1972, 0.2347, 0.1637, 0.1711],\n",
      "          [0.2495, 0.2112, 0.1879, 0.1881, 0.1633],\n",
      "          [0.2317, 0.2054, 0.2205, 0.1777, 0.1648],\n",
      "          [0.2413, 0.1989, 0.2199, 0.2001, 0.1398]],\n",
      "\n",
      "         [[0.2197, 0.1024, 0.1988, 0.2356, 0.2435],\n",
      "          [0.2215, 0.1130, 0.2657, 0.1770, 0.2229],\n",
      "          [0.2484, 0.1284, 0.2125, 0.1624, 0.2481],\n",
      "          [0.2163, 0.1334, 0.2363, 0.1576, 0.2565]],\n",
      "\n",
      "         [[0.1769, 0.1603, 0.1640, 0.2405, 0.2583],\n",
      "          [0.1990, 0.1813, 0.1562, 0.2020, 0.2614],\n",
      "          [0.1995, 0.1734, 0.1606, 0.2053, 0.2613],\n",
      "          [0.2272, 0.1938, 0.1854, 0.1933, 0.2002]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1279,  0.0214,  0.1579, -0.0181],\n",
      "          [-0.3069, -0.3732, -0.2307, -0.4183],\n",
      "          [-0.2853, -0.3218, -0.0638, -0.3987],\n",
      "          [-0.3591, -0.3934, -0.2415, -0.4854]],\n",
      "\n",
      "         [[-0.1258, -0.3343, -0.3038, -0.3035],\n",
      "          [-0.0916, -0.2566, -0.3044, -0.1208],\n",
      "          [ 0.0211, -0.1940, -0.3620, -0.1069],\n",
      "          [ 0.1849,  0.0661, -0.0610,  0.0371]],\n",
      "\n",
      "         [[ 0.0563,  0.1958,  0.1123,  0.1558],\n",
      "          [ 0.1033,  0.2877,  0.2582,  0.1662],\n",
      "          [ 0.1749,  0.2272,  0.1484,  0.1562],\n",
      "          [ 0.2995,  0.3744,  0.4559,  0.3372]],\n",
      "\n",
      "         [[ 0.0926,  0.0171, -0.1239, -0.0510],\n",
      "          [ 0.0542, -0.0762, -0.0907, -0.0230],\n",
      "          [-0.0084, -0.0914, -0.0654, -0.0166],\n",
      "          [-0.2103, -0.2349, -0.2938, -0.0894]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2636, 0.2370, 0.2716, 0.2278],\n",
      "          [0.2558, 0.2394, 0.2760, 0.2288],\n",
      "          [0.2436, 0.2349, 0.3040, 0.2175],\n",
      "          [0.2517, 0.2432, 0.2831, 0.2219]],\n",
      "\n",
      "         [[0.2869, 0.2329, 0.2401, 0.2402],\n",
      "          [0.2757, 0.2337, 0.2228, 0.2677],\n",
      "          [0.2969, 0.2394, 0.2024, 0.2612],\n",
      "          [0.2831, 0.2514, 0.2214, 0.2442]],\n",
      "\n",
      "         [[0.2319, 0.2666, 0.2453, 0.2562],\n",
      "          [0.2255, 0.2712, 0.2633, 0.2401],\n",
      "          [0.2494, 0.2628, 0.2429, 0.2448],\n",
      "          [0.2333, 0.2515, 0.2728, 0.2423]],\n",
      "\n",
      "         [[0.2779, 0.2577, 0.2238, 0.2407],\n",
      "          [0.2726, 0.2393, 0.2358, 0.2523],\n",
      "          [0.2593, 0.2386, 0.2449, 0.2572],\n",
      "          [0.2485, 0.2425, 0.2286, 0.2804]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5003, -0.0935, -0.3303,  0.0266,  0.1164],\n",
      "          [-0.6275, -0.4751, -0.3689,  0.1590, -0.4024],\n",
      "          [-0.4135, -0.1753, -0.1213,  0.2414,  0.2961],\n",
      "          [-0.4491, -0.0586, -0.3174,  0.0953, -0.2045]],\n",
      "\n",
      "         [[-0.2755,  0.2257, -0.1353,  0.4306, -0.5790],\n",
      "          [-0.4641,  0.1105, -0.0731,  0.2060, -0.5674],\n",
      "          [-0.1895,  0.1704,  0.0658,  0.1031, -0.5866],\n",
      "          [-0.2247,  0.0693, -0.0442, -0.0494, -0.3016]],\n",
      "\n",
      "         [[-0.1343,  0.1107, -0.3728,  0.0229, -0.3078],\n",
      "          [-0.0151,  0.2247, -0.2686, -0.0231, -0.3008],\n",
      "          [ 0.1070,  0.2186, -0.2929,  0.1352, -0.3646],\n",
      "          [-0.1613,  0.2607, -0.2123,  0.1343, -0.4312]],\n",
      "\n",
      "         [[ 0.3228, -0.2741, -0.3990,  0.2416,  0.0049],\n",
      "          [ 0.1822, -0.2354, -0.3041,  0.5074,  0.0137],\n",
      "          [-0.1818, -0.4180, -0.4340,  0.5714, -0.0077],\n",
      "          [ 0.0546, -0.3728, -0.3302,  0.5446,  0.0891]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1382, 0.2076, 0.1639, 0.2341, 0.2561],\n",
      "          [0.1448, 0.1686, 0.1875, 0.3178, 0.1813],\n",
      "          [0.1322, 0.1677, 0.1770, 0.2544, 0.2687],\n",
      "          [0.1511, 0.2232, 0.1723, 0.2604, 0.1929]],\n",
      "\n",
      "         [[0.1523, 0.2514, 0.1752, 0.3086, 0.1124],\n",
      "          [0.1406, 0.2498, 0.2079, 0.2748, 0.1268],\n",
      "          [0.1743, 0.2498, 0.2250, 0.2336, 0.1172],\n",
      "          [0.1768, 0.2372, 0.2117, 0.2106, 0.1637]],\n",
      "\n",
      "         [[0.1970, 0.2517, 0.1552, 0.2305, 0.1656],\n",
      "          [0.2087, 0.2653, 0.1620, 0.2071, 0.1569],\n",
      "          [0.2252, 0.2518, 0.1509, 0.2316, 0.1405],\n",
      "          [0.1791, 0.2732, 0.1702, 0.2407, 0.1368]],\n",
      "\n",
      "         [[0.2713, 0.1493, 0.1318, 0.2501, 0.1974],\n",
      "          [0.2221, 0.1463, 0.1366, 0.3074, 0.1877],\n",
      "          [0.1701, 0.1343, 0.1321, 0.3612, 0.2024],\n",
      "          [0.2000, 0.1304, 0.1361, 0.3264, 0.2070]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 4])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5661, -0.3868, -0.4155, -0.4567],\n",
      "          [-0.5072, -0.4371, -0.4529, -0.5804],\n",
      "          [-0.4323, -0.3627, -0.4267, -0.5783],\n",
      "          [-0.8685, -0.6609, -0.6973, -1.0762]],\n",
      "\n",
      "         [[-0.0012, -0.2015, -0.2847, -0.5269],\n",
      "          [-0.4668, -0.5948, -0.7552, -0.8174],\n",
      "          [-0.4015, -0.5569, -0.6107, -0.8277],\n",
      "          [-0.1992, -0.4171, -0.4927, -0.6391]],\n",
      "\n",
      "         [[-0.0785, -0.1625, -0.1377, -0.1990],\n",
      "          [-0.0354, -0.1453, -0.1086, -0.1070],\n",
      "          [-0.1647, -0.3103, -0.2492, -0.1794],\n",
      "          [-0.0742, -0.2436, -0.2362, -0.1710]],\n",
      "\n",
      "         [[-0.4644, -0.2832, -0.1165, -0.6195],\n",
      "          [-0.4139, -0.2463, -0.1210, -0.4607],\n",
      "          [-0.4042, -0.3695, -0.2286, -0.6591],\n",
      "          [-0.3341, -0.1459, -0.0559, -0.3350]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2235, 0.2674, 0.2598, 0.2493],\n",
      "          [0.2464, 0.2643, 0.2602, 0.2290],\n",
      "          [0.2537, 0.2720, 0.2551, 0.2192],\n",
      "          [0.2364, 0.2910, 0.2805, 0.1921]],\n",
      "\n",
      "         [[0.3162, 0.2588, 0.2381, 0.1869],\n",
      "          [0.3000, 0.2639, 0.2248, 0.2113],\n",
      "          [0.3012, 0.2578, 0.2443, 0.1967],\n",
      "          [0.3131, 0.2518, 0.2335, 0.2017]],\n",
      "\n",
      "         [[0.2668, 0.2453, 0.2514, 0.2365],\n",
      "          [0.2662, 0.2385, 0.2474, 0.2478],\n",
      "          [0.2653, 0.2294, 0.2438, 0.2615],\n",
      "          [0.2776, 0.2343, 0.2361, 0.2520]],\n",
      "\n",
      "         [[0.2237, 0.2681, 0.3167, 0.1915],\n",
      "          [0.2234, 0.2641, 0.2994, 0.2132],\n",
      "          [0.2498, 0.2587, 0.2978, 0.1936],\n",
      "          [0.2209, 0.2666, 0.2918, 0.2207]]]], grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 4, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2520, -0.0125,  0.4686,  0.7208, -0.0541],\n",
      "          [ 0.1657, -0.0986,  0.4346,  0.3871, -0.0185],\n",
      "          [-0.0472, -0.2414,  0.5518,  0.6078, -0.3457],\n",
      "          [-0.0041, -0.1363,  0.4432,  0.7118, -0.0342]],\n",
      "\n",
      "         [[ 0.0035, -0.1783, -0.2235, -0.0650,  0.3793],\n",
      "          [ 0.0762, -0.2006, -0.0815, -0.0849,  0.2542],\n",
      "          [-0.0877, -0.1630, -0.0851, -0.1476,  0.3018],\n",
      "          [ 0.1364, -0.1772, -0.2128, -0.2635,  0.1994]],\n",
      "\n",
      "         [[ 0.0350, -0.1191, -0.3503, -0.3512, -0.2417],\n",
      "          [-0.1485, -0.1623, -0.3936,  0.0410, -0.0872],\n",
      "          [ 0.0013, -0.0561, -0.2978,  0.2480, -0.1154],\n",
      "          [-0.1383, -0.0653, -0.2947,  0.2131, -0.0058]],\n",
      "\n",
      "         [[-0.0210, -0.0569,  0.2156,  0.3953,  0.1723],\n",
      "          [ 0.1949,  0.0840,  0.4115,  0.5510,  0.2441],\n",
      "          [ 0.0121, -0.0510,  0.2700,  0.3748,  0.1322],\n",
      "          [ 0.2980,  0.1876,  0.4806,  0.5230,  0.3048]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1871, 0.1436, 0.2324, 0.2990, 0.1378],\n",
      "          [0.1939, 0.1489, 0.2538, 0.2420, 0.1613],\n",
      "          [0.1584, 0.1305, 0.2884, 0.3051, 0.1176],\n",
      "          [0.1549, 0.1357, 0.2423, 0.3169, 0.1503]],\n",
      "\n",
      "         [[0.1992, 0.1661, 0.1587, 0.1860, 0.2900],\n",
      "          [0.2147, 0.1628, 0.1834, 0.1827, 0.2565],\n",
      "          [0.1870, 0.1734, 0.1875, 0.1761, 0.2760],\n",
      "          [0.2397, 0.1752, 0.1691, 0.1607, 0.2553]],\n",
      "\n",
      "         [[0.2515, 0.2156, 0.1711, 0.1710, 0.1907],\n",
      "          [0.1984, 0.1957, 0.1553, 0.2398, 0.2109],\n",
      "          [0.2060, 0.1945, 0.1527, 0.2636, 0.1833],\n",
      "          [0.1820, 0.1958, 0.1557, 0.2587, 0.2078]],\n",
      "\n",
      "         [[0.1677, 0.1618, 0.2125, 0.2544, 0.2035],\n",
      "          [0.1781, 0.1594, 0.2212, 0.2543, 0.1871],\n",
      "          [0.1725, 0.1619, 0.2232, 0.2479, 0.1945],\n",
      "          [0.1867, 0.1672, 0.2242, 0.2339, 0.1880]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2395,  0.1404,  0.3210,  0.1951,  0.1329],\n",
      "          [ 0.0118, -0.0532,  0.3069, -0.5174,  0.1626],\n",
      "          [ 0.1766, -0.7818,  0.0590, -0.1086, -0.9620],\n",
      "          [-0.4970,  0.4021, -0.8975, -1.2484,  0.4275],\n",
      "          [ 0.2749, -0.5126, -0.1097, -0.5808,  0.1973]],\n",
      "\n",
      "         [[ 0.4573,  0.4029,  0.3288,  0.4772,  0.0271],\n",
      "          [ 0.3998,  1.0938, -0.5403, -1.2679, -0.4596],\n",
      "          [ 0.6733,  0.4310,  0.9766, -0.5359, -0.2255],\n",
      "          [ 0.2616,  1.0729, -0.2539, -0.2612,  0.6684],\n",
      "          [ 0.7999,  0.5974,  0.7491, -0.5931,  0.5989]],\n",
      "\n",
      "         [[ 0.3183, -0.2448, -0.0254, -0.6228,  0.1935],\n",
      "          [-0.5858, -0.6052, -0.5828,  0.5178, -0.1846],\n",
      "          [-0.2251,  0.1265, -0.1393, -0.4333, -0.7280],\n",
      "          [ 0.2426,  0.8439,  0.5287,  0.8523,  0.4910],\n",
      "          [ 0.5761,  0.4374,  0.4910, -0.3361, -0.0469]],\n",
      "\n",
      "         [[ 0.0809, -0.2571,  0.0125, -0.0872,  0.6678],\n",
      "          [-0.3736, -0.4222, -0.2660, -1.0008,  0.2519],\n",
      "          [ 0.3577,  0.2538, -0.6258, -0.6895,  0.2478],\n",
      "          [ 0.4344,  0.4937,  0.9413, -0.2732, -0.5681],\n",
      "          [ 0.7424,  1.0873,  0.9315,  0.0282,  0.0882]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2063, 0.1869, 0.2239, 0.1974, 0.1855],\n",
      "          [0.1987, 0.1862, 0.2669, 0.1171, 0.2311],\n",
      "          [0.2990, 0.1147, 0.2658, 0.2248, 0.0958],\n",
      "          [0.1404, 0.3452, 0.0941, 0.0663, 0.3540],\n",
      "          [0.2869, 0.1305, 0.1953, 0.1219, 0.2654]],\n",
      "\n",
      "         [[0.2224, 0.2106, 0.1956, 0.2268, 0.1446],\n",
      "          [0.2497, 0.4999, 0.0975, 0.0471, 0.1057],\n",
      "          [0.2601, 0.2041, 0.3522, 0.0776, 0.1059],\n",
      "          [0.1683, 0.3787, 0.1005, 0.0998, 0.2527],\n",
      "          [0.2609, 0.2131, 0.2479, 0.0648, 0.2134]],\n",
      "\n",
      "         [[0.2816, 0.1603, 0.1997, 0.1099, 0.2485],\n",
      "          [0.1335, 0.1309, 0.1339, 0.4024, 0.1994],\n",
      "          [0.2029, 0.2884, 0.2211, 0.1648, 0.1227],\n",
      "          [0.1374, 0.2507, 0.1829, 0.2528, 0.1761],\n",
      "          [0.2683, 0.2336, 0.2464, 0.1078, 0.1439]],\n",
      "\n",
      "         [[0.1890, 0.1348, 0.1765, 0.1598, 0.3399],\n",
      "          [0.1828, 0.1742, 0.2036, 0.0976, 0.3418],\n",
      "          [0.2839, 0.2559, 0.1062, 0.0996, 0.2544],\n",
      "          [0.2183, 0.2316, 0.3624, 0.1076, 0.0801],\n",
      "          [0.2160, 0.3050, 0.2610, 0.1058, 0.1123]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.3475,  0.0994, -0.4648,  0.1028,  0.2478],\n",
      "          [-0.0183, -0.0477, -0.1713,  0.5416,  0.0066],\n",
      "          [-0.0523, -0.1331, -0.2703, -0.8440, -0.4722],\n",
      "          [ 0.5174, -0.2056,  0.3190, -0.2788, -0.3403],\n",
      "          [ 0.1679, -0.0380, -0.2151, -0.1576,  0.1390]],\n",
      "\n",
      "         [[ 0.3052,  0.2309,  0.3256,  0.0040,  0.0038],\n",
      "          [-0.3571,  0.6437,  0.0746,  0.1682, -0.4267],\n",
      "          [-0.2486,  0.4489, -0.3160, -0.1348, -0.2052],\n",
      "          [-0.0913,  0.6526,  0.0840,  0.1031,  0.2421],\n",
      "          [-0.3368, -0.1025, -0.5434,  0.4922, -0.6041]],\n",
      "\n",
      "         [[ 0.3288, -0.3313, -0.1318, -0.3611, -0.1035],\n",
      "          [-0.0890,  0.5222,  0.1178,  0.2538,  0.7173],\n",
      "          [ 0.6276, -0.0307, -0.0702, -0.5683, -0.0593],\n",
      "          [ 0.5921,  0.4173, -0.3991, -0.2854,  0.1617],\n",
      "          [ 0.3083,  0.4323,  0.2397, -0.4344,  0.1569]],\n",
      "\n",
      "         [[ 0.3521,  0.1618,  0.2178, -0.6847, -0.6201],\n",
      "          [ 0.0863, -0.0999,  0.1451, -0.0762, -0.6385],\n",
      "          [-0.3196, -0.1210, -0.5272,  0.0189, -0.1441],\n",
      "          [-0.3634, -0.5838, -0.4535,  0.1820, -0.4558],\n",
      "          [-0.0370, -0.3611,  0.1318, -0.2449, -0.5423]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2556, 0.1995, 0.1135, 0.2001, 0.2314],\n",
      "          [0.1784, 0.1732, 0.1531, 0.3123, 0.1829],\n",
      "          [0.2607, 0.2404, 0.2096, 0.1181, 0.1713],\n",
      "          [0.3144, 0.1526, 0.2578, 0.1418, 0.1334],\n",
      "          [0.2387, 0.1943, 0.1627, 0.1724, 0.2319]],\n",
      "\n",
      "         [[0.2258, 0.2096, 0.2305, 0.1671, 0.1670],\n",
      "          [0.1268, 0.3450, 0.1953, 0.2145, 0.1183],\n",
      "          [0.1637, 0.3288, 0.1530, 0.1834, 0.1710],\n",
      "          [0.1448, 0.3047, 0.1725, 0.1759, 0.2021],\n",
      "          [0.1630, 0.2061, 0.1326, 0.3735, 0.1248]],\n",
      "\n",
      "         [[0.3032, 0.1567, 0.1913, 0.1521, 0.1968],\n",
      "          [0.1295, 0.2386, 0.1593, 0.1825, 0.2901],\n",
      "          [0.3545, 0.1835, 0.1764, 0.1072, 0.1784],\n",
      "          [0.3052, 0.2562, 0.1133, 0.1269, 0.1984],\n",
      "          [0.2272, 0.2572, 0.2122, 0.1081, 0.1953]],\n",
      "\n",
      "         [[0.2912, 0.2408, 0.2546, 0.1033, 0.1101],\n",
      "          [0.2367, 0.1965, 0.2510, 0.2012, 0.1147],\n",
      "          [0.1777, 0.2168, 0.1444, 0.2493, 0.2118],\n",
      "          [0.1868, 0.1499, 0.1707, 0.3223, 0.1703],\n",
      "          [0.2313, 0.1673, 0.2739, 0.1879, 0.1396]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1021, -0.2332,  0.6299,  0.2263,  0.0619],\n",
      "          [-0.0517,  0.5228,  0.0652, -0.2262, -0.0119],\n",
      "          [ 0.1776,  0.2693,  0.5685, -0.0616, -0.2591],\n",
      "          [ 0.2788,  0.3829,  0.3617,  0.3597,  0.1862],\n",
      "          [ 0.3236, -0.3062,  0.1389, -0.1866, -0.0488]],\n",
      "\n",
      "         [[-0.5248,  0.3693, -0.6615,  0.4349, -0.0823],\n",
      "          [-0.4120,  0.3984, -0.8165,  0.0657, -0.0575],\n",
      "          [ 0.2362,  0.1537, -0.2189,  0.0038, -0.5390],\n",
      "          [-0.1582, -0.2202, -0.3743,  0.4602, -0.4225],\n",
      "          [-0.0694,  0.6304,  0.2031,  0.4489,  0.6304]],\n",
      "\n",
      "         [[ 0.7373,  0.5109,  0.7700, -0.0688, -0.2485],\n",
      "          [-0.2786, -0.3513,  0.0552,  0.2527, -0.4027],\n",
      "          [ 0.5061,  0.1780, -0.1129,  0.4132,  0.4234],\n",
      "          [-0.1004, -0.0685,  0.0805,  0.2880, -0.1615],\n",
      "          [ 0.1497, -0.1040,  0.1389,  0.1127, -0.5986]],\n",
      "\n",
      "         [[ 0.0611,  0.0034, -0.2116,  0.1761,  0.3232],\n",
      "          [ 0.1734, -0.4805,  0.2738,  0.1564,  0.3930],\n",
      "          [ 0.1107,  0.4320, -0.0807,  0.2168,  0.6740],\n",
      "          [ 0.3962, -0.0476,  0.4065, -0.4097,  0.6091],\n",
      "          [ 0.2040,  0.1328, -0.1264,  0.0853,  0.2414]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1533, 0.1345, 0.3187, 0.2129, 0.1806],\n",
      "          [0.1730, 0.3073, 0.1944, 0.1453, 0.1800],\n",
      "          [0.1997, 0.2189, 0.2952, 0.1572, 0.1290],\n",
      "          [0.1926, 0.2137, 0.2092, 0.2088, 0.1756],\n",
      "          [0.2737, 0.1458, 0.2275, 0.1643, 0.1886]],\n",
      "\n",
      "         [[0.1179, 0.2882, 0.1028, 0.3077, 0.1835],\n",
      "          [0.1438, 0.3234, 0.0960, 0.2319, 0.2050],\n",
      "          [0.2626, 0.2418, 0.1666, 0.2081, 0.1209],\n",
      "          [0.1862, 0.1750, 0.1500, 0.3457, 0.1430],\n",
      "          [0.1247, 0.2511, 0.1638, 0.2094, 0.2511]],\n",
      "\n",
      "         [[0.2739, 0.2184, 0.2831, 0.1223, 0.1022],\n",
      "          [0.1692, 0.1573, 0.2362, 0.2878, 0.1494],\n",
      "          [0.2445, 0.1761, 0.1316, 0.2228, 0.2251],\n",
      "          [0.1771, 0.1829, 0.2122, 0.2612, 0.1666],\n",
      "          [0.2380, 0.1846, 0.2354, 0.2293, 0.1126]],\n",
      "\n",
      "         [[0.1951, 0.1841, 0.1485, 0.2188, 0.2535],\n",
      "          [0.2060, 0.1071, 0.2278, 0.2025, 0.2566],\n",
      "          [0.1647, 0.2271, 0.1360, 0.1831, 0.2892],\n",
      "          [0.2306, 0.1480, 0.2330, 0.1030, 0.2854],\n",
      "          [0.2185, 0.2035, 0.1570, 0.1941, 0.2269]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.2717,  0.2667,  0.0747, -0.1308,  0.1876, -0.3332, -0.4859,\n",
      "           -0.3111],\n",
      "          [ 0.3738,  0.5731,  0.3639,  0.2166,  0.5316,  0.0358, -0.3046,\n",
      "           -0.0678],\n",
      "          [ 0.4348,  0.4668,  0.3752,  0.2423,  0.6285,  0.0411, -0.2185,\n",
      "           -0.0200],\n",
      "          [ 1.0092,  0.9973,  0.7178,  0.6327,  1.0435,  0.5733,  0.1450,\n",
      "            0.3959],\n",
      "          [ 0.8820,  0.7571,  0.5898,  0.3676,  0.6868,  0.3499,  0.1840,\n",
      "            0.3220],\n",
      "          [ 0.6871,  0.7945,  0.7169,  0.4133,  0.7802,  0.4136,  0.1236,\n",
      "            0.3131],\n",
      "          [ 0.9839,  0.8440,  0.6686,  0.4040,  0.7687,  0.4040,  0.1334,\n",
      "            0.4185],\n",
      "          [ 0.8436,  0.7357,  0.6947,  0.5526,  0.6512,  0.4535,  0.3369,\n",
      "            0.5405]],\n",
      "\n",
      "         [[ 0.3766,  0.5708,  0.4134,  0.0633,  0.1745,  0.4845,  0.7650,\n",
      "            0.4715],\n",
      "          [ 0.4020,  0.6492,  0.4946,  0.3248,  0.4715,  0.6392,  0.9071,\n",
      "            0.8155],\n",
      "          [ 0.0588,  0.3056,  0.2305, -0.1256,  0.1319,  0.2475,  0.4564,\n",
      "            0.4287],\n",
      "          [ 0.1230,  0.3013,  0.2095, -0.0548,  0.1100,  0.2196,  0.5778,\n",
      "            0.4342],\n",
      "          [ 0.3728,  0.6940,  0.5712,  0.3659,  0.4963,  0.7837,  0.8642,\n",
      "            0.8670],\n",
      "          [ 0.3608,  0.6276,  0.4896,  0.1207,  0.3017,  0.4309,  0.6378,\n",
      "            0.6432],\n",
      "          [ 0.2365,  0.6303,  0.4545,  0.0942,  0.3229,  0.5365,  0.5637,\n",
      "            0.7696],\n",
      "          [ 0.5811,  0.8431,  0.7837,  0.4562,  0.6371,  0.7682,  0.7795,\n",
      "            1.0319]],\n",
      "\n",
      "         [[-0.4315, -0.5830, -0.1020, -0.2600, -0.1469, -0.3177, -0.2402,\n",
      "           -0.1256],\n",
      "          [-0.2914, -0.5058, -0.1892, -0.3392, -0.1855, -0.3329, -0.3387,\n",
      "           -0.2628],\n",
      "          [-0.4950, -0.5731, -0.4559, -0.3754, -0.3758, -0.4968, -0.6901,\n",
      "           -0.4568],\n",
      "          [-0.9083, -0.9481, -0.6588, -0.7663, -0.6761, -0.9012, -1.1361,\n",
      "           -0.7897],\n",
      "          [-0.2933, -0.4069, -0.1466, -0.1836, -0.1359, -0.2570, -0.6334,\n",
      "           -0.2841],\n",
      "          [-0.3750, -0.4312, -0.2402, -0.1562, -0.1667, -0.4534, -0.6521,\n",
      "           -0.3779],\n",
      "          [-0.5504, -0.5996, -0.1644, -0.4005, -0.3206, -0.6384, -0.6447,\n",
      "           -0.2773],\n",
      "          [ 0.1947,  0.2456,  0.4563,  0.2989,  0.2839,  0.3190,  0.0889,\n",
      "            0.1427]],\n",
      "\n",
      "         [[ 0.5048,  0.6486,  0.4862,  0.6562,  0.6301,  0.4446,  0.7402,\n",
      "            0.5567],\n",
      "          [ 0.7566,  0.7518,  0.6126,  0.8801,  0.7028,  0.5887,  1.0688,\n",
      "            0.6597],\n",
      "          [ 0.6091,  0.7384,  0.6638,  0.8446,  0.7047,  0.5316,  1.0028,\n",
      "            0.6521],\n",
      "          [ 1.1298,  1.0852,  1.1421,  1.2679,  1.1127,  1.0770,  1.4959,\n",
      "            1.0608],\n",
      "          [ 0.8233,  0.9150,  0.8579,  0.9654,  0.8983,  0.7651,  1.1671,\n",
      "            0.7666],\n",
      "          [ 1.0617,  1.1486,  0.9249,  1.2305,  1.0168,  0.8499,  1.1313,\n",
      "            0.8425],\n",
      "          [ 0.7706,  0.7667,  0.6733,  0.8383,  0.6704,  0.4369,  0.7656,\n",
      "            0.5371],\n",
      "          [ 1.1202,  1.1907,  1.0886,  1.2705,  1.2700,  1.0920,  1.3741,\n",
      "            1.0530]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1673, 0.1665, 0.1374, 0.1119, 0.1538, 0.0914, 0.0784, 0.0934],\n",
      "          [0.1408, 0.1719, 0.1395, 0.1204, 0.1649, 0.1005, 0.0715, 0.0906],\n",
      "          [0.1461, 0.1509, 0.1377, 0.1205, 0.1774, 0.0986, 0.0760, 0.0927],\n",
      "          [0.1648, 0.1629, 0.1232, 0.1131, 0.1706, 0.1066, 0.0695, 0.0893],\n",
      "          [0.1753, 0.1547, 0.1308, 0.1048, 0.1442, 0.1029, 0.0872, 0.1001],\n",
      "          [0.1425, 0.1586, 0.1468, 0.1083, 0.1564, 0.1084, 0.0811, 0.0980],\n",
      "          [0.1811, 0.1575, 0.1322, 0.1014, 0.1461, 0.1014, 0.0774, 0.1029],\n",
      "          [0.1575, 0.1414, 0.1357, 0.1177, 0.1299, 0.1066, 0.0949, 0.1163]],\n",
      "\n",
      "         [[0.1178, 0.1431, 0.1222, 0.0861, 0.0963, 0.1312, 0.1737, 0.1295],\n",
      "          [0.1019, 0.1305, 0.1118, 0.0943, 0.1092, 0.1292, 0.1689, 0.1541],\n",
      "          [0.1051, 0.1345, 0.1247, 0.0874, 0.1130, 0.1269, 0.1564, 0.1521],\n",
      "          [0.1093, 0.1306, 0.1191, 0.0915, 0.1079, 0.1203, 0.1722, 0.1492],\n",
      "          [0.0952, 0.1313, 0.1161, 0.0945, 0.1077, 0.1436, 0.1556, 0.1560],\n",
      "          [0.1125, 0.1469, 0.1279, 0.0885, 0.1060, 0.1206, 0.1484, 0.1492],\n",
      "          [0.0988, 0.1464, 0.1228, 0.0857, 0.1077, 0.1333, 0.1370, 0.1683],\n",
      "          [0.1057, 0.1374, 0.1295, 0.0933, 0.1118, 0.1275, 0.1289, 0.1659]],\n",
      "\n",
      "         [[0.1058, 0.0909, 0.1470, 0.1255, 0.1406, 0.1185, 0.1281, 0.1436],\n",
      "          [0.1262, 0.1019, 0.1398, 0.1203, 0.1403, 0.1211, 0.1204, 0.1299],\n",
      "          [0.1238, 0.1145, 0.1287, 0.1395, 0.1395, 0.1236, 0.1019, 0.1286],\n",
      "          [0.1165, 0.1119, 0.1494, 0.1342, 0.1469, 0.1173, 0.0927, 0.1311],\n",
      "          [0.1235, 0.1103, 0.1431, 0.1379, 0.1446, 0.1281, 0.0879, 0.1247],\n",
      "          [0.1213, 0.1146, 0.1388, 0.1509, 0.1494, 0.1121, 0.0919, 0.1209],\n",
      "          [0.1113, 0.1060, 0.1638, 0.1293, 0.1401, 0.1019, 0.1013, 0.1463],\n",
      "          [0.1172, 0.1233, 0.1522, 0.1300, 0.1281, 0.1327, 0.1054, 0.1112]],\n",
      "\n",
      "         [[0.1150, 0.1328, 0.1129, 0.1338, 0.1304, 0.1083, 0.1456, 0.1212],\n",
      "          [0.1241, 0.1235, 0.1074, 0.1404, 0.1176, 0.1049, 0.1695, 0.1126],\n",
      "          [0.1110, 0.1263, 0.1172, 0.1404, 0.1221, 0.1027, 0.1645, 0.1158],\n",
      "          [0.1187, 0.1135, 0.1202, 0.1363, 0.1167, 0.1126, 0.1712, 0.1108],\n",
      "          [0.1155, 0.1266, 0.1195, 0.1331, 0.1245, 0.1089, 0.1628, 0.1091],\n",
      "          [0.1284, 0.1401, 0.1120, 0.1520, 0.1228, 0.1039, 0.1377, 0.1031],\n",
      "          [0.1355, 0.1350, 0.1229, 0.1450, 0.1226, 0.0970, 0.1348, 0.1073],\n",
      "          [0.1168, 0.1253, 0.1132, 0.1357, 0.1357, 0.1135, 0.1506, 0.1092]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.0240,  0.0652, -0.0101,  0.2238,  0.0824],\n",
      "          [ 0.0097, -0.0382,  0.2362,  0.3565, -0.1137],\n",
      "          [ 0.0634, -0.0861, -0.1805, -0.0551, -0.1397],\n",
      "          [-0.2899, -0.3446,  0.0832,  0.3734, -0.2247],\n",
      "          [-0.2888, -0.3526,  0.2108,  0.2746, -0.1641],\n",
      "          [-0.2960, -0.2088,  0.0312,  0.1300, -0.1586],\n",
      "          [-0.3192, -0.4092,  0.0548,  0.0101, -0.3592],\n",
      "          [-0.1825, -0.2962,  0.0146, -0.0440, -0.2681]],\n",
      "\n",
      "         [[ 0.4068,  0.3591,  0.0363,  0.0844, -0.0333],\n",
      "          [ 0.2955,  0.2239, -0.0746,  0.0777, -0.1136],\n",
      "          [ 0.3673,  0.3271, -0.0582,  0.2942, -0.0337],\n",
      "          [ 0.3626,  0.1619, -0.0793,  0.3268, -0.3222],\n",
      "          [ 0.3771,  0.1119, -0.1216,  0.0171, -0.2742],\n",
      "          [ 0.3291,  0.1777, -0.0750,  0.1259, -0.4279],\n",
      "          [ 0.0502,  0.2025,  0.0769,  0.0347, -0.6117],\n",
      "          [ 0.2095,  0.3387, -0.0253, -0.0856, -0.4448]],\n",
      "\n",
      "         [[ 0.4332, -0.6178, -0.0254, -0.3222,  0.2536],\n",
      "          [ 0.1851, -0.6081,  0.0638, -0.3740,  0.1217],\n",
      "          [ 0.1577, -0.4120, -0.0645, -0.0550,  0.2888],\n",
      "          [ 0.1464, -0.5091,  0.0730, -0.2354,  0.2329],\n",
      "          [ 0.0114, -0.4690, -0.2192,  0.0094,  0.0649],\n",
      "          [ 0.1053, -0.4619, -0.2328, -0.0505,  0.1608],\n",
      "          [-0.0013, -0.6643, -0.2166, -0.2983,  0.0816],\n",
      "          [ 0.0029, -0.3409, -0.0882,  0.2474,  0.3068]],\n",
      "\n",
      "         [[-0.3424, -0.2994, -0.4166, -0.1716, -0.0596],\n",
      "          [-0.4185, -0.3327, -0.7196, -0.5375, -0.3183],\n",
      "          [-0.4014, -0.3561, -0.7610, -0.5168,  0.0334],\n",
      "          [-0.5623, -0.3950, -0.6319, -0.3395, -0.3988],\n",
      "          [-0.3565, -0.4570, -0.7015, -0.3844, -0.3161],\n",
      "          [-0.4501, -0.4360, -0.6695, -0.4082, -0.3289],\n",
      "          [-0.2903, -0.1945, -0.4969, -0.5279, -0.1722],\n",
      "          [-0.2232, -0.2280, -0.3317, -0.2328,  0.0134]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1890, 0.1970, 0.1827, 0.2309, 0.2004],\n",
      "          [0.1816, 0.1731, 0.2278, 0.2569, 0.1605],\n",
      "          [0.2299, 0.1980, 0.1802, 0.2042, 0.1877],\n",
      "          [0.1561, 0.1478, 0.2266, 0.3030, 0.1666],\n",
      "          [0.1544, 0.1449, 0.2545, 0.2713, 0.1749],\n",
      "          [0.1624, 0.1772, 0.2253, 0.2487, 0.1864],\n",
      "          [0.1749, 0.1598, 0.2542, 0.2431, 0.1680],\n",
      "          [0.1932, 0.1724, 0.2352, 0.2219, 0.1773]],\n",
      "\n",
      "         [[0.2492, 0.2376, 0.1721, 0.1806, 0.1605],\n",
      "          [0.2445, 0.2276, 0.1689, 0.1966, 0.1624],\n",
      "          [0.2373, 0.2280, 0.1551, 0.2206, 0.1589],\n",
      "          [0.2544, 0.2082, 0.1636, 0.2455, 0.1283],\n",
      "          [0.2783, 0.2135, 0.1690, 0.1942, 0.1451],\n",
      "          [0.2623, 0.2255, 0.1751, 0.2141, 0.1230],\n",
      "          [0.2131, 0.2482, 0.2189, 0.2098, 0.1099],\n",
      "          [0.2385, 0.2714, 0.1886, 0.1776, 0.1240]],\n",
      "\n",
      "         [[0.3042, 0.1063, 0.1923, 0.1429, 0.2542],\n",
      "          [0.2598, 0.1176, 0.2302, 0.1486, 0.2439],\n",
      "          [0.2317, 0.1311, 0.1856, 0.1874, 0.2642],\n",
      "          [0.2369, 0.1230, 0.2201, 0.1617, 0.2583],\n",
      "          [0.2239, 0.1385, 0.1778, 0.2235, 0.2362],\n",
      "          [0.2385, 0.1352, 0.1701, 0.2041, 0.2521],\n",
      "          [0.2409, 0.1241, 0.1942, 0.1790, 0.2617],\n",
      "          [0.1903, 0.1350, 0.1738, 0.2430, 0.2579]],\n",
      "\n",
      "         [[0.1823, 0.1903, 0.1693, 0.2163, 0.2419],\n",
      "          [0.2073, 0.2259, 0.1534, 0.1841, 0.2292],\n",
      "          [0.1930, 0.2020, 0.1347, 0.1720, 0.2982],\n",
      "          [0.1804, 0.2133, 0.1683, 0.2255, 0.2125],\n",
      "          [0.2161, 0.1955, 0.1531, 0.2102, 0.2251],\n",
      "          [0.2004, 0.2033, 0.1610, 0.2090, 0.2263],\n",
      "          [0.2071, 0.2280, 0.1685, 0.1633, 0.2331],\n",
      "          [0.1942, 0.1933, 0.1742, 0.1923, 0.2460]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3221, -0.2315, -0.2357, -0.2302, -0.2671, -0.2131, -0.3764,\n",
      "           -0.3387],\n",
      "          [-0.2258, -0.1720, -0.1949, -0.2289, -0.3241, -0.2184, -0.3516,\n",
      "           -0.3744],\n",
      "          [-0.5219, -0.4114, -0.4368, -0.4494, -0.5702, -0.4542, -0.5023,\n",
      "           -0.5993],\n",
      "          [-0.2773, -0.2599, -0.2110, -0.2066, -0.3232, -0.2324, -0.4204,\n",
      "           -0.4639],\n",
      "          [-0.4058, -0.3980, -0.3195, -0.2363, -0.4512, -0.3512, -0.4662,\n",
      "           -0.5287],\n",
      "          [-0.2767, -0.1664, -0.1161, -0.1308, -0.2717, -0.1747, -0.2587,\n",
      "           -0.3259],\n",
      "          [-0.3795, -0.3896, -0.4321, -0.4409, -0.6685, -0.4702, -0.4852,\n",
      "           -0.4792],\n",
      "          [-0.5596, -0.5210, -0.4664, -0.5050, -0.6997, -0.5303, -0.5785,\n",
      "           -0.5861]],\n",
      "\n",
      "         [[ 0.0878, -0.0259, -0.0405,  0.1664,  0.1010,  0.1176,  0.2231,\n",
      "            0.0092],\n",
      "          [-0.1971, -0.3042, -0.2474, -0.0922, -0.1960, -0.1176, -0.1466,\n",
      "           -0.1976],\n",
      "          [-0.1435, -0.1437, -0.0627,  0.0386, -0.0767,  0.0076, -0.0762,\n",
      "           -0.0509],\n",
      "          [-0.0828, -0.0599, -0.0266,  0.0701, -0.0412,  0.1119,  0.0515,\n",
      "            0.1075],\n",
      "          [-0.2399, -0.3193, -0.2354, -0.0873, -0.2120, -0.0297, -0.1259,\n",
      "           -0.0966],\n",
      "          [-0.1988, -0.2901, -0.1979, -0.0463, -0.1484, -0.0190, -0.1244,\n",
      "           -0.1243],\n",
      "          [-0.3233, -0.3596, -0.2267, -0.0617, -0.1653, -0.0082, -0.1280,\n",
      "           -0.1132],\n",
      "          [-0.3143, -0.3267, -0.2987, -0.1164, -0.2386, -0.1726, -0.2701,\n",
      "           -0.2196]],\n",
      "\n",
      "         [[ 0.3411,  0.2531,  0.0607,  0.0440,  0.1116,  0.0039,  0.0459,\n",
      "            0.1446],\n",
      "          [ 0.3671,  0.2448,  0.1449, -0.0340,  0.1299,  0.0038,  0.0436,\n",
      "            0.2013],\n",
      "          [ 0.4609,  0.3868,  0.1244,  0.1464,  0.2259,  0.1337,  0.0773,\n",
      "            0.1594],\n",
      "          [ 0.5644,  0.3743,  0.2690,  0.2118,  0.2901,  0.2576,  0.1461,\n",
      "            0.3866],\n",
      "          [ 0.3424,  0.2508,  0.1178,  0.0731,  0.1737,  0.1631, -0.0043,\n",
      "            0.1989],\n",
      "          [ 0.4215,  0.3311,  0.1819,  0.1270,  0.2236,  0.1443,  0.0763,\n",
      "            0.2436],\n",
      "          [ 0.2915,  0.3097,  0.1762,  0.1917,  0.3014,  0.0786,  0.1205,\n",
      "            0.2024],\n",
      "          [ 0.2319,  0.2058,  0.1926,  0.1545,  0.2731,  0.0950,  0.1289,\n",
      "            0.2907]],\n",
      "\n",
      "         [[ 0.1179,  0.0416, -0.0239, -0.2356, -0.1243,  0.0706, -0.0051,\n",
      "            0.2355],\n",
      "          [-0.0367, -0.0572, -0.1153, -0.2430, -0.2277,  0.0763, -0.1209,\n",
      "            0.1615],\n",
      "          [-0.0481, -0.0727, -0.1373, -0.2496, -0.2375,  0.0631, -0.1136,\n",
      "            0.1123],\n",
      "          [ 0.1098,  0.0171, -0.0840, -0.0633, -0.1888,  0.1735,  0.0450,\n",
      "            0.1939],\n",
      "          [ 0.1986,  0.0670,  0.0617, -0.0135, -0.0507,  0.3012,  0.1649,\n",
      "            0.2987],\n",
      "          [-0.0804, -0.1242, -0.1396, -0.2997, -0.3057,  0.0071, -0.1104,\n",
      "            0.0854],\n",
      "          [-0.3181, -0.3353, -0.3588, -0.4724, -0.5374, -0.2242, -0.3747,\n",
      "           -0.0981],\n",
      "          [-0.0614, -0.1735, -0.1840, -0.2204, -0.2258,  0.0610, -0.0390,\n",
      "            0.0998]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1193, 0.1306, 0.1300, 0.1308, 0.1260, 0.1330, 0.1130, 0.1173],\n",
      "          [0.1292, 0.1363, 0.1332, 0.1288, 0.1171, 0.1301, 0.1139, 0.1113],\n",
      "          [0.1212, 0.1354, 0.1320, 0.1303, 0.1155, 0.1297, 0.1236, 0.1122],\n",
      "          [0.1273, 0.1295, 0.1360, 0.1366, 0.1216, 0.1331, 0.1103, 0.1056],\n",
      "          [0.1232, 0.1241, 0.1342, 0.1459, 0.1177, 0.1301, 0.1159, 0.1089],\n",
      "          [0.1172, 0.1309, 0.1376, 0.1356, 0.1178, 0.1298, 0.1194, 0.1116],\n",
      "          [0.1361, 0.1347, 0.1291, 0.1280, 0.1020, 0.1243, 0.1225, 0.1232],\n",
      "          [0.1243, 0.1292, 0.1364, 0.1312, 0.1080, 0.1280, 0.1219, 0.1210]],\n",
      "\n",
      "         [[0.1255, 0.1120, 0.1104, 0.1358, 0.1272, 0.1293, 0.1437, 0.1160],\n",
      "          [0.1235, 0.1110, 0.1175, 0.1372, 0.1237, 0.1338, 0.1299, 0.1235],\n",
      "          [0.1152, 0.1152, 0.1249, 0.1382, 0.1231, 0.1340, 0.1232, 0.1264],\n",
      "          [0.1129, 0.1155, 0.1194, 0.1316, 0.1177, 0.1372, 0.1291, 0.1366],\n",
      "          [0.1159, 0.1070, 0.1164, 0.1350, 0.1191, 0.1430, 0.1299, 0.1337],\n",
      "          [0.1179, 0.1076, 0.1180, 0.1373, 0.1240, 0.1411, 0.1270, 0.1270],\n",
      "          [0.1069, 0.1031, 0.1177, 0.1388, 0.1252, 0.1465, 0.1299, 0.1319],\n",
      "          [0.1163, 0.1149, 0.1181, 0.1418, 0.1255, 0.1340, 0.1216, 0.1279]],\n",
      "\n",
      "         [[0.1541, 0.1411, 0.1164, 0.1145, 0.1225, 0.1100, 0.1147, 0.1266],\n",
      "          [0.1560, 0.1380, 0.1249, 0.1045, 0.1231, 0.1085, 0.1129, 0.1322],\n",
      "          [0.1586, 0.1473, 0.1133, 0.1158, 0.1254, 0.1143, 0.1081, 0.1173],\n",
      "          [0.1596, 0.1320, 0.1188, 0.1122, 0.1213, 0.1174, 0.1050, 0.1336],\n",
      "          [0.1486, 0.1356, 0.1187, 0.1135, 0.1255, 0.1242, 0.1051, 0.1287],\n",
      "          [0.1522, 0.1391, 0.1198, 0.1134, 0.1249, 0.1154, 0.1078, 0.1274],\n",
      "          [0.1353, 0.1378, 0.1206, 0.1225, 0.1367, 0.1094, 0.1140, 0.1238],\n",
      "          [0.1292, 0.1259, 0.1243, 0.1196, 0.1347, 0.1127, 0.1166, 0.1371]],\n",
      "\n",
      "         [[0.1380, 0.1279, 0.1198, 0.0969, 0.1083, 0.1317, 0.1221, 0.1553],\n",
      "          [0.1282, 0.1256, 0.1185, 0.1043, 0.1059, 0.1435, 0.1178, 0.1563],\n",
      "          [0.1288, 0.1257, 0.1178, 0.1053, 0.1066, 0.1440, 0.1206, 0.1512],\n",
      "          [0.1350, 0.1230, 0.1112, 0.1135, 0.1001, 0.1438, 0.1265, 0.1468],\n",
      "          [0.1330, 0.1166, 0.1160, 0.1076, 0.1037, 0.1474, 0.1286, 0.1470],\n",
      "          [0.1291, 0.1236, 0.1217, 0.1037, 0.1031, 0.1409, 0.1253, 0.1524],\n",
      "          [0.1267, 0.1245, 0.1216, 0.1086, 0.1018, 0.1392, 0.1197, 0.1579],\n",
      "          [0.1281, 0.1145, 0.1133, 0.1093, 0.1087, 0.1448, 0.1310, 0.1505]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5417, -0.2501, -0.2508,  0.2529, -0.0874],\n",
      "          [-0.6028, -0.0598, -0.3284,  0.4196,  0.1310],\n",
      "          [-0.5105, -0.3206, -0.1855,  0.4309, -0.0551],\n",
      "          [-0.5764, -0.2300, -0.1581,  0.5030, -0.0022],\n",
      "          [-0.5814, -0.1561, -0.2488,  0.4738, -0.0261],\n",
      "          [-0.4724, -0.0080, -0.0539,  0.4506,  0.0369],\n",
      "          [-0.3562, -0.0764,  0.0020,  0.5415,  0.0677],\n",
      "          [-0.4925,  0.0072, -0.3012,  0.3492,  0.1562]],\n",
      "\n",
      "         [[ 0.3177,  0.1321,  0.1669,  0.4635, -0.1251],\n",
      "          [ 0.0052,  0.0090,  0.1058,  0.3112, -0.3290],\n",
      "          [ 0.2830,  0.0170,  0.0601,  0.1583, -0.1553],\n",
      "          [ 0.3595,  0.0618,  0.1837,  0.1085, -0.0902],\n",
      "          [ 0.3715, -0.0106,  0.0655,  0.2074, -0.1392],\n",
      "          [ 0.1929,  0.0073,  0.0181,  0.0631, -0.0591],\n",
      "          [ 0.1898,  0.2261,  0.1892,  0.3019,  0.0061],\n",
      "          [ 0.3405,  0.0020,  0.0115,  0.2617, -0.1792]],\n",
      "\n",
      "         [[ 0.0931, -0.0768, -0.0887,  0.1380,  0.1571],\n",
      "          [-0.0879,  0.0267, -0.0394,  0.4191,  0.1077],\n",
      "          [-0.0290,  0.2086, -0.0557,  0.3443,  0.0584],\n",
      "          [-0.1659,  0.0508,  0.0300,  0.4646, -0.0022],\n",
      "          [-0.0157, -0.0216, -0.0236,  0.2228,  0.0330],\n",
      "          [-0.1650, -0.0073,  0.0442,  0.3234, -0.0162],\n",
      "          [ 0.1110,  0.1232,  0.0051,  0.3858,  0.0220],\n",
      "          [ 0.2276,  0.2538,  0.2574,  0.3753,  0.1273]],\n",
      "\n",
      "         [[-0.0922, -0.4872, -0.4504,  0.3942,  0.0009],\n",
      "          [-0.0395, -0.1426, -0.5999,  0.5770,  0.0939],\n",
      "          [-0.1623, -0.5125, -0.4881,  0.4570, -0.1184],\n",
      "          [-0.2440, -0.5869, -0.3938,  0.4641, -0.0578],\n",
      "          [-0.0287, -0.4110, -0.4826,  0.4374, -0.0919],\n",
      "          [-0.0310, -0.4087, -0.4356,  0.6009,  0.2815],\n",
      "          [-0.0114, -0.4246, -0.2855,  0.7325, -0.0330],\n",
      "          [ 0.0239, -0.2216, -0.4019,  0.3664,  0.1273]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1340, 0.1793, 0.1792, 0.2965, 0.2110],\n",
      "          [0.1124, 0.1934, 0.1478, 0.3124, 0.2340],\n",
      "          [0.1293, 0.1564, 0.1790, 0.3315, 0.2039],\n",
      "          [0.1156, 0.1634, 0.1756, 0.3402, 0.2052],\n",
      "          [0.1171, 0.1792, 0.1633, 0.3364, 0.2040],\n",
      "          [0.1206, 0.1919, 0.1833, 0.3035, 0.2007],\n",
      "          [0.1293, 0.1710, 0.1850, 0.3172, 0.1975],\n",
      "          [0.1236, 0.2037, 0.1496, 0.2867, 0.2364]],\n",
      "\n",
      "         [[0.2227, 0.1850, 0.1916, 0.2577, 0.1430],\n",
      "          [0.1929, 0.1936, 0.2133, 0.2620, 0.1381],\n",
      "          [0.2442, 0.1872, 0.1954, 0.2156, 0.1576],\n",
      "          [0.2502, 0.1858, 0.2098, 0.1946, 0.1596],\n",
      "          [0.2586, 0.1765, 0.1904, 0.2194, 0.1552],\n",
      "          [0.2312, 0.1920, 0.1941, 0.2030, 0.1797],\n",
      "          [0.2005, 0.2079, 0.2004, 0.2243, 0.1669],\n",
      "          [0.2531, 0.1804, 0.1821, 0.2339, 0.1505]],\n",
      "\n",
      "         [[0.2088, 0.1762, 0.1741, 0.2184, 0.2226],\n",
      "          [0.1654, 0.1854, 0.1736, 0.2745, 0.2011],\n",
      "          [0.1728, 0.2192, 0.1683, 0.2511, 0.1886],\n",
      "          [0.1535, 0.1906, 0.1867, 0.2884, 0.1808],\n",
      "          [0.1885, 0.1874, 0.1870, 0.2392, 0.1979],\n",
      "          [0.1615, 0.1890, 0.1990, 0.2631, 0.1874],\n",
      "          [0.1944, 0.1968, 0.1749, 0.2559, 0.1779],\n",
      "          [0.1953, 0.2005, 0.2012, 0.2264, 0.1767]],\n",
      "\n",
      "         [[0.1962, 0.1322, 0.1371, 0.3191, 0.2154],\n",
      "          [0.1829, 0.1650, 0.1044, 0.3388, 0.2090],\n",
      "          [0.1877, 0.1322, 0.1355, 0.3486, 0.1961],\n",
      "          [0.1722, 0.1223, 0.1483, 0.3497, 0.2075],\n",
      "          [0.2062, 0.1407, 0.1310, 0.3286, 0.1936],\n",
      "          [0.1785, 0.1224, 0.1191, 0.3359, 0.2440],\n",
      "          [0.1817, 0.1202, 0.1381, 0.3822, 0.1778],\n",
      "          [0.2019, 0.1580, 0.1319, 0.2844, 0.2239]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 8])\n",
      "scaled_prod: \n",
      " tensor([[[[-6.3810e-01, -4.8292e-01, -4.7023e-01, -6.0567e-01, -5.6849e-01,\n",
      "           -6.6048e-01, -5.5627e-01, -4.8783e-01],\n",
      "          [-7.1208e-01, -5.6190e-01, -7.1549e-01, -6.2491e-01, -7.6756e-01,\n",
      "           -8.1773e-01, -7.1127e-01, -5.6248e-01],\n",
      "          [-6.1395e-01, -5.0065e-01, -7.0198e-01, -5.9410e-01, -6.8098e-01,\n",
      "           -7.3833e-01, -6.1706e-01, -3.8977e-01],\n",
      "          [-7.2061e-01, -5.6607e-01, -6.8335e-01, -5.5969e-01, -5.9858e-01,\n",
      "           -7.5114e-01, -6.5294e-01, -4.9533e-01],\n",
      "          [-6.5589e-01, -5.8656e-01, -7.4762e-01, -6.8319e-01, -6.4817e-01,\n",
      "           -8.1778e-01, -7.8333e-01, -5.3859e-01],\n",
      "          [-5.4088e-01, -4.3112e-01, -6.1243e-01, -3.9561e-01, -5.6619e-01,\n",
      "           -6.7170e-01, -5.5594e-01, -3.8515e-01],\n",
      "          [-5.4688e-01, -4.4839e-01, -5.5171e-01, -5.6951e-01, -6.3541e-01,\n",
      "           -6.5586e-01, -5.4130e-01, -3.6315e-01],\n",
      "          [-5.8260e-01, -4.7207e-01, -5.3545e-01, -4.3741e-01, -6.1583e-01,\n",
      "           -6.2354e-01, -4.4792e-01, -4.8228e-01]],\n",
      "\n",
      "         [[-4.9925e-01, -4.1970e-01, -3.8948e-01, -4.1554e-01, -5.9958e-01,\n",
      "           -4.7606e-01, -4.0703e-01, -4.6535e-01],\n",
      "          [-5.3659e-01, -5.2708e-01, -4.5904e-01, -5.3660e-01, -6.0759e-01,\n",
      "           -4.8210e-01, -4.6057e-01, -3.7241e-01],\n",
      "          [-5.1378e-01, -6.3403e-01, -5.3896e-01, -6.1771e-01, -6.3424e-01,\n",
      "           -5.6342e-01, -5.4485e-01, -4.2825e-01],\n",
      "          [-3.6427e-01, -4.7785e-01, -3.4964e-01, -5.1147e-01, -5.2627e-01,\n",
      "           -3.7142e-01, -3.0745e-01, -4.0397e-01],\n",
      "          [-5.5911e-01, -5.7910e-01, -4.2569e-01, -5.7049e-01, -5.8328e-01,\n",
      "           -5.5067e-01, -4.6739e-01, -4.3262e-01],\n",
      "          [-3.9921e-01, -4.7435e-01, -3.3348e-01, -3.8658e-01, -4.5647e-01,\n",
      "           -4.0946e-01, -3.7456e-01, -4.3498e-01],\n",
      "          [-3.8178e-01, -4.4722e-01, -3.1916e-01, -3.5315e-01, -4.1577e-01,\n",
      "           -4.5041e-01, -4.0315e-01, -3.3491e-01],\n",
      "          [-3.2927e-01, -3.5929e-01, -2.5600e-01, -2.5255e-01, -3.3761e-01,\n",
      "           -3.8113e-01, -2.7600e-01, -3.3186e-01]],\n",
      "\n",
      "         [[ 1.7969e-01,  2.2794e-01, -9.4660e-02,  3.2258e-02,  2.2544e-01,\n",
      "            1.4718e-01, -6.0240e-02,  4.8609e-02],\n",
      "          [ 1.0341e-01,  1.4634e-01, -2.0137e-01, -2.5653e-02,  1.8525e-01,\n",
      "            4.6003e-02, -2.2277e-01,  3.0743e-02],\n",
      "          [ 4.8637e-02,  1.3042e-01, -1.4292e-01, -4.5366e-02,  1.0978e-01,\n",
      "           -4.3308e-02, -2.4221e-01,  2.7137e-02],\n",
      "          [ 1.2971e-01,  1.4936e-01, -2.6865e-01, -1.7381e-02,  1.8911e-01,\n",
      "            1.3139e-01, -1.3403e-01, -2.9538e-02],\n",
      "          [ 4.5092e-02,  1.0801e-01, -2.4931e-01, -7.9781e-02,  1.0687e-01,\n",
      "           -1.3918e-02, -1.3052e-01, -5.1756e-02],\n",
      "          [-8.6511e-02, -1.8714e-02, -3.1287e-01, -2.6990e-01,  3.4853e-02,\n",
      "           -1.7254e-01, -2.8939e-01, -1.4156e-01],\n",
      "          [ 2.2142e-01,  2.0415e-01, -6.0227e-02,  8.5540e-02,  2.0827e-01,\n",
      "            9.2336e-02, -3.8373e-02,  8.7911e-02],\n",
      "          [ 8.6295e-02,  1.0932e-01, -9.7177e-02, -6.3070e-02,  1.9212e-01,\n",
      "            1.3812e-02, -1.5796e-01, -2.1736e-01]],\n",
      "\n",
      "         [[-3.1875e-01,  5.6367e-03, -3.4728e-01, -1.4354e-01, -1.0489e-01,\n",
      "            9.6248e-03,  1.7517e-01, -2.5911e-03],\n",
      "          [-3.9726e-01, -2.0398e-01, -5.4944e-01, -3.8170e-01, -3.2399e-01,\n",
      "           -1.6187e-01, -2.7870e-04, -1.8260e-01],\n",
      "          [-2.5853e-01, -1.0075e-01, -4.3645e-01, -2.0382e-01, -1.8160e-01,\n",
      "           -1.2617e-01,  4.7616e-02, -5.9217e-02],\n",
      "          [-1.8496e-01, -6.4025e-02, -3.8913e-01, -2.8535e-01, -7.2001e-02,\n",
      "           -2.8714e-02,  1.5282e-01, -4.0825e-02],\n",
      "          [-3.5250e-01, -1.4029e-01, -4.6401e-01, -3.0730e-01, -2.4199e-01,\n",
      "           -1.4735e-01, -3.7197e-02, -1.5594e-01],\n",
      "          [-3.8623e-01, -2.7633e-01, -5.7738e-01, -4.1826e-01, -2.5847e-01,\n",
      "           -1.6893e-01,  9.2415e-03, -1.6452e-01],\n",
      "          [-4.5793e-01, -3.1840e-01, -7.4433e-01, -5.0455e-01, -3.5332e-01,\n",
      "           -3.4614e-01, -1.0730e-01, -2.9629e-01],\n",
      "          [-3.8056e-01, -8.8067e-02, -4.0476e-01, -2.3768e-01, -1.0889e-01,\n",
      "           -1.2326e-01,  7.2740e-02, -1.1769e-01]]]], grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1152, 0.1345, 0.1362, 0.1190, 0.1235, 0.1126, 0.1250, 0.1339],\n",
      "          [0.1211, 0.1407, 0.1207, 0.1321, 0.1146, 0.1090, 0.1212, 0.1406],\n",
      "          [0.1231, 0.1379, 0.1127, 0.1256, 0.1151, 0.1087, 0.1227, 0.1541],\n",
      "          [0.1136, 0.1326, 0.1179, 0.1334, 0.1284, 0.1102, 0.1216, 0.1423],\n",
      "          [0.1279, 0.1371, 0.1167, 0.1244, 0.1289, 0.1088, 0.1126, 0.1438],\n",
      "          [0.1218, 0.1359, 0.1134, 0.1409, 0.1188, 0.1069, 0.1200, 0.1423],\n",
      "          [0.1235, 0.1363, 0.1229, 0.1208, 0.1131, 0.1108, 0.1242, 0.1484],\n",
      "          [0.1177, 0.1314, 0.1234, 0.1361, 0.1138, 0.1130, 0.1346, 0.1301]],\n",
      "\n",
      "         [[0.1198, 0.1298, 0.1337, 0.1303, 0.1084, 0.1226, 0.1314, 0.1240],\n",
      "          [0.1200, 0.1211, 0.1296, 0.1200, 0.1118, 0.1267, 0.1295, 0.1414],\n",
      "          [0.1306, 0.1158, 0.1273, 0.1177, 0.1157, 0.1242, 0.1266, 0.1422],\n",
      "          [0.1310, 0.1169, 0.1329, 0.1131, 0.1114, 0.1301, 0.1387, 0.1259],\n",
      "          [0.1201, 0.1177, 0.1372, 0.1187, 0.1172, 0.1211, 0.1316, 0.1363],\n",
      "          [0.1261, 0.1169, 0.1346, 0.1277, 0.1191, 0.1248, 0.1292, 0.1216],\n",
      "          [0.1257, 0.1177, 0.1338, 0.1293, 0.1215, 0.1173, 0.1230, 0.1317],\n",
      "          [0.1232, 0.1195, 0.1325, 0.1330, 0.1221, 0.1169, 0.1299, 0.1228]],\n",
      "\n",
      "         [[0.1360, 0.1428, 0.1034, 0.1174, 0.1424, 0.1317, 0.1070, 0.1193],\n",
      "          [0.1362, 0.1422, 0.1004, 0.1197, 0.1478, 0.1286, 0.0983, 0.1267],\n",
      "          [0.1329, 0.1443, 0.1098, 0.1210, 0.1413, 0.1213, 0.0994, 0.1301],\n",
      "          [0.1382, 0.1409, 0.0928, 0.1193, 0.1466, 0.1384, 0.1061, 0.1178],\n",
      "          [0.1343, 0.1430, 0.1001, 0.1185, 0.1429, 0.1266, 0.1127, 0.1219],\n",
      "          [0.1332, 0.1425, 0.1062, 0.1109, 0.1503, 0.1222, 0.1087, 0.1260],\n",
      "          [0.1404, 0.1380, 0.1059, 0.1226, 0.1386, 0.1234, 0.1083, 0.1229],\n",
      "          [0.1374, 0.1406, 0.1143, 0.1183, 0.1527, 0.1278, 0.1076, 0.1014]],\n",
      "\n",
      "         [[0.0982, 0.1358, 0.0954, 0.1170, 0.1216, 0.1364, 0.1609, 0.1347],\n",
      "          [0.1092, 0.1325, 0.0938, 0.1109, 0.1175, 0.1382, 0.1624, 0.1354],\n",
      "          [0.1128, 0.1321, 0.0944, 0.1192, 0.1218, 0.1288, 0.1532, 0.1377],\n",
      "          [0.1150, 0.1298, 0.0938, 0.1040, 0.1288, 0.1345, 0.1612, 0.1329],\n",
      "          [0.1098, 0.1357, 0.0982, 0.1149, 0.1226, 0.1348, 0.1505, 0.1336],\n",
      "          [0.1108, 0.1237, 0.0915, 0.1073, 0.1259, 0.1377, 0.1646, 0.1383],\n",
      "          [0.1152, 0.1325, 0.0865, 0.1100, 0.1279, 0.1288, 0.1636, 0.1354],\n",
      "          [0.1005, 0.1347, 0.0981, 0.1159, 0.1319, 0.1300, 0.1582, 0.1307]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 8, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.4084, -0.0736,  0.3576,  0.6718, -0.1454],\n",
      "          [ 0.1791, -0.0120,  0.3283,  0.8458, -0.1789],\n",
      "          [ 0.1439,  0.0244,  0.0985,  0.7778, -0.0595],\n",
      "          [ 0.4472,  0.0383,  0.2500,  0.7018, -0.0185],\n",
      "          [ 0.2190, -0.0807,  0.2016,  0.5397, -0.1307],\n",
      "          [ 0.1870,  0.0216,  0.2048,  0.5779, -0.1567],\n",
      "          [ 0.2899, -0.0493,  0.2521,  0.5643, -0.1031],\n",
      "          [ 0.0437,  0.0435,  0.1251,  0.7128, -0.1486]],\n",
      "\n",
      "         [[-0.0205, -0.2530,  0.1118,  0.1041,  0.4710],\n",
      "          [ 0.0133,  0.0262,  0.0874,  0.0465,  0.4009],\n",
      "          [ 0.1081,  0.0267, -0.0616,  0.0311,  0.4218],\n",
      "          [ 0.0810,  0.0014,  0.1496,  0.1210,  0.3923],\n",
      "          [-0.0902,  0.0622,  0.1422, -0.0711,  0.2253],\n",
      "          [ 0.0796, -0.0316,  0.1119,  0.1219,  0.2575],\n",
      "          [-0.1973, -0.3164, -0.1005, -0.2818,  0.2670],\n",
      "          [-0.1345,  0.1496,  0.0048,  0.0356,  0.2662]],\n",
      "\n",
      "         [[ 0.1008, -0.0784, -0.4866, -0.0243, -0.0781],\n",
      "          [ 0.1829, -0.2512, -0.4559,  0.0919,  0.0122],\n",
      "          [ 0.0779,  0.0020, -0.2874,  0.0793, -0.0696],\n",
      "          [ 0.0989,  0.0999, -0.4163, -0.0516,  0.0214],\n",
      "          [-0.0288,  0.0239, -0.2416, -0.0064,  0.0372],\n",
      "          [-0.0563, -0.0122, -0.2798,  0.0120, -0.0106],\n",
      "          [ 0.2986,  0.1203, -0.0443, -0.1615,  0.0853],\n",
      "          [-0.0090, -0.0887, -0.4699, -0.2219, -0.0091]],\n",
      "\n",
      "         [[ 0.0736,  0.3086,  0.5081,  0.9993,  0.2124],\n",
      "          [ 0.1416,  0.2343,  0.4856,  0.7964,  0.2914],\n",
      "          [ 0.2241,  0.1869,  0.1839,  0.8399,  0.0877],\n",
      "          [ 0.0648,  0.1740,  0.3986,  0.5944,  0.1878],\n",
      "          [ 0.4817,  0.4120,  0.4718,  0.7189,  0.3963],\n",
      "          [ 0.1493,  0.2577,  0.2473,  0.6281,  0.1583],\n",
      "          [ 0.1665,  0.0813,  0.0819,  0.8700,  0.3308],\n",
      "          [ 0.0691,  0.3165,  0.1876,  0.7642, -0.0202]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2250, 0.1390, 0.2139, 0.2928, 0.1293],\n",
      "          [0.1775, 0.1466, 0.2061, 0.3457, 0.1241],\n",
      "          [0.1804, 0.1601, 0.1724, 0.3400, 0.1472],\n",
      "          [0.2271, 0.1509, 0.1865, 0.2930, 0.1426],\n",
      "          [0.2080, 0.1542, 0.2044, 0.2867, 0.1466],\n",
      "          [0.1979, 0.1677, 0.2015, 0.2926, 0.1403],\n",
      "          [0.2143, 0.1527, 0.2064, 0.2820, 0.1447],\n",
      "          [0.1706, 0.1705, 0.1850, 0.3331, 0.1407]],\n",
      "\n",
      "         [[0.1754, 0.1390, 0.2002, 0.1987, 0.2867],\n",
      "          [0.1787, 0.1810, 0.1924, 0.1847, 0.2632],\n",
      "          [0.1976, 0.1822, 0.1668, 0.1830, 0.2704],\n",
      "          [0.1852, 0.1710, 0.1983, 0.1927, 0.2528],\n",
      "          [0.1719, 0.2002, 0.2169, 0.1752, 0.2357],\n",
      "          [0.1936, 0.1732, 0.1999, 0.2020, 0.2313],\n",
      "          [0.1818, 0.1614, 0.2003, 0.1671, 0.2893],\n",
      "          [0.1624, 0.2158, 0.1867, 0.1925, 0.2425]],\n",
      "\n",
      "         [[0.2433, 0.2034, 0.1352, 0.2147, 0.2034],\n",
      "          [0.2543, 0.1648, 0.1343, 0.2322, 0.2144],\n",
      "          [0.2230, 0.2067, 0.1547, 0.2233, 0.1924],\n",
      "          [0.2281, 0.2283, 0.1363, 0.1962, 0.2111],\n",
      "          [0.2019, 0.2128, 0.1632, 0.2065, 0.2157],\n",
      "          [0.2015, 0.2106, 0.1612, 0.2158, 0.2109],\n",
      "          [0.2509, 0.2099, 0.1781, 0.1584, 0.2027],\n",
      "          [0.2292, 0.2117, 0.1446, 0.1853, 0.2292]],\n",
      "\n",
      "         [[0.1337, 0.1691, 0.2064, 0.3373, 0.1536],\n",
      "          [0.1517, 0.1664, 0.2139, 0.2919, 0.1762],\n",
      "          [0.1771, 0.1706, 0.1701, 0.3278, 0.1545],\n",
      "          [0.1577, 0.1759, 0.2202, 0.2678, 0.1783],\n",
      "          [0.1957, 0.1826, 0.1938, 0.2482, 0.1797],\n",
      "          [0.1712, 0.1908, 0.1888, 0.2764, 0.1728],\n",
      "          [0.1657, 0.1521, 0.1522, 0.3348, 0.1952],\n",
      "          [0.1581, 0.2025, 0.1780, 0.3168, 0.1446]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1040, -1.3830, -0.1741,  0.3726, -0.1455],\n",
      "          [ 0.2160, -0.2021,  0.5427, -0.1913,  0.5266],\n",
      "          [ 0.0776, -1.8931, -0.0752, -0.7943, -0.7390],\n",
      "          [-0.7029,  0.0215, -1.2155, -0.7779, -0.1655],\n",
      "          [ 0.6981, -0.4133,  0.0281, -0.6031,  0.2091]],\n",
      "\n",
      "         [[ 0.7003,  0.7180,  0.4191,  0.5423,  0.3505],\n",
      "          [ 0.3493,  0.9618, -0.1341, -0.8884, -0.5300],\n",
      "          [ 0.4442,  0.2188,  0.5315, -0.4179, -0.0796],\n",
      "          [ 0.1467,  0.4234,  0.0174, -0.1533,  0.3396],\n",
      "          [ 0.4783,  0.3511,  0.4306, -0.3859,  0.2274]],\n",
      "\n",
      "         [[-0.1364,  0.2716, -0.2267, -0.6267,  0.3114],\n",
      "          [-0.8977, -0.4380, -1.1144, -0.8513, -0.1246],\n",
      "          [-0.4308,  0.8927, -0.4314, -0.5227, -0.4662],\n",
      "          [ 0.2863,  0.9860,  0.0551,  0.5353,  0.7877],\n",
      "          [ 0.2198,  0.3539,  0.4206,  0.1565, -0.1126]],\n",
      "\n",
      "         [[ 0.5147,  0.0287,  0.3939, -0.1206,  0.7638],\n",
      "          [-0.5082,  0.1640, -0.1047, -1.4313,  0.4067],\n",
      "          [ 0.3996,  0.1957, -0.1560, -0.7919,  0.4157],\n",
      "          [ 0.0902,  0.8183,  0.6661, -0.7323, -0.0719],\n",
      "          [ 1.2788,  1.0046,  0.7707, -0.2055, -0.5247]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2457, 0.0555, 0.1860, 0.3214, 0.1914],\n",
      "          [0.1971, 0.1297, 0.2732, 0.1311, 0.2689],\n",
      "          [0.3499, 0.0488, 0.3003, 0.1463, 0.1546],\n",
      "          [0.1587, 0.3275, 0.0950, 0.1472, 0.2716],\n",
      "          [0.3668, 0.1207, 0.1877, 0.0998, 0.2249]],\n",
      "\n",
      "         [[0.2309, 0.2350, 0.1743, 0.1971, 0.1627],\n",
      "          [0.2400, 0.4428, 0.1480, 0.0696, 0.0996],\n",
      "          [0.2561, 0.2045, 0.2795, 0.1082, 0.1517],\n",
      "          [0.1941, 0.2560, 0.1706, 0.1438, 0.2354],\n",
      "          [0.2479, 0.2183, 0.2364, 0.1045, 0.1929]],\n",
      "\n",
      "         [[0.1787, 0.2688, 0.1633, 0.1095, 0.2797],\n",
      "          [0.1515, 0.2399, 0.1219, 0.1586, 0.3281],\n",
      "          [0.1310, 0.4921, 0.1309, 0.1195, 0.1265],\n",
      "          [0.1484, 0.2987, 0.1177, 0.1903, 0.2449],\n",
      "          [0.1991, 0.2277, 0.2434, 0.1869, 0.1428]],\n",
      "\n",
      "         [[0.2318, 0.1426, 0.2054, 0.1228, 0.2974],\n",
      "          [0.1361, 0.2665, 0.2037, 0.0541, 0.3397],\n",
      "          [0.2696, 0.2199, 0.1547, 0.0819, 0.2740],\n",
      "          [0.1629, 0.3373, 0.2897, 0.0716, 0.1385],\n",
      "          [0.3632, 0.2761, 0.2185, 0.0823, 0.0598]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 0.1732, -0.0822, -0.6572,  0.2325,  0.6669],\n",
      "          [ 0.3002,  0.0706, -0.3852,  0.8224,  0.3508],\n",
      "          [-0.1338, -0.3841,  0.0109, -0.6546, -0.3186],\n",
      "          [ 0.4976, -0.1632,  0.3190, -0.6721, -0.3373],\n",
      "          [ 0.0354, -0.0557, -0.1415, -0.1844, -0.3019]],\n",
      "\n",
      "         [[ 0.1491,  0.1559,  0.1019, -0.2019, -0.2222],\n",
      "          [-0.0319,  0.3158, -0.1555, -0.3158, -0.2820],\n",
      "          [-0.1397,  0.4543, -0.4570, -0.1694, -0.2746],\n",
      "          [ 0.0445,  0.4978, -0.1524,  0.2540,  0.2103],\n",
      "          [-0.7565,  0.2477, -0.5459,  0.6796, -0.6648]],\n",
      "\n",
      "         [[ 0.4816, -0.3163,  0.0563, -0.3962, -0.0358],\n",
      "          [ 0.1494,  0.3538,  0.1523,  0.2784,  0.4058],\n",
      "          [ 0.4340, -0.3233,  0.0824, -0.3253, -0.2944],\n",
      "          [ 0.8810,  0.3138, -0.1510, -0.3873,  0.4521],\n",
      "          [ 0.4802,  0.1192,  0.1623, -0.2905,  0.0403]],\n",
      "\n",
      "         [[ 0.1356,  0.1994,  0.1284, -0.7165, -0.1366],\n",
      "          [ 0.2177,  0.2195,  0.3554, -0.3122, -0.4180],\n",
      "          [-0.4743, -0.2143, -0.5664, -0.1680, -0.2641],\n",
      "          [-0.0941, -0.2812, -0.6538,  0.1234, -0.4811],\n",
      "          [-0.2810,  0.1085, -0.0649, -0.3329, -0.4748]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2037, 0.1578, 0.0888, 0.2161, 0.3337],\n",
      "          [0.1986, 0.1578, 0.1000, 0.3347, 0.2089],\n",
      "          [0.2294, 0.1786, 0.2651, 0.1363, 0.1907],\n",
      "          [0.3229, 0.1667, 0.2701, 0.1002, 0.1401],\n",
      "          [0.2343, 0.2139, 0.1964, 0.1881, 0.1673]],\n",
      "\n",
      "         [[0.2297, 0.2312, 0.2191, 0.1617, 0.1584],\n",
      "          [0.2070, 0.2931, 0.1829, 0.1558, 0.1612],\n",
      "          [0.1857, 0.3364, 0.1352, 0.1803, 0.1623],\n",
      "          [0.1722, 0.2709, 0.1414, 0.2123, 0.2032],\n",
      "          [0.0974, 0.2659, 0.1203, 0.4096, 0.1068]],\n",
      "\n",
      "         [[0.3210, 0.1445, 0.2098, 0.1334, 0.1913],\n",
      "          [0.1767, 0.2168, 0.1772, 0.2010, 0.2283],\n",
      "          [0.3202, 0.1501, 0.2253, 0.1499, 0.1545],\n",
      "          [0.3502, 0.1986, 0.1248, 0.0985, 0.2280],\n",
      "          [0.2832, 0.1974, 0.2061, 0.1310, 0.1824]],\n",
      "\n",
      "         [[0.2355, 0.2510, 0.2338, 0.1004, 0.1794],\n",
      "          [0.2343, 0.2347, 0.2689, 0.1379, 0.1241],\n",
      "          [0.1724, 0.2236, 0.1572, 0.2341, 0.2127],\n",
      "          [0.2313, 0.1919, 0.1322, 0.2875, 0.1571],\n",
      "          [0.1821, 0.2688, 0.2261, 0.1729, 0.1500]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 5, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1566,  0.0396,  0.6338, -0.0276,  0.0270],\n",
      "          [ 0.1923,  0.4104,  0.0833,  0.0136,  0.0653],\n",
      "          [-0.1450,  0.1926,  0.3659,  0.2910, -0.3617],\n",
      "          [ 0.0808,  0.3539,  0.3245,  0.2216,  0.0580],\n",
      "          [ 0.5760,  0.1610, -0.0082, -0.4187,  0.3327]],\n",
      "\n",
      "         [[-0.3028,  0.3583, -0.7706,  0.3507,  0.1719],\n",
      "          [-0.2368,  0.1307, -0.9237,  0.0156, -0.5759],\n",
      "          [ 0.3424, -0.0937, -0.0296,  0.2568, -0.8621],\n",
      "          [ 0.0099, -0.1587, -0.1962,  0.2872, -0.2384],\n",
      "          [ 0.0696,  0.6996,  0.0272,  0.1512,  0.4568]],\n",
      "\n",
      "         [[ 0.9784,  0.3085,  0.4794, -0.0745, -0.3437],\n",
      "          [-0.2469, -0.1790,  0.0560,  0.3227, -0.0376],\n",
      "          [ 0.3320, -0.1829, -0.2059,  0.0663,  0.2589],\n",
      "          [ 0.1815, -0.1112,  0.2181,  0.1101, -0.0908],\n",
      "          [ 0.1393, -0.1662,  0.2178, -0.0970, -0.5426]],\n",
      "\n",
      "         [[-0.1519,  0.0059, -0.4063, -0.0095,  0.3095],\n",
      "          [ 0.1207, -0.1204,  0.3741,  0.0580,  0.5691],\n",
      "          [-0.2462,  0.5585, -0.0529,  0.3246,  0.5084],\n",
      "          [ 0.3546, -0.2330,  0.2348, -0.1076,  0.8234],\n",
      "          [ 0.1812,  0.1475, -0.1059,  0.1482,  0.3454]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1479, 0.1800, 0.3261, 0.1683, 0.1777],\n",
      "          [0.2059, 0.2560, 0.1846, 0.1722, 0.1813],\n",
      "          [0.1558, 0.2183, 0.2596, 0.2409, 0.1254],\n",
      "          [0.1749, 0.2298, 0.2231, 0.2013, 0.1709],\n",
      "          [0.2966, 0.1958, 0.1654, 0.1097, 0.2325]],\n",
      "\n",
      "         [[0.1410, 0.2731, 0.0883, 0.2710, 0.2266],\n",
      "          [0.2022, 0.2919, 0.1017, 0.2602, 0.1440],\n",
      "          [0.2814, 0.1819, 0.1940, 0.2583, 0.0844],\n",
      "          [0.2102, 0.1776, 0.1710, 0.2773, 0.1639],\n",
      "          [0.1564, 0.2936, 0.1499, 0.1697, 0.2304]],\n",
      "\n",
      "         [[0.3657, 0.1872, 0.2220, 0.1276, 0.0975],\n",
      "          [0.1557, 0.1666, 0.2107, 0.2751, 0.1919],\n",
      "          [0.2579, 0.1541, 0.1506, 0.1977, 0.2397],\n",
      "          [0.2234, 0.1667, 0.2317, 0.2080, 0.1702],\n",
      "          [0.2431, 0.1791, 0.2629, 0.1919, 0.1229]],\n",
      "\n",
      "         [[0.1759, 0.2060, 0.1364, 0.2028, 0.2790],\n",
      "          [0.1792, 0.1408, 0.2309, 0.1683, 0.2806],\n",
      "          [0.1198, 0.2679, 0.1454, 0.2120, 0.2548],\n",
      "          [0.2141, 0.1190, 0.1899, 0.1349, 0.3421],\n",
      "          [0.2056, 0.1988, 0.1543, 0.1989, 0.2423]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.0110, -0.0914, -0.0856,  ..., -0.0018, -0.1849, -0.3622],\n",
      "          [ 0.8476,  0.5700,  0.3465,  ...,  0.5702,  0.1163, -0.0804],\n",
      "          [ 0.7353,  0.3953,  0.2428,  ...,  0.2837, -0.0851, -0.2882],\n",
      "          ...,\n",
      "          [ 1.0806,  0.6583,  0.4582,  ...,  0.5365,  0.0705,  0.1890],\n",
      "          [ 1.3149,  0.9712,  0.6824,  ...,  0.7052,  0.1822,  0.2705],\n",
      "          [ 0.8799,  0.6012,  0.3775,  ...,  0.5706,  0.1678,  0.2335]],\n",
      "\n",
      "         [[ 0.7298,  0.7055,  0.6601,  ...,  0.7728,  0.6715,  0.4246],\n",
      "          [ 0.6442,  0.5694,  0.5914,  ...,  0.7143,  0.5276,  0.3643],\n",
      "          [ 0.6354,  0.5228,  0.5807,  ...,  0.6420,  0.4538,  0.3195],\n",
      "          ...,\n",
      "          [ 0.4431,  0.4620,  0.4389,  ...,  0.5037,  0.2503,  0.2726],\n",
      "          [ 0.5674,  0.4188,  0.4515,  ...,  0.6299,  0.3734,  0.2882],\n",
      "          [ 0.7086,  0.4159,  0.5528,  ...,  0.6915,  0.4764,  0.3485]],\n",
      "\n",
      "         [[-0.3880, -0.4540, -0.1715,  ..., -0.1129, -0.6528, -0.2645],\n",
      "          [-0.3109, -0.6697, -0.3651,  ..., -0.2748, -0.6259, -0.3797],\n",
      "          [-0.1572, -0.4739, -0.3497,  ..., -0.0182, -0.4220, -0.2442],\n",
      "          ...,\n",
      "          [-0.1985, -0.2957, -0.2166,  ...,  0.0978, -0.2454,  0.0162],\n",
      "          [-0.0087, -0.1928, -0.1841,  ...,  0.1422, -0.1949,  0.2437],\n",
      "          [-0.0543, -0.1651, -0.1567,  ...,  0.1221, -0.1608,  0.0230]],\n",
      "\n",
      "         [[ 0.9563,  0.8687,  0.9386,  ...,  1.0129,  1.1059,  0.5496],\n",
      "          [ 1.2105,  1.1680,  1.1852,  ...,  1.3404,  1.2717,  0.6531],\n",
      "          [ 0.9462,  0.8336,  0.8188,  ...,  0.9174,  0.8882,  0.3258],\n",
      "          ...,\n",
      "          [ 0.9345,  0.9792,  0.9550,  ...,  0.8748,  0.9739,  0.6905],\n",
      "          [ 0.9167,  1.0076,  1.1067,  ...,  1.1809,  1.0421,  0.8526],\n",
      "          [ 1.0210,  1.2212,  1.0155,  ...,  0.9926,  1.1189,  0.6964]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0741, 0.0684, 0.0688,  ..., 0.0748, 0.0623, 0.0522],\n",
      "          [0.0971, 0.0736, 0.0588,  ..., 0.0736, 0.0467, 0.0384],\n",
      "          [0.0978, 0.0696, 0.0598,  ..., 0.0623, 0.0431, 0.0351],\n",
      "          ...,\n",
      "          [0.1061, 0.0695, 0.0569,  ..., 0.0616, 0.0386, 0.0435],\n",
      "          [0.1136, 0.0806, 0.0604,  ..., 0.0617, 0.0366, 0.0400],\n",
      "          [0.0947, 0.0716, 0.0573,  ..., 0.0695, 0.0464, 0.0496]],\n",
      "\n",
      "         [[0.0644, 0.0628, 0.0600,  ..., 0.0672, 0.0607, 0.0474],\n",
      "          [0.0658, 0.0610, 0.0624,  ..., 0.0705, 0.0585, 0.0497],\n",
      "          [0.0690, 0.0617, 0.0653,  ..., 0.0695, 0.0576, 0.0503],\n",
      "          ...,\n",
      "          [0.0633, 0.0645, 0.0630,  ..., 0.0672, 0.0522, 0.0534],\n",
      "          [0.0692, 0.0597, 0.0616,  ..., 0.0737, 0.0570, 0.0524],\n",
      "          [0.0784, 0.0585, 0.0671,  ..., 0.0771, 0.0622, 0.0547]],\n",
      "\n",
      "         [[0.0582, 0.0545, 0.0723,  ..., 0.0766, 0.0447, 0.0658],\n",
      "          [0.0716, 0.0500, 0.0678,  ..., 0.0742, 0.0522, 0.0668],\n",
      "          [0.0772, 0.0562, 0.0637,  ..., 0.0887, 0.0592, 0.0708],\n",
      "          ...,\n",
      "          [0.0643, 0.0583, 0.0632,  ..., 0.0865, 0.0614, 0.0797],\n",
      "          [0.0688, 0.0573, 0.0578,  ..., 0.0800, 0.0571, 0.0886],\n",
      "          [0.0706, 0.0632, 0.0637,  ..., 0.0842, 0.0635, 0.0763]],\n",
      "\n",
      "         [[0.0630, 0.0577, 0.0618,  ..., 0.0666, 0.0731, 0.0419],\n",
      "          [0.0644, 0.0617, 0.0628,  ..., 0.0734, 0.0685, 0.0369],\n",
      "          [0.0728, 0.0650, 0.0641,  ..., 0.0707, 0.0687, 0.0391],\n",
      "          ...,\n",
      "          [0.0648, 0.0677, 0.0661,  ..., 0.0610, 0.0674, 0.0507],\n",
      "          [0.0549, 0.0601, 0.0664,  ..., 0.0715, 0.0623, 0.0515],\n",
      "          [0.0625, 0.0764, 0.0622,  ..., 0.0608, 0.0689, 0.0452]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.1955, -0.1758,  0.1456,  0.3191,  0.1881],\n",
      "          [-0.0216, -0.1156,  0.2949,  0.3397, -0.0378],\n",
      "          [-0.1281, -0.2241,  0.3970,  0.2655,  0.2336],\n",
      "          [-0.3840, -0.3064,  0.0985,  0.1393,  0.0826],\n",
      "          [-0.1779, -0.2437,  0.3842,  0.1502,  0.0238],\n",
      "          [-0.1627, -0.2781,  0.1622, -0.1868, -0.0661],\n",
      "          [-0.2760, -0.0716,  0.3715,  0.2695,  0.0668],\n",
      "          [-0.1101,  0.1087,  0.1657,  0.0735,  0.2020],\n",
      "          [-0.1522,  0.0220,  0.1492,  0.1589,  0.0854],\n",
      "          [-0.0633, -0.0112,  0.1598, -0.0331,  0.0969],\n",
      "          [-0.1973, -0.1582,  0.0639,  0.1075,  0.1288],\n",
      "          [ 0.0770, -0.0852,  0.1365,  0.2037,  0.2637],\n",
      "          [ 0.1349, -0.1523,  0.0914,  0.0462,  0.2933],\n",
      "          [-0.0138, -0.0110,  0.2437,  0.0581,  0.1094],\n",
      "          [ 0.2759,  0.2731,  0.2382,  0.2232,  0.4145],\n",
      "          [-0.1467,  0.1024,  0.3079,  0.1345,  0.1002]],\n",
      "\n",
      "         [[ 0.4575,  0.2808,  0.2885,  0.1601, -0.0173],\n",
      "          [ 0.1161, -0.0978,  0.1886,  0.0978, -0.3258],\n",
      "          [ 0.2124,  0.0168,  0.0890,  0.0075, -0.2006],\n",
      "          [-0.0667,  0.0556,  0.2386, -0.1151, -0.2905],\n",
      "          [ 0.0818,  0.1205,  0.2056,  0.1812, -0.2797],\n",
      "          [ 0.2969,  0.1160,  0.2720,  0.4942, -0.3240],\n",
      "          [ 0.2954,  0.0945,  0.0820,  0.0062, -0.5206],\n",
      "          [ 0.1998,  0.2736,  0.0052, -0.0665, -0.5186],\n",
      "          [ 0.3620,  0.2007,  0.1216,  0.0529, -0.6199],\n",
      "          [ 0.4043,  0.0910,  0.0922,  0.1395, -0.4328],\n",
      "          [ 0.4003,  0.2383,  0.1508,  0.3230, -0.3029],\n",
      "          [ 0.3313,  0.1762,  0.1353,  0.2181, -0.3286],\n",
      "          [ 0.4982,  0.2243,  0.1594,  0.2367, -0.1877],\n",
      "          [ 0.3523,  0.0977,  0.0841,  0.2445, -0.2773],\n",
      "          [ 0.3749,  0.1527,  0.3336,  0.2499, -0.3131],\n",
      "          [ 0.3180,  0.3100,  0.2502,  0.2435, -0.3305]],\n",
      "\n",
      "         [[ 0.0985, -0.8337,  0.0309,  0.1368, -0.0060],\n",
      "          [ 0.0526, -0.6811,  0.0717, -0.0763,  0.0057],\n",
      "          [-0.1979, -0.6720, -0.1419,  0.1316,  0.0673],\n",
      "          [-0.0413, -0.6572,  0.0468, -0.0484,  0.1632],\n",
      "          [ 0.2353, -0.4090,  0.0877,  0.0248,  0.2701],\n",
      "          [ 0.0144, -0.4558, -0.0635, -0.0035,  0.1553],\n",
      "          [ 0.1000, -0.2779, -0.0404,  0.1025,  0.2793],\n",
      "          [ 0.2190, -0.1678,  0.0073, -0.0043,  0.3682],\n",
      "          [ 0.1911, -0.3591, -0.0212,  0.0667,  0.3215],\n",
      "          [ 0.4020, -0.2993,  0.1828, -0.0220,  0.4052],\n",
      "          [ 0.2406, -0.3504,  0.1603,  0.2117,  0.1599],\n",
      "          [ 0.1825, -0.5864,  0.1453,  0.0721,  0.1325],\n",
      "          [ 0.2532, -0.3693,  0.0169,  0.0651, -0.0626],\n",
      "          [ 0.1891, -0.5258,  0.2230,  0.0994,  0.0679],\n",
      "          [ 0.0714, -0.6394,  0.1334,  0.0837, -0.2377],\n",
      "          [ 0.1087, -0.3167,  0.2327,  0.2889,  0.1354]],\n",
      "\n",
      "         [[-0.4103, -0.0356, -0.3894, -0.2794,  0.1428],\n",
      "          [-0.2775, -0.0103, -0.6305, -0.5120, -0.1127],\n",
      "          [-0.2708, -0.2538, -0.7011, -0.2980, -0.2908],\n",
      "          [-0.2633, -0.1522, -0.7022, -0.4724, -0.0132],\n",
      "          [-0.3726, -0.3278, -0.8458, -0.3630, -0.1491],\n",
      "          [-0.4647, -0.2603, -0.7777, -0.2989, -0.1220],\n",
      "          [-0.1021, -0.1875, -0.5952, -0.3022, -0.1648],\n",
      "          [-0.3316, -0.1619, -0.6940, -0.3018, -0.2387],\n",
      "          [-0.2699, -0.1441, -0.6249, -0.3900, -0.1099],\n",
      "          [-0.1473,  0.0638, -0.6109, -0.3523, -0.1804],\n",
      "          [-0.2580, -0.1674, -0.6782, -0.2967, -0.0843],\n",
      "          [-0.1695,  0.1031, -0.5618, -0.2249, -0.1572],\n",
      "          [-0.3418,  0.1787, -0.3518, -0.0902,  0.0037],\n",
      "          [-0.2742,  0.1491, -0.6010, -0.2235,  0.0057],\n",
      "          [-0.1866,  0.1781, -0.3445, -0.1753, -0.1373],\n",
      "          [-0.0183,  0.1207, -0.4373, -0.1391, -0.1174]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1523, 0.1553, 0.2142, 0.2548, 0.2235],\n",
      "          [0.1754, 0.1597, 0.2407, 0.2517, 0.1726],\n",
      "          [0.1534, 0.1394, 0.2594, 0.2274, 0.2203],\n",
      "          [0.1432, 0.1548, 0.2320, 0.2417, 0.2283],\n",
      "          [0.1587, 0.1486, 0.2784, 0.2203, 0.1941],\n",
      "          [0.1868, 0.1665, 0.2586, 0.1824, 0.2058],\n",
      "          [0.1375, 0.1687, 0.2628, 0.2373, 0.1937],\n",
      "          [0.1631, 0.2030, 0.2149, 0.1960, 0.2229],\n",
      "          [0.1619, 0.1928, 0.2189, 0.2210, 0.2054],\n",
      "          [0.1816, 0.1913, 0.2269, 0.1871, 0.2131],\n",
      "          [0.1645, 0.1710, 0.2135, 0.2231, 0.2279],\n",
      "          [0.1904, 0.1619, 0.2021, 0.2161, 0.2295],\n",
      "          [0.2086, 0.1565, 0.1997, 0.1909, 0.2444],\n",
      "          [0.1817, 0.1823, 0.2351, 0.1953, 0.2056],\n",
      "          [0.1977, 0.1972, 0.1904, 0.1876, 0.2271],\n",
      "          [0.1547, 0.1985, 0.2438, 0.2050, 0.1980]],\n",
      "\n",
      "         [[0.2471, 0.2071, 0.2087, 0.1835, 0.1537],\n",
      "          [0.2219, 0.1791, 0.2385, 0.2178, 0.1426],\n",
      "          [0.2391, 0.1966, 0.2113, 0.1948, 0.1582],\n",
      "          [0.1909, 0.2157, 0.2590, 0.1819, 0.1526],\n",
      "          [0.2011, 0.2090, 0.2276, 0.2221, 0.1401],\n",
      "          [0.2190, 0.1828, 0.2136, 0.2668, 0.1177],\n",
      "          [0.2620, 0.2143, 0.2116, 0.1962, 0.1159],\n",
      "          [0.2408, 0.2592, 0.1982, 0.1845, 0.1174],\n",
      "          [0.2669, 0.2272, 0.2099, 0.1960, 0.1000],\n",
      "          [0.2730, 0.1996, 0.1998, 0.2095, 0.1182],\n",
      "          [0.2469, 0.2100, 0.1924, 0.2285, 0.1222],\n",
      "          [0.2446, 0.2095, 0.2011, 0.2184, 0.1264],\n",
      "          [0.2669, 0.2030, 0.1902, 0.2055, 0.1344],\n",
      "          [0.2519, 0.1952, 0.1926, 0.2261, 0.1342],\n",
      "          [0.2412, 0.1932, 0.2315, 0.2129, 0.1212],\n",
      "          [0.2284, 0.2266, 0.2135, 0.2120, 0.1194]],\n",
      "\n",
      "         [[0.2343, 0.0922, 0.2190, 0.2434, 0.2111],\n",
      "          [0.2308, 0.1108, 0.2353, 0.2029, 0.2202],\n",
      "          [0.1861, 0.1158, 0.1968, 0.2587, 0.2426],\n",
      "          [0.2061, 0.1113, 0.2251, 0.2046, 0.2529],\n",
      "          [0.2362, 0.1240, 0.2038, 0.1914, 0.2446],\n",
      "          [0.2135, 0.1334, 0.1975, 0.2097, 0.2458],\n",
      "          [0.2104, 0.1442, 0.1828, 0.2109, 0.2517],\n",
      "          [0.2248, 0.1527, 0.1819, 0.1798, 0.2609],\n",
      "          [0.2269, 0.1309, 0.1835, 0.2003, 0.2585],\n",
      "          [0.2527, 0.1253, 0.2030, 0.1654, 0.2535],\n",
      "          [0.2288, 0.1267, 0.2111, 0.2223, 0.2111],\n",
      "          [0.2340, 0.1085, 0.2254, 0.2095, 0.2226],\n",
      "          [0.2575, 0.1382, 0.2033, 0.2133, 0.1878],\n",
      "          [0.2313, 0.1132, 0.2393, 0.2114, 0.2049],\n",
      "          [0.2325, 0.1142, 0.2473, 0.2353, 0.1707],\n",
      "          [0.1996, 0.1304, 0.2259, 0.2390, 0.2050]],\n",
      "\n",
      "         [[0.1574, 0.2289, 0.1607, 0.1794, 0.2736],\n",
      "          [0.2008, 0.2624, 0.1411, 0.1589, 0.2368],\n",
      "          [0.2164, 0.2201, 0.1407, 0.2106, 0.2121],\n",
      "          [0.2059, 0.2301, 0.1327, 0.1670, 0.2643],\n",
      "          [0.2029, 0.2122, 0.1264, 0.2048, 0.2537],\n",
      "          [0.1803, 0.2212, 0.1318, 0.2128, 0.2540],\n",
      "          [0.2333, 0.2142, 0.1425, 0.1910, 0.2191],\n",
      "          [0.1996, 0.2366, 0.1390, 0.2057, 0.2191],\n",
      "          [0.2043, 0.2316, 0.1432, 0.1811, 0.2397],\n",
      "          [0.2152, 0.2658, 0.1354, 0.1753, 0.2082],\n",
      "          [0.2039, 0.2233, 0.1340, 0.1962, 0.2426],\n",
      "          [0.2021, 0.2655, 0.1365, 0.1912, 0.2046],\n",
      "          [0.1569, 0.2641, 0.1554, 0.2019, 0.2217],\n",
      "          [0.1778, 0.2716, 0.1283, 0.1871, 0.2353],\n",
      "          [0.1867, 0.2689, 0.1594, 0.1888, 0.1961],\n",
      "          [0.2175, 0.2499, 0.1430, 0.1927, 0.1969]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3864, -0.3006, -0.1409,  ..., -0.2720, -0.4227, -0.3889],\n",
      "          [-0.3560, -0.2029, -0.0733,  ..., -0.2665, -0.3534, -0.3508],\n",
      "          [-0.6120, -0.4244, -0.4683,  ..., -0.3585, -0.4583, -0.4669],\n",
      "          ...,\n",
      "          [-0.4454, -0.3124, -0.0760,  ..., -0.2300, -0.3444, -0.3525],\n",
      "          [-0.2115, -0.0782,  0.0315,  ..., -0.1458, -0.1892, -0.1728],\n",
      "          [-0.5839, -0.4369, -0.2533,  ..., -0.5062, -0.5954, -0.5814]],\n",
      "\n",
      "         [[-0.1769, -0.4389, -0.3327,  ..., -0.1354, -0.2486, -0.2683],\n",
      "          [-0.0385, -0.2054, -0.1225,  ...,  0.0279, -0.0139, -0.0692],\n",
      "          [-0.0921, -0.1828, -0.1073,  ..., -0.0271, -0.0007, -0.0477],\n",
      "          ...,\n",
      "          [-0.0305, -0.3160, -0.2453,  ..., -0.0289, -0.1172, -0.1756],\n",
      "          [-0.0367, -0.1398,  0.0525,  ...,  0.1205,  0.1175,  0.1069],\n",
      "          [-0.0439, -0.1543, -0.0717,  ...,  0.0702,  0.0017, -0.0211]],\n",
      "\n",
      "         [[ 0.0492,  0.3133,  0.1831,  ...,  0.0920,  0.3737,  0.0772],\n",
      "          [ 0.0917,  0.4557,  0.3089,  ...,  0.1505,  0.4915,  0.0132],\n",
      "          [ 0.2036,  0.4515,  0.4474,  ...,  0.2230,  0.4273,  0.0768],\n",
      "          ...,\n",
      "          [ 0.2437,  0.4681,  0.4479,  ...,  0.2675,  0.4882,  0.2356],\n",
      "          [ 0.0895,  0.3140,  0.2839,  ...,  0.0891,  0.2551, -0.0453],\n",
      "          [ 0.3243,  0.5213,  0.4436,  ...,  0.1920,  0.4411,  0.3028]],\n",
      "\n",
      "         [[ 0.1435, -0.1169, -0.0907,  ...,  0.0063, -0.1455, -0.2564],\n",
      "          [ 0.0737, -0.2078, -0.1862,  ..., -0.0993, -0.3381, -0.3513],\n",
      "          [ 0.0303, -0.2524, -0.2001,  ...,  0.0149, -0.2917, -0.3642],\n",
      "          ...,\n",
      "          [ 0.2589, -0.0700, -0.0583,  ..., -0.0127, -0.1667, -0.1873],\n",
      "          [ 0.0014, -0.2397, -0.1778,  ..., -0.1488, -0.3758, -0.3955],\n",
      "          [ 0.1114, -0.1959, -0.1643,  ..., -0.1272, -0.2964, -0.3603]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0635, 0.0692, 0.0812,  ..., 0.0712, 0.0612, 0.0633],\n",
      "          [0.0607, 0.0707, 0.0805,  ..., 0.0664, 0.0609, 0.0610],\n",
      "          [0.0586, 0.0707, 0.0677,  ..., 0.0755, 0.0683, 0.0678],\n",
      "          ...,\n",
      "          [0.0568, 0.0648, 0.0821,  ..., 0.0704, 0.0628, 0.0623],\n",
      "          [0.0607, 0.0694, 0.0774,  ..., 0.0649, 0.0621, 0.0631],\n",
      "          [0.0593, 0.0687, 0.0825,  ..., 0.0641, 0.0586, 0.0594]],\n",
      "\n",
      "         [[0.0660, 0.0508, 0.0565,  ..., 0.0688, 0.0615, 0.0603],\n",
      "          [0.0625, 0.0529, 0.0574,  ..., 0.0668, 0.0640, 0.0606],\n",
      "          [0.0573, 0.0524, 0.0565,  ..., 0.0612, 0.0628, 0.0600],\n",
      "          ...,\n",
      "          [0.0674, 0.0507, 0.0544,  ..., 0.0675, 0.0618, 0.0583],\n",
      "          [0.0565, 0.0510, 0.0618,  ..., 0.0662, 0.0660, 0.0653],\n",
      "          [0.0581, 0.0520, 0.0565,  ..., 0.0651, 0.0608, 0.0594]],\n",
      "\n",
      "         [[0.0530, 0.0690, 0.0606,  ..., 0.0553, 0.0733, 0.0545],\n",
      "          [0.0506, 0.0728, 0.0629,  ..., 0.0536, 0.0754, 0.0468],\n",
      "          [0.0528, 0.0677, 0.0674,  ..., 0.0539, 0.0661, 0.0465],\n",
      "          ...,\n",
      "          [0.0539, 0.0674, 0.0661,  ..., 0.0552, 0.0688, 0.0534],\n",
      "          [0.0556, 0.0696, 0.0675,  ..., 0.0556, 0.0656, 0.0486],\n",
      "          [0.0580, 0.0706, 0.0653,  ..., 0.0508, 0.0652, 0.0567]],\n",
      "\n",
      "         [[0.0674, 0.0520, 0.0533,  ..., 0.0588, 0.0505, 0.0452],\n",
      "          [0.0749, 0.0565, 0.0578,  ..., 0.0630, 0.0496, 0.0490],\n",
      "          [0.0669, 0.0504, 0.0531,  ..., 0.0659, 0.0485, 0.0451],\n",
      "          ...,\n",
      "          [0.0757, 0.0545, 0.0551,  ..., 0.0577, 0.0494, 0.0484],\n",
      "          [0.0709, 0.0557, 0.0593,  ..., 0.0610, 0.0486, 0.0477],\n",
      "          [0.0746, 0.0549, 0.0566,  ..., 0.0587, 0.0496, 0.0465]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.5024, -0.2472, -0.5894, -0.2504, -0.0244],\n",
      "          [-0.4183, -0.3677, -0.4331, -0.0952, -0.1241],\n",
      "          [-0.5699, -0.2164, -0.4343,  0.1666,  0.0441],\n",
      "          [-0.4141, -0.3150, -0.5738,  0.1617,  0.1825],\n",
      "          [-0.4168, -0.3177, -0.3604,  0.0017,  0.1335],\n",
      "          [-0.3743,  0.0140, -0.2353, -0.0123,  0.1964],\n",
      "          [-0.4782,  0.0722, -0.2928, -0.0836,  0.1124],\n",
      "          [-0.3064, -0.0339, -0.2480,  0.1560,  0.0060],\n",
      "          [-0.3112, -0.0040, -0.2768,  0.0788,  0.1613],\n",
      "          [-0.3642,  0.0656, -0.2369, -0.0549, -0.0365],\n",
      "          [-0.3621, -0.1122, -0.3308,  0.2115, -0.0037],\n",
      "          [-0.1036, -0.0439, -0.3332,  0.1141,  0.2440],\n",
      "          [-0.0359, -0.0945, -0.0691,  0.0672,  0.3160],\n",
      "          [-0.2103, -0.2008, -0.0872,  0.2142,  0.0792],\n",
      "          [-0.0835, -0.1676, -0.0961,  0.3204,  0.3420],\n",
      "          [-0.2440, -0.0784, -0.2601,  0.2178,  0.2149]],\n",
      "\n",
      "         [[ 0.3186,  0.3572,  0.1404,  0.4690, -0.3351],\n",
      "          [ 0.2067,  0.2386, -0.0215,  0.3921, -0.2509],\n",
      "          [ 0.1604,  0.2738,  0.0092,  0.2227, -0.3592],\n",
      "          [ 0.0847,  0.3542, -0.1702,  0.2779, -0.3911],\n",
      "          [ 0.4057,  0.1417, -0.0934, -0.0725, -0.0704],\n",
      "          [ 0.2263,  0.2282, -0.2232,  0.1902, -0.2995],\n",
      "          [ 0.3314,  0.1722, -0.1653,  0.1861, -0.1830],\n",
      "          [ 0.2990,  0.3072, -0.0421,  0.3330, -0.3475],\n",
      "          [ 0.1851,  0.1076, -0.1906,  0.2974, -0.3666],\n",
      "          [ 0.1782,  0.1596, -0.1816,  0.1734, -0.3217],\n",
      "          [ 0.0247,  0.1062, -0.2016,  0.4538, -0.1036],\n",
      "          [ 0.3972,  0.1461,  0.0050,  0.5308, -0.1666],\n",
      "          [ 0.3368,  0.4063,  0.0176,  0.5029, -0.1235],\n",
      "          [ 0.1694,  0.1125, -0.0572,  0.5541, -0.2872],\n",
      "          [ 0.2228,  0.2002, -0.0025,  0.3779, -0.1599],\n",
      "          [ 0.2415,  0.0028, -0.0874,  0.3415, -0.1853]],\n",
      "\n",
      "         [[ 0.3486, -0.0401, -0.2617, -0.0038, -0.0266],\n",
      "          [ 0.1265, -0.1939, -0.4366, -0.0858, -0.0214],\n",
      "          [ 0.0382, -0.2104, -0.4479, -0.0863, -0.1277],\n",
      "          [ 0.0894, -0.1278, -0.4987,  0.1245, -0.2436],\n",
      "          [ 0.1244, -0.1271, -0.5052,  0.0390, -0.0517],\n",
      "          [-0.0901, -0.2611, -0.6269,  0.0224, -0.1394],\n",
      "          [-0.0129, -0.0239, -0.3417, -0.0299, -0.2122],\n",
      "          [ 0.0889, -0.1208, -0.2927, -0.0398, -0.0105],\n",
      "          [ 0.2822, -0.0201, -0.2255,  0.1596,  0.0038],\n",
      "          [ 0.2701, -0.0237, -0.2807,  0.1056,  0.0847],\n",
      "          [-0.0987,  0.1329, -0.2527,  0.1346, -0.0265],\n",
      "          [ 0.0465, -0.0131, -0.2072,  0.2270, -0.0027],\n",
      "          [-0.0149,  0.1217, -0.2399,  0.2189,  0.1938],\n",
      "          [ 0.1449,  0.0982, -0.0660,  0.1787,  0.0336],\n",
      "          [ 0.1381, -0.1753, -0.0721,  0.0727,  0.1822],\n",
      "          [ 0.2041, -0.0808, -0.2126,  0.2064, -0.0447]],\n",
      "\n",
      "         [[ 0.2303,  0.0876, -0.5846,  0.2830,  0.2849],\n",
      "          [ 0.0517, -0.3197, -0.5375,  0.3551,  0.0773],\n",
      "          [-0.0926, -0.0938, -0.5572,  0.6211,  0.1129],\n",
      "          [ 0.1014, -0.1263, -0.7422,  0.4248,  0.1322],\n",
      "          [-0.0027, -0.1753, -0.5218,  0.5886,  0.3153],\n",
      "          [ 0.2974, -0.2026, -0.3531,  0.3214,  0.2676],\n",
      "          [ 0.2948,  0.0172, -0.4330,  0.3703,  0.3851],\n",
      "          [ 0.1033, -0.1696, -0.4556,  0.6013,  0.1433],\n",
      "          [ 0.1022, -0.1455, -0.4360,  0.3487,  0.1277],\n",
      "          [-0.0268, -0.2869, -0.7667,  0.2754, -0.0696],\n",
      "          [-0.0823, -0.2326, -0.6494,  0.4940,  0.0158],\n",
      "          [ 0.1325, -0.3588, -0.7234,  0.3457, -0.0129],\n",
      "          [ 0.0605, -0.3822, -0.7519,  0.2796, -0.1095],\n",
      "          [ 0.0088, -0.4545, -0.5699,  0.2941, -0.1645],\n",
      "          [-0.0746, -0.2971, -0.5709,  0.5182,  0.0865],\n",
      "          [-0.0240, -0.5321, -0.6962,  0.4912,  0.0402]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.1637, 0.2114, 0.1501, 0.2107, 0.2641],\n",
      "          [0.1736, 0.1826, 0.1710, 0.2398, 0.2330],\n",
      "          [0.1332, 0.1897, 0.1526, 0.2783, 0.2462],\n",
      "          [0.1526, 0.1686, 0.1301, 0.2715, 0.2772],\n",
      "          [0.1559, 0.1721, 0.1649, 0.2369, 0.2702],\n",
      "          [0.1464, 0.2159, 0.1683, 0.2103, 0.2591],\n",
      "          [0.1384, 0.2399, 0.1666, 0.2053, 0.2498],\n",
      "          [0.1580, 0.2075, 0.1675, 0.2509, 0.2160],\n",
      "          [0.1544, 0.2100, 0.1598, 0.2281, 0.2477],\n",
      "          [0.1557, 0.2393, 0.1768, 0.2121, 0.2161],\n",
      "          [0.1533, 0.1969, 0.1582, 0.2721, 0.2194],\n",
      "          [0.1813, 0.1925, 0.1441, 0.2254, 0.2567],\n",
      "          [0.1838, 0.1733, 0.1778, 0.2038, 0.2613],\n",
      "          [0.1665, 0.1681, 0.1883, 0.2546, 0.2224],\n",
      "          [0.1685, 0.1549, 0.1664, 0.2523, 0.2579],\n",
      "          [0.1579, 0.1863, 0.1554, 0.2506, 0.2498]],\n",
      "\n",
      "         [[0.2194, 0.2280, 0.1836, 0.2550, 0.1141],\n",
      "          [0.2144, 0.2213, 0.1706, 0.2580, 0.1357],\n",
      "          [0.2156, 0.2415, 0.1853, 0.2294, 0.1282],\n",
      "          [0.2033, 0.2662, 0.1575, 0.2466, 0.1263],\n",
      "          [0.2765, 0.2124, 0.1679, 0.1714, 0.1718],\n",
      "          [0.2384, 0.2388, 0.1521, 0.2299, 0.1409],\n",
      "          [0.2548, 0.2173, 0.1551, 0.2204, 0.1524],\n",
      "          [0.2338, 0.2357, 0.1662, 0.2419, 0.1225],\n",
      "          [0.2322, 0.2149, 0.1595, 0.2598, 0.1337],\n",
      "          [0.2336, 0.2293, 0.1630, 0.2325, 0.1417],\n",
      "          [0.1888, 0.2048, 0.1505, 0.2899, 0.1660],\n",
      "          [0.2401, 0.1868, 0.1622, 0.2744, 0.1366],\n",
      "          [0.2169, 0.2325, 0.1576, 0.2561, 0.1369],\n",
      "          [0.2064, 0.1950, 0.1646, 0.3033, 0.1307],\n",
      "          [0.2162, 0.2113, 0.1726, 0.2525, 0.1474],\n",
      "          [0.2345, 0.1847, 0.1687, 0.2591, 0.1530]],\n",
      "\n",
      "         [[0.2769, 0.1877, 0.1504, 0.1947, 0.1903],\n",
      "          [0.2521, 0.1830, 0.1436, 0.2039, 0.2175],\n",
      "          [0.2424, 0.1891, 0.1491, 0.2141, 0.2054],\n",
      "          [0.2431, 0.1957, 0.1350, 0.2519, 0.1743],\n",
      "          [0.2459, 0.1912, 0.1310, 0.2257, 0.2062],\n",
      "          [0.2223, 0.1874, 0.1300, 0.2488, 0.2116],\n",
      "          [0.2217, 0.2192, 0.1595, 0.2179, 0.1816],\n",
      "          [0.2337, 0.1895, 0.1596, 0.2055, 0.2116],\n",
      "          [0.2511, 0.1856, 0.1511, 0.2221, 0.1901],\n",
      "          [0.2499, 0.1863, 0.1441, 0.2120, 0.2076],\n",
      "          [0.1833, 0.2311, 0.1571, 0.2315, 0.1970],\n",
      "          [0.2054, 0.1935, 0.1594, 0.2461, 0.1956],\n",
      "          [0.1838, 0.2107, 0.1468, 0.2322, 0.2265],\n",
      "          [0.2131, 0.2034, 0.1726, 0.2204, 0.1906],\n",
      "          [0.2211, 0.1616, 0.1792, 0.2071, 0.2311],\n",
      "          [0.2385, 0.1794, 0.1572, 0.2390, 0.1859]],\n",
      "\n",
      "         [[0.2262, 0.1962, 0.1002, 0.2385, 0.2390],\n",
      "          [0.2162, 0.1491, 0.1199, 0.2929, 0.2218],\n",
      "          [0.1696, 0.1694, 0.1066, 0.3462, 0.2083],\n",
      "          [0.2155, 0.1716, 0.0927, 0.2978, 0.2223],\n",
      "          [0.1780, 0.1498, 0.1059, 0.3216, 0.2447],\n",
      "          [0.2425, 0.1471, 0.1265, 0.2484, 0.2354],\n",
      "          [0.2266, 0.1717, 0.1094, 0.2443, 0.2480],\n",
      "          [0.1992, 0.1516, 0.1139, 0.3278, 0.2074],\n",
      "          [0.2142, 0.1672, 0.1250, 0.2740, 0.2197],\n",
      "          [0.2193, 0.1691, 0.1047, 0.2967, 0.2102],\n",
      "          [0.1883, 0.1620, 0.1068, 0.3351, 0.2077],\n",
      "          [0.2416, 0.1478, 0.1027, 0.2990, 0.2089],\n",
      "          [0.2395, 0.1539, 0.1063, 0.2982, 0.2021],\n",
      "          [0.2293, 0.1443, 0.1286, 0.3050, 0.1928],\n",
      "          [0.1854, 0.1484, 0.1129, 0.3354, 0.2178],\n",
      "          [0.2061, 0.1240, 0.1052, 0.3450, 0.2197]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 16])\n",
      "scaled_prod: \n",
      " tensor([[[[-0.3679, -0.5404, -0.4639,  ..., -0.4386, -0.3449, -0.6706],\n",
      "          [-0.4907, -0.4683, -0.4632,  ..., -0.3895, -0.2742, -0.6164],\n",
      "          [-0.5093, -0.6442, -0.6580,  ..., -0.4159, -0.4529, -0.6199],\n",
      "          ...,\n",
      "          [-0.2734, -0.4870, -0.3632,  ..., -0.3647, -0.3391, -0.5215],\n",
      "          [-0.3285, -0.5074, -0.3076,  ..., -0.3917, -0.3222, -0.5515],\n",
      "          [-0.3125, -0.4810, -0.4185,  ..., -0.2587, -0.4115, -0.5309]],\n",
      "\n",
      "         [[-0.0283, -0.2685, -0.5020,  ..., -0.0038, -0.1311, -0.0724],\n",
      "          [-0.0916, -0.3506, -0.5535,  ...,  0.0519, -0.2227, -0.1058],\n",
      "          [-0.2332, -0.4090, -0.6765,  ..., -0.0590, -0.2410, -0.2029],\n",
      "          ...,\n",
      "          [ 0.1664, -0.1822, -0.4053,  ...,  0.2706, -0.0671,  0.1148],\n",
      "          [ 0.2679, -0.1004, -0.2864,  ...,  0.2680,  0.0785,  0.1568],\n",
      "          [-0.0788, -0.2569, -0.3491,  ...,  0.0861, -0.1504, -0.0153]],\n",
      "\n",
      "         [[ 0.3009,  0.0807,  0.0338,  ..., -0.0452, -0.0623, -0.2531],\n",
      "          [ 0.0739, -0.0484,  0.0467,  ..., -0.2013, -0.0047, -0.3908],\n",
      "          [ 0.1299,  0.0030,  0.0416,  ..., -0.2217, -0.0203, -0.2576],\n",
      "          ...,\n",
      "          [ 0.0985,  0.0968,  0.1728,  ...,  0.0502,  0.0915, -0.1726],\n",
      "          [ 0.1953,  0.1472,  0.2357,  ...,  0.0947,  0.1059, -0.0434],\n",
      "          [ 0.1515,  0.0629,  0.1546,  ..., -0.0767, -0.0274, -0.1726]],\n",
      "\n",
      "         [[-0.0538,  0.0213,  0.0056,  ...,  0.4347,  0.3192,  0.4169],\n",
      "          [-0.5200, -0.3405, -0.4732,  ...,  0.1368, -0.0556,  0.0796],\n",
      "          [-0.5314, -0.2740, -0.2772,  ...,  0.1475,  0.0453,  0.1011],\n",
      "          ...,\n",
      "          [-0.4931, -0.5100, -0.5594,  ...,  0.1283, -0.2278, -0.0914],\n",
      "          [-0.5327, -0.3764, -0.5430,  ...,  0.1211, -0.0432,  0.1093],\n",
      "          [-0.4816, -0.3987, -0.5866,  ...,  0.2295, -0.0346,  0.1184]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.0704, 0.0592, 0.0639,  ..., 0.0656, 0.0720, 0.0520],\n",
      "          [0.0598, 0.0612, 0.0615,  ..., 0.0662, 0.0743, 0.0527],\n",
      "          [0.0665, 0.0581, 0.0573,  ..., 0.0730, 0.0704, 0.0596],\n",
      "          ...,\n",
      "          [0.0735, 0.0594, 0.0672,  ..., 0.0671, 0.0688, 0.0574],\n",
      "          [0.0690, 0.0577, 0.0704,  ..., 0.0648, 0.0694, 0.0552],\n",
      "          [0.0680, 0.0574, 0.0611,  ..., 0.0717, 0.0616, 0.0546]],\n",
      "\n",
      "         [[0.0788, 0.0620, 0.0491,  ..., 0.0807, 0.0711, 0.0754],\n",
      "          [0.0784, 0.0605, 0.0494,  ..., 0.0905, 0.0688, 0.0773],\n",
      "          [0.0729, 0.0611, 0.0468,  ..., 0.0868, 0.0723, 0.0751],\n",
      "          ...,\n",
      "          [0.0811, 0.0572, 0.0458,  ..., 0.0900, 0.0642, 0.0770],\n",
      "          [0.0885, 0.0612, 0.0508,  ..., 0.0885, 0.0732, 0.0792],\n",
      "          [0.0756, 0.0633, 0.0577,  ..., 0.0892, 0.0704, 0.0806]],\n",
      "\n",
      "         [[0.0822, 0.0660, 0.0630,  ..., 0.0582, 0.0572, 0.0473],\n",
      "          [0.0711, 0.0629, 0.0692,  ..., 0.0540, 0.0657, 0.0447],\n",
      "          [0.0754, 0.0664, 0.0691,  ..., 0.0531, 0.0649, 0.0512],\n",
      "          ...,\n",
      "          [0.0660, 0.0658, 0.0710,  ..., 0.0628, 0.0655, 0.0503],\n",
      "          [0.0682, 0.0650, 0.0710,  ..., 0.0617, 0.0624, 0.0537],\n",
      "          [0.0724, 0.0662, 0.0726,  ..., 0.0576, 0.0605, 0.0523]],\n",
      "\n",
      "         [[0.0474, 0.0510, 0.0503,  ..., 0.0772, 0.0688, 0.0758],\n",
      "          [0.0426, 0.0510, 0.0447,  ..., 0.0822, 0.0678, 0.0776],\n",
      "          [0.0397, 0.0513, 0.0512,  ..., 0.0782, 0.0706, 0.0747],\n",
      "          ...,\n",
      "          [0.0466, 0.0458, 0.0436,  ..., 0.0868, 0.0608, 0.0696],\n",
      "          [0.0427, 0.0499, 0.0422,  ..., 0.0820, 0.0696, 0.0811],\n",
      "          [0.0421, 0.0458, 0.0379,  ..., 0.0858, 0.0659, 0.0768]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "scaled_prod.shape: \n",
      " torch.Size([1, 4, 16, 5])\n",
      "scaled_prod: \n",
      " tensor([[[[ 5.9672e-01, -3.9250e-01,  2.2201e-01,  7.5779e-01, -1.9198e-01],\n",
      "          [ 1.7833e-01, -3.2379e-01,  3.6893e-01,  8.1861e-01, -1.4086e-01],\n",
      "          [ 3.8142e-01, -4.6201e-01,  3.5153e-01,  7.4206e-01, -1.6699e-01],\n",
      "          [ 1.0004e-01, -3.8663e-01,  3.6052e-01,  7.4213e-01, -1.2846e-01],\n",
      "          [ 4.7098e-01, -1.6279e-01,  5.1894e-01,  9.5278e-01,  8.5138e-02],\n",
      "          [ 8.6705e-02, -1.4784e-01,  4.0148e-01,  9.2302e-01,  1.4293e-01],\n",
      "          [ 2.2538e-01, -2.3864e-01,  5.7734e-01,  7.5911e-01, -5.8601e-02],\n",
      "          [ 3.3497e-01, -5.7812e-03,  5.9306e-01,  8.9236e-01,  1.1486e-01],\n",
      "          [ 3.1135e-01, -2.2981e-01,  5.0734e-01,  7.8156e-01,  1.7985e-02],\n",
      "          [ 1.6862e-01, -9.1082e-02,  5.2005e-01,  7.8759e-01,  8.6252e-03],\n",
      "          [ 4.0923e-01,  3.7148e-03,  5.2719e-01,  1.2501e+00,  7.1740e-02],\n",
      "          [ 3.1431e-01, -2.5323e-01,  3.8955e-01,  7.7115e-01,  3.2555e-03],\n",
      "          [ 3.9402e-01, -2.1463e-01,  2.9172e-01,  8.0933e-01,  7.0296e-02],\n",
      "          [ 4.4802e-01, -1.0024e-01,  3.2009e-01,  8.4717e-01, -1.4153e-01],\n",
      "          [ 3.2049e-01, -2.8317e-01,  2.2725e-01,  5.7336e-01, -6.6930e-03],\n",
      "          [ 1.6364e-01, -2.4801e-01,  1.2544e-01,  4.4342e-01,  1.0497e-01]],\n",
      "\n",
      "         [[ 8.1757e-03, -1.5775e-01, -2.2423e-01, -1.1371e-01,  3.3018e-01],\n",
      "          [ 2.4372e-01, -1.3826e-01, -6.5849e-02, -3.9418e-02,  3.9561e-01],\n",
      "          [ 1.1508e-01, -1.8720e-01, -2.8007e-02,  8.7999e-02,  2.9385e-01],\n",
      "          [ 1.9893e-01, -2.5264e-01, -2.5062e-02,  5.5794e-02,  1.9320e-01],\n",
      "          [ 1.9583e-01, -2.7910e-02,  7.0584e-02, -4.5148e-02,  3.6664e-01],\n",
      "          [ 2.9351e-01, -9.4320e-03,  1.7537e-01, -7.0296e-02,  2.8713e-01],\n",
      "          [ 1.8278e-02, -1.3251e-01,  1.4831e-01, -4.4625e-02,  1.4060e-01],\n",
      "          [-7.7082e-02, -1.9958e-01, -9.3546e-03,  9.2779e-03,  1.6771e-01],\n",
      "          [ 1.4439e-02, -1.6403e-01, -9.1227e-03, -5.4967e-02,  2.5803e-01],\n",
      "          [-2.2098e-02, -1.1150e-01, -3.5775e-01, -2.9509e-02,  2.1293e-01],\n",
      "          [ 7.1455e-02, -2.2574e-01, -2.3326e-01, -9.6524e-02,  3.3802e-01],\n",
      "          [ 1.6476e-01, -2.7908e-01, -1.2431e-01,  6.3445e-02,  4.0522e-01],\n",
      "          [ 2.5632e-01, -1.6205e-01, -1.8751e-01, -2.7203e-02,  2.8015e-01],\n",
      "          [ 2.8865e-01, -5.7080e-03, -3.1622e-02, -1.8925e-01,  1.4632e-01],\n",
      "          [ 1.7628e-01, -6.4753e-02,  5.3393e-02,  9.8195e-03,  5.2111e-02],\n",
      "          [ 1.3879e-01, -3.6062e-02,  1.3353e-01, -2.8780e-02,  3.4232e-01]],\n",
      "\n",
      "         [[ 2.7891e-01, -1.3024e-01, -5.7368e-01, -1.5981e-01, -1.6562e-02],\n",
      "          [ 2.2077e-01, -8.3442e-02, -4.7074e-01, -1.4543e-01, -8.9879e-02],\n",
      "          [ 3.4637e-01, -6.3287e-02, -4.3622e-01, -2.3313e-02,  9.0740e-02],\n",
      "          [ 2.2861e-01, -6.4848e-02, -2.0537e-01,  7.2897e-02,  4.9830e-03],\n",
      "          [ 1.9055e-01,  7.5468e-02, -1.4651e-01, -2.0204e-02, -6.8483e-02],\n",
      "          [ 3.1795e-01,  1.0428e-03, -2.5747e-01, -8.0509e-02,  1.9085e-01],\n",
      "          [ 4.2662e-01,  3.8271e-02, -1.5067e-01, -2.0651e-02,  2.3668e-01],\n",
      "          [ 1.8670e-01, -2.0167e-01, -3.6375e-01, -1.8456e-01,  1.0755e-01],\n",
      "          [ 3.7598e-01,  1.7429e-02, -3.6836e-01, -7.5837e-02,  6.3058e-02],\n",
      "          [ 3.0774e-01,  6.6264e-02, -4.1721e-01,  8.2261e-02, -3.1413e-02],\n",
      "          [ 4.2454e-01,  6.8365e-03, -3.6701e-01, -1.9768e-02,  1.4570e-01],\n",
      "          [ 4.6260e-01,  4.7610e-02, -3.2077e-01, -7.4100e-02,  9.6306e-02],\n",
      "          [ 5.0773e-01,  2.3625e-01, -2.2746e-01,  2.3494e-01,  1.7040e-01],\n",
      "          [ 5.4549e-01,  2.2883e-03, -9.7795e-02, -3.0146e-02,  1.7711e-01],\n",
      "          [ 4.4930e-01,  1.7931e-02, -2.2413e-01,  1.0635e-01,  1.9788e-01],\n",
      "          [ 4.0345e-01,  3.5169e-02, -4.3556e-01,  9.5874e-02,  3.5567e-01]],\n",
      "\n",
      "         [[ 3.8228e-02,  5.2835e-02,  4.4938e-01,  6.3658e-01,  1.7913e-01],\n",
      "          [ 3.8732e-01,  2.5131e-01,  6.5449e-01,  8.0757e-01,  1.3912e-01],\n",
      "          [ 2.9919e-01,  1.8423e-01,  5.0431e-01,  7.7110e-01,  3.5935e-01],\n",
      "          [ 3.1813e-02, -1.5906e-02,  1.7691e-01,  4.1939e-01,  3.1115e-02],\n",
      "          [ 4.7347e-01,  3.1696e-01,  6.5925e-01,  6.9471e-01,  8.1445e-02],\n",
      "          [ 2.2273e-01, -3.0661e-03,  3.8369e-01,  4.4198e-01, -2.7506e-02],\n",
      "          [ 3.6678e-01,  2.3360e-01,  5.0487e-01,  5.9213e-01,  2.6812e-01],\n",
      "          [ 3.6115e-03, -1.5317e-01,  1.0795e-01,  5.1794e-01, -9.2001e-02],\n",
      "          [ 1.3307e-01, -1.4705e-02,  3.4329e-01,  4.3280e-01,  2.4417e-01],\n",
      "          [ 7.1322e-03, -1.7689e-01,  2.2265e-01,  5.7908e-01,  3.0813e-02],\n",
      "          [-5.0021e-03, -1.3559e-02,  3.5161e-01,  6.1256e-01,  1.2814e-01],\n",
      "          [ 2.4045e-01, -1.1180e-01,  3.8061e-01,  5.3863e-01,  2.4107e-01],\n",
      "          [ 2.0476e-01,  1.7592e-02,  3.5999e-01,  4.7366e-01,  2.7648e-01],\n",
      "          [ 2.7339e-01, -1.0470e-02,  2.8734e-01,  4.6997e-01, -6.2007e-02],\n",
      "          [ 1.1789e-01, -3.2912e-02,  2.9751e-02,  4.5192e-01, -5.7184e-02],\n",
      "          [ 2.6349e-01,  6.9929e-02,  2.5293e-01,  4.4886e-01,  2.1539e-01]]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "softmaxed_prod: \n",
      " tensor([[[[0.2711, 0.1008, 0.1864, 0.3185, 0.1232],\n",
      "          [0.1839, 0.1113, 0.2225, 0.3488, 0.1336],\n",
      "          [0.2266, 0.0975, 0.2199, 0.3250, 0.1309],\n",
      "          [0.1783, 0.1096, 0.2314, 0.3389, 0.1419],\n",
      "          [0.2050, 0.1088, 0.2150, 0.3319, 0.1394],\n",
      "          [0.1532, 0.1212, 0.2099, 0.3536, 0.1621],\n",
      "          [0.1815, 0.1141, 0.2581, 0.3096, 0.1367],\n",
      "          [0.1800, 0.1281, 0.2331, 0.3144, 0.1445],\n",
      "          [0.1944, 0.1131, 0.2365, 0.3111, 0.1450],\n",
      "          [0.1694, 0.1307, 0.2408, 0.3147, 0.1444],\n",
      "          [0.1717, 0.1145, 0.1932, 0.3981, 0.1225],\n",
      "          [0.2017, 0.1144, 0.2175, 0.3186, 0.1478],\n",
      "          [0.2134, 0.1161, 0.1927, 0.3233, 0.1544],\n",
      "          [0.2221, 0.1283, 0.1954, 0.3310, 0.1232],\n",
      "          [0.2239, 0.1224, 0.2040, 0.2883, 0.1614],\n",
      "          [0.2045, 0.1355, 0.1968, 0.2705, 0.1928]],\n",
      "\n",
      "         [[0.2039, 0.1727, 0.1616, 0.1805, 0.2813],\n",
      "          [0.2307, 0.1575, 0.1693, 0.1738, 0.2686],\n",
      "          [0.2094, 0.1548, 0.1815, 0.2038, 0.2504],\n",
      "          [0.2327, 0.1482, 0.1860, 0.2017, 0.2314],\n",
      "          [0.2149, 0.1718, 0.1896, 0.1689, 0.2549],\n",
      "          [0.2317, 0.1711, 0.2059, 0.1610, 0.2302],\n",
      "          [0.1973, 0.1697, 0.2247, 0.1853, 0.2230],\n",
      "          [0.1879, 0.1662, 0.2011, 0.2048, 0.2400],\n",
      "          [0.1991, 0.1666, 0.1945, 0.1858, 0.2540],\n",
      "          [0.2046, 0.1871, 0.1463, 0.2031, 0.2588],\n",
      "          [0.2159, 0.1604, 0.1592, 0.1825, 0.2819],\n",
      "          [0.2190, 0.1405, 0.1640, 0.1979, 0.2785],\n",
      "          [0.2453, 0.1614, 0.1574, 0.1847, 0.2512],\n",
      "          [0.2526, 0.1882, 0.1834, 0.1567, 0.2191],\n",
      "          [0.2273, 0.1786, 0.2010, 0.1924, 0.2007],\n",
      "          [0.2038, 0.1711, 0.2028, 0.1724, 0.2499]],\n",
      "\n",
      "         [[0.2874, 0.1909, 0.1225, 0.1853, 0.2139],\n",
      "          [0.2729, 0.2013, 0.1367, 0.1892, 0.2000],\n",
      "          [0.2788, 0.1851, 0.1275, 0.1927, 0.2159],\n",
      "          [0.2470, 0.1842, 0.1600, 0.2114, 0.1975],\n",
      "          [0.2388, 0.2129, 0.1705, 0.1935, 0.1843],\n",
      "          [0.2602, 0.1895, 0.1464, 0.1747, 0.2292],\n",
      "          [0.2698, 0.1830, 0.1515, 0.1725, 0.2232],\n",
      "          [0.2585, 0.1753, 0.1491, 0.1783, 0.2388],\n",
      "          [0.2824, 0.1973, 0.1341, 0.1797, 0.2065],\n",
      "          [0.2645, 0.2078, 0.1281, 0.2111, 0.1884],\n",
      "          [0.2849, 0.1876, 0.1291, 0.1827, 0.2156],\n",
      "          [0.2945, 0.1945, 0.1346, 0.1722, 0.2042],\n",
      "          [0.2691, 0.2051, 0.1290, 0.2048, 0.1920],\n",
      "          [0.2976, 0.1728, 0.1564, 0.1673, 0.2059],\n",
      "          [0.2742, 0.1781, 0.1398, 0.1946, 0.2132],\n",
      "          [0.2623, 0.1815, 0.1133, 0.1928, 0.2500]],\n",
      "\n",
      "         [[0.1540, 0.1563, 0.2323, 0.2801, 0.1773],\n",
      "          [0.1824, 0.1592, 0.2383, 0.2777, 0.1423],\n",
      "          [0.1729, 0.1541, 0.2122, 0.2771, 0.1836],\n",
      "          [0.1791, 0.1708, 0.2071, 0.2639, 0.1790],\n",
      "          [0.2007, 0.1716, 0.2417, 0.2504, 0.1356],\n",
      "          [0.2001, 0.1597, 0.2351, 0.2492, 0.1558],\n",
      "          [0.1930, 0.1689, 0.2215, 0.2417, 0.1748],\n",
      "          [0.1803, 0.1541, 0.2001, 0.3016, 0.1639],\n",
      "          [0.1797, 0.1550, 0.2218, 0.2426, 0.2009],\n",
      "          [0.1704, 0.1418, 0.2114, 0.3019, 0.1745],\n",
      "          [0.1558, 0.1545, 0.2226, 0.2890, 0.1780],\n",
      "          [0.1922, 0.1352, 0.2212, 0.2590, 0.1924],\n",
      "          [0.1859, 0.1541, 0.2171, 0.2432, 0.1997],\n",
      "          [0.2128, 0.1602, 0.2158, 0.2590, 0.1522],\n",
      "          [0.1995, 0.1716, 0.1827, 0.2787, 0.1675],\n",
      "          [0.2012, 0.1658, 0.1991, 0.2422, 0.1917]]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "[34, 34, 34, 34, 34]\n",
      "predicted sentence: \n",
      " CCCCC\n"
     ]
    }
   ],
   "source": [
    "# Predicting next words\n",
    "sent = \"This is a simple sentence\"\n",
    "encoded_sent = encoding.encode(sent)\n",
    "enc_x = torch.tensor(encoded_sent).unsqueeze(0)\n",
    "dec_x = torch.tensor(encoding.encode(\"C\")).unsqueeze(0)\n",
    "\n",
    "transformer = Transformer(vocab_size=encoding.n_vocab, n=3, d=256, h=4)\n",
    "\n",
    "predicted_tokens = []\n",
    "for _ in range(5):\n",
    "    output = transformer(enc_x=enc_x, dec_x=dec_x)\n",
    "    softmaxed = F.softmax(output, dim=-1)\n",
    "    predicted = softmaxed.argmax(dim=-1)\n",
    "    predicted_tokens.append(predicted.tolist()[-1][-1]) \n",
    "    dec_x = torch.cat((dec_x, predicted), dim=-1)\n",
    "\n",
    "print(predicted_tokens)\n",
    "print(f\"predicted sentence: \\n {encoding.decode(predicted_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a4533-0646-49c1-a22f-04f055be1cba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5588cc54-99dc-481d-8a78-d7d9e8adfd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hi.', 'START Salut!<|endoftext|>')\n",
      "('Stop!', 'START Arrte-toi !<|endoftext|>')\n",
      "('Hi.', 'START Salut!<|endoftext|>')\n",
      "('Run!', 'START Cours\\u202f!<|endoftext|>')\n",
      "('Run!', 'START Courez\\u202f!<|endoftext|>')\n",
      "('Hi.', 'START Salut!<|endoftext|>')\n",
      "('Run!', 'START Cours\\u202f!<|endoftext|>')\n",
      "('Run!', 'START Courez\\u202f!<|endoftext|>')\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "\n",
    "class Partition(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\"\n",
    "\n",
    "class Tokens(Enum):\n",
    "    START = \"START \"\n",
    "    END = \"<|endoftext|>\"\n",
    "    PAD = \" PAD\"\n",
    "    START_NUM = 23380\n",
    "    END_NUM = 100257\n",
    "    PAD_NUM = 62854\n",
    "    \n",
    "\n",
    "class EnFrDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file: Path | str, partition: Partition = Partition.TRAIN, val_ratio: float = 0.1):\n",
    "        # partition = TRAIN | VAL\n",
    "        self._partition = partition\n",
    "        self._val_ratio = val_ratio\n",
    "\n",
    "        self._data = []\n",
    "        self._train_map: dict[int, int] = {}\n",
    "        self._val_map: dict[int, int] = {}\n",
    "        train_id = 0\n",
    "        val_id = 0\n",
    "        with open(file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile)\n",
    "            # we want data indexes start from 0, but filter out the first header row\n",
    "            for i, row in enumerate(reader, start=-1):\n",
    "                if i == -1:\n",
    "                    continue\n",
    "                en = row[0]\n",
    "                fr = Tokens.START.value + row[1] + Tokens.END.value\n",
    "                self._data.append(tuple([en, fr]))\n",
    "                if int(i * val_ratio) == int((i - 1) * val_ratio):\n",
    "                    self._train_map[train_id] = i\n",
    "                    train_id += 1\n",
    "                else:\n",
    "                    self._val_map[val_id] = i\n",
    "                    val_id += 1\n",
    "\n",
    "    class Iterator():\n",
    "\n",
    "        def __init__(self, outer):\n",
    "            self.cur = 0\n",
    "            self.outer = outer\n",
    "\n",
    "        def __next__(self):\n",
    "            if self.cur == len(self.outer._data):\n",
    "                raise StopIteration()\n",
    "            cur = self.outer._data[self.cur]\n",
    "            self.cur += 1\n",
    "            return cur\n",
    "\n",
    "    def __iter__(self):\n",
    "        return EnFrDataset.Iterator(self)\n",
    "    \n",
    "    @property\n",
    "    def partition(self):\n",
    "        return self._partition\n",
    "\n",
    "    @partition.setter\n",
    "    def partition(self, partition):\n",
    "        self._partition = partition\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._train_map) if self._partition == Partition.TRAIN else len(self._val_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._data[self._train_map[idx]] if self._partition == Partition.TRAIN else self._data[self._val_map[idx]]\n",
    "\n",
    "dataset = EnFrDataset(\"../data/eng_-french.csv\")\n",
    "train_sample = dataset[0]\n",
    "dataset.partition = Partition.VAL\n",
    "val_sample = dataset[0]\n",
    "assert train_sample != val_sample\n",
    "print(train_sample)\n",
    "print(val_sample)\n",
    "\n",
    "for i, d in enumerate(dataset):\n",
    "    if i > 2:\n",
    "        break\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09eb729-53bb-420b-a608-73b1365e6dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ef7bbe-c8a8-493e-8677-49d9c02dbd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def build_train_sample(en_str: str, dec_str: str):\n",
    "    en_encoded = encoding.encode(en_str)\n",
    "    dec_encoded = encoding.encode(dec_str)\n",
    "    en_sents = []\n",
    "    dec_sents = []\n",
    "    target_sents = []\n",
    "    for \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3fbfee8d-38b9-4abb-b127-5e620ea387f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('They are five in all.', 'You have to live with it.'), ('Elles sont cinq en tout.', 'Il vous faut vivre avec.')]\n",
      "[(\"It's fairly warm today.\", 'We never speak French at home.'), (\"Il fait assez chaud, aujourd'hui.\", 'Nous ne parlons jamais franais chez nous.')]\n",
      "[(\"This rope is strong, isn't it?\", \"Tom and I don't usually agree.\"), (\"Cette corde est rsistante, n'est-ce pas\\u202f?\", \"Tom et moi ne sommes habituellement pas d'accord.\")]\n",
      "[('I noticed a change.', 'It was too difficult for me.'), (\"J'ai remarqu un changement.\", \"C'tait trop difficile pour moi.\")]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# def collate_fn\n",
    "\n",
    "dataset.partition = Partition.TRAIN\n",
    "training_generator = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "for i, s in enumerate(training_generator):\n",
    "    print(s)\n",
    "    if i > 2:\n",
    "        break\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d5995-4736-4fec-9e51-e3672a9dc765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc62b3c0-a20a-466d-b5fe-05b33071e963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c0dbc9-7e82-48b4-9b90-0ddf28b10784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21175a-9751-4413-8cdb-579c52134778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207745b-3455-48f2-a6c1-d6546569344a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fbfc3e-aca8-4edb-99e5-025c945d85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da787162-9955-4de5-a82d-60501d62ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Partition(Enum):\n",
    "    TRAIN = \"train\"\n",
    "    VAL = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08f9da-be37-4a19-992e-11b2c6e1ce7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a2346-9e74-4eab-aab3-bd5bb0a0d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.3]]), dim=-1)\n",
    "torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.4]]).argmax(dim=-1)\n",
    "# torch.max(torch.tensor([[0.1,0.2,0.3],[0.1, 0.2, 0.4]]), dim=-1)\n",
    "\n",
    "t1 = torch.tensor([[0.1, 0.2]])\n",
    "t2 = torch.tensor([[0.3]])\n",
    "torch.cat((t1, t2), dim=1).tolist()[-1][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "683599c0-fd00-40b0-8bb1-4e477a2114a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45e55c-6d60-409b-b26e-0b218224483a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e70b0-a647-455b-bdfb-332d095aafc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082af878-9425-4445-b4b4-592cef79a2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dba170-623a-486b-8b67-58360bde104f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4d1a8-69aa-4c60-b3b4-ebb2e31f1c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda8a40-c41b-4eb3-90af-446f97e501f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f4736-acd3-4bd9-a9f5-b00240a17b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([1, 2, 3])\n",
    "mask = torch.ones([1, 2])\n",
    "mask[0, 1] = 0\n",
    "mask = mask.unsqueeze(1)\n",
    "print(mask == 0)\n",
    "x.masked_fill(mask == 0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4ff31-01d1-4144-b1ad-b2b600609d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bb090-365d-4c4d-986d-b048e7345f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
