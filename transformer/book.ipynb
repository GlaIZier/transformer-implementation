{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d29dfa4-a1e1-4dd2-b2c5-e3ed8653fbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def self_attention(q, k, v):\n",
    "    # if 3 dim: b t d\n",
    "    #prod = Q.bmm(K.permute(0, 2, 1))\n",
    "    # or\n",
    "    # prod = torch.einsum(\"btd, bsd -> bts\", q, k)\n",
    "    # if 4 dim: b h t dh\n",
    "    prod = torch.einsum(\"bhtd, bhsd -> bhts\", q, k)\n",
    "    scaled_prod = prod/torch.sqrt(torch.tensor(q.shape[-1]))\n",
    "    softmaxed_prod = F.softmax(scaled_prod, dim=-1)\n",
    "    # print(softmaxed_prod.shape)\n",
    "    # print(softmaxed_prod)\n",
    "    return softmaxed_prod @ v\n",
    "\n",
    "\n",
    "x = torch.rand([2, 3, 4, 5])\n",
    "self_attention(x, x, x)\n",
    "self_attention(x, x, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fae60133-3d0c-4ada-8789-51107800432a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        assert d % h == 0\n",
    "        self.d = d\n",
    "        self.dh = d // h\n",
    "        self.h = h\n",
    "        self.wq = nn.Linear(self.d, self.d)\n",
    "        self.wk = nn.Linear(self.d, self.d)\n",
    "        self.wv = nn.Linear(self.d, self.d)\n",
    "        self.wo = nn.Linear(self.d, self.d)\n",
    " \n",
    "    def forward(self, q, k, v):\n",
    "        # b, t, d\n",
    "        b, t, d = q.size()\n",
    "        wq = self.wq(q)\n",
    "        wk = self.wk(k)\n",
    "        wv = self.wv(v)\n",
    "        wq = wq.view(b, t, self.h, self.dh)\n",
    "        wk = wk.view(b, t, self.h, self.dh)\n",
    "        wv = wv.view(b, t, self.h, self.dh)\n",
    "        # b, t, h, dh\n",
    "        # if changing from 4 dim -> 3 dim: b*h, t, dh\n",
    "        # wq = wq.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wk = wk.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # wv = wv.permute(0, 2, 1, 3).reshape(b * self.h, t, self.dh)\n",
    "        # another option 4 dim -> 3 dim\n",
    "        # wq = wq.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wk = wk.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # wv = wv.transpose(1, 2).contiguous().view(b * self.h, t, self.dh)\n",
    "        # changing the number of dims is not necessary as @ supports 4 dims\n",
    "        attn = self_attention(wq, wk, wv)\n",
    "        # b * h, t, dh\n",
    "        # attn = attn.view(b, self.h, t, self.dh).permute(0, 2, 1, 3).reshape(b, t, d)\n",
    "        attn = attn.view(b, self.h, t, self.dh).transpose(1, 2).contiguous().view(b, t, d)\n",
    "        wo = self.wo(attn)\n",
    "        return wo\n",
    "        # # 1 2 3 4\n",
    "        # x = F.relu(self.conv1(x))\n",
    "        # return F.relu(self.conv2(x))\n",
    "\n",
    "mhsa = MHSA()\n",
    "x = torch.rand(2, 3, 512)\n",
    "mhsa(x, x, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d0cd6d-12f4-44f0-b8b9-62a18a6d2f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderLayer(nn.Module): \n",
    "\n",
    "    def __init__(self, d: int = 512, h: int = 8, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mhsa = MHSA(d, h)\n",
    "        self.norm1 = nn.LayerNorm(d)\n",
    "        self.ff1 = nn.Linear(d, d * 4)\n",
    "        self.ff2 = nn.Linear(d * 4, d)\n",
    "        self.norm2 = nn.LayerNorm(d)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = x + self.dropout(self.mhsa(x, x, x))\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.dropout(self.ff2(F.relu(self.ff1(x))))\n",
    "        x = self.norm2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "encoder_layer = EncoderLayer()\n",
    "x = torch.rand(2, 3, 512)\n",
    "encoder_layer(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e48412b-a00c-45e5-829f-441a7df2318e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module): \n",
    "\n",
    "    def __init__(self, n: int = 6, d: int = 512, h: int = 8):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(10000, d)\n",
    "        self.layers = [EncoderLayer(d, h) for _ in range(n)]\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.size()\n",
    "        x = self.embed(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "encoder = Encoder()\n",
    "x = torch.rand(2, 3, 512)\n",
    "encoder(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89a581bb-0afc-4b25-bd8e-f970e607146a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5, 0, 7, 5],\n",
       "         [1, 1, 5, 5],\n",
       "         [9, 5, 5, 3]],\n",
       "\n",
       "        [[0, 3, 6, 2],\n",
       "         [4, 7, 6, 3],\n",
       "         [8, 4, 6, 0]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0 , 10, [2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeadb5ba-e1cd-49c6-a69f-113232f40947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.8490,  0.4501, -1.4563],\n",
       "          [-0.9596, -1.2613,  1.6425],\n",
       "          [-0.3422, -0.1801,  1.0419],\n",
       "          [-0.6716, -0.1358, -0.2875]],\n",
       "\n",
       "         [[-0.2980,  0.9643,  1.0251],\n",
       "          [-0.9596, -1.2613,  1.6425],\n",
       "          [-0.2980,  0.9643,  1.0251],\n",
       "          [-1.5537,  0.9632, -0.6325]],\n",
       "\n",
       "         [[-1.5537,  0.9632, -0.6325],\n",
       "          [-0.2980,  0.9643,  1.0251],\n",
       "          [-1.5537,  0.9632, -0.6325],\n",
       "          [-0.2941,  0.9305,  0.4273]]],\n",
       "\n",
       "\n",
       "        [[[-1.5537,  0.9632, -0.6325],\n",
       "          [-0.9596, -1.2613,  1.6425],\n",
       "          [-0.2980,  0.9643,  1.0251],\n",
       "          [-0.3422, -0.1801,  1.0419]],\n",
       "\n",
       "         [[-0.8490,  0.4501, -1.4563],\n",
       "          [-0.3422, -0.1801,  1.0419],\n",
       "          [-0.2980,  0.9643,  1.0251],\n",
       "          [ 2.7038,  0.0230, -1.3034]],\n",
       "\n",
       "         [[ 2.7038,  0.0230, -1.3034],\n",
       "          [-0.2941,  0.9305,  0.4273],\n",
       "          [-1.5537,  0.9632, -0.6325],\n",
       "          [-0.9596, -1.2613,  1.6425]]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = nn.Embedding(10, 3)\n",
    "e(torch.randint(0 , 10, [2, 3, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de158ce9-9dda-4405-9542-85a4254691cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9dfe4e-8ed9-4ac5-a9ef-6554f8221af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5]],\n",
       "\n",
       "        [[ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(12)\n",
    "a = a.view(2,3,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24727adf-6ce8-4c46-bb12-1bfacb8deffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  2,  4],\n",
       "         [ 6,  8, 10]],\n",
       "\n",
       "        [[ 1,  3,  5],\n",
       "         [ 7,  9, 11]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d7cf8d-11de-42a9-9864-9d81fcd3c254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(2, 3, 4, 5)\n",
    "b = torch.rand(2, 3, 5, 6)\n",
    "(a @ b).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890a0ea-110f-49ab-9e91-1845cb7f5ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
